<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<link rel="preload" as="style" href="The%20Library%20%E2%80%94%20LessWrong_files/allStyles.css"><link rel="stylesheet" type="text/css" href="The%20Library%20%E2%80%94%20LessWrong_files/icon.css"><link rel="stylesheet" type="text/css" href="The%20Library%20%E2%80%94%20LessWrong_files/reset-min.css"><link rel="stylesheet" type="text/css" href="The%20Library%20%E2%80%94%20LessWrong_files/css.css"><link rel="stylesheet" type="text/css" href="The%20Library%20%E2%80%94%20LessWrong_files/jvr1gjm.css"><link rel="stylesheet" type="text/css" href="The%20Library%20%E2%80%94%20LessWrong_files/tqv5rhd.css"><script type="text/javascript" async="" charset="utf-8" src="The%20Library%20%E2%80%94%20LessWrong_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-C0eb2CrhokW3SgZMDSrT/ioPvOCBoj1s7JouJ8IrLFB+j5cW9qY3JDWtShxtCryz"></script><script async="" src="The%20Library%20%E2%80%94%20LessWrong_files/google-analytics_analytics.js"></script><script>window.publicInstanceSettings = {"forumType":"LessWrong","title":"LessWrong","siteNameWithArticle":"LessWrong","sentry":{"url":"https://1ab1949fc8d04608b43132f37bb2a1b0@sentry.io/1301611","environment":"production","release":"69f0f3c5d57b596e8249571383f8a280eff9bb23"},"debug":false,"aboutPostId":"bJ2haLkcGeLtTWaD5","faqPostId":"2rWKkWuPrgTMpLRbp","contactPostId":"ehcYkvyz7dh9L7Wt8","expectedDatabaseId":"production","tagline":"A community blog devoted to refining the art of rationality","faviconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","faviconWithBadge":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_with_badge.ico","forumSettings":{"headerTitle":"LESSWRONG","shortForumTitle":"LW","tabTitle":"LessWrong"},"analytics":{"environment":"lesswrong.com"},"cluster":{"enabled":true,"numWorkers":2},"testServer":false,"fmCrosspost":{"siteName":"the EA Forum","baseUrl":"https://forum.effectivealtruism.org/"},"allowTypeIIIPlayer":true,"hasRejectedContentSection":true,"hasCuratedPosts":true,"performanceMetricLogging":{"enabled":true,"batchSize":100},"reviewBotId":"tBchiz3RM7rPwujrJ","recombee":{"databaseId":"lightcone-infrastructure-lesswrong-prod-2","publicApiToken":"sb95OJbQ7mKLQAm1abPog2m5vCPj7XqZlVYdHGyANcjzqaHT5fX6HEgB0vCfiLav"},"homepagePosts":{"feeds":[{"name":"forum-classic","label":"Latest","description":"The classic LessWrong frontpage algorithm that combines karma with time discounting, plus any tag-based weighting if applied.","showToLoggedOut":true},{"name":"recombee-hybrid","label":"Enriched","description":"An equal mix of Latest and Recommended.","showSparkleIcon":true,"defaultTab":true,"showToLoggedOut":true},{"name":"recombee-lesswrong-custom","label":"Recommended","description":"Personalized recommendations from the history of LessWrong, using a machine learning model that takes into account posts you've read and/or voted on.","showSparkleIcon":true,"showToLoggedOut":true},{"name":"forum-subscribed-authors","label":"Subscribed","description":"Posts and comments by people you've explicitly subscribed to.","isInfiniteScroll":true},{"name":"vertex-default","label":"Vertex","description":"Experimental feed for Google Vertex recommendations.","showLabsIcon":true,"adminOnly":true},{"name":"forum-bookmarks","label":"Bookmarks","description":"A list of posts you saved because you wanted to have them findable later."},{"name":"forum-continue-reading","label":"Resume Reading","description":"Further posts in post sequences that you started reading.","disabled":true}]}}</script><link rel="shortcut icon" href="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico"><script>window.publicSettings = {"forum":{"numberOfDays":10,"postInterval":30,"numberOfWeeks":4,"numberOfYears":4,"maxPostsPerDay":5,"numberOfMonths":4},"type3":{"cutoffDate":"2023-07-01","explicitlyAllowedPostIds":["SvKSwT6xYfYahH4XN","2weRdcvqANDq3zdPH","Zm7WAJMTaFvuh2Wc7","HcjL8ydHxPezj6wrt","pgGiqLQg2KWsaz5RE","jFzovY2CERF5bd2EW","sm6npdgZArSn4afeZ","CfX6pGepdjQYELSpK","NyFuuKQ8uCEDtd2du","LCjtqsQWapoSfDHqK","MxyRNd6qJsYAcXKuw","reG3g4wwzwJcKnFfh","zfeWGvTrS6wKQeeoF","oHsMeXehPy4jHcmwy","ofL22R6KZsfrvdmwg","655TmdcwAgryPGPWS","hhrv8aAcmkzJxvP58","iqQJiKcephtMgzJgN","mnpkM57R6ZbjnwrYw","6mRv7Cr57AJAtRFHv","ak9wY2t9K3K4GxCXv","Ay6GBGNcCgP55dRQ7","aH4mjhgqNPyYvJT85","JpoLCHytYiCm7fwNA","efMgZujzfjP9B9H4R","BjLxPLsev54LFCS3A","HTGCGASf9xfB6edAh","H6LnGwjKiGvDyR5yo","qL8Z9TBCNWQyN6yLq","F4xwRTrFQyazHufjD","LY7Nca846X8kcT8Jk","K9aLcuxAPyf5jGyFX","2AuvBPw6Rb7yxkvKc","muhtBvbh4etjkKXd9","ALEYMFAuFSCz8v5YE","CJxSgaqG6y7z6Rbij","k5TpDCEHeK4qwnJt8","4Y2J7NtuweW2B8JvB","BpYDqQNZ2NZNCqPp6","oMiogKLkK8L59WzDe","TyQSMmoJpRG3HBv5S","8KHR3tfa4SJjMSkXd","g4pi2jfQHFF6mPdjw","znEhB9hJtwXica5s3","Sd2r7H8bCmd9ChGbX","P2nYKqwmHdYKARTG8","FW3DEYbKPZJh5A8Bj","K3hFLRn7MvYacL466","ouSpHCCPgsXkwxAGb","w9SuQtRJLbDpeir6L","yPQGYn9rSme9RRpiQ","BD6WYC4GT6dnWaJRN","c8khnHoRTSGjmHLLf","TaPr4YSBbiakeKdwX","pyNPXST7feDX45ygt","ERPL3v2Y976W7XG3j","XpXQ4KNzLa9ZHYw8p","PBhrHw5X8sDmHDWkX","8KhThQXzsAEZ59iko","iYJo382hY28K7eCrP","KrEwDMN4YXp5YWD45","rNJ39yQmzTnseh8nL","hMQPyLDbg3bA7P6aN","3Jqz6JE8K6vyQ9hJ5","SQAfPKZBAAKYMjx25","Y345zuBetHqGnotwm","pZerSnxv6FPqvgoYu","3bPH2az479gzxDMbf","QXShCBvPydkwafekn","iLMkKDKmfbMkDuQBm","iNCg6mjw584r9BWZK","9oqF382ASmjaGBo7z","DdNB42JgBzbbvmAum","JP7eZYHB7aY6fA4TR","snwX7hXgLFikqDBr6","CsKrQdQJJCFPjfKjF","vhxywjnBH6ioRnnt3","A4MK9RQqSAJZjanQD","PCpzG9NJeviXM5YSq","KCcdhZK7omEMwBdju","kdmCm5NQTpqhJmGm6","2p8BWvcJvKkXGMsch","FLnDFnXyWrKr6eiT6","2gWs8SScqeDFidqyv","2HafkDSNdtMzptzcN","cTQRGJTQ2eGKm5G9g","qaHHJ3kkCQS4nsoGJ","gS8Jmcfoa9FAh92YK","eRhFaibbTeGbjdaaf","xij43oLTBRnEQv2bT","BZMc9Xzqw5WcCMHrr","2jZykdLg9fBGqKd46","gBChm3THPGFcrq5eH","9HSwh2mE3tX6xvZ2W","tEHJXNhw6t87foqJL","T5McDuWDeCvDZKeSj","PeTL97v92LxRJBsrM","Cq45AuedYnzekp3LX","pfmZ5cYQCahABGZzi","3wBj8BPquskZAbXu9","xPJKZyPCvap4Fven8","BPKvZuLRyiJBjfNbg","um7w5RogAHhxGy8Ti","CcyGR3pp3FCDuW6Pf","BfaAADSQ88cuxLQoD","ckuuDa8DmJ4pdFeD8","pczHfyxmnFhtKthqR","dymK5c7BkpgXH4acw","B4AyJXYPpGbBmxQzd","xNBRkPNHAGQ6EQaLS","88TN6y9M5xxAHHNwW","Lt8Rn4rkYwqiTXGPy","QdXrkWoK2Pp6XhNuQ","NjzBrtvDS4jXi5Krp","ZWC3n9c6v4s35rrZ3","Fy2b55mLtghd4fQpx","eaczwARbFnrisFx8E","KLjQedNYNEP4tW73W","DSnamjnW7Ad8vEEKd","7iDtkfyn322nPzTP4","eaSJtg8Kvc56bFBdt","AmaWMMWPzuQ62Ernf","jkf2YjuH8Z2E7hKBA","BroeiXGh9PrKZEkJ5","9Tw5RqnEzqEtaoEkq","EMJ3egz48BtZS8Pws","MkKcnPdTZ3pQ9F5yC","kjArXFinD3deRZNRu","Q8zqoBWBBHD2RjDuS","ePA4NDzZkunz98tLx","4xKeNKFXFB458f5N8","irbREZtZzPi7WEYex","QxZs5Za4qXBegXCgu","ZmQv4DFx6y4jFbhLy","M7rwT264CSYY6EdR3","z3cTkXbA7jgwGWPcv","9thqSN8HDLM3LTxK5","MtNnFg4uN32YPoKNa","Ep2Z42hYqj68QZz6w","ibk7q8msSYxZXmfCf","EgDpZS4HHeh5vqJPe","5dhWhjfxn4tPfFQdi","Wh8HAK6LR5CAoPCCC","Yy7mgec8tsbTAuTqb","azoP7WeKYYfgCozoh","Zh9AiXNjQaYXjmNaC","bJiyYJeCyh4HcKHub","aPrCzeFfbBmRsvzby","vXCK3kptLLggEfojX","M2LWXsJxKS626QNEA","LQp9cZPzJncFKh5c8","CZnBQtvDw33rmWpBD","miHttwTgajY2sjY3L","K2JBqDeETX2yEgyyZ","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","mja6jZ6k9gAwki9Nu","qjSHfbjmSyMnGR9DS","Sx26Aj3xuMzmnKE4A","P3uavjFmZD5RopJKk","pJJdcZgB6mPNWoSWr","oGezscrQvPDgGvrbt","AYbhqi65SWzHzy7Xx","E4cKD9iTWHaE7f3AJ","x9FNKTEt68Rz6wQ6P","HAEPbGaMygJq8L59k","znBJwbuT3f5eWgM4E","yJfBzcDL9fBHJfZ6P","YAkpzvjC768Jm2TYb","LTtNXM9shNM9AC2mp","9hR2RmpJmxT8dyPo4","WQWhXzALcrzrJtqRh","p7WXmG6Fbo3eaSwm3","KheBaeW8Pi7LwewoF","A2Qam9Bd9xpbb2wLQ","asmZvCPHcB4SkSCMW","euJm4RwkAptZnP89i","r8stxYL29NF9w53am","6yTShbTdtATxKonY5","yDRX2fdkm3HqfTpav","EhEZoTFzys9EDmEXn","YSWa8rYeD3aDaofSP","rwkkcgSpnAyE8oNo3","HmfxSWnqnK265GEFM","Ltey8BS83qSkd9M3u","atcJqdhCxTZiJSxo2","pC47ZTsPNAkjavkXs","wJnm5cBiZGmKn595f","GrtbTAPfkJa4D6jjH","LgavAYtzFQZKg95WC","reitXJgJXFzKpdKyd","ZiQqsgGX6a42Sfpii","neQ7eXuaXpiYw7SBy","hQHuXuRGZxxWXaPgg","9kcTNWopvXFncXgPy","baTWMegR42PAsH9qJ","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","R6M4vmShiowDn56of","6Fpvch8RR29qLEWNH","N6WM6hs7RQMKDhYjB","pdaGN6pQyQarFHXF4","SA9hDewwsYgnuscae","i9xyZBS3qzA8nFXNQ","bx3gkHJehRCYZAF3r","Jk9yMXpBLMWNTFLzh","JvZhhzycHu2Yd57RN","vzfz4AS6wbooaTeQk","gHefoxiznGfsbiAu9","sbcmACvB6DqYXYidL","kipMvuaK3NALvFHc9","xdwbX9pFEr7Pomaxv","XvN2QQpKTuEzgkZHY","uFNgRumrDTpBfQGrs","ii4xtogen7AyYmN6B","kpPnReyBC54KESiSn","FRv7ryoqtvSuqBxuT","u8GMcpEN9Z6aQiCvp","B2CfMNfay2P8f2yyc","JD7fwtRQ27yc8NoqS","mRwJce3npmzbKfxws","3rxMBRCYEmHCNDLhu","FWvzwCDRgcjb9sigb","KrJfoZzpSDpnrv9va","LpM3EAakwYdS6aRKf","Cf2xxC3Yx9g6w7yXN","qHCDysDnvhteW7kRd","mELQFMi9egPn5EAjK","qDmnyEMtJkE9Wrpau","4ZvJab25tDebB8FGE","4QemtxDFaGXyGSrGD","Psr9tnQFuEXiuqGcR","qmXqHKpgRfg83Nif9","ximou2kyQorm6MPjX","eccTPEonRe4BAvNpD","2cYebKxNp47PapHTL","pv7Qpu8WSge8NRbpB","PqMT9zGrNsGJNfiFR","B9kP6x5rpmuCzpfWb","zB4f7QqKhBHa5b37a","qc7P2NwfxQMC3hdgm","RcifQCKkRc9XTjxC2","YABJKJ3v97k9sbxwg","bNXdnRTpSXk9p4zmi","fRsjBseRuvRhMPPE5","MzKKi7niyEqkBPnyu","NQgWL7tvAPgN2LTLn","cujpciCqNbawBihhQ","wEebEiPpEwjYvnyqq","AqbWna2S85pFTsHH4","Nwgdq6kHke5LY692J","8xLtE3BwgegJ7WBbf","SWxnP5LZeJzuT3ccd","Tr7tAyt5zZpdTwTQK","ax695frGJEzGxFBK4","FkgsxrGf3QxhfLWHG","vJ7ggyjuP4u2yHNcP","X5RyaEDHNq5qutSHK","xhD6SHAAE9ghKZ9HS","AyNHoTWWAJ5eb99ji","F5ktR95qqpmGXXmLq","znfkdCoHMANwqc2WE","jbE85wCkRr9z7tqmD","4K5pJnKBGkqqTbyxx","yeADMcScw8EW9yxpH","9QxnfMYccz9QRgZ5z","X2i9dQQK3gETCyqh2","4XRjPocTprL4L8tmB","D6trAzh6DApKPhbv4","BcYfsi7vmhDvzQGiF","i42Dfoh4HtsCAfXxL","zp5AEENssb8ZDnoZR","KwdcMts8P8hacqwrX","RQpNHSiWaXTvDxt6R","nSjavaKcBrtNktzGa","hNqte2p48nqKux3wS","7im8at9PmhbT4JHsW","SwcyMEgLyd4C3Dern","AHhCrJ2KpTjsCSwbt","rz73eva3jv267Hy7B","E4zGWYzh6ZiG85b2z","hvGoYXi2kgnS3vxqb","D4hHASaZuLCW92gMy","v7c47vjta3mavY3QC","G5TwJ9BGxcgh5DsmQ","YRgMCXMbkKBZgMz4M","ham9i5wf4JCexXnkN","a4jRN9nbD79PAhWTB","xJyY5QkQvNJpZLJRo","ivpKSjM4D6FbqF4pZ","p7x32SEt43ZMC9r7r","f886riNJcArmpFahm","xhE4TriBSPywGuhqi","ThvvCE2HsLohJYd7b","diruo47z32eprenTg","JJFphYfMsdFMuprBy","ZDZmopKquzHYPRNxq","KkwtLtroaNToWs2H6","vKErZy7TFhjxtyBuG","3L46WGauGpr7nYubu","CSZnj2YNMKGfsMbZA","G2Lne2Fi7Qra5Lbuf","x6hpkYyzMG6Bf8T3W","aFaKhG86tTrKvtAnT","PrCmeuBPC4XLDQz8C","dYspinGtiba5oDCcv","9cbEPEuCa9E7uHMXT","N5Jm6Nj4HkNKySA5Z","asmZvCPHcB4SkSCMW","duxy4Hby5qMsv42i8","Djs38EWYZG8o7JMWY","A8iGaZ3uHNNGgJeaD","XYYyzgyuRH5rFN64K","2jfiMgKkh7qw9z8Do","JPan54R525D68NoEt","o4cgvYmNZnfS4xhxL","CeZXDmp8Z363XaM6b","DQKgYhEYP86PLW7tZ","niQ3heWwF6SydhS7R","gvK5QWRLk3H8iqcNy","fnkbdwckdfHS2H22Q","YicoiQurNBxSp7a65","JBFHzfPkXHB2XfDGj","tj8QP2EFdP8p54z6i","9fB4gvoooNYa4t56S","zTfSXQracE7TW8x4w","YcdArE79SDxwWAuyF","8xRSjC76HasLnMGSf","CvKnhXTu9BPcdKE4W","DtcbfwSrcewFubjxp","NxF5G6CJiof6cemTw","4ZwGqkMTyAvANYEDw","EF5M6CmKRd6qZk27Z","cCMihiwtZx7kdcKgt","Qz6w4GYZpgeDp6ATB","TPjbTXntR54XSZ3F2","x3fNwSe5aWZb5yXEG","bnY3L48TtDrKTzGRb","ZFtesgbY9XwtqqyZ5","S7csET9CgBtpi7sCh","tTWL6rkfEuQN9ivxj","L6Ktf952cwdMJnzWm","P6fSj3t4oApQQTB7E","4s2gbwMHSdh2SByyZ","sTwW3QLptTQKuyRXx","EYd63hYSzadcNnZTD","tF8z9HBoBn783Cirz","hyShz2ABiKX56j5tJ","YN6daWakNnkXEeznB","6DuJxY8X45Sco4bS2","TMFNQoRZxM4CuRCY6","q3JY4iRzjq56FyjGF","diutNaWF669WgEt3v","5okDRahtDewnWfFmz","r3NHPD3dLFNk9QE2Y","ALkH4o53ofm862vxc","N9oKuQKuf7yvCCtfq","WjsyEBHgSstgfXTvm","2G8j8D5auZKKAjSfY","rBkZvbGDQZhEymReM","nNqXfnjiezYukiMJi","36Dhz325MZNq3Cs6B","f2GF3q6fgyx8TqZcn","byewoxJiAfwE6zpep","nEBbw2Bc2CnN2RMxy","w4aeAFzSAguvqA5qu","xFotXGEotcKouifky","rzqACeBGycZtqCfaX","DoPo4PDjgSySquHX8","o3RLHYviTE4zMb9T9","5gfqG3Xcopscta3st","GNhMPAWcfBCASy8e6","uXH4r6MmKPedk8rMA","Gg9a4y8reWKtLe3Tn","bBdfbWfWxHN9Chjcq","sT6NxFxso6Z9xjS7o","k9dsbn8LZ6tTesDS3","exa5kmvopeRyfJgCy","YTJp5WBcktBimdxBG","X79Rc5cA5mSWBexnd","SvKpaPbZ2tibeDpgh","rQKstXH8ZMAdN5iqD","vQKbgEKjGZcpbCqDs","Z9cbwuevS9cqaR96h","pHHaNkG8xDcaq5DJF","sjRG35aq5fosJ6mdG","pPWiLGsWCtN92vLwu","D5BP9CxKHkcjA7gLv","57sq9qA3wurjres4K","t2LGSDwT7zSnAGybG","7Pq9KwZhG6vejmYpo","g3PwPgcdcWiP33pYn","zcriHTKgKNehSSdyG","kvLPC5YWgSujcHSkY","HnC29723hm6kJT7KP","CRiJuJxgArjBMJLvK","dyJfGeWo5GX2u6NGi","QLmSFeFexgTLsNeeA","kmT47aLQmqzcw329Y","givHhuPu6G43g8kWN","83DimRqppcaoyYAsy","vvzfFcbmKgEsDBRHh","FfNEt8mpi6qanNmXg","MrAfiomDNWCzxjei5","73kwTFKgi4AagxFHJ","iBBK4j6RWC7znEiDv","W8vSrHAM9qoWdzFoP","Rx9GLepCxctXDqCPc","4X9JLr2SpB6v68twG","yxTP9FckrwoMjxPc4","FuZ7MoR3dJEJuoRbN","xRyLxfytmLFZ6qz5s","mwGAyWmsSqzMz4WMd","xxC3Ka7axphW8kJ9E","KT8Mf3ey6uwQAkWek","GDT6tKH5ajphXHGny","ZXaRHHLsxaTTQQsZb","CHdsSaQGAvtkXBzmJ","HAEPbGaMygJq8L59k","SmDziGM9hBjW9DKmf","8NKu9WES7KeKRWEKK","NfdHG6oHBJ8Qxc26s","LTtNXM9shNM9AC2mp","uKp6tBFStnsvrot5t","baTWMegR42PAsH9qJ","Xqcorq5EyJBpZcCrN","7cAsBPGh98pGyrhz9","ZbgCx2ntD5eu8Cno9","9kcTNWopvXFncXgPy","HxWdXMqoQtjDhhNGA","xwBuoE9p8GE7RAuhd","inedT6KkbLSDwZvfd","sWLLdG6DWJEy3CH7n","dhj9dhiwhq3DX6W8z","yLLkWMDbC9ZNKbjDG","P3Yt66Wh5g7SbkKuT","brXr7PJ2W4Na2EW2q","45mNHCMaZgsvfDXbw","7izSBpNJSEXSAbaFh","pfoZSkZ389gnz5nZm","jfG6vdJZCwTQmG7kb","sGnPTfjE5JthAStqg","gvA4j8pGYG4xtaTkw","PZtsoaoSLpKjjbMqM","jnDibtfvWNHLucf4D","GrtbTAPfkJa4D6jjH","zEWJBFFMvQ835nq6h","64FdKLwmea8MCLWkE","Dx9LoqsEh3gHNJMDk","FMkQtPvzsriQAow5q","XuLG6M7sHuenYWbfC","PGv9THs68ArPur7yP","NcGBmDEe5qXB7dFBF","tEDXpFgsHsm5T8sWz","7gsehrZnvXo2YGiT7","x4n4jcoDP7xh5LWLq","boBZkTqPdboX5u7g9","CJw2tNHaEimx6nwNy","CcC8MocynqKPmMPwL","Rrt7uPJ8r3sYuLrXo","rwjv8bZfSuE9ZAigH","khYYedgupgrHonWNc","wrkEnGrTTrM2mnmGa","f9s7pHub6hbsX7YKT","YduZEfz8usGbJXN4x","55SHk8kh9dDvaDTCC","SFG9Cm7mf5eP4juKs","eLRSCC7r4KinuxqZX","oW6mbA3XHzcfJTwNq","kWMkDoy3izRTobZFe","LtsJLfnP4YwhGdaCf","w9kwayt5SWqBQe8Nx","h5CGM5qwivGk2f5T9","iPGpENE4ARKbzzQmt","PQ3nutgxfTgvq69Xt","3zZjF3YKJ257x79mu","9Qwignbzu4ddXLTsT","aiCtrN9EF2FjKz5sv","JcpwEKbmNHdwhpq5n","idipkijjz5PoxAwju","F7RgpHHDpZYBjZGia","xWTSHJASRaLABgHWc","Fg8dtE8HHkDoiGcwt","zPJE7MDtL25RpN7Cc","qqhdj3W3vSfB5E9ss","9SE67uz98kh6x2CxR","gR6H3egpRPNYnoTrA","qPoaA5ZSedivA4xJa","H6L7fuEN9qXDanQ6W","gfexKxsBDM6v2sCMo","7uJnA3XDpTgemRH2c","stb3Jjumzhv49zCEb","XjMkPyaPYTf7LrKiT","XuyRMxky6G8gq7a69","huRxRzwcvwTzvtEPY","8bWbNwiSGbGi9jXPS","sq3WkpyqGANT7hGRP","AyfDnnAdjG7HHeD3d","WmfapdnpFfHWzkdXY","8rYxw9xZfwy86jkpG","zFhhDCxz87yKwqYQf","doiMq8aH2yiZaCJsT","MQzbaHoiQutiHkx2M","ra9Pt2JkEDnKW4jsc","9YDk52NPrfq7nqLvd","KTEciTeFwL2tTujZk","6bSjRezJDxR2omHKE","r5H6YCmnn8DMtBtxt","JbcWQCxKWn3y49bNB","R4FX6wDmppvZ2JqpB","9vnWFwng8QzEnBT8z","XCtFBWoMeFwG8myYh","6uwLq8kofo4Tzxfe2","G993PFTwqqdQv4eTg","DWgWbXRfXLGHPgZJM","K7wtTqTEoKXC9Kb24","hmai5Lru5kWXpH7Ju","w4jjwDPa853m9P4ag","xvAkpCSdqgtYhEceo","6vMBpZtoRw4ia2JrK","Wzjjynmp8gMmdX6dt","CsN6WxwDnPzxAFhps","CLXkgEerPi9MpJCem","BKjJJH2cRpJcAnP7T","qXtbBAxmFkAQLQEJE","jES7mcPvKpfmzMTgC","D7epkkJb3CqDTYgX9","FpcgSoJDNNEZ4BQfj","mF8dkhZF9hAuLHXaD","camG6t6SxzfasF42i","HALKHS4pMbfghxsjD","HDXLTFnSndhpLj2XZ","fgYQjTktBmNZvMqce","fwNskn4dosKng9BCB","B5auLtDfQrvwEkw4Q","z7YvA5osMotdL5F4w","Hoh6umyMWSqzPGMJZ","vHSrtmr3EBohcw6t8","nsCwdYJEpmW5Hw5Xm","LKAXgTen4Xbqb8eZY","22GrdspteQc8EonMn","TSaJ9Zcvc3KWh3bjX","sJK6HN5vTPPnuuNgQ","mh3xapTix6fFtd3xM","JBnaLpsrYXLXjFocu","uR8c2NPp4bWHQ5u45","d4YGxMpzmvxknHfbe","wcNEXDHowiWkRxDNv","scNCmwaduCgJmCBYh","LsXtcLyzyfGg3gT5R","McN9BNtNcbYNfdCB5","4tzEAgdbNTwB6nKyL","sCFGEhwcB8MX3FQf5","G4uMdBzgDsxMsTNmr","34Gkqus9vusXRevR8","7MCqRnZzvszsxgtJi","HXxHcRCxR4oHrAsEr","cmrtpfG7hGEL9Zh9f","oHk9T3jbx2J5zJ39P","sYt3ZCrBq2QAf3rak","r8stxYL29NF9w53am","zymnWfGwf6BdDt64c","yyDrMYBfvYtKbmPmm","4gevjbK77NQS6hybY","jnjjzkH8Fdzg4D6EK","XKfQF73YnyMRiRf9a","gYfgWSxCpFdk2cZfE","CQsEwAyJP6NYvKZw6","JiLcxpWzCrnwkndsT","gpk8dARHBi7Mkmzt9","GrbeyZzp6NwzSWpds","9MZdwQ7u53oaRiBYX","gFyJgnu5vAbzELBM8","ouQNu3hhfKLBRuwR7","m5AH78nscsGjMbBwv","oKYWbXioKaANATxKY","cq5x4XDnLcBrYbb66","KjdP2WjWng6skwbY7","wfpdejMWog4vEDLDg","7F5jo5LD9FD7DpxCX","kDjKF2yFhFEWe4hgC","pWi5WmvDcN4Hn7Bo6","NGc3Yjecg9pDMznWq","xxvKhjpcTAJwvtbWM","DJnvFsZ2maKxPi7v7","zo9zKcz47JxDErFzQ","fyZBtNB3Ki3fM4a6Y","H4kadKrC2xLK24udn","BxersHYN2qcFoonwg","Ck5cgNS2Eozc8mBeJ","wr9dH2GjztvCz6pYX","EzAt4SbtQcXtDNhHK","syeBtmGoKvjJTH6sH","eWqFy8wESHbxNod7i","8cWMX6L8St8k9pPRC","jP583FwKepjiWbeoQ","rMfpnorsMoRwyn4iP","TKk7rShf9d5ePN7vR","fNJvYD6XqnX82i4jA","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","3GAnfeG9KmsbsWeTj","JKgGvJCzNoBQss2bq","JjGs6mDZxeCWkg3ii","AzKx6EjaoaMuk595v","duAkuSqJhGDcfMaTA","pXLqpguHJzxSjDdx7","FbJYEn6eWA5JnGeGP","8GiTowD6XqTNzgCz7","qfDgEreMoSEtmLTws","96N8BT9tJvybLbn5z","SCs4KpcShb23hcTni","bDMoMvw2PYgijqZCC","nqwzrpkPvviLHWXaE","YuZXRxWSqaCoZHEXr","6YYmkpumigAmh3efu","SgszmZwrDHwG3qurr","9EyzaH3jzH3PyQtM5","eR7Su77N2nK3e5YRZ","GSBCw94DsxLgDat6r","cpdsMuAHSWhWnKdog","avvXAvGhhGgkJDDso","KnPN7ett8RszE79PH","ptmmK9PWgYTuWToaZ","XNhfw5Bqsi4SGNNBk","PKy8NuNPknenkDY74","3yqf6zJSwBF34Zbys","YpyW97jRbtvBAncAr","LwcKYR8bykM6vDHyo","H6hMugfY3tDQGfqYL","iyRpsScBa6y4rduEt","mLuQfS7gmfr4nwTdv","TrvkWBwYvvJjSqSCj","yXHcqrCpiHC5tDuEc","HKfBeWN8ufNdFgzG6","P8yeoeJ2bwmnD93mZ","kxW6q5YdTGWh5sWby","ksatPnddyZjHwZWwG","st7DiQP23YQSxumCt","tE7y8FZe7wSSzoRaS","L4HQ3gnSrBETRdcGu","eqxqgFxymP8hXDTt5","uKWXktrR7KpbgZAs4","h4vWsBBjASgiQ2pn6","DXBziiT2RFLcmLY9J","k42G2aaNhRNB7hdCJ","XSKQLeQnBupFo7GGC","BnDF5kejzQLqd5cjH","AMmqk74zWmvP8tXEJ","NQQzXpahhkb6f6ZCe","Tk5ovpucaqweCu4tu","9WX59u7g2sdKqnjDm","Xht9swezkGZLAxBrd","8c8AZq5hgifmnHKSN","nMNi86hgNjaNnh8iu","s3rAKTkdSHb6Hwwoz","rqnbrJhDKCoZvNGEZ","Ea8pt2dsrS6D4P54F","uN3wjp2K6TEQ2oAML","DAc4iuy4D3EiNBt9B","jqCz2X49FRn5Bgb5b","8hxvfZiqH24oqyr6y","puYfAEJJomeodeSsi","S54HKhxQyttNLATKu","igSPcmvTigCHxWt8x","4esQ684vtR9zcjHgW","yGaw4NqRha8hgx5ny","eHnupDgggBqDqT5eg","k7oxdbNaGATZbtEg3","bbGEiSmNiTpPrFhcQ","Z6dmoLyfBdmo6HEss","QcXuwQvvPkqcKZmXS","7FJRnxbRtT7Sbzizs","oBTkthd7h8sDpkiu2","cmiRk9XtT9Psnd3Yr","G6npMHwgRGSQDKavX","hwxj4gieR7FWNwYfa","yGycR8tFA3JJbvApp","jxy7rBcQink8a7C9b","vQNJrJqebXEWjJfnz","kjmpq33kHg7YpeRYW","FwYMuD2sNcaEpE5on","4rwABGAd9kZG8nf2P","GkXKvkLAcTm5ackCq","TrmMcujGZt5JAtMGg","gBpYo7mt2zNBmtBJd","aNRYQFnMQbA7uu99u","YMokuZdoY9tEDHjzv","MG8Yhsxqu9JY4xRPr","zEvqFtT4AtTztfYC4","fzeoYhKoYPR3tDYFT","8npC4KRcAJtGdErTq","AYbhqi65SWzHzy7Xx","N99KgncSXewWqkzMA","2KacvW34BbXFmDBtQ","tSgcorrgBnrCH8nL3","NHuLAS3oKZWr2X9hP","9hR2RmpJmxT8dyPo4","fwSDKTZvraSdmwFsj","Cf2zBkoocqcjnrNFD","MPj7t2w3nk4s9EYYh","TTPux7QFBpKxZtMKE","shcSdHGPhnLQkpSbX","M4w2rdYgCKctbADMn","hMjFMSQZb4swKugfv","mkrvsNi8cYGSjGqkh","DXcezGmnBcAYL2Y2u","Aq8BQMXRZX3BoFd4c","FoJSa8mgLPT83g9e8","Xt85tj6GQJCuuXT68","JAAHjm4iZ2j5Exfo2","sAiHxHkQrsYsRpKFP","6phFYpNQH9SmWL9Jt","Rkxj7TFxhbm59AKJh","rNFzvii8LtCL5joJo","Hw26MrLuhGWH7kBLm","Zvu6ZP47dMLHXMiG3","HByDKLLdaWEcA2QQD","7qhtuQLCCvmwCPfXK","FgjcHiWvADgsocE34","Lp4Q9kSGsJHLfoHX3","3xF66BNSC5caZuKyC","BseaxjsiDPKvGtDrm","Q924oPJzK92FifuFg","oJwJzeZ6ar2Hr7KAX","H7Rs8HqrwBDque8Ru","gEKHX8WKrXGM4roRC","FKB7iEergZaC7PvQf","suxvE2ddnYMPJN9HD","iETtCZcfmRyHp69w4","mz3hwS4c9bc9EHAm9","KFLdfuw35qkgjzWer","RApxEu3A4GnvGoEe2","XLbDQL2qYi9FDozvL","p4XpZWcQksSiCPG72","mB95aqTSJLNR9YyjH","2NaAhMPGub8F2Pbr7","BbM47qBPzdSRruY4z","dYnHLWMXCYdm9xu5j","qHpazCw3ryvBojGSa","wyYubb3eC5FS365nk","wmjPGE8TZKNLSKzm4","CBWSDdzjqfnexBurB","gBnSRErajRtvhMnDr","BfBF6T6HA82zBxPrv","dbDHEQyKqnMDDqq2G","doPejjd84w8BmERqj","PT8vSxsusqWuN7JXp","dKxX76SCfCvceJXHv","DSzpr8Y9299jdDLc9","hnLutdvjC8kPScPAj","vit9oWGj6WgXpRhce","CsKboswS3z5iaiutC","kjQXzkTGuixoJtQnq","RgJicDmXHDxcJ9Fsw","L6iFpR9ZyTmzHvYci","Z5ZBPEgufmDsm7LAv","PRAyQaiMWg2La7XQy","x6Kv7nxKHfLGtPJej","3pjv6uDvY9sqmsnvY","Aet2mbnK7GDDfrEQu","scL68JtnSr3iakuc6","3SG4WbNPoP8fsuZgs","XfpJ6WQBDcEcC8Mu4","iprqfLaDLCGoJFeiZ","frApEhpyKQAcFvbXJ","znBJwbuT3f5eWgM4E","cR7Zfrc4BtnFes46y","hbmsW2k9DxED5Z4eJ","SzecSPYxqRa5GCaSF","hxaq9MCaSrwWPmooZ","FSmPtu7foXwNYpWiB","WQWhXzALcrzrJtqRh","jYNT3Qihn2aAYaaPb","gebzzEwn2TaA6rGkc","WhHFvzFsYfMxgYCdo","tjxgbovwc5Ft7wrtc","2brqzQWfmNx5Agdrx","QaDwBio8MLqRvTREH","Jko7pt7MwwTBrfG3A","A9tJFJY7DsGTFKKkh","Wnqua6eQkewL3bqsF","DJB82jKwgJE5NsWgT","5b6YcFbEBCZbX6YSK","zk6RK3xFaDeJHsoym","FQqcejhNWGG8vHDch","srge9MCLHSiwzaX6r","DJRe5obJd7kqCkvRr","D8ds9idKWbwzCseCh","hTMFt3h7QqA2qecn7","9LXxgXySTFsnookkw","CHtwDXy63BsLkQx4n","u5RLu5F3zKTB3Qjnu","4tke3ibK9zfnvh9sE","2WngsveoLhFubuLMH","ADwayvunaJqBLzawa","NG6FrXgmqPd5Wn3mh","Ww5xKq5brC4xAJY7o","HL6x8zHo9BkuK3tic","PKBXczqhry7iK3Ruw","oBBzqkZwkxDvsKBGB","HuFZJkGptWDtRbkWs","iQWk5jYeDg5ACCmpx","RdpqsQ6xbHzyckW9m","sizjfDgCgAsuLJQmm","X3p8mxE5dHYDZNxCm","wZGpoZgDANdkwTrwt","uAc7bWgpEhrGwFcv7","3nDR23ksSQJ98WNDm","sMsvcdxbK2Xqx8EHr","evYFijNMdjfbPaCho","Psp8ZpYLCDJjshpRb","Zupr296Zy74wpihXT","68dHanLWsS6SEyZp9","x9FNKTEt68Rz6wQ6P","DWHkxqX4t79aThDkg","xLm9mgJRPvmPGpo7Q","6LzKRP88mhL9NKNrS","XYDsYSbBjqgPAgcoQ","eRohP4gbxuBuhqTbe","Wpf3Gsa8A89mmjkk8","PfcQguFpT8CDHcozj","XPwEptSSFRCnfHqFk","pohTfSGsNQZYbGpCy","zcPLNNw4wgBX5k8kQ","2meuc3kPRkBcRpj3R","bzhGBHrGrFfQss4Df","2269iGRnWruLHsZ5r","kj37Hzb2MsALwLqWt","Qz9GvoPbnFwGrHHQB","pJJdcZgB6mPNWoSWr","dtmmP4YdJEfK9y4Rc","QPqm5aj2meRmE7kR8","2oybbEw697CQgcRE5","TYTEJxzeK3jBMq2TZ","K4eDzqS2rbcBDsCLZ","FcRt3xAF4ynojfj6G","gMXsyhPiEJbGerF6F","9sguwESkteCgqFMbj","mvPfao35Moah8py46","kuDKtwwbsksAW4BG2","pL56xPoniLvtMDQ4J","ENBzEkoyvdakz4w5d","wM4bcDxEh75NDkhjo","YAkpzvjC768Jm2TYb","ExssKjAaXEEYcnzPd","n3LAgnHg6ashQK3fF","GMCs73dCPTL8dWYGq","8gapy2nLy4wysXSGL","dgFcJtHaYfaoByAK9","HhWhaSzQr6xmBki8F","CpvyhFy9WvCNsifkY","aan3jPEEwPhrcGZjj","mhA4vkeaRn9cpxkag","iA25AvZqAr6G8mAXR","C4tR3BEpuWviT7Sje","FghubkDy6Dp6mnxk7","RKz7pc6snBttndxXz","jiJquD34sa9Lyo5wc","c8EeJtqnsKyXdLtc5","ZGGGBR9sDgtLgMDaA","uM6mENiJi2pNPpdnC","o9dnstYoc7cwpgdhg","YSWa8rYeD3aDaofSP","pC47ZTsPNAkjavkXs","QtyKq4BDyuJ3tysoK","bYrF8rXFYwPqnfxTp","KbyRPCAsWv5GtfrbG","c2RzFadrxkzyRAFXa","9ZodFr54FtpLThHZh","xmoYza9vgcRvWD5PA","sbb9bZgojmEa7Yjrc","6yTShbTdtATxKonY5","BHYBdijDcAKQ6e45Z","qGEqpy7J78bZh3awf","KJbQyFbXiiYDDWbaS","PYtus925Gcg7cqTEq","yTvBSFrXhZfL8vr5a","Aud7CL7uhz55KL8jG","bXTNKjsD4y3fabhwR","AmNjHo8xXMKnZEWRS","CHD5m9fnosr7L3dto","MN4NRkMw7ggt9587K","CDXDnruBJe23rpdfC","y5GftLezdozEHdXkL","d6yNW5T6J9rtnGizc","pT48swb8LoPowiAzR","27AWRKbKyXuzQoaSk","vNHf7dx5QZA4SLSZb","KwbJFexa4MEdhJbs4","mja6jZ6k9gAwki9Nu","fW9n8bEuMpLwkxCx6","muXfZr5EYCfZqLmsb","5PBWgHiCiiJHjPRSn","PAYMMgPi2L3MPP967","RaxaXBNmStYe289gC","DMxe4XKXnjyMEAAGw","xF7gBJYsy6qenmmCS","gMszBSAX23uqYhytR","HbXXd2givHBBLxr3d","Z5wF8mdonsM2AuGgt","utySCY9nJt9xGYGGQ","gCz7cB6JG66EhweSS","krHDNc7cDvfEL8z9a","aNAFrGbzXddQBMDqh","sksP9Lkv9wqaAhXsA","p3s8RvkcyTwzu27ps","8ccTZ9ZxpJrvnxt4F","p7WXmG6Fbo3eaSwm3","CPBmbgYZpsGqkiz2R","yDRX2fdkm3HqfTpav","WbLAA8qZQNdbRgKte","75dnjiD8kv2khe9eQ","JZZENevaLzLLeC3zn","MgFDzAfCku9MSDLuw","PQtEqmyqHWDa2vf5H","zbqLuTgTCu365MNu9","P3uavjFmZD5RopJKk","8gqrbnW758qjHFTrH","pZaPhGg2hmmPwByHc","4hLcbXaqudM9wSeor","WxW6Gc6f2z3mzmqKs","j9HoG56Y6KuopSzdn","GhFoAxG49RXFzze5Y","rD57ysqawarsbry6v","LCfaLXcWnk8pujnX4","tAXrD8Y6hcJ8dt6Nt","af9MjBqF2hgu3EN6r","FRRb6Gqem8k69ocbi","LbyxFk8JmPKPAQBvL","PHmYhE4sKnwzYgvkh","fZJRxYLtNNzpbWZAA","kgmkdf3C7EkDX7dnT","Gs29k3beHiqWFZqnn","MMAK6eeMCH3JGuqeZ","cdB5f2adKoLGW8Ytc","5e49dHLDJoDpeXGnh","Ccsx339LE9Jhoii9K","PHnMDhfiadQt6Gj23","Jo89KvfAs9z7owoZp","fri4HdDkwhayCYFaE","tD9zEiHfkvakpnNam","xggxWfyzZmnz7hydm","JgBBuDf5uZHmpEMDs","vbcjYg6h3XzuqaaN8","hRohhttbtpY3SHmmD","6KzFwcDy7hsCkzJKY","F2DZXsMdhGyX4FPAd","esRZaPXSHgWzyB2NL","AqsjZwxHNqH64C2b6","4psQW7vRwt7PE5Pnj","voLHQgNncnjjgAPH7","aaHDA4X6cTzFrvuSX","LHtMNz7ua8zu4rSZr","zjMKpSB2Xccn9qi5t","BAzCGCys4BkzGDCWR","goC9qv4PWf2cjfnbm","Z2CuyKtkCmWGQtAEh","c3iQryHA4tnAvPZEv","vwLxd6hhFvPbvKmBH","Js34Ez9nrDeJCTYQL","fJvjin8ETkzhFdadC","W59Nb72sYJhMJKGB8","xiPMaYGTm2xfsB8WF","oPEWyxJjRo4oKHzMu","PjfsbKrK5MnJDDoFr","sBBGxdvhKcppQWZZE","vwM7hnT9ysE3suwfk","BzYmJYECAc3xyCTt6","uiyWHaTrz3ML7JqDX","vZssZr2wq7YrG3FMa","73QyjLymEak4L8RDC","6vcxuRHzeM99jYcYd","bG4PR9uSsZqHg2gYY","HoQ5Rp7Gs6rebusNP","9iA87EfNKnREgdTJN","QEYWkRoCn4fZxXQAY","kAgJJa3HLSZxsuSrf","FZaDFYbnRoHmde7F6","BNfL58ijGawgpkh9b","4gDbqL3Tods8kHDqs","DwqgLXn5qYC7GqExF","atcJqdhCxTZiJSxo2","zRn6cLtxyNodudzhw","P32AuYu9MqM2ejKKY","K2JBqDeETX2yEgyyZ","3FoMuCLqZggTxoC3S","LcEzxX2FNTKbB6KXS","o5F2p3krzT4JgzqQc","cy3BhHrGinZCp3LXE","zsG9yKcriht2doRhM","WYmmC3W6ZNhEgAmWG","EL4HNa92Z95FKL9R2","EKu66pFKDHFYPaZ6q","Pa5NqtxHBkGuCh98G","JKj5Krff5oKMb8TjT","vwt3wKXWaCvqZyF74","4basF9w9jaPZpoC8R","Bfq6ncLfYdtCb6sat","jDQm7YJxLnMnSNHFu","FDJnZt8Ks2djouQTZ","f3o9ydY7iPjFF2fyk","KnQs55tjxWopCzKsk","Ww2dxwWpSfkQB4NZb","ZawRiFR8ytvpqfBPX","ZGzDNfNCXzfx6hYAH","rFjhz5Ks685xHbMXW","Mrz2srZWc7EzbADSo","B4DuwmtqF3HhNwvua","zQKgKjecvR4W7oJw5","BSpdshJWGAW6TuNzZ","JHcTP4Ad8QAmRTCZm","GGn8MBiY8Xz6NdNdH","hQysqfSEzciRazx8k","AtfQFj8umeyBBkkxa","r99tazGiLgzqFX7ka","uFYQaGCRwt3wKtyZP","BFamedwSgRdGGKXQQ","teaxCFgtmCQ3E9fy8","ka8eveZpT7hXLhRTM","euJm4RwkAptZnP89i","LLRtjkvh9AackwuNB","yPLr2tnXbiFXkMWvk","ervaGwJ2ZcwqfCcLx","4AHXDwcGab5PhKhHT","NuueGqPZdotjMQKLu","qjSHfbjmSyMnGR9DS","xtzvtJBNofk4FPAtt","SkcM4hwgH3AP6iqjs","Br4xDbYu4Frwrb64a","HvcZmKS43SLCbJvRb","BEtzRE2M5m9YEAQpX","EhEZoTFzys9EDmEXn","bmoQ2wy7Nd7EiJdpg","pYcFPMBtQveAjcSfH","zb3hWt99i9Fm93KPq","W9rJv26sxs4g2B9bL","Dod9AWz8Rp4Svdpof","hQHuXuRGZxxWXaPgg","zB3ukZJqt3pQDw9jz","KheBaeW8Pi7LwewoF","Ek7M3xGAoXDdQkPZQ","guDcrPqLsnhEjrPZj","7XbcDaeigMaxW43EB","ttGbpJQ8shBi8hDhh","wJnm5cBiZGmKn595f","puhPJimawPuNZ5wAR","eoHbneGvqDu25Hasc","gHgs2e2J5azvGFatb","x5ASTMPKPowLKpLpZ","EhAbh2pQoAXkm9yor","jfq2BH5kfQqu2vYv3","Mf2MCkYgSZSJRz5nM","mXgsd5o9uuYaQKHMz","YM6Qgiz9RT7EmeFpp","PcfHSSAMNFMgdqFyB","uX3HjXo6BWos3Zgy5","nzmCvRvPm4xJuqztv","CMt3ijXYuCynhPWXa","Ndtb22KYBxpBsagpj","yFJ7vCjefBxnTchmG","SQ9cZtfrzDJmw9A2m","PJLABqQ962hZEqhdB","HmfxSWnqnK265GEFM","i3BTagvt3HbPMx6PN","ZEgQGAjQm5rTAnGuM","ctpkTaqTKbmm6uRgC","qEweugBipR5P2cMyK","xnPFYBuaGhpq869mY","YtvZxRpZjcFNwJecS","ido3qfidfDJbigTEQ","85J8hjEn48FicYfvp","N6vZEnCn6A95Xn39p","tJQsxD34maYw2g5E4","96TBXaHwLbFyeAxrg","ixZLTmFfnKRbaStA5","2x7fwbwb35sG8QmEt","oaqKjHbgsoqEXBMZ2","t2NN6JwMFaqANuLqH","J9pNx22bj5RuiRjAj","AN2cBr6xKWCB8dRQG","G5eMM3Wp3hbCuKKPE","y5jAuKqkShdjMNZab","vADtvr9iDeYsCDfxd","x4GmqcwjFTnWeRiud","5ntgky9ShzKKWu7us","z8usYeKX7dtTWsEnk","3S4nyoNEEuvNsbXt8","EEv9JeuY5xfuDDSgF","ASpGaS3HGEQCbJbjS","AXXaXJvf7WcTessog","QL7J9wmS6W2fWpofd","osYFcQtxnRKB4F4HA","MajyZJrsf8fAywWgY","bvqC4Ci7rXq4sN9df","GctJD5oCDRxCspEaZ","A9NxPTwbw6r6Awuwt","dKTh9Td3KaJ8QW6gw","oTX2LXHqXqYg2u4g6","LuXb6CZG4x7pDRBP8","hamma4XgeNrsvAJv5","BfTW9jmDzujYkhjAb","DoHcgTvyxdorAMquE","EbFABnst8LsidYs5Y","Sdx6A6yLByRRs8iLY","qbHLGo5vu8HD3JqEM","48WeP7oTec3kBEada","LgavAYtzFQZKg95WC","5QpufhoH2ASnppsjs","Kz9zMgWB5C27Pmdkh","qy5dF7bQcFjSKaW58","wkuDgmpxwbu2M2k3w","JcpzFpPBSmzuksmWM","zMxrkFrB6ka4Lb7fM","PX7AdEkpuChKqrNoj","ui6mDLdqXkaXiDMJ5","uXn3LyA8eNqpvdoZw","FwiPfF8Woe5JrzqEu","hzuSDMx7pd2uxFc5w","mHqQxwKuzZS69CXX5","yKXKcyoBzWtECzXrE","zHS4FJhByRjqsuH4o","a5JAiTdytou3Jg749","HEn2qiMxk5BggN83J","tYAvXXgSwHCzNTK8f","WXvt8bxYnwBYpy9oT","kLR5H4pbaBjzZxLv6","CtXaFo3hikGMWW4C9","4DBBQkEQvNEWafkek","qwdupkFd6kmeZHYXy","EHbJ69JDs4suovpLw","w5F4w8tNZc6LcBKRP","xqkGmfikqapbJ2YMj","yRAo2KEGWenKYZG9K","scwoBEju75C45W5n3","qJgz2YapqpFEDTLKn","aSQy7yHj6nPD44RNo","Ltey8BS83qSkd9M3u","9Yc7Pp7szcjPgPsjf","hN2aRnu798yas5b2k","ERWeEA8op6s6tYCKy","yJfBzcDL9fBHJfZ6P","BZ6XaCwN4QGgH9CxF","3nMpdmt8LrzxQnkGp","TNHQLZK5pHbxdnz4e","F6ZTtBXn2cFLmWPdM","neQ7eXuaXpiYw7SBy","k2SNji3jXaLGhBeYP","WsSybGTqpBoHpXJyQ","jtMXj24Masrnq3SpS","jqTeghCJ2anMHPPjG","B7P97C27rvHPz3s9B","uK6sQCNMw8WKzJeCQ","hurF9uFGkJYXzpHEE","xEHy9oivifjgFbnvc","33KewgYhNSxFpbpXg","c5GHf2kMGhA4Tsj4g","dC7mP5nSwvpL65Qu5","hpjou9ZnLZkSJR7sd","bshZiaLefDejvPKuS","AvjbBjAAbKBk73v5F","XqvnWFtRD2keJdwjX","KJ9MFBPwXGwNpadf2","37sHjeisS9uJufi4u","5iZTwGHv2tNfFmeDa","gziZACDg6EBpGZbJe","RYcoJdvmoBbi5Nax7","9o3QBg2xJXcRCxGjS","vs3kzjLhbdKsndnBy","bZ2w99pEAeAbKnKqo","bjjbp5i5G8bekJuxv","vwqLfDfsHmiavFAGP","Yp2vYb4zHXEeoTkJc","z6QQJbtpkEAX3Aojj","ubPAo3zGeJNqtZDqT","pfibDHFZ3waBo6pAc","cumc876woKaZLmQs5","Ty2tjPwv8uyPK9vrz","ZiQqsgGX6a42Sfpii","ybYBCK9D7MZCcdArB","pNcFYZnPdXyL2RfgA","rEBXN3x6kXgD4pLxs","no5jDTut5Byjqb4j5","qCsxiojX7BSLuuBgQ","uyBeAN5jPEATMqKkX","aHaqgTNnFzD7NGLMx","bQ6zpf6buWgP939ov","mkbGjzxD8d8XqKHzA","CKpByWmsZ8WmpHtYa","midXmMb2Xg37F2Kgn","reitXJgJXFzKpdKyd","LFNXiQuGrar3duBzJ","KcvJXhKqx4itFNWty","RWu8eZqbwgB9zaerh","EFQ3F6kmt4WHXRqik","FfPukic3Qskd9ZAkk","A2Qam9Bd9xpbb2wLQ","t9svvNPNmFf5Qa3TA","n5TqCuizyJDfAPjkr","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","Kyc5dFDzBg4WccrbK","RWo4LwFzpHNQCTcYt","vbWBJGWyWyKyoxLBe","PsEppdvgRisz5xAHG","tscc3e5eujrsEeFN4","GG2rtBReAm6o3mrtn","E4cKD9iTWHaE7f3AJ","yCWPkLi8wJvewPbEp","AcKRB8wDpdaN6v6ru","LbrPTJ4fmABEdEnLf","rtM3jFaoQn3eoAiPh","eDicGjD9yte6FLSie","xg3hXCYQPJkwHyik2","bJ2haLkcGeLtTWaD5","PBRWb2Em5SNeWYwwB","7hFeMWC6Y5eaSixbD","aMHq4mA2PHSM2TMoH","wpZJvgQ4HvJE2bysy","2brqzQWfmNx5Agdrx","GLMFmFvXGyAcG25ni","NLBbCQeNLFvBJJkrt","bYrF8rXFYwPqnfxTp","v7c47vjta3mavY3QC","3MvaoZbGPxtRFCijw","TappK5n3kZmQzWEWD","tSemJckYr29Gnxod2","WdkLDpBGMCWhfByAY","EctieqKwDQcQHhqZy","hNqte2p48nqKux3wS","qw3Z79HELMsmLkL9F","zwDz9pgT43fRczkB4","Fafzj3wMvoCW4WjeF","kxW6q5YdTGWh5sWby","G5eMM3Wp3hbCuKKPE","kSiT2XjfTnDHKx44W","DSzpr8Y9299jdDLc9","wZGpoZgDANdkwTrwt","qajfiXo5qRThZQG7s","rRzZzBBQ36CrqhZTY","aP36QcAsxyuEispq6","TxcRbCYHaeL59aY7E","MFNJ7kQttCuCXHp8P","PQ3nutgxfTgvq69Xt","JJFphYfMsdFMuprBy","ythFNoiAotjvuEGkg","GZSzMqr8hAB2dR8pk","BBQ5HEnL3ShefQxEj","fzeoYhKoYPR3tDYFT","bXuAXCbzw9hsJSuEN","mbCccXJuuRBZdXdpH","m7THsgXyxxiEXgyHv","xtHd6sfdr2bZHa6Pb","pfaTqpWFghfrbvzaD","u8GMcpEN9Z6aQiCvp","gBpYo7mt2zNBmtBJd","rkpDX7j7va6c8Q7cZ","NGkBfd8LTqcpbQn5Z","GEPX7jgLMB8vR2qaK"]},"locale":"en-US","mapbox":{"apiKey":"pk.eyJ1IjoiaGFicnlrYSIsImEiOiJjaWxvcnhidzgwOGlodHJrbmJ2bmVmdjRtIn0.inr-_5rWOOslGQxY8iDFOA"},"petrov":{"afterTime":1727400080403,"beforeTime":1727376805595,"petrovPostId":"6LJ6xcHEjKF9zWKzs","petrovServerUrl":"https://forum.effectivealtruism.org/graphql","petrovGamePostId":"KTEciTeFwL2tTujZk"},"reacts":{"addNewReactKarmaThreshold":10,"downvoteExistingReactKarmaThreshold":20,"addNameToExistingReactKarmaThreshold":5},"stripe":{"publicKey":"pk_live_51HtKAwA2QvoATZCZiy9f2nc6hA52YS1BE81cFu9FEV1IKar0Bwx6hIpxxxYHnhaxO9KM7kRYofZId3sUUI7Q0NeO00tGni3Wza"},"algolia":{"appId":"fakeAppId","searchKey":"fakeSearchKey","indexPrefix":"test_"},"llmChat":{"userIds":["McgHKH6MMYSnPwQcm","6Fx2vQtkYSZkaCvAg","MEu8MdhruX5jfGsFQ","YaNNYeR5HjKLDBefQ","hBEAsEpoNHaZfefxR","NFmcwmaFeTWfgrvBN","ZnpELPxzzD2CiigNy","Q7NW4XaWQmfPfdcFj","NXeHNNSFHGESrYkPv","QDNJ93vrjoaRBesk2","iMBN2523tmh4Yicc3","5iPRfSnjako6iM6LG","aBHfQ4C5fSM4TPyTn","n4M37rPXGyL6p8ivK","e9ToWWzhwWp5GSE7P","TCjNiBLBPyhZq5BuM","XLwKyCK7JmC292ZCC","S3ydcLKdejjkodNut","ENgxBL95Sc7MRwYty","KCExMGwS2ETzN3Ksr","XGEcH5rmq4yGvD82A","YFiFbXgjBpDKZT93g","dZMo8p7fGCgPMfdfD","Pdca6FNZBrXj9z28n","LHbu27FubhwFv8ZJt","gYxdDBQ3AZbde8HgZ","5JqkvjdNcxwN8D86a","6c2KCEXTGogBZ9KoE","haTrhurXNmNN8EiXc"]},"logoUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1498011194/LessWrong_Logo_skglnw.svg","ckEditor":{"uploadUrl":"https://39669.cke-cs.com/easyimage/upload/","webSocketUrl":"39669.cke-cs.com/ws"},"recombee":{"enabled":true},"hasEvents":true,"logRocket":{"apiKey":"mtnxzn/lesswrong","sampleDensity":5},"reCaptcha":{"apiKey":"6LfFgqEUAAAAAHKdMgzGO-1BRBhHw1x6_8Ly1cXc"},"siteImage":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg","cloudinary":{"cloudName":"lesswrong-2-0","uploadPresetBanner":"navcjwf7","uploadPresetGridImage":"tz0mgw2s","uploadPresetSocialPreview":"nn5tppry"},"googleMaps":{"apiKey":"AIzaSyA3C48rl26gynG3qIuNuS-3Bh_Zz9jFXkY"},"adminAccount":{"email":"team@lesswrong.com","username":"LessWrong"},"annualReview":{"end":"2024-02-01T08:00:00Z","start":"2023-12-04T00:10:00Z","reviewPhaseEnd":"2024-01-15T08:00:00Z","votingPhaseEnd":"2024-02-01T08:00:00Z","nominationPhaseEnd":"2023-12-17T08:00:00Z","votingResultsPostId":"TSaJ9Zcvc3KWh3bjX","announcementPostPath":"/posts/B6CxEApaatATzown6/the-lesswrong-2022-review","reviewWinnerSectionsInfo":{"modeling":{"tag":"World Modeling","order":2,"title":"World","coords":{"leftXPct":0.05,"leftYPct":0,"rightXPct":0.57,"rightYPct":0,"middleXPct":0.31,"middleYPct":0,"leftFlipped":true,"leftWidthPct":0.26,"rightWidthPct":0.26,"middleWidthPct":0.26},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753450/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_15ba02c3-b268-45f1-a780-322bbaa6fc22_eu9l0l.png"},"ai safety":{"tag":"AI","order":5,"title":"Technical AI Safety","coords":{"leftXPct":0.2,"leftYPct":0.3,"rightXPct":0.554,"rightYPct":0.3,"middleXPct":0.467,"middleYPct":0.3,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,fl_progressive,q_auto/v1708570131/lwbot_topographic_watercolor_artwork_of_a_giant_robot_hand_gent_e4e9f305-9611-4787-8768-d7af3d702ed4_ta2ii9.png"},"practical":{"tag":"Practical","order":3,"title":"Practical","coords":{"leftXPct":0.2,"leftYPct":0.05,"rightXPct":0.634,"rightYPct":0.05,"middleXPct":0.417,"middleYPct":0.05,"leftFlipped":false,"leftWidthPct":0.217,"rightWidthPct":0.217,"middleWidthPct":0.217},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708974564/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_4f6449e2-569b-48a3-b878-a400315b3ef0_hqutxe.png"},"ai strategy":{"tag":"AI","order":4,"title":"AI Strategy","coords":{"leftXPct":0,"leftYPct":0,"rightXPct":0.66,"rightYPct":0,"middleXPct":0.33,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753570/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_8dda30ee-71d6-4b24-80c7-a8499a5b25c6_uacvgk.png"},"rationality":{"tag":"Rationality","order":0,"title":"Rationality","coords":{"leftXPct":0.12,"leftYPct":0,"rightXPct":0.72,"rightYPct":0,"middleXPct":0.42,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.3,"rightFlipped":true,"rightWidthPct":0.3,"middleWidthPct":0.3},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753260/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_09275054-eb84-43c4-9cfa-4a05e1818c9e_rmov5i.png"},"optimization":{"tag":"World Optimization","order":1,"title":"Optimization","coords":{"leftXPct":0.1,"leftYPct":0.2,"rightXPct":0.7,"rightYPct":0.2,"middleXPct":0.4,"middleYPct":0.2,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753382/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_242eda7f-95a9-4c3b-8090-991a1b11286f_xcjhxq.png"}},"reviewWinnerYearGroupsInfo":{"2018":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008323/ruby37_green_on_white_aquarelle_sketch_by_thomas_schaller_of_ri_7a3fa89a-ac7a-466f-929f-b396cb4d9bd5_p8rh9t.png"},"2019":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008331/ruby37_blue_on_white_aquarelle_sketch_by_thomas_schaller_of_gre_f421cc99-2bb5-4357-b164-d05c2f4fe84e_aib1co.png"},"2020":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.01,"rightXPct":0.72,"rightYPct":0.01,"middleXPct":0.34,"middleYPct":0.01,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008346/ruby37_aquarelle_sketch_of_futuristic_landscape_by_thomas_schal_f07d5805-9fb0-4dcc-9295-7f063624e28c_slcokh.png"},"2021":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.545,"rightYPct":0.1,"middleXPct":0.278,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/a_270/q_auto,f_auto/ohabryka_Topographic_aquarelle_book_cover_by_Thomas_W._Schaller_f9c9dbbe-4880-4f12-8ebb-b8f0b900abc1_m4k6dy_734413"},"2022":{"tag":null,"coords":{"leftXPct":0,"leftYPct":0.1,"rightXPct":0.79,"rightYPct":0.1,"middleXPct":0.43,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008351/ruby37_aquarelle_sketch_of_a_woman_focusing_hard_studying_in_an_2ac568ef-408e-4561-acc8-84c76bb42fba_gwt8uq.png"}},"showReviewOnFrontPageIfActive":true},"googleVertex":{"enabled":true},"intercomAppId":"wtb8z7sj","commentInterval":15,"googleDocImport":{"enabled":true},"moderationEmail":"team@lesswrong.com","timeDecayFactor":1.15,"googleTagManager":{"apiKey":"GTM-TRC765W"},"textReplacements":{"Less Wrong":"Down Bad","Alignment Forum":"Standards Committee","Artificial Intelligence":"Fake News"},"alternateHomePage":false,"gatherTownMessage":"Schelling social hours on Tues 1pm and Thurs 6pm PT","bookDisplaySetting":false,"gardenOpenToPublic":false,"karmaRewarderId100":"iqWr6C3oEB4yWpzn5","legacyRouteAcronym":"lw","maxRenderQueueSize":3,"recommendationsTab":{"manuallyStickiedPostIds":[]},"frontpageScoreBonus":0,"karmaRewarderId1000":"mBBmKWkmw8bgJmGiG","defaultVisibilityTags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10}],"enableGoodHeartProject":false,"maxDocumentsPerRequest":5000,"defaultSequenceBannerId":"sequences/vnyzzznenju0hzdv6pqb.jpg","defaultModeratorComments":[{"id":"FfMok764BCY6ScqWm","label":"Option A"},{"id":"yMHoNoYZdk5cKa3wQ","label":"Option B"}],"newUserIconKarmaThreshold":50,"dialogueMatchmakingEnabled":true,"hideUnreviewedAuthorComments":"2023-04-04T18:54:35.895Z","gatherTownUserTrackingIsBroken":true,"postModerationWarningCommentId":"sLay9Tv65zeXaQzR4","commentModerationWarningCommentId":"LbGNE5Ssnvs6MYnLu","performanceMetricLoggingEnax5bled":true,"firstCommentAcknowledgeMessageCommentId":"QgwD7PkQHFp3nfhjj"}</script><script>window.tabId = "LZy7Zt2EnnBsZZjEW"</script><script>window.isReturningVisitor = false</script><script async="" src="The%20Library%20%E2%80%94%20LessWrong_files/bundle.js"></script><title>The Library — LessWrong</title><meta data-react-helmet="true" charset="utf-8"><meta data-react-helmet="true" name="description" content="A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"><meta data-react-helmet="true" name="twitter:image:src" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"><meta data-react-helmet="true" name="twitter:description" content="A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:url" content="https://www.lesswrong.com/library"><meta data-react-helmet="true" property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"><meta data-react-helmet="true" property="og:description" content="A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" http-equiv="delegate-ch" content="sec-ch-dpr https://res.cloudinary.com;"><meta data-react-helmet="true" http-equiv="Accept-CH" content="DPR, Viewport-Width, Width"><link data-react-helmet="true" rel="canonical" href="The%20Library%20%E2%80%94%20LessWrong_files/library.html"><link data-react-helmet="true" rel="alternate" type="application/rss+xml" href="https://www.lesswrong.com/feed.xml"><meta name="twitter:card" content="summary"><script>window.themeOptions = {"name":"default"}</script><style id="jss-insertion-point"></style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: rgba(0, 0, 0, 0.54);
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(0, 0, 0, 0.26);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-moz-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-moz-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-moz-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(0,0,0,0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(0, 0, 0, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-contained {
  color: rgba(0, 0, 0, 0.87);
  box-shadow: 0px 1px 5px 0px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 3px 1px -2px rgba(0,0,0,0.12);
  background-color: #e0e0e0;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
  box-shadow: none;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:hover {
  background-color: #d5d5d5;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #e0e0e0;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-containedPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(0,0,0,0.2),0px 12px 17px 2px rgba(0,0,0,0.14),0px 5px 22px 4px rgba(0,0,0,0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: rgba(0, 0, 0, 0.54);
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiPopover">
.MuiPopover-paper {
  outline: none;
  position: absolute;
  min-width: 16px;
  max-width: calc(100% - 32px);
  overflow-y: auto;
  overflow-x: hidden;
  min-height: 16px;
  max-height: calc(100% - 32px);
}
</style><style data-jss="" data-meta="MuiTooltip">
.MuiTooltip-popper {
  z-index: 1500;
  opacity: 0.9;
}
.MuiTooltip-tooltip {
  color: #fff;
  padding: 9.1px;
  z-index: 10000000;
  font-size: 13px;
  max-width: 300px;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  background-color: rgba(75,75,75,.94);
}
.MuiTooltip-touch {
  padding: 8px 16px;
  font-size: 0.875rem;
  line-height: 1.14286em;
}
.MuiTooltip-tooltipPlacementLeft {
  margin: 0 24px ;
  transform-origin: right center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementLeft {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementRight {
  margin: 0 24px;
  transform-origin: left center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementRight {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementTop {
  margin: 24px 0;
  transform-origin: center bottom;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementTop {
    margin: 14px 0;
  }
}
.MuiTooltip-tooltipPlacementBottom {
  margin: 24px 0;
  transform-origin: center top;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementBottom {
    margin: 14px 0;
  }
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(0, 0, 0, 0.12);
}
</style><style data-jss="">
.jss97 {
  top: 0;
  left: 0;
  bottom: 0;
  z-index: 1199;
  position: fixed;
}
.jss98 {
  right: auto;
}
.jss99 {
  left: auto;
  right: 0;
}
.jss100 {
  right: 0;
  bottom: auto;
}
.jss101 {
  top: auto;
  right: 0;
  bottom: 0;
}
</style><style data-jss="" data-meta="MuiListItem">
.MuiListItem-root {
  width: 100%;
  display: flex;
  position: relative;
  box-sizing: border-box;
  text-align: left;
  align-items: center;
  padding-top: 8px;
  padding-bottom: 8px;
  justify-content: flex-start;
  text-decoration: none;
}
.MuiListItem-root.MuiListItem-selected, .MuiListItem-root.MuiListItem-selected:hover {
  background-color: rgba(0, 0, 0, 0.14);
}
.MuiListItem-container {
  position: relative;
}
.MuiListItem-focusVisible {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiListItem-dense {
  padding-top: 8px;
  padding-bottom: 8px;
}
.MuiListItem-disabled {
  opacity: 0.5;
}
.MuiListItem-divider {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
  background-clip: padding-box;
}
.MuiListItem-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiListItem-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiListItem-button {
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
}
.MuiListItem-button:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
@media (hover: none) {
  .MuiListItem-button:hover {
    background-color: transparent;
  }
}
.MuiListItem-secondaryAction {
  padding-right: 32px;
}
</style><style data-jss="" data-meta="MuiMenuItem">
.MuiMenuItem-root {
  color: #424242;
  width: auto;
  height: 24px;
  overflow: hidden;
  font-size: 14.3px;
  box-sizing: content-box;
  font-weight: 400;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.1em;
  white-space: nowrap;
  padding-left: 16px;
  text-overflow: ellipsis;
  padding-right: 16px;
}
</style><link id="main-styles" rel="stylesheet" type="text/css" onerror="window.missingMainStylesheet=true" href="The%20Library%20%E2%80%94%20LessWrong_files/allStyles.css"><script async="" src="The%20Library%20%E2%80%94%20LessWrong_files/wtb8z7sj"></script></head>
<body class="abTestNoEffect_group2 collectionsPageABTest_originalLayoutGroup booksProgressBarABTest_control welcomeBoxABTest_welcomeBox twoLineEventsSidebar_expanded dialogueFacilitationMessages_optIn frontpageDialogueReciprocityRecommendations_noShow showOpinionsInReciprocity_show showRecommendedContentInMatchForm_show checkNotificationMessageContent_v4 newFrontpagePostFeedsWithRecommendationsOptIn_classicFrontpage">
<script>0</script><div id="react-app"><div class="wrapper Layout-wrapper" id="wrapper"><div></div><span></span><div class="IntercomWrapper-intercomFrame" id="intercom-outer-frame"></div><noscript class="noscript-warning"> This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. </noscript><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TRC765W" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div class="Header-root"><div style="height:64px" class="Header-headroom headroom-wrapper"><div class="headroom headroom--unfixed headroom-disable-animation"><header class="Header-appBar"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton Header-hideLgUp" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton Header-hideMdDown" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><h2 class="Typography-root Typography-title Header-title"><div class="Header-hideSmDown"><div class="Header-titleSubtitleContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LESSWRONG</a></div></div><div class="Header-hideMdUp"><a class="Header-titleLink" href="https://www.lesswrong.com/">LW</a></div></h2><div class="Header-rightHeaderItems"><div class="SearchBar-root"><div class="SearchBar-rootChild"><div class="SearchBar-searchInputArea SearchBar-searchInputAreaSmall"><div><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root SearchBar-searchIcon SearchBar-searchIconSmall" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><div></div></div></div></div><div class="UsersAccountMenu-root"><button tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat" type="button"><span class="MuiButton-label"><span class="UsersAccountMenu-userButton">Login</span></span><span class="MuiTouchRipple-root"></span></button></div></div></div></header><div class="jss97 jss98" style="width: 20px;"></div></div></div></div><div class="Layout-standaloneNavFlex Layout-spacedGridActivated"><div class=""><div class="NavigationStandalone-sidebar" direction="right"><div class="TabNavigationMenu-root"><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/"><span class="TabNavigationItem-icon TabNavigationItem-homeIcon"><svg version="1.1" x="0px" y="0px" viewBox="0 0 100 100"><g fill="currentColor"><path d="M29.1,29.2l6.4,11.6l4.3-0.8l0.8-4.3L29.1,29.2z M40.7,64.5l-0.8-4.3l-4.3-0.8L29.2,71L40.7,64.5z M70.9,70.9l-6.4-11.6l-4.3,0.8l-0.8,4.3L70.9,70.9z M64.4,40.8l6.4-11.6l-11.6,6.4l0.8,4.3L64.4,40.8z M67.4,58.8l10.8,19.4L58.8,67.4L50,98.8l-8.8-31.4L21.9,78.2l10.8-19.4L1.2,50.1l31.4-8.8L21.9,21.9l19.4,10.8L50,1.3l8.8,31.4l19.4-10.8L67.4,41.3L98.8,50L67.4,58.8zM57.7,57.8L83.5,50L50,50.1l7.7-7.7L50,16.6v33.5l-7.7-7.7l-25.8,7.7H50l-7.7,7.7L50,83.5V50.1L57.7,57.8z"></path></g></svg></span><span class="TabNavigationItem-navText">Home</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/allPosts"><span class="TabNavigationItem-icon"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" viewBox="0 0 100 125"><g transform="translate(0,-952.36218)"><path style="text-indent:0;text-transform:none;direction:ltr;baseline-shift:baseline" d="m 12.80945,964.36661 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 17.97124,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -17.97124,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 25.958459,0 a 1.9989971,2.0020794 0 1 0 0.1872,3.99977 l 47.923308,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -47.923308,0 a 1.9970041,2.0000833 0 0 0 -0.1872,0 z m -25.958459,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.99859 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z" stroke="none" visibility="visible" display="inline" overflow="visible"></path></g></svg></span><span class="TabNavigationItem-navText">All Posts</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/tags/all"><span class="TabNavigationItem-icon"><svg version="1.1" x="0px" y="0px" viewBox="10 10 90 90"><path d="M62.648,14.41c-7.396-0.624-14.651,2.03-19.906,7.285c-3.807,3.807-6.268,8.75-7.065,14.054  c-5.283,0.785-10.225,3.236-14.085,7.096c-4.19,4.19-6.772,9.755-7.272,15.667c-0.563,6.697,1.512,13.212,5.848,18.346  c4.335,5.136,10.413,8.273,17.106,8.834c7.398,0.628,14.655-2.029,19.91-7.284c3.805-3.805,6.265-8.749,7.062-14.053  c5.283-0.784,10.227-3.235,14.086-7.096c4.189-4.189,6.773-9.754,7.273-15.67C86.77,27.771,76.473,15.578,62.648,14.41z   M55.561,76.783c-4.597,4.596-11.109,7.21-18.092,6.621c-12.582-1.06-21.918-12.119-20.858-24.7  c0.472-5.594,2.923-10.55,6.606-14.232c3.273-3.273,7.529-5.515,12.226-6.336c-0.347,6.424,1.708,12.638,5.875,17.574  c4.333,5.134,10.411,8.272,17.105,8.835c1.166,0.1,2.327,0.106,3.479,0.045C61.069,69.348,58.789,73.555,55.561,76.783z   M62.178,62.248c-1.171,0.082-2.354,0.109-3.561,0.008c-12.482-1.05-21.755-11.945-20.866-24.399  c1.169-0.083,2.353-0.11,3.558-0.008C53.788,38.903,63.064,49.792,62.178,62.248z M83.315,41.397  c-0.474,5.596-2.924,10.554-6.606,14.237c-3.275,3.274-7.531,5.515-12.228,6.336C65.207,48.47,55.063,36.705,41.5,35.559  c-1.164-0.098-2.324-0.106-3.475-0.044c0.832-4.758,3.113-8.964,6.341-12.193c4.596-4.596,11.109-7.211,18.09-6.621  C75.037,17.763,84.375,28.817,83.315,41.397z"></path><path d="M49.384,64.735c-1.677-0.739-3.272-1.645-4.772-2.708c-0.927-0.657-1.816-1.369-2.662-2.144  c-0.861-0.788-1.692-1.613-2.459-2.517c-0.019-0.022-0.042-0.043-0.061-0.065c-0.542-0.641-1.042-1.309-1.52-1.99  c-0.549-0.786-1.045-1.602-1.508-2.434c-0.364-0.656-0.699-1.324-1.008-2.006c-0.354-0.782-0.671-1.578-0.95-2.39  c-0.223-0.648-0.419-1.305-0.593-1.97c-0.203-0.773-0.373-1.557-0.507-2.349c-0.11-0.644-0.194-1.292-0.257-1.946  c-0.031-0.311-0.077-0.62-0.097-0.933c-0.668,0.218-1.318,0.476-1.956,0.76c-1.053,0.47-2.062,1.028-3.019,1.67  c-0.922,0.618-1.794,1.315-2.611,2.085c-0.147,0.139-0.298,0.273-0.442,0.417c-0.436,0.436-0.848,0.891-1.24,1.361  c-0.574,0.689-1.085,1.423-1.562,2.178c-0.375,0.594-0.72,1.204-1.031,1.833c-0.359,0.724-0.683,1.464-0.953,2.227  c-0.218,0.613-0.401,1.24-0.56,1.875c-0.186,0.746-0.323,1.506-0.424,2.273c-0.041,0.315-0.095,0.628-0.122,0.946  c-0.027,0.321-0.022,0.641-0.034,0.961c-0.03,0.775-0.018,1.545,0.04,2.31c0.049,0.652,0.128,1.3,0.239,1.94  c0.138,0.796,0.312,1.581,0.544,2.353c0.201,0.672,0.433,1.335,0.704,1.984c0.345,0.827,0.752,1.628,1.207,2.408  c0.411,0.703,0.871,1.38,1.37,2.038c0.222,0.293,0.431,0.594,0.67,0.877c0.483,0.572,0.999,1.106,1.534,1.617  c0.834,0.796,1.73,1.51,2.675,2.146c1.964,1.324,4.146,2.282,6.464,2.853c1.042,0.257,2.103,0.454,3.192,0.546  c1.064,0.09,2.12,0.066,3.168-0.009c2.392-0.17,4.716-0.755,6.883-1.729c1.045-0.47,2.054-1.022,3.013-1.668  c0.919-0.616,1.788-1.315,2.608-2.085c0.151-0.144,0.316-0.269,0.464-0.416c0.435-0.435,0.826-0.899,1.216-1.366  c0.581-0.692,1.121-1.412,1.6-2.169c0.375-0.593,0.709-1.209,1.02-1.836c0.358-0.723,0.675-1.464,0.943-2.228  c0.048-0.134,0.111-0.26,0.156-0.394c-0.179-0.012-0.356-0.025-0.532-0.04C55.116,66.745,52.149,65.953,49.384,64.735z"></path><path d="M43.815,51.052L54.95,47.54c-0.607-0.724-1.259-1.412-1.96-2.046l-10.529,3.321C42.864,49.591,43.318,50.336,43.815,51.052z  "></path><path d="M47.913,42.134l-7.13,2.249c0.208,0.827,0.469,1.632,0.776,2.419l9.346-2.948C49.961,43.201,48.963,42.623,47.913,42.134z"></path><path d="M41.102,40.309c-0.299-0.025-0.605-0.042-0.924-0.05c0.025,0.662,0.086,1.316,0.175,1.963l4.163-1.313  C43.412,40.619,42.274,40.409,41.102,40.309z"></path><path d="M58.824,59.795c0.301,0.025,0.607,0.042,0.926,0.051c-0.02-0.525-0.073-1.043-0.133-1.559l-3.442,1.086  C57.04,59.562,57.919,59.719,58.824,59.795z"></path><path d="M52.566,58.213l6.684-2.108c-0.191-0.831-0.45-1.637-0.742-2.43l-9.067,2.86C50.426,57.181,51.47,57.742,52.566,58.213z"></path><path d="M47.283,54.918l10.356-3.267c-0.386-0.777-0.806-1.537-1.283-2.259l-11.098,3.501C45.888,53.612,46.56,54.294,47.283,54.918  z"></path></svg></span><span class="TabNavigationItem-navText">Concepts</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-navButton TabNavigationItem-selected" role="menuitem" href="https://www.lesswrong.com/library"><span class="TabNavigationItem-icon TabNavigationItem-selectedIcon"><svg version="1.0" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 84.000000 84.000000" preserveAspectRatio="xMidYMid meet"><g transform="translate(0.0,84.0) scale(0.1,-0.1)" stroke="none"><path d="M170 695 c0 -3 -14 -67 -31 -143 -17 -75 -35 -159 -40 -187 -5 -27 -12 -58 -15 -67 -5 -16 2 -18 53 -18 71 0 156 -21 223 -55 l50 -25 0 225 0 224 -27 15 c-51 25 -213 49 -213 31z"></path><path d="M536 689 c-21 -5 -54 -16 -72 -25 l-34 -16 0 -224 c0 -123 2 -224 4 -224 2 0 23 11 47 24 59 33 150 56 222 56 56 0 59 1 54 23 -3 12 -22 99 -42 192 -20 94 -38 178 -41 188 -4 13 -16 17 -52 16 -26 -1 -64 -5 -86 -10z"></path><path d="M70 576 c-42 -207 -67 -352 -62 -357 4 -4 99 -23 210 -43 l204 -37 201 37 c111 20 205 39 209 43 4 4 -8 87 -27 186 -47 244 -40 223 -70 217 -18 -3 -24 -9 -21 -21 8 -26 76 -330 76 -339 0 -4 -30 -8 -67 -9 -73 0 -200 -31 -263 -63 l-38 -20 -54 25 c-77 35 -173 58 -250 58 -38 1 -68 4 -68 7 0 5 39 181 75 336 4 17 -1 23 -20 26 -22 5 -25 1 -35 -46z"></path></g></svg></span><span class="TabNavigationItem-navText">Library</span><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/leastwrong"><div class="TabNavigationSubItem-root">Best of LessWrong</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/highlights"><div class="TabNavigationSubItem-root">Sequence Highlights</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/rationality"><div class="TabNavigationSubItem-root">Rationality: A-Z</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/codex"><div class="TabNavigationSubItem-root">The Codex</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/hpmor"><div class="TabNavigationSubItem-root">HPMOR</div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root TabNavigationItem-tooltip"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-navButton" role="menuitem" href="https://www.lesswrong.com/community"><span class="TabNavigationItem-icon"><svg width="28" height="34" viewBox="0 0 28 34" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.042 0.653442C21.3573 0.653442 27.3273 6.45284 27.3273 13.6408C27.3273 20.7471 21.3573 26.5465 14.042 26.5465C6.64258 26.5465 0.672607 20.7471 0.672607 13.6408C0.672607 6.45284 6.64258 0.653442 14.042 0.653442ZM11.4354 13.2324C11.4354 13.2324 10.9309 13.1507 10.8468 13.1507C10.0059 13.3141 10.0059 13.1507 10.7627 13.6408C11.2672 13.9676 11.099 13.9676 11.6035 13.8859C11.7717 13.9676 11.9399 13.9676 12.108 14.0492C12.108 14.1309 12.108 14.2943 12.108 14.376C12.108 14.376 12.5285 14.621 12.6125 14.621H13.2852C13.3693 14.621 14.042 14.2126 12.8648 13.8859C12.6966 13.8859 12.4444 13.8859 12.1921 13.9676C12.108 13.8042 12.024 13.6408 11.8558 13.4775C11.8558 13.4775 11.3513 13.2324 11.4354 13.2324ZM24.3843 7.18798C25.5615 9.06666 26.3183 11.2721 26.3183 13.6408C26.3183 14.2943 26.2342 15.0294 26.1501 15.6829C25.5615 15.1928 24.9729 14.7844 24.8888 14.7027C24.6366 14.4576 24.6366 14.8661 24.4684 15.3561C24.3843 15.9279 23.7116 15.4378 23.2071 15.4378C22.7026 15.4378 22.3663 14.7844 22.3663 14.7844C21.4414 14.0492 21.6936 13.6408 21.6936 12.4973C21.6936 12.1706 21.8618 11.7622 22.114 11.5988C22.7026 10.9453 22.1981 10.5369 22.8708 10.0468C23.1231 9.88347 24.048 9.63843 24.048 9.63843C24.5525 8.98497 24.8047 8.82161 23.5435 9.06666C23.4594 9.14834 22.9549 9.06666 22.7026 8.90329C22.3663 8.65825 23.1231 8.49488 23.1231 8.49488C23.4594 8.08648 23.7957 7.75975 24.1321 7.43302C24.2162 7.35134 24.3002 7.26966 24.3843 7.18798ZM14.042 1.7153C15.2192 1.7153 16.3122 1.87867 17.4053 2.12371C17.6576 2.45044 18.078 2.94053 18.1621 3.02221C18.2462 3.10389 18.4984 3.75735 18.4984 3.75735C17.9939 4.49248 17.8258 4.90089 16.7327 4.4108C16.3963 4.32912 15.8077 3.5123 15.8077 3.5123C15.8077 3.5123 14.8828 2.53212 14.7146 2.45044C14.3783 2.20539 13.8738 2.36876 13.6216 2.77717C13.7897 3.02221 13.8738 3.18557 14.042 3.43062C14.7987 3.43062 14.7987 3.26726 15.051 3.83903C14.7987 3.92071 14.5465 4.00239 14.2101 4.08407C13.4534 4.57416 13.7056 4.57416 12.8648 4.00239C12.8648 4.00239 12.3603 3.43062 12.2762 3.34894C12.1921 3.26726 11.8558 2.53212 11.6876 2.28708C11.6876 2.20539 11.6035 2.04203 11.6876 1.87867C12.4444 1.79699 13.2011 1.7153 14.042 1.7153ZM14.4624 25.5664C13.6216 25.5664 12.7807 25.4847 11.8558 25.403C11.9399 24.8312 11.9399 24.3411 11.9399 23.851C11.9399 22.5441 12.2762 22.2991 11.1831 21.564C10.9309 21.1555 10.5945 20.6655 10.2582 20.257C9.50144 19.5219 9.75369 19.6036 10.1741 18.6234C10.2582 18.215 10.3423 17.8066 10.4264 17.4799C10.2582 17.0715 10.1741 16.6631 10.0059 16.2546C9.6696 15.9279 9.33327 15.5195 8.99693 15.1928C7.14708 14.7027 7.23117 14.9477 5.88582 13.5591C5.63357 13.1507 5.38132 12.7423 5.04498 12.3339C4.12005 11.2721 4.28822 11.4354 3.95189 10.1285C3.8678 9.55675 3.78372 8.98497 3.69963 8.49488C3.61555 8.16816 3.53147 7.84143 3.44738 7.59639C5.12906 4.81921 7.90384 2.77717 11.1831 2.04203C11.099 2.45044 11.015 2.85885 10.9309 3.34894C8.91285 4.90089 7.90384 5.3093 10.3423 6.2078C10.9309 7.1063 10.7627 7.5147 11.5195 6.94293C11.5195 6.45284 11.4354 5.96275 11.3513 5.47266C12.8648 4.49248 12.4444 4.65584 14.2101 5.55434C14.4624 5.79939 14.7146 6.04443 14.9669 6.28948C16.1441 6.77957 16.2282 6.53452 15.2192 7.26966C14.9669 7.18798 14.6306 7.18798 14.2942 7.1063C14.1261 7.26966 13.9579 7.43302 13.7897 7.59639C14.2101 8.49488 14.4624 8.4132 13.5375 8.65825C13.2852 8.82161 13.033 9.06666 12.7807 9.23002C12.4444 9.23002 12.108 9.23002 11.7717 9.23002C11.7717 9.23002 11.7717 10.2102 11.7717 10.3736C11.7717 10.6186 11.015 11.2721 11.015 11.2721C11.015 11.2721 10.5945 11.8438 10.8468 12.1706C11.015 12.4973 10.5945 12.7423 10.5945 12.7423C10.3423 12.4973 10.1741 12.1706 9.92186 11.9255C9.58552 11.9255 9.1651 12.0072 8.74468 12.0889C8.49243 12.2522 8.24018 12.3339 7.98792 12.4973C7.90384 12.7423 7.81975 13.0691 7.81975 13.3141C7.90384 13.7225 7.98792 14.1309 8.15609 14.5393C8.32426 14.5393 8.57651 14.5393 8.82876 14.4576C8.82876 13.2324 8.57651 13.2324 9.58552 14.0492C9.6696 14.2943 9.6696 14.5393 9.6696 14.8661C10.0059 14.9477 10.2582 15.0294 10.5104 15.1111C10.5945 15.3561 10.5945 15.6829 10.5945 15.9279C11.015 16.2546 11.4354 16.4997 11.8558 16.7447C12.7807 16.9081 13.7897 16.9081 14.5465 17.4799C15.1351 17.8066 15.7237 18.0516 16.3963 18.2967C16.3963 18.5417 16.4804 18.7868 16.5645 19.0318C16.9008 19.1135 17.3213 19.1135 17.6576 19.1135C18.078 19.1952 18.4984 19.1952 18.9189 19.1952C18.9189 19.4402 18.9189 19.6853 18.9189 19.9303C18.7507 21.3189 18.6666 21.0739 17.6576 21.9724C17.3213 22.2174 16.9849 22.4625 16.6486 22.7892C15.8077 23.9327 16.06 23.7694 14.7146 24.2594C14.6306 24.6679 14.5465 25.1579 14.4624 25.5664Z" fill="currentColor" fill-opacity="0.7"></path></svg></span><span class="TabNavigationItem-navText">Community Events</span><span class="MuiTouchRipple-root"></span></a></span><span><div></div><div><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-eventWrapper TabNavigationEventsList-twoLine" role="menuitem" href="https://www.lesswrong.com/events/drSKaciaB3JoBeoST/replacing-guilt-1"><div class="TabNavigationSubItem-root TabNavigationEventsList-event TabNavigationEventsList-twoLineEvent"><span class="TabNavigationEventsList-title">Replacing Guilt</span><div></div><span class="TabNavigationEventsList-secondLine"><span class="LWTooltip-root"><time class="TabNavigationEventsList-date" datetime="2024-10-10T23:00:00.000Z">Thu Oct 10</time></span><span class="TabNavigationEventsList-dot">•</span><span class="TabNavigationEventsList-city">Waterloo</span></span></div><span class="MuiTouchRipple-root"></span></a></span><span class="LWTooltip-root"><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-gutters MuiListItem-button MuiMenuItem-root TabNavigationEventsList-eventWrapper TabNavigationEventsList-twoLine" role="menuitem" href="https://www.lesswrong.com/events/mL88XQ4k75dgWxCpL/freiburg-acx-meetup-fall-2024"><div class="TabNavigationSubItem-root TabNavigationEventsList-event TabNavigationEventsList-twoLineEvent"><span class="TabNavigationEventsList-title">Freiburg - ACX Meetup Fall 2024</span><div></div><span class="TabNavigationEventsList-secondLine"><span class="LWTooltip-root"><time class="TabNavigationEventsList-date" datetime="2024-10-11T16:00:00.000Z">Fri Oct 11</time></span><span class="TabNavigationEventsList-dot">•</span><span class="TabNavigationEventsList-city">Freiburg im Breisgau</span></span></div><span class="MuiTouchRipple-root"></span></a></span></div></span><div class="TabNavigationMenu-divider"></div><div><a class="SubscribeWidget-root"><div class="TabNavigationSubItem-root">Subscribe (RSS/Email)</div></a></div><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/posts/YMo5PuXnZDwRjhHhE/the-story-of-i-have-been-a-good-bing"><div class="TabNavigationSubItem-root">LW the Album</div><span class="MuiTouchRipple-root"></span></a><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/about"><div class="TabNavigationSubItem-root">About</div><span class="MuiTouchRipple-root"></span></a><a tabindex="-1" class="MuiButtonBase-root MuiListItem-root MuiListItem-default MuiListItem-button MuiMenuItem-root TabNavigationItem-menuItem TabNavigationItem-subItemOverride" role="menuitem" href="https://www.lesswrong.com/faq"><div class="TabNavigationSubItem-root">FAQ</div><span class="MuiTouchRipple-root"></span></a></div></div></div><div class="TabNavigationMenuFooter-wrapper"><div class="TabNavigationMenuFooter-root"><a class="TabNavigationFooterItem-navButton" title="Latest posts, comments and curated content." href="https://www.lesswrong.com/"><span class="TabNavigationFooterItem-icon TabNavigationFooterItem-homeIcon"><svg version="1.1" x="0px" y="0px" viewBox="0 0 100 100"><g fill="currentColor"><path d="M29.1,29.2l6.4,11.6l4.3-0.8l0.8-4.3L29.1,29.2z M40.7,64.5l-0.8-4.3l-4.3-0.8L29.2,71L40.7,64.5z M70.9,70.9l-6.4-11.6l-4.3,0.8l-0.8,4.3L70.9,70.9z M64.4,40.8l6.4-11.6l-11.6,6.4l0.8,4.3L64.4,40.8z M67.4,58.8l10.8,19.4L58.8,67.4L50,98.8l-8.8-31.4L21.9,78.2l10.8-19.4L1.2,50.1l31.4-8.8L21.9,21.9l19.4,10.8L50,1.3l8.8,31.4l19.4-10.8L67.4,41.3L98.8,50L67.4,58.8zM57.7,57.8L83.5,50L50,50.1l7.7-7.7L50,16.6v33.5l-7.7-7.7l-25.8,7.7H50l-7.7,7.7L50,83.5V50.1L57.7,57.8z"></path></g></svg></span><span class="TabNavigationFooterItem-navText">Home</span></a><a class="TabNavigationFooterItem-navButton" title="See all posts, filtered and sorted however you like." href="https://www.lesswrong.com/allPosts"><span class="TabNavigationFooterItem-icon"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" x="0px" y="0px" viewBox="0 0 100 125"><g transform="translate(0,-952.36218)"><path style="text-indent:0;text-transform:none;direction:ltr;baseline-shift:baseline" d="m 12.80945,964.36661 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 17.97124,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -17.97124,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 25.958459,0 a 1.9989971,2.0020794 0 1 0 0.1872,3.99977 l 47.923308,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -47.923308,0 a 1.9970041,2.0000833 0 0 0 -0.1872,0 z m -25.958459,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.99977 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.99977 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.99859 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z m 0,23.9986 a 1.9989971,2.0020794 0 1 0 0.187201,3.9998 l 57.90733,0 a 1.9970041,2.0000833 0 1 0 0,-3.9998 l -57.90733,0 a 1.9970041,2.0000833 0 0 0 -0.187201,0 z" stroke="none" visibility="visible" display="inline" overflow="visible"></path></g></svg></span><span class="TabNavigationFooterItem-navText">All Posts</span></a><a class="TabNavigationFooterItem-navButton" href="https://www.lesswrong.com/tags/all"><span class="TabNavigationFooterItem-icon"><svg version="1.1" x="0px" y="0px" viewBox="10 10 90 90"><path d="M62.648,14.41c-7.396-0.624-14.651,2.03-19.906,7.285c-3.807,3.807-6.268,8.75-7.065,14.054  c-5.283,0.785-10.225,3.236-14.085,7.096c-4.19,4.19-6.772,9.755-7.272,15.667c-0.563,6.697,1.512,13.212,5.848,18.346  c4.335,5.136,10.413,8.273,17.106,8.834c7.398,0.628,14.655-2.029,19.91-7.284c3.805-3.805,6.265-8.749,7.062-14.053  c5.283-0.784,10.227-3.235,14.086-7.096c4.189-4.189,6.773-9.754,7.273-15.67C86.77,27.771,76.473,15.578,62.648,14.41z   M55.561,76.783c-4.597,4.596-11.109,7.21-18.092,6.621c-12.582-1.06-21.918-12.119-20.858-24.7  c0.472-5.594,2.923-10.55,6.606-14.232c3.273-3.273,7.529-5.515,12.226-6.336c-0.347,6.424,1.708,12.638,5.875,17.574  c4.333,5.134,10.411,8.272,17.105,8.835c1.166,0.1,2.327,0.106,3.479,0.045C61.069,69.348,58.789,73.555,55.561,76.783z   M62.178,62.248c-1.171,0.082-2.354,0.109-3.561,0.008c-12.482-1.05-21.755-11.945-20.866-24.399  c1.169-0.083,2.353-0.11,3.558-0.008C53.788,38.903,63.064,49.792,62.178,62.248z M83.315,41.397  c-0.474,5.596-2.924,10.554-6.606,14.237c-3.275,3.274-7.531,5.515-12.228,6.336C65.207,48.47,55.063,36.705,41.5,35.559  c-1.164-0.098-2.324-0.106-3.475-0.044c0.832-4.758,3.113-8.964,6.341-12.193c4.596-4.596,11.109-7.211,18.09-6.621  C75.037,17.763,84.375,28.817,83.315,41.397z"></path><path d="M49.384,64.735c-1.677-0.739-3.272-1.645-4.772-2.708c-0.927-0.657-1.816-1.369-2.662-2.144  c-0.861-0.788-1.692-1.613-2.459-2.517c-0.019-0.022-0.042-0.043-0.061-0.065c-0.542-0.641-1.042-1.309-1.52-1.99  c-0.549-0.786-1.045-1.602-1.508-2.434c-0.364-0.656-0.699-1.324-1.008-2.006c-0.354-0.782-0.671-1.578-0.95-2.39  c-0.223-0.648-0.419-1.305-0.593-1.97c-0.203-0.773-0.373-1.557-0.507-2.349c-0.11-0.644-0.194-1.292-0.257-1.946  c-0.031-0.311-0.077-0.62-0.097-0.933c-0.668,0.218-1.318,0.476-1.956,0.76c-1.053,0.47-2.062,1.028-3.019,1.67  c-0.922,0.618-1.794,1.315-2.611,2.085c-0.147,0.139-0.298,0.273-0.442,0.417c-0.436,0.436-0.848,0.891-1.24,1.361  c-0.574,0.689-1.085,1.423-1.562,2.178c-0.375,0.594-0.72,1.204-1.031,1.833c-0.359,0.724-0.683,1.464-0.953,2.227  c-0.218,0.613-0.401,1.24-0.56,1.875c-0.186,0.746-0.323,1.506-0.424,2.273c-0.041,0.315-0.095,0.628-0.122,0.946  c-0.027,0.321-0.022,0.641-0.034,0.961c-0.03,0.775-0.018,1.545,0.04,2.31c0.049,0.652,0.128,1.3,0.239,1.94  c0.138,0.796,0.312,1.581,0.544,2.353c0.201,0.672,0.433,1.335,0.704,1.984c0.345,0.827,0.752,1.628,1.207,2.408  c0.411,0.703,0.871,1.38,1.37,2.038c0.222,0.293,0.431,0.594,0.67,0.877c0.483,0.572,0.999,1.106,1.534,1.617  c0.834,0.796,1.73,1.51,2.675,2.146c1.964,1.324,4.146,2.282,6.464,2.853c1.042,0.257,2.103,0.454,3.192,0.546  c1.064,0.09,2.12,0.066,3.168-0.009c2.392-0.17,4.716-0.755,6.883-1.729c1.045-0.47,2.054-1.022,3.013-1.668  c0.919-0.616,1.788-1.315,2.608-2.085c0.151-0.144,0.316-0.269,0.464-0.416c0.435-0.435,0.826-0.899,1.216-1.366  c0.581-0.692,1.121-1.412,1.6-2.169c0.375-0.593,0.709-1.209,1.02-1.836c0.358-0.723,0.675-1.464,0.943-2.228  c0.048-0.134,0.111-0.26,0.156-0.394c-0.179-0.012-0.356-0.025-0.532-0.04C55.116,66.745,52.149,65.953,49.384,64.735z"></path><path d="M43.815,51.052L54.95,47.54c-0.607-0.724-1.259-1.412-1.96-2.046l-10.529,3.321C42.864,49.591,43.318,50.336,43.815,51.052z  "></path><path d="M47.913,42.134l-7.13,2.249c0.208,0.827,0.469,1.632,0.776,2.419l9.346-2.948C49.961,43.201,48.963,42.623,47.913,42.134z"></path><path d="M41.102,40.309c-0.299-0.025-0.605-0.042-0.924-0.05c0.025,0.662,0.086,1.316,0.175,1.963l4.163-1.313  C43.412,40.619,42.274,40.409,41.102,40.309z"></path><path d="M58.824,59.795c0.301,0.025,0.607,0.042,0.926,0.051c-0.02-0.525-0.073-1.043-0.133-1.559l-3.442,1.086  C57.04,59.562,57.919,59.719,58.824,59.795z"></path><path d="M52.566,58.213l6.684-2.108c-0.191-0.831-0.45-1.637-0.742-2.43l-9.067,2.86C50.426,57.181,51.47,57.742,52.566,58.213z"></path><path d="M47.283,54.918l10.356-3.267c-0.386-0.777-0.806-1.537-1.283-2.259l-11.098,3.501C45.888,53.612,46.56,54.294,47.283,54.918  z"></path></svg></span><span class="TabNavigationFooterItem-navText">Concepts</span></a><a class="TabNavigationFooterItem-navButton TabNavigationFooterItem-selected" title="Curated collections of LessWrong's best writing." href="https://www.lesswrong.com/library"><span class="TabNavigationFooterItem-icon"><svg version="1.0" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 84.000000 84.000000" preserveAspectRatio="xMidYMid meet"><g transform="translate(0.0,84.0) scale(0.1,-0.1)" stroke="none"><path d="M170 695 c0 -3 -14 -67 -31 -143 -17 -75 -35 -159 -40 -187 -5 -27 -12 -58 -15 -67 -5 -16 2 -18 53 -18 71 0 156 -21 223 -55 l50 -25 0 225 0 224 -27 15 c-51 25 -213 49 -213 31z"></path><path d="M536 689 c-21 -5 -54 -16 -72 -25 l-34 -16 0 -224 c0 -123 2 -224 4 -224 2 0 23 11 47 24 59 33 150 56 222 56 56 0 59 1 54 23 -3 12 -22 99 -42 192 -20 94 -38 178 -41 188 -4 13 -16 17 -52 16 -26 -1 -64 -5 -86 -10z"></path><path d="M70 576 c-42 -207 -67 -352 -62 -357 4 -4 99 -23 210 -43 l204 -37 201 37 c111 20 205 39 209 43 4 4 -8 87 -27 186 -47 244 -40 223 -70 217 -18 -3 -24 -9 -21 -21 8 -26 76 -330 76 -339 0 -4 -30 -8 -67 -9 -73 0 -200 -31 -263 -63 l-38 -20 -54 25 c-77 35 -173 58 -250 58 -38 1 -68 4 -68 7 0 5 39 181 75 336 4 17 -1 23 -20 26 -22 5 -25 1 -35 -46z"></path></g></svg></span><span class="TabNavigationFooterItem-navText">Library</span></a><a class="TabNavigationFooterItem-navButton" title="Find a meetup near you." href="https://www.lesswrong.com/community"><span class="TabNavigationFooterItem-icon"><svg width="28" height="34" viewBox="0 0 28 34" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.042 0.653442C21.3573 0.653442 27.3273 6.45284 27.3273 13.6408C27.3273 20.7471 21.3573 26.5465 14.042 26.5465C6.64258 26.5465 0.672607 20.7471 0.672607 13.6408C0.672607 6.45284 6.64258 0.653442 14.042 0.653442ZM11.4354 13.2324C11.4354 13.2324 10.9309 13.1507 10.8468 13.1507C10.0059 13.3141 10.0059 13.1507 10.7627 13.6408C11.2672 13.9676 11.099 13.9676 11.6035 13.8859C11.7717 13.9676 11.9399 13.9676 12.108 14.0492C12.108 14.1309 12.108 14.2943 12.108 14.376C12.108 14.376 12.5285 14.621 12.6125 14.621H13.2852C13.3693 14.621 14.042 14.2126 12.8648 13.8859C12.6966 13.8859 12.4444 13.8859 12.1921 13.9676C12.108 13.8042 12.024 13.6408 11.8558 13.4775C11.8558 13.4775 11.3513 13.2324 11.4354 13.2324ZM24.3843 7.18798C25.5615 9.06666 26.3183 11.2721 26.3183 13.6408C26.3183 14.2943 26.2342 15.0294 26.1501 15.6829C25.5615 15.1928 24.9729 14.7844 24.8888 14.7027C24.6366 14.4576 24.6366 14.8661 24.4684 15.3561C24.3843 15.9279 23.7116 15.4378 23.2071 15.4378C22.7026 15.4378 22.3663 14.7844 22.3663 14.7844C21.4414 14.0492 21.6936 13.6408 21.6936 12.4973C21.6936 12.1706 21.8618 11.7622 22.114 11.5988C22.7026 10.9453 22.1981 10.5369 22.8708 10.0468C23.1231 9.88347 24.048 9.63843 24.048 9.63843C24.5525 8.98497 24.8047 8.82161 23.5435 9.06666C23.4594 9.14834 22.9549 9.06666 22.7026 8.90329C22.3663 8.65825 23.1231 8.49488 23.1231 8.49488C23.4594 8.08648 23.7957 7.75975 24.1321 7.43302C24.2162 7.35134 24.3002 7.26966 24.3843 7.18798ZM14.042 1.7153C15.2192 1.7153 16.3122 1.87867 17.4053 2.12371C17.6576 2.45044 18.078 2.94053 18.1621 3.02221C18.2462 3.10389 18.4984 3.75735 18.4984 3.75735C17.9939 4.49248 17.8258 4.90089 16.7327 4.4108C16.3963 4.32912 15.8077 3.5123 15.8077 3.5123C15.8077 3.5123 14.8828 2.53212 14.7146 2.45044C14.3783 2.20539 13.8738 2.36876 13.6216 2.77717C13.7897 3.02221 13.8738 3.18557 14.042 3.43062C14.7987 3.43062 14.7987 3.26726 15.051 3.83903C14.7987 3.92071 14.5465 4.00239 14.2101 4.08407C13.4534 4.57416 13.7056 4.57416 12.8648 4.00239C12.8648 4.00239 12.3603 3.43062 12.2762 3.34894C12.1921 3.26726 11.8558 2.53212 11.6876 2.28708C11.6876 2.20539 11.6035 2.04203 11.6876 1.87867C12.4444 1.79699 13.2011 1.7153 14.042 1.7153ZM14.4624 25.5664C13.6216 25.5664 12.7807 25.4847 11.8558 25.403C11.9399 24.8312 11.9399 24.3411 11.9399 23.851C11.9399 22.5441 12.2762 22.2991 11.1831 21.564C10.9309 21.1555 10.5945 20.6655 10.2582 20.257C9.50144 19.5219 9.75369 19.6036 10.1741 18.6234C10.2582 18.215 10.3423 17.8066 10.4264 17.4799C10.2582 17.0715 10.1741 16.6631 10.0059 16.2546C9.6696 15.9279 9.33327 15.5195 8.99693 15.1928C7.14708 14.7027 7.23117 14.9477 5.88582 13.5591C5.63357 13.1507 5.38132 12.7423 5.04498 12.3339C4.12005 11.2721 4.28822 11.4354 3.95189 10.1285C3.8678 9.55675 3.78372 8.98497 3.69963 8.49488C3.61555 8.16816 3.53147 7.84143 3.44738 7.59639C5.12906 4.81921 7.90384 2.77717 11.1831 2.04203C11.099 2.45044 11.015 2.85885 10.9309 3.34894C8.91285 4.90089 7.90384 5.3093 10.3423 6.2078C10.9309 7.1063 10.7627 7.5147 11.5195 6.94293C11.5195 6.45284 11.4354 5.96275 11.3513 5.47266C12.8648 4.49248 12.4444 4.65584 14.2101 5.55434C14.4624 5.79939 14.7146 6.04443 14.9669 6.28948C16.1441 6.77957 16.2282 6.53452 15.2192 7.26966C14.9669 7.18798 14.6306 7.18798 14.2942 7.1063C14.1261 7.26966 13.9579 7.43302 13.7897 7.59639C14.2101 8.49488 14.4624 8.4132 13.5375 8.65825C13.2852 8.82161 13.033 9.06666 12.7807 9.23002C12.4444 9.23002 12.108 9.23002 11.7717 9.23002C11.7717 9.23002 11.7717 10.2102 11.7717 10.3736C11.7717 10.6186 11.015 11.2721 11.015 11.2721C11.015 11.2721 10.5945 11.8438 10.8468 12.1706C11.015 12.4973 10.5945 12.7423 10.5945 12.7423C10.3423 12.4973 10.1741 12.1706 9.92186 11.9255C9.58552 11.9255 9.1651 12.0072 8.74468 12.0889C8.49243 12.2522 8.24018 12.3339 7.98792 12.4973C7.90384 12.7423 7.81975 13.0691 7.81975 13.3141C7.90384 13.7225 7.98792 14.1309 8.15609 14.5393C8.32426 14.5393 8.57651 14.5393 8.82876 14.4576C8.82876 13.2324 8.57651 13.2324 9.58552 14.0492C9.6696 14.2943 9.6696 14.5393 9.6696 14.8661C10.0059 14.9477 10.2582 15.0294 10.5104 15.1111C10.5945 15.3561 10.5945 15.6829 10.5945 15.9279C11.015 16.2546 11.4354 16.4997 11.8558 16.7447C12.7807 16.9081 13.7897 16.9081 14.5465 17.4799C15.1351 17.8066 15.7237 18.0516 16.3963 18.2967C16.3963 18.5417 16.4804 18.7868 16.5645 19.0318C16.9008 19.1135 17.3213 19.1135 17.6576 19.1135C18.078 19.1952 18.4984 19.1952 18.9189 19.1952C18.9189 19.4402 18.9189 19.6853 18.9189 19.9303C18.7507 21.3189 18.6666 21.0739 17.6576 21.9724C17.3213 22.2174 16.9849 22.4625 16.6486 22.7892C15.8077 23.9327 16.06 23.7694 14.7146 24.2594C14.6306 24.6679 14.5465 25.1579 14.4624 25.5664Z" fill="currentColor" fill-opacity="0.7"></path></svg></span><span class="TabNavigationFooterItem-navText">Community</span></a></div></div><div class="Layout-searchResultsArea"></div><div class="Layout-main"><div class="flash-messages FlashMessages-root"></div><div class="SingleColumnSection-root"><h1 class="Typography-root Typography-display3 LibraryPage-pageTitle">The Library</h1></div><div class="SingleColumnSection-root"><div class="SingleColumnSection-root LWCoreReading-root"><div class="CollectionsItem-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality"></a></div><div class="CollectionsItem-content"><h2 class="Typography-root Typography-title CollectionsItem-title"><a href="https://www.lesswrong.com/rationality">Rationality: A-Z</a></h2><div class="CollectionsItem-subtitle">Also known as "The Sequences"</div><div class="CollectionsItem-description ContentStyles-base content ContentStyles-postHighlight"><div><div>
        <p>
          How can we think better on purpose? <em>Why</em> should we think better on purpose?<br>
          For two years Eliezer Yudkowsky wrote a blogpost a day, 
braindumping thoughts on rationality, ambition and artificial 
intelligence. Those posts were edited into this introductory collection,
 recommended reading for all Lesswrong users.
        </p>
      </div></div></div></div><img src="The%20Library%20%E2%80%94%20LessWrong_files/mississippi-compass_gwqjvs.png" class="CollectionsItem-image" style="width:130px"></div></div></div><div class="CollectionsItem-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/highlights"></a></div><div class="CollectionsItem-content"><h2 class="Typography-root Typography-title CollectionsItem-title"><a href="https://www.lesswrong.com/highlights">The Sequences Highlights</a></h2><div class="CollectionsItem-description ContentStyles-base content ContentStyles-postHighlight"><div><div>
        <p>LessWrong can be kind of intimidating - there's a lot of 
concepts to learn. We recommend getting started with the Highlights, a 
collection of 50 top posts from Eliezer's Sequences.</p>
        <p>A day or two read, covering the foundations of rationality.</p>
        </div></div></div></div><img src="The%20Library%20%E2%80%94%20LessWrong_files/rdl8pwokejuqyxipg6vx.webp" class="CollectionsItem-image" style="width:130px"></div></div></div><div class="CollectionsItem-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor"></a></div><div class="CollectionsItem-content"><h2 class="Typography-root Typography-title CollectionsItem-title"><a href="https://www.lesswrong.com/hpmor">Harry Potter and the Methods of Rationality</a></h2><div class="CollectionsItem-description ContentStyles-base content ContentStyles-postHighlight"><div><div>
        <p>What if Harry Potter was a scientist? What would you do if the universe had magic in it? <br>A story that conveys many rationality concepts, making them more visceral and emotionally compelling.</p></div></div></div></div><img src="The%20Library%20%E2%80%94%20LessWrong_files/DALL_E_2022-07-13_21.49.04_-_11_year_old_wizard_boy_with_sho.png" class="CollectionsItem-image" style="width:130px"></div></div></div><div class="CollectionsItem-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex"></a></div><div class="CollectionsItem-content"><h2 class="Typography-root Typography-title CollectionsItem-title"><a href="https://www.lesswrong.com/codex">The Codex</a></h2><div class="CollectionsItem-description ContentStyles-base content ContentStyles-postHighlight"><div><div>Essays
 by Scott Alexander exploring science, medicine, philosophy, futurism, 
and politics. (There's also one about hallucinatory cactus people but 
it's not representative).</div></div></div></div><img src="The%20Library%20%E2%80%94%20LessWrong_files/codex_u7ptgt.png" class="CollectionsItem-image" style="width:130px"></div></div></div><div class="CollectionsItem-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="CollectionsItem-linkCard LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/bestoflesswrong"></a></div><div class="CollectionsItem-content"><h2 class="Typography-root Typography-title CollectionsItem-title"><a href="https://www.lesswrong.com/bestoflesswrong">Best of LessWrong</a></h2><div class="CollectionsItem-description ContentStyles-base content ContentStyles-postHighlight"><div><div>Each
 December, the LessWrong community reviews the best posts from the 
previous year, and votes on which ones have stood the tests of time.</div></div></div></div><img src="The%20Library%20%E2%80%94%20LessWrong_files/DALL_E_2022-07-13_22.57.43_-_Books_and_emerald_compass_displ.png" class="CollectionsItem-image" style="width:130px"></div></div></div></div></div><div class="Divider-root"><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div><div class="Divider-compass"><svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><path d="M69.948,30.052l-13.739,7.632L50,4.574l-6.208,33.111l-13.74-7.633l7.633,13.739L4.574,50l33.111,6.208l-7.632,13.739  l13.739-7.633L50,95.426l6.208-33.112l13.74,7.634l-7.634-13.74L95.426,50l-33.111-6.208L69.948,30.052z M64.8,35.2l-4.558,8.203  l-3.07-0.576l-0.576-3.07L64.8,35.2z M35.2,35.2l8.203,4.557l-0.576,3.07l-3.07,0.576L35.2,35.2z M35.2,64.8l4.557-8.203l3.07,0.576  l0.576,3.07L35.2,64.8z M64.8,64.8l-8.203-4.557l0.576-3.07l3.07-0.576L64.8,64.8z M55.459,55.459L50,50v34.574l-5.459-29.115L50,50  H15.426l29.115-5.459L50,50V15.426l5.459,29.115L50,50h34.574L55.459,55.459z"></path></svg></div><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 id="curated-sequences" class="Typography-root Typography-display1 SectionTitle-title">Curated Sequences</h1><div class="SectionTitle-children"></div></div><div class="LibraryPage-sequencesGridWrapperWrapper"><div class="SequencesGridWrapper-gridWrapper"><div class="SequencesGrid-grid"><div class="SequencesGrid-gridContent"><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#5g5TkQTe9rmPS5vvM"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/wwkkaskmbcajjogyv1hu.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Predictably Wrong</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/highlights#NBDFAKt3GbFwnwzQF"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/vuzt0hjdrboxywfd4wbt.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Thinking Better on Purpose</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ruby">Ruby</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#PtgH6ALi5CoJnPmGS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/i9dkgkhw14vwar63i4xn.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Methods of Rationality</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/mzgtmmTKKn5MuCzFJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/r68kkaexxymt3ckkc6pp.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AGI safety from first principles</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ricraz">Richard_Ngo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#XsMTxdQ6fprAQMoKi"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rfpef83ejiwbsi1pmroz.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Argument and Analysis</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Rm6oQRJJmhGCcLvxh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mxpqfzoorr921qviypmq.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Embedded Agency</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/v55BhXbpJuaExkpcD"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hxbqvswdmhyoomidbpyu.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">2022 MIRI Alignment Discussion</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/robbbb">Rob Bensinger</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/n945eovrA3oDueqtq"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gpk2pxurl1yymecllfoo.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">2021 MIRI Conversations</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/robbbb">Rob Bensinger</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZnSMHcWjRx6yT4H92"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qu5jdoyzz4jov7siczag.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">LessWrong Political Prerequisites</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/CmrW8fCmSLK7E25sa"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ek5uoqxjn8zl6l9unirr.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Infra-Bayesianism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/diffractor">Diffractor</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/evLkoqsbi79AnM5sz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xhjq89g5vufbwx0df0uf.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Intro to Naturalism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/brienneyudkowsky">LoganStrohl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pFatcKW3JJhTSxqAF"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/m0lpxsua2jmtwbmwlttp.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Replacing Guilt</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/so8res">So8res</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/n3utvGrgC2SGi9xQX"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gdwaqd3wg9zngxrbwbqm.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Conditioning Predictive Models</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/evhub">evhub</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/f2YA4eGskeztcJsqT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/iwls9nubn9dkangx3q5t.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Cyborgism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/janus-1">janus</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/a6ne2ve5uturEEQK7"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/o6bsfz6il5u2kep6vksv.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Engineer’s Interpretability Sequence</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scasper">scasper</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/dDMzozPbe4aJRkfTr"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/v2gocvypckw2doyt5aex.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Stories</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ricraz">Richard_Ngo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/6uDBPacS6zDipqbZ9"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lalel10qzujyi47rqiww.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Valence</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/steve2152">Steven Byrnes</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/BbAvHtorCZqp97X9W"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sqq40tz8m2jsvyrj8s4r.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Otherness and control in the age of AGI</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/joe-carlsmith">Joe Carlsmith</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/TF77XsD5PbucbJsG3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/whqbkvzjopvlh7paq73r.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Luna Lovegood</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/yYxggfHYRrqnJXuRx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nsphhanrutzgofgj5xvu.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Most Important Century</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/holdenkarnofsky">HoldenKarnofsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/EmDuGeRw749sD3GKd"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/prcccqtc5w7ytolilruu.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Iterated Amplification</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/paulfchristiano">paulfchristiano</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4dHMdK5TLN6xcqtyc"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/x0pxuhnauzakdnrqijhe.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Value Learning</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/rohinmshah">Rohin Shah</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/KAv8z6oJCTxjR8vdR"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/prnzteddh56bhbv5nmae.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">CFAR Handbook</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/cfar-2017">CFAR!Duncan</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xEFeCwk3pdYdeG2rL"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mrcucooleoeaj8ybccb3.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Gears Which Turn The World</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/kNANcHLNtJt5qeuSS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/y7bhrihn26iisjvhu61y.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Immoral Mazes</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/zvi">Zvi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/hBFDRZCPLcrRDubgm"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sbiiwhliynfuouklvwph.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Keep your beliefs cruxy and your frames explicit</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/r9tYkB2a8Fp4DN8yB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rzdw9faewnetbmumls9y.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Risks from Learned Optimization</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/evhub">evhub</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/d3WgHDBAPYYScp5Em"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ncfkdhspgrfhhjpbisaj.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Fun Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qWoFR4ytMpQ5vw3FT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sio9b8jw1apesuispocg.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Three Worlds Collide</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HXkpm9b8o964jbQ89"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rqnuxewffasun6tvdkng.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Slack and the Sabbath </div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/zvi">Zvi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZNNi2uNx9E6iwGKKG"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/vitugifyyh2upm9ucjzh.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Introduction to Game Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/G2GDw3m4MJ5ixSM92"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/djfksyoldrjt4ef5jts3.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Blue-Minimizing Robot</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qRxTKm7DAftSuTGvj"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/chv9ct9cisa2fne7htnk.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Hammertime</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/alkjash">alkjash</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pC6DYFLPMTCbEwH8W"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nhvoi5fvxxzthqhu2ctt.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Babble and Prune</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/alkjash">alkjash</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SqFbMbtxGybdS2gRs"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/i2ogsvmipbdolntkew4a.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Highly Advanced Epistemology 101 for Beginners</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/yFvZa9wkv5JoqhM8F"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/yxlirutmux2fjqnnjhoc.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Rationality and Philosophy</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lukeprog">lukeprog</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/XipJ7DMjYyriAm7fr"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qpreo6bc9vxwyf2l1dzo.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Decision Theory: Newcomb's Problem</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/annasalamon">AnnaSalamon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oi873FWi6pHWxswSa"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/yp01lueog8rjaybsizux.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Science of Winning at Life</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lukeprog">lukeprog</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/bQgRsy23biR52poMf"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kvoeqrfluqd0jv5fvwez.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">No-Nonsense Metaethics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lukeprog">lukeprog</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oLGCcbnvabyibnG9d"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/vbhv0s06jdmonk6garvf.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Inadequate Equilibria</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/2A7rrZ4ySx6R8mfoT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/a9iwqgsxkqznfrtskanw.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Cartesian Frames</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scott-garrabrant">Scott Garrabrant</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ynMFrq9K5iNMfSZNg"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ozdf0thhtehmpmbf9dys.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Living Luminously</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/alicorn">Alicorn</a></span></span></span></div></div></div></span></div></div></div></div></div></div><div class="Divider-root"><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div><div class="Divider-compass"><svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><path d="M69.948,30.052l-13.739,7.632L50,4.574l-6.208,33.111l-13.74-7.633l7.633,13.739L4.574,50l33.111,6.208l-7.632,13.739  l13.739-7.633L50,95.426l6.208-33.112l13.74,7.634l-7.634-13.74L95.426,50l-33.111-6.208L69.948,30.052z M64.8,35.2l-4.558,8.203  l-3.07-0.576l-0.576-3.07L64.8,35.2z M35.2,35.2l8.203,4.557l-0.576,3.07l-3.07,0.576L35.2,35.2z M35.2,64.8l4.557-8.203l3.07,0.576  l0.576,3.07L35.2,64.8z M64.8,64.8l-8.203-4.557l0.576-3.07l3.07-0.576L64.8,64.8z M55.459,55.459L50,50v34.574l-5.459-29.115L50,50  H15.426l29.115-5.459L50,50V15.426l5.459,29.115L50,50h34.574L55.459,55.459z"></path></svg></div><div class="Divider-divider"><svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 100 125" enable-background="new 0 0 100 100" xml:space="preserve"><g><g><polygon fill="none" points="6.256,50.245 10.108,51.512 10.727,50.274 9.255,48.746   "></polygon><polygon fill="none" points="89.273,50.274 89.892,51.512 93.744,50.245 90.745,48.746   "></polygon><path d="M11.396,49.969l-1.818-1.888c-0.105-0.109-0.269-0.138-0.405-0.07l-3.981,1.99c-0.126,0.063-0.201,0.195-0.191,0.336    c0.01,0.14,0.104,0.26,0.238,0.304l4.937,1.624c0.036,0.012,0.072,0.017,0.108,0.017c0.128,0,0.25-0.071,0.31-0.192l0.863-1.725    C11.522,50.233,11.498,50.075,11.396,49.969z M10.108,51.512l-3.852-1.267l2.999-1.499l1.472,1.528L10.108,51.512z"></path><path d="M94.808,50.001l-3.981-1.99c-0.136-0.068-0.3-0.04-0.405,0.07l-1.818,1.888c-0.102,0.106-0.126,0.264-0.06,0.396    l0.863,1.725c0.06,0.12,0.182,0.192,0.31,0.192c0.036,0,0.072-0.005,0.108-0.017l4.937-1.624c0.133-0.044,0.227-0.164,0.238-0.304    C95.009,50.196,94.934,50.064,94.808,50.001z M89.892,51.512l-0.619-1.238l1.472-1.528l2.999,1.499L89.892,51.512z"></path><path d="M87.916,50.231l1.543-2.1c0.113-0.154,0.08-0.371-0.074-0.485c-0.155-0.113-0.372-0.08-0.485,0.074l-1.611,2.193h-32.22    l-1.515-1.665c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.097-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.06-0.03,0.116-0.06,1.545-1.488h32.334l0.965,1.644c0.065,0.11,0.181,0.171,0.299,0.171    c0.06,0,0.12-0.015,0.175-0.048c0.165-0.097,0.22-0.31,0.123-0.475L87.916,50.231z"></path><path d="M48.835,48.225c-0.141-0.129-0.361-0.118-0.49,0.023l-1.589,1.746c-0.125,0.137-0.12,0.348,0.011,0.479    c1.564,1.564,1.617,1.59,1.679,1.621c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.34-0.109-0.438c-0.106-0.091-0.711-0.688-1.311-1.285l1.366-1.502    C48.987,48.574,48.977,48.354,48.835,48.225z"></path><path d="M53.244,49.995l-1.589-1.746c-0.129-0.142-0.348-0.152-0.49-0.023c-0.142,0.129-0.152,0.348-0.023,0.49l1.366,1.502    c-0.6,0.598-1.205,1.194-1.311,1.285c-0.137,0.098-0.187,0.283-0.109,0.438c0.061,0.121,0.183,0.191,0.31,0.191    c0.052,0,0.105-0.012,0.155-0.037c0.062-0.031,0.115-0.058,1.679-1.621C53.363,50.343,53.368,50.132,53.244,49.995z"></path><path d="M45.593,50.217l1.366-1.502c0.129-0.142,0.119-0.361-0.023-0.49c-0.142-0.129-0.361-0.118-0.49,0.023l-1.515,1.665h-32.22    L11.1,47.72c-0.113-0.154-0.33-0.188-0.485-0.074c-0.154,0.113-0.188,0.331-0.074,0.485l1.543,2.1l-0.98,1.668    c-0.097,0.165-0.042,0.378,0.124,0.475c0.055,0.032,0.116,0.048,0.175,0.048c0.119,0,0.235-0.061,0.299-0.171l0.965-1.644h32.334    c1.429,1.427,1.485,1.458,1.545,1.488c0.05,0.025,0.103,0.037,0.155,0.037c0.127,0,0.25-0.07,0.31-0.191    c0.078-0.155,0.028-0.341-0.109-0.438C46.798,51.411,46.192,50.815,45.593,50.217z"></path></g></g></svg></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 id="community-sequences" class="Typography-root Typography-display1 SectionTitle-title">Community Sequences</h1><div class="SectionTitle-children"><a href="https://www.lesswrong.com/sequencesnew"><span class="Typography-root Typography-body2 SectionButton-root"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M4 6H2v14c0 1.1.9 2 2 2h14v-2H4V6zm16-4H8c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-1 9h-4v4h-2v-4H9V9h4V5h2v4h4v2z"></path></svg>Create New Sequence</span></a></div></div><div class="LibraryPage-sequencesGridWrapperWrapper"><div class="SequencesGridWrapper-gridWrapper"><div class="SequencesGrid-grid"><div class="SequencesGrid-gridContent"><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qhdHbCJ3PYesL9dde"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gforsnvfonkxbjkfbj8m.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Intuitive Self-Models</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/steve2152">Steven Byrnes</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/B9HWqQSt3NcLx34qc"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/osc2ogpwhlw5rkmj8uyl.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The AI Alignment and Deployment Problems</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sdm">Sammy Martin</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Ed7Ffv4LLK3GS3oj3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/krq7ksuxdb5pye3lrzps.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title"> Welfare and moral weights</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/michaelstjules">MichaelStJules</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/gEvTvhr8hNRrdHC62"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/j21eqgktvcnbri2bcask.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Linear Diffusion of Sparse Lognormals: Causal Inference Against Scientism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/tailcalled">tailcalled</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pwazxmKw7qKo8hoWo"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/a740dwayvur42i3oma3d.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Acausal Trade</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/niplav">niplav</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/KfCjeconYRdFbMxsy"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kdwavysy3pj1dqm0l1jk.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">CAST: Corrigibility As Singular Target</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/max-harms">Max Harms</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SybKaNSqyADrnMQ7H"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/srkofmpkmr2b5to0uimt.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Situational Awareness Summarized</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/joe-rogero">Joe Rogero</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3kQJuSMxoiYWnvLcA"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hbkqht1s3tlwe1gus2oi.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Math of Geometric Utilitarianism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/strivingforlegibility">StrivingForLegibility</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4toN42rxApcqMb8uY"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kwhpr6papjsvaa5bg6dg.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Geometric Utilitarianism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/strivingforlegibility">StrivingForLegibility</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oTMuc9C3KKdZ6FcCB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/afhsthmxkh51qxnbnkyg.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Procedural Executive Function</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/daystareld">DaystarEld</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xCmj2w2ZrcwxdH9z3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pd0fyvvdyqt7l5nqewng.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Big Picture AI Safety</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/euanmclean">EuanMcLean</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/LN5LaQKkuRv3AMzZY"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ndkwvkl6bin8cmzscjzl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Statistical Mechanics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/j-bostock">J Bostock</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4TT69Yt5FDWijAWab"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ucbczzkojjrcoekqld8n.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Aspiration-based, non-maximizing AI agent designs [Aspiration-based designs]</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jobst-heitzig">Jobst Heitzig</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/PC3yJgdKvk8kzqZyA"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nk0stxekqftc7ehklz91.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Control</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/fabien-roger">Fabien Roger</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/rXu6aHeXGBaru34dm"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/wu1u6pm8yk3goqodz4mz.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Adverse Selection</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ricki-heicklen">Ricki Heicklen</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xHSo6FcdmhziuAABK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/q1chjbiz8fpdm0pe4hnb.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Provable AI Alignment (ProvAIA)</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/maria-kapros">Maria Kapros</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/MrJYDaziAimvX2skP"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/cton85zmumsganzwwv8w.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Weak-To-Strong Generalization (W2SG)</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/maria-kapros">Maria Kapros</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/BCzYL9uuQ3cAdWrDj"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/zvl93jesql15ptgcaana.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Sëbus: A Book About Happiness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sashawu">SashaWu</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HQD8juYNZ2Wj5F4KC"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hkv4khdwm8q0y0xnmpcs.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">On Wholesomeness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/owencb">owencb</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/XJBaPPEYAPeDzuAsy"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/bpfhxrootb3bbaugb1tr.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Sense Of Physical Necessity: A Naturalism Demo</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/brienneyudkowsky">LoganStrohl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/fGbbiJFaoHfXQwMEf"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kmifzvvistwjf3v6wehn.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Deliberative Algorithms as Scaffolding</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/cole-wyeth">Cole Wyeth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Z6vSYoeNBXbDxhARn"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/czdivejo9tchnuoh5eft.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Counterfactuals and Updatelessness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/martinsq">Martín Soto</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ACvmpfhSyKAChzyWi"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/r7zvdwfxekqsdsgfjhfl.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Quantitative cruxes and evidence in Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/martinsq">Martín Soto</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/sCcEZLWHXCaaoMGM8"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gj6zbtnlfr3sjjyhuoj6.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Distributed Strategic Epistemology</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/strivingforlegibility">StrivingForLegibility</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/sZyz9daQRoCLnxeoK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fykndoja7eepkguibc2q.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Delegative Decision Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/strivingforlegibility">StrivingForLegibility</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pbD2D5Ar8ZmfyueWb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/is0eednqhkzmsid3omwd.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Formalising Catastrophic Goodhart</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/vojtakovarik">VojtaKovarik</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/cw2bAC99BRhRe3s5e"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ltckyeplytr9c6iwdffp.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">From Big Ideas To Real-World Results</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/paul-rohde-1">Paul Rohde</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xEkBK3SRrp6DhGf7c"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pc13o6rdk8haadlak7jq.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Rapid Coordination Field Manual</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ampdot">ampdot</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3fKJWML4mgSZmKRm4"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/zedoeymvge56leno7gns.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Ethicophysics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/madhatter-1">MadHatter</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/wtCknhCK4qHdKu98i"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/u7lo7nsviahyumovqkic.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Exploring the Digital Wildnerness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/bill-benzon">Bill Benzon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Qn8DhSrdA2qPH2eJT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lqm3zsxzkwq8gewtmqic.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Game Theory without Argmax</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/cleo-nardo">Cleo Nardo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3QXNgNKXoLrdXJwWE"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qqcvyvug1ovfnpabvpw2.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Value Change Problem (sequence)</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/nora_ammann">Nora_Ammann</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SAjYaHfCAGzKsjHZp"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ue6lrjd7p9qak0hmunvi.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Large Language Model Psychology</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/quentin-feuillade-montixi">Quentin FEUILLADE--MONTIXI</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/EYjH8M5KLmjuNtJEj"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hh2cjrw72wuidexoj4uq.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Monthly Algorithmic Problems in Mech Interp</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/callummcdougall">CallumMcDougall</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/PCRrXJnQn8XWGMgSp"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/dodotlgx8d6qu4jlk7ao.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Crowdsourced knowledge base</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/iwis">iwis</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/9GExrjksy3hCopmNz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gi9ve7bulu9l4y7erxnm.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Waterloo Rationality Meetups Showcase</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jenn">jenn</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/FFyGrZcJqoECGzdjW"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/yzf6ygblg4obhworqd9p.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Consciousness Discourse</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sil-ver">Rafael Harth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aRt3rA2iqDdRosrbs"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mtzwrkdmtwdnl5pamzcv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">An Opinionated Guide to Computability and Complexity</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sharmake-farah">Noosphere89</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xvYFPnHWH2HgaJLAa"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/laveuityitueek3myo7m.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Narrative Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/anton-zheltoukhov">Eris</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SfFQE8DXbgkjk62JK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sydqmaxvgepivxfrz9ct.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Developmental Interpretability</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jesse-hoogland">Jesse Hoogland</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/i5wW3SfeohtTGmNEK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fm1auhxmhvw4ikle3wli.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Meta-rationality</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ricraz">Richard_Ngo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/fYxyZkbxSboLbnJnm"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qwnnvbvyesafgrqujqct.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Catastrophic Risks From AI</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/dan-h">Dan H</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/czrXjvCLsqGepybHC"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qlybo5wtdqpuhy0ads4d.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Distilling Singular Learning Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/liam-carroll">Liam Carroll</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pcdHisDEGLbxrbSHD"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lnhbdq991ckstqnmjcgl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Towards Causal Foundations of Safe AGI</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/tom4everitt">tom4everitt</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/hCwqaQEqeR9mvYtkC"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/baibconyylqi6zwnlgv3.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">CAIS Philosophy Fellowship Midpoint Deliverables</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/dan-h">Dan H</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xoXeJZRCBEBnBoGbC"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jjxqkjcjwjc2jicmmuww.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Machine Learning For Scientific Discovery </div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eleni-angelou">Eleni Angelou</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qXZLFGqpD7aeEgXGL"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/zwfwmyrrz09ydbelj91b.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Replacing fear</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ricraz">Richard_Ngo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/zLib3j2Fdnnx3aP3F"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jddkxtgeufgd3gwzyewz.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Nuts and Bolts of Naturalism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/brienneyudkowsky">LoganStrohl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/sCGfFb5DPfjEmtEdn"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fu4vhd1ud5y4niijbicd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Interpreting a Maze-Solving Network</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/turntrout">TurnTrout</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ypeT2wPARHsyqRE6d"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/m495oy3dchmrqs9cgdvq.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">From Atoms To Agents</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/nhGNHyJHbrofpPbRG"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/cdtrtfuhbzmsmt02vw09.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Interpreting Othello-GPT</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/neel-nanda-1">Neel Nanda</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/szTeA3wBxDPLZ4JWk"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ioijls4uq88ywmapn8ww.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Singularity now: is GPT-4 trying to takeover the world?</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/christopher-king">Christopher King</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/kGwLB3LrYFgtqmjCk"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mklxr0kzd9pknuj0ccr1.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">I'm pretty sure AI is as dumb as We Are</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eve-grey">Eve Grey</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pYsCmc9obhYPuL3u6"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xyqnctcfyc4cd0hzuttl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Untitled Novel</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/xavier-shrier">Xavier Shrier</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/wbPTdgCragwkFNc2T"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/upeottuao2vnnzkf1vju.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">A Data-Driven Path to Effortless Weightloss: Potatoes, Potassium, Drugs, Chocolate, and much much more</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/cuoredivetro">CuoreDiVetro</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/WWx8sZ9tE9skptytH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sfp2p4ev7cgc1rwt3oys.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Shallow Reality of 'Deep Learning Theory'</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jesse-hoogland">Jesse Hoogland</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/mCkMrL9jyR94AAqwW"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ozcq5k5a9bdljajdrzsh.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Leveling Up: advice &amp; resources for junior alignment researchers</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/akash-wasil">Akash</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/GtitGChLssMNnAACK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gnejgf3cwzeh6niek6at.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">LLM Mindreading</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/david-udell">David Udell</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/A9TEiFP8xW8k3ufng"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kg9gupi9exiboyrgruei.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">On Becoming a Great Alignment Researcher (Efficiently)</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jacques-thibodeau">jacquesthibs</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/N7nDePaNabJdnbXeE"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gp0eyntbsd1vx4tszga3.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Simulators</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/janus-1">janus</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/guzvzGnRHzMBWLqKZ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ry3xytraygnpefsjlkn6.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Simulator seminar sequence</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jan-2">Jan</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/kqADGu9teohhezBdu"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/vjnyhazarf1rduofemx1.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Bias in Evaluating AGI X-Risks</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/remmelt-ellen">Remmelt</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/vWuwsyNCNzYmtHn5Q"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/o7r8lnz92g9zaxxqzbbj.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Developments toward Uncontrollable AI</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/remmelt-ellen">Remmelt</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xz6SprQmpHzuehFCz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/itbyl1iidb7lcvb61uy7.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Why Not Try Build Safe AGI?</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/remmelt-ellen">Remmelt</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/YsJsYKhXbyobtBJDW"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jjtohtgkqlgwvta5tdef.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Alignment Stream of Thought</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jozdien">Jozdien</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4hmf7rdfuXDJkxhfg"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/smzefbor0uw8tzlkj9xj.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Geometric Rationality</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scott-garrabrant">Scott Garrabrant</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/g7jBpyxfuddFNgtbZ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gbws9q8r2asyy6704wmd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Some comments on the CAIS paradigm</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/particlemania">particlemania</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/uTtXe9DJABbmCLWLK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gmr8r6qpgl3yj0lj5ort.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">(Lawrence's) Reflections on Research</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lawrencec">LawrenceC</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/t6KTt378yQHJSbDis"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/j0tstysudzzlzoyvpl22.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Entropy from first principles</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/alex_altair">Alex_Altair</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/h95ayYYwMebGEYN5y"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jtzbqdl3stxouo702bgo.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">[Redwood Research] Causal Scrubbing</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lawrencec">LawrenceC</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/AEbqhmiBcxs5kFv72"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/vsa5cnigz9os4xzfymsn.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Generalised models</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HBMLmW9WsgsdZWg4R"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/zjuphaqz788cugxqam6v.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Experiments in instrumental convergence</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/edouard-harris">Edouard Harris</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aK4hyeJyM2sYNS4Yc"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/tlcrrzghctxeom3wxywz.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Research Journals</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/shoshannah-tekofsky">Shoshannah Tekofsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/H3xEgE7bPGKvucfQk"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/b5t9qm0vlokhupbq6lld.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Hypothesis Subspace</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/paul-bricman">Paul Bricman</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/gnAaZtdwjDBBRpDmw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pj40kbneytrownlrszuk.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Maximal Lottery-Lotteries</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scott-garrabrant">Scott Garrabrant</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4WiyAJ2Y7Fuyz8RtM"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lw5ocgbxikjnc96ylwoe.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Thoughts in Philosophy of Science of AI Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/nora_ammann">Nora_Ammann</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/TLSzP4xP42PPBctgw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ew9xftwaeblanqm0wags.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">"Why Not Just..."</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/eqtiQjbk83JHyttrr"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nioey0vmsmfdxwfmfzxm.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Meetup in a box</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/screwtape">Screwtape</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZytYxd523oTnBNnRT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/djyavmfiohab552uyym1.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Law-Following AI</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/cullen_okeefe">Cullen</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pJHp3uBgM2EFCoYn3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/vduxv5qcyaegjrqmlwgy.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">My AI Risk Model</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/peterbarnett">peterbarnett</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/nyEFg3AuJpdAozmoX"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/igo7185zypqhuclvbmiv.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Shard Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/quintin-pope">Quintin Pope</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/jiqxd9ZmSSocs5Qcz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/h7t4jrkxka9cz8gcwjjy.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AGI-assisted Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/tor-okland-barstad">Tor Økland Barstad</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/AthjSa2Sm8jGWCbP5"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ekjvgqkg8dhrc7gi3lmh.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Alignment For Foxes</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lone-pine">Lone Pine</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ApA5XmewGQ8wSrv5C"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hx2qe7bqcpznvp28qecr.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Selection Theorems: Modularity</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/callummcdougall">CallumMcDougall</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pfowch7ryfxniAhyb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/wxpkq5bqm0s12iusg5jt.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Breaking Down Goal-Directed Behaviour</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/oliver-sourbut">Oliver Sourbut</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/B9Qc8ifidAtDpsuu8"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kf43lbtk8qsb0k5xf6hk.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">A Tour of AI Timelines</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/anson-ho">anson.ho</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/CB6F6zyLGMhmfitw9"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/l3besfyrxydbqiyyezsf.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Math Upskilling Notes</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/david-udell">David Udell</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Nsms3ub442NYvw9cb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/eqsj2dzshymipot7sjyv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Networking: A Game Manual</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sts">Severin T. Seehrich</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ogntdnjG6Y9tbLsNS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nbj1jq7brwyuw7ejbajk.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Basic Foundations for Agent Models</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/FaEBwhhe3otzYKGQt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/slevsx1j1haxjctldnrp.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Pragmatic AI Safety</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/dan-h">Dan H</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/opnkEkLCej3mPHwHx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pmltv9dtszc5wp5kdyqd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Insights from Dath Ilan</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/david-udell">David Udell</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/eAuK3qJd678LFdGyz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/io0c2qfnrtfhrmtwgaqf.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">An Inside View of AI Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/anshuman-radhakrishnan-1">Ansh Radhakrishnan</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/DpZy5s9g2TAKEJwst"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/j4m2sdkmmfgde9s5vmst.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Races and Macrostrategy</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/mtrazzi">Michaël Trazzi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/GyvZkBRf8m6NAccgw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xk0gg6ssrjawsadjjwi6.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Treacherous Turn</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/mtrazzi">Michaël Trazzi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aB9DPaYnktuufLy47"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gsp7brjwlterqhyun9rb.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Inside View (Podcast)</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/mtrazzi">Michaël Trazzi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/rmZt45HAxFFgJ8vEH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/smnncjswwfimrf7whpzc.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Winding My Way Through Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/david-udell">David Udell</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/jef8ntrWuJ7SvZjCM"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/f2axdsbocokopu8xqlhi.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Interpretability Research for the Most Important Century</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/evan-r-murphy">Evan R. Murphy</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/2TBwjAn2TPyJMDEui"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/dhmcniqhalzr0k4wtzce.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Neural Networks, More than you wanted to Show</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/donald-hobson">Donald Hobson</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/u9uawicHx7Ng7vwxA"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ioryyvk58iumc7rqrxrk.gif"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Concept Extrapolation</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pfxyqvAZ4o4bguAJk"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qeqgeavixfgpmuwra8cd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Calculus in Game and Decision Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/heighn">Heighn</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/KgrG4cQdLtL9DvNr2"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/islbncjmdnjzycymbxsm.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Alignment Stream of Thought</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/leogao">leogao</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/jstoEiuKxHPfASRJK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fikythwrcfe0varcc0o6.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Civilization &amp; Cooperation</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/duncan-sabien-deactivated">Duncan Sabien (Deactivated)</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/T9pBzinPXYB3mxSGi"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/olbwt8pvheukxrffwrjl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Trends in Machine Learning</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jsevillamol">Jsevillamol</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HMs2yT9D6LjYR5jQT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lmo4v4vwjfmm17m1yi1r.webp"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Fundamental Uncertainty: A Book</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/gordon-seidoh-worley">Gordon Seidoh Worley</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/q2WQMoQSexx7xqqZR"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nmulhhhejomtinqwokqo.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Intuitive Introduction to Functional Decision Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/heighn">Heighn</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HzcM2dkCq7fwXBej8"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/syfg3bxc7ltctmwh6tdy.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Intro to Brain-Like-AGI Safety</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/steve2152">Steven Byrnes</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/nDjTh6xRPL23YSH6k"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rkfbvapopx8d13qkjcdp.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Mechanics of Tradecraft</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lc">lc</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/CDF4uBtZnef6TMpQ6"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/th1woz0nsth3n8cqr6jn.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Independent AI Research </div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/j-bostock">J Bostock</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aek5ksSs2FHTeofsf"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jzecciql3lon4euljay8.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Agency: What it is and why it matters</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/daniel-kokotajlo">Daniel Kokotajlo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/vLArRpNdkex68oem8"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/yuauvyzko4ttusbzpkkz.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Thoughts on Corrigibility</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/turntrout">TurnTrout</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/LLEJJoaYpCoS5JYSY"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/j3kqlrz4cpyilodutaz0.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Epistemic Cookbook for Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/bJi3hd8E8qjBeHz9Z"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/urllfotmjrjlirssmxvb.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Transformative AI and Compute</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lennart">lennart</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xujLGRKFLKsPCTimd"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/kxuwii95ftf9rqlhh8u4.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Safety Subprojects</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/MCYqCMTsDHbn3kcKg"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gbmam3lajmmdgxfnwd6z.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Coordination Frontier</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/gDiScDuMrWNpzwNSJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mckwcocoomsz3kav1rhe.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">D&amp;D.Sci</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abstractapplic">abstractapplic</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Fu7Euu3F96rKhFRWH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sulofl6pfuwna4z1kelm.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Framing Practicum</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/zCksS4AXFnLBWweC6"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rmcuabpdpjfalf8oujuc.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Rationality in Research</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/j-bostock">J Bostock</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/STQByy4J8NfLKkGQa"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/egwdzq0ns5dahonxsqqm.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Defense in Depth: A Layman's Guide</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/carlos-ramirez">Carlos Ramirez</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aERZoriyHfCqvWkzg"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/igazgiypmjrfxytj6sr7.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Modeling Transformative AI Risk (MTAIR)</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/davidmanheim">Davidmanheim</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HFyami76kSs4vEHqy"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/cdk1lbbugck3fuhyqznr.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Practical Guide to Anthropics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/fSMbebQyR4wheRrvk"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hawnw9czray8awc74rnl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Causes of Power-seeking and Instrumental Convergence</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/turntrout">TurnTrout</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/jyqhEPACWZy8vYfGD"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rwfdloqbow07oxromibo.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">2021 Less Wrong Darwin Game</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/kxs3eeEti9ouwWFzr"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/papqhmf2yk4akum0c96m.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Finite Factored Sets</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scott-garrabrant">Scott Garrabrant</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/z7wp9Bkqc9A9zK53M"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mt8fxuupvxsfbdoyurwx.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Comprehensive Information Gatherings</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Ejxov75SxyPXsATRn"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/l7p6vhx7f9elyi0dmqsn.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Using Credence Calibration for Everything</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/christiankl">ChristianKl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/kmryZRz5r9bjsug9e"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ulp94jg5elf2chyiyk1s.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Anthropic Decision Theory</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/pvXAS868E2BZEc2Fu"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/v28qejntskxxzhein3id.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Reviews for the Alignment Forum</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xqgwpmwDYsn8osoje"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/aqdcs1betbxutz09ovuh.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Notes on Virtues</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/david-gross">David Gross</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/eC3gbMmpvt9LxeDap"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/k1tdbwn2g9y5ypgodvwu.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Participating in a Covid-19 Vaccination Trial</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ejacob">ejacob</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/tYCu3WG89kAW8QmoM"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jxzxbyckaescizy2kqvx.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Predictions &amp; Self-awareness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/john_maxwell">John_Maxwell</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Gmc7vtnpyKZRHWdt5"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/yby8iw13ritasosi2wyh.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Pointing at Normativity</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3dCMdafmKmb6dRjMF"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/wnlmweawfjjklihjixlw.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Counterfactual Planning</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/koen-holtman">Koen.Holtman</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qpvqinidbEE3i73Jd"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/scowd9dmlwwoetx7qg1q.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Alignment Unwrapped</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/5Eg2urmQjA4ZNcezy"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ghpu9dsknv3las9zbkts.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Timelines</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/daniel-kokotajlo">Daniel Kokotajlo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/9TN3i7Q4PPdkx86hA"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lpubrzavuciv5ev2hadh.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Pseudorandomness Contest</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/unexpectedvalues">Eric Neyman</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/TjdhvTSptCYakw3Lc"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/tznrkjpde92au0xgrpki.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Bayeswatch</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/weBHYgBXg9thEQNEe"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fn5yd3xegiqolxco9r0f.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Cryonics Signup Guide</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/mingyuan">mingyuan</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/TfPXpiwaESD65Mokx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/cstwcfjqlrfu3t6vp4yz.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">NLP and other Self-Improvement</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/christiankl">ChristianKl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/dZMDxPBZgHzorNDTt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/j5gwomexig10cowr2aqa.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Takeoff and Takeover in the Past and Future</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/daniel-kokotajlo">Daniel Kokotajlo</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/NqMKtBufKW4Wht6rZ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rldwvn4se1tgbxye5ot5.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Forecasting Newsletter</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/nunosempere">NunoSempere</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ReFDRRfGDec4AadbE"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/yctst2bgouu1dbmjhpsr.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Sunzi's《Methods of War》</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/rencyawwfr4rfwt5C"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/otywqf6z3hibsyjzf6hh.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">COVID-19 Updates and Analysis</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/zvi">Zvi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/o58ZMNaovdztbLfvN"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gdsxz69znyhwqmwxscci.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Deconfusing Goal-Directedness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/B26RwutvaDa6hvJuP"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ymrbpsuqop40irqdqrss.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Grueling Subject</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/christiankl">ChristianKl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/wKPWFvdMyvgDWfusX"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lu1ai6md81d4baooaqke.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">2020 Less Wrong Darwin Game</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/nJzqnsZCfg2k4s2BP"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mnqx0jyutuarhup7dv6r.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Quantitative Finance</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/xezt7HYfpWR6nwp7Z"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/un3g7ivwgsq7a2rjonxg.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Factored Cognition</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sil-ver">Rafael Harth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/sSaQTybKvfGf4PDNh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/uwnok8aofw3nc8but4ef.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Zen and Rationality</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/gordon-seidoh-worley">Gordon Seidoh Worley</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/akMLzwcRdJNnmBoLa"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/zanxblogtn9p4vdklctd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Privacy Practices</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/wnQWakxdRodnKm5kH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fzui7w4ivtmerhnpbagd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Staying Sane While Taking Ideas Seriously</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/orthonormal">orthonormal</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/bQ32GY5waKWi88vdX"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hgjwpdw7tn2srnixkq2k.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Naturalized Induction</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/robbbb">Rob Bensinger</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/WZNq65bHHKwQasyP6"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lzlskfwpvezagrmnvs01.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">What You Can and Can't Learn from Games</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/davis_kingsley">Davis_Kingsley</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qMtriMPLdriNkAfSJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xav5uhzztpedlv5oghj1.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Short Stories</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/DTnoFhDm7ZT2ecJMw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fd5xursprgfsdr2npyuv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Toying With Goal-Directedness</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/T8PftwGSnxgxTzpip"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/awj56iuivlzxw7qljui9.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Against Rationalization II</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/dspeyer">dspeyer</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HmANELvkhAZ9eDxFS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/l7yrnqdlxaxs9zugjlwe.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Consequences of Logical Induction</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZnWZRqi5mhXxXaD6z"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/cpre6odkeicn9udxubgc.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Through the Haskell Jungle</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/JWD7qZZ5A8CYe82uA"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/c6uuako804bvchtpuvxb.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Lessons from Isaac</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/adamshimi">adamShimi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/5MFN7FnvKFL9ynXXX"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ffdjf7oete6zhk97gpop.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Filk</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/gordon-seidoh-worley">Gordon Seidoh Worley</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/iRwYCpcAXuFD24tHh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/bzf1gg0u70r2med4zl4j.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Subagents and impact measures</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/knbhjv252HshMSwpt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/rzm0l9swjnzkpkhdv3pj.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">If I were a well-intentioned AI...</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/stuart_armstrong">Stuart_Armstrong</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4NFwxwzLzpiikfkk3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ssjjtlezhpn0ohdj70xr.gif"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Moral uncertainty</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/michaela">MichaelA</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/5CNs9wmHWFQTNjFKo"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/n7mmd8y0qqxspgczwlxo.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Medical Paradigms</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/christiankl">ChristianKl</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/C8wgFMCmoMNbvDSMP"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pnnxmjqtobtjigu8npvy.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Understanding Machine Learning</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/sil-ver">Rafael Harth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3xKXGh9RXaYTYZYgZ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hzjcr0aemfscqjqqmcot.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Antimemetics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/lsusr">lsusr</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3hfjaztptwEt2cCve"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/bfiiu2gxl9cmqdzupyq1.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Gears of Aging</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aQTBuq9X98m2KkWpx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/wqk7v5xrrzsicqeqaq1d.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Map and Territory Cross-Posts</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/gordon-seidoh-worley">Gordon Seidoh Worley</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/CRvxidrCkp7YE7gSK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/brectils3qx8qld40pwx.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Phenomenological AI Alignment</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/gordon-seidoh-worley">Gordon Seidoh Worley</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/BP8vfvg5RhXsBERX9"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hnfysaizcam3hxcolhu4.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Changing your Mind With Memory Reconsolidation</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/mr-hire">Matt Goldenberg</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/cSQHJPrpSvwt9dRyW"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ghbmxx3vlp7guodnnbiq.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">base-line to enlightenment - the physical route to better</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/leggi">leggi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HeYtBkNbEe7wpjc6X"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/lo7y1hicsr26hauyceuy.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Partial Agency</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/8Kc3YamAyaACWXwb3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/v3ajhz2g8a3smfoe0rzg.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Concept Safety</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/kaj_sotala">Kaj_Sotala</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/YuTinYEzsyHmPoocw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/af5nlyg8hegpowunhuvh.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Alignment Writing Day 2019</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/benito">Ben Pace</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/GTEay24Lxm3xoE4hy"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/wvbqtcv9ymlfnupzvqbs.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Novum Organum</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ruby">Ruby</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Js5d6ddsCkAQskjbz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/gs4cvrauqegczcwxkwbp.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Logical Counterfactuals and Proposition graphs</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/donald-hobson">Donald Hobson</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3qa3jAE9sqFqH9okL"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ywdewueykortbn24udxz.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">AI Alignment Writing Day 2018</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/benito">Ben Pace</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/nMGrhBYXWjPhZoyNL"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/of8ou0qm4hsuzesaajqb.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Daily Insights</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/matthew-barnett">Matthew Barnett</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nzjkcyvey3hvevcpnrks.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Model Comparison</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/johnswentworth">johnswentworth</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/7CdoznhJaLEKHwvJW"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/izfzehxanx48hvf10lnl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Reframing Impact</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/turntrout">TurnTrout</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SBfqYgHf2zvxyKDtB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qd9wvl6nusnr0welcjps.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Alternate Alignment Ideas</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/FYMiCeXEgMzsB5stm"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xwf1fjfnznrnjxfed47e.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Concepts in formal epistemology</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/habryka4">habryka</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/96XzQgTL2HBNkBwL4"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xefmk3xj3uotojpo3ckv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">So You Want To Colonize The Universe</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/diffractor">Diffractor</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/Yh4YsGDD9WYiZqRnf"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mctmz7gacncxldcu1wz0.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Mechanism Design</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/badger">badger</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/9s8CgrX5C3AEw9ZM2"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/horzoacdquuitpc6q4mv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Decision Analysis</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/vaniver">Vaniver</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/hs42Xd4joLcTP6uTb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/r8usyus20ivlpuj8np6i.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Priming</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/sdTckKmNM6zb7yGRt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/mjogxcwbbaclxmmckeiw.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Positivism and Self Deception</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/vz9Zrj3oBGsttG3Jh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/julk2d57t313v13ouuiv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Kickstarter for Coordinated Action</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/YX6dCo6NSNQJDEwXR"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/hwp3py6c4gaada6ehcrt.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Prediction-Driven Collaborative Reasoning Systems</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/ozziegooen">ozziegooen</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/59wjNdSYeakrjuubu"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/uxa2se2zqqpiugkuvc8t.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Assorted Maths</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/donald-hobson">Donald Hobson</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/jzezzpcw18v4khqsm9am.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Multiagent Models of Mind</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/kaj_sotala">Kaj_Sotala</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/yai5mppkuCHPQmzpN"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xuf9i29cbjdx4nwmwqmd.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Open Threads</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/n44Fqx5W4BhMugCMS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/tmrrkzlxrso98pfuuwdl.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Keith Stanovich: What Intelligence Tests Miss</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/kaj_sotala">Kaj_Sotala</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/uLEjM2ij5y3CXXW6c"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/q5nsfykzhz81bmljrghs.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Filtered Evidence, Filtered Arguments</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/fgHSwxFitysGKHH56"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xgnadljnuhg4ylqdln3b.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">CDT=EDT?</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/5WF3wmwvxX9TEbFXf"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pjuagn5hgu8m1ry2humq.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Fixed Points</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scott-garrabrant">Scott Garrabrant</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/W2fkmatEzyrmbbrDt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/ds26mimg1uvv82k5d63v.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Metaethics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ePDpMhJoKCff6qnvh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/e0chotk2uafu1ic9kvny.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Quantum Physics</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/AmFb5xWbPWWQyQ244"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/nczv7w6hr10v4rumtusv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Ethical Injunctions</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/dT7CKGXwq9vt76CeX"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/b7vwrndrypohpwvcfkpc.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Alignment Newsletter</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/rohinmshah">Rohin Shah</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/zucjLBpQ9S9eWPWGu"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/q4ojwvuezywfaps2ggb6.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Share Models, Not Beliefs</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/benito">Ben Pace</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZBNBTSMAXbyJwJoKY"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/txb8l4ka4fq6sofvazkb.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Voting Theory Primer for Rationalists</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/jameson-quinn">Jameson Quinn</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/KGYLvTqFiFE2CpHfJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/fkqj34glr5rquxm6z9sr.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Becoming Stronger</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/turntrout">TurnTrout</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/HcMcHb6Cz7R9RdC5D"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/bh1xoz9srtcz0inmhgce.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Hufflepuff Cynicism</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/abramdemski">abramdemski</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/aoLetzM8xnBPqKBGj"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/sp6frpnna2ygpjbcegci.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Tensions in Truthseeking</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/4C33PKt2cQdA7oyfJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/cif8pkhxt31hf3v7eksv.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Murphy's Quest</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/alkjash">alkjash</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oyZGWX9WkgWzEDt6M"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/t3pxywtw1baepqsjeljw.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Project Hufflepuff</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/9rRrzkBaXcivjZtZS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/pjqk3risfgu2idnvy4gv.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Instrumental Rationality</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/cuFK7pjwdDEoQewid"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/qbud3h3pnwtgmjvmizgg.png"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Philosophy Corner</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/charlie-steiner">Charlie Steiner</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/3bbvzoRA8n6ZgbiyK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/s7y4ljhyfpt4o2quyi7g.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Rational Ritual</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/GcZCMu7ZYHpJCh5bx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/xck0kfqyngm0qgubpctj.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">The Darwin Game</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/zvi">Zvi</a></span></span></span></div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/WPgA9x5ZvKu9oYvgB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="The%20Library%20%E2%80%94%20LessWrong_files/bq5jmtw9pxqliaievqab.jpg"></div><div class="SequencesGridItem-meta"><div class="SequencesGridItem-title">Drawing Less Wrong</div><div class="SequencesGridItem-author">by <span><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/raemon">Raemon</a></span></span></span></div></div></div></span></div></div></div></div></div></div><div class="Footer-root"></div></div><div class="Layout-imageColumn"><picture><img loading="lazy" src="The%20Library%20%E2%80%94%20LessWrong_files/ohabryka_Topographic_aquarelle_book_cover_by_Thomas_W.jpg" class="Layout-backgroundImage"></picture></div></div></div></div>

<script>window.ssrRenderedAt = "2024-10-10T20:32:26.923Z"</script>
<script>window.ssrMetadata = {"renderedAt":"2024-10-10T20:32:26.923Z","cacheFriendly":false,"timezone":"Atlantic/Reykjavik"}</script>
<script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","currentUser":null,"unreadNotificationCounts":{"__typename":"NotificationCounts","unreadNotifications":0,"unreadPrivateMessages":0,"faviconBadgeNumber":0,"checkedAt":"2024-10-10T20:32:26.946Z"},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":2,\"view\":\"globalEvents\"}}})":{"__typename":"MultiPostOutput","results":[],"totalCount":null},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":100,\"view\":\"curatedSequences\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:5g5TkQTe9rmPS5vvM"},{"__ref":"Sequence:NBDFAKt3GbFwnwzQF"},{"__ref":"Sequence:PtgH6ALi5CoJnPmGS"},{"__ref":"Sequence:mzgtmmTKKn5MuCzFJ"},{"__ref":"Sequence:XsMTxdQ6fprAQMoKi"},{"__ref":"Sequence:Rm6oQRJJmhGCcLvxh"},{"__ref":"Sequence:v55BhXbpJuaExkpcD"},{"__ref":"Sequence:n945eovrA3oDueqtq"},{"__ref":"Sequence:ZnSMHcWjRx6yT4H92"},{"__ref":"Sequence:CmrW8fCmSLK7E25sa"},{"__ref":"Sequence:evLkoqsbi79AnM5sz"},{"__ref":"Sequence:pFatcKW3JJhTSxqAF"},{"__ref":"Sequence:n3utvGrgC2SGi9xQX"},{"__ref":"Sequence:f2YA4eGskeztcJsqT"},{"__ref":"Sequence:a6ne2ve5uturEEQK7"},{"__ref":"Sequence:dDMzozPbe4aJRkfTr"},{"__ref":"Sequence:6uDBPacS6zDipqbZ9"},{"__ref":"Sequence:BbAvHtorCZqp97X9W"},{"__ref":"Sequence:TF77XsD5PbucbJsG3"},{"__ref":"Sequence:yYxggfHYRrqnJXuRx"},{"__ref":"Sequence:EmDuGeRw749sD3GKd"},{"__ref":"Sequence:4dHMdK5TLN6xcqtyc"},{"__ref":"Sequence:KAv8z6oJCTxjR8vdR"},{"__ref":"Sequence:xEFeCwk3pdYdeG2rL"},{"__ref":"Sequence:kNANcHLNtJt5qeuSS"},{"__ref":"Sequence:hBFDRZCPLcrRDubgm"},{"__ref":"Sequence:r9tYkB2a8Fp4DN8yB"},{"__ref":"Sequence:d3WgHDBAPYYScp5Em"},{"__ref":"Sequence:qWoFR4ytMpQ5vw3FT"},{"__ref":"Sequence:HXkpm9b8o964jbQ89"},{"__ref":"Sequence:ZNNi2uNx9E6iwGKKG"},{"__ref":"Sequence:G2GDw3m4MJ5ixSM92"},{"__ref":"Sequence:qRxTKm7DAftSuTGvj"},{"__ref":"Sequence:pC6DYFLPMTCbEwH8W"},{"__ref":"Sequence:SqFbMbtxGybdS2gRs"},{"__ref":"Sequence:yFvZa9wkv5JoqhM8F"},{"__ref":"Sequence:XipJ7DMjYyriAm7fr"},{"__ref":"Sequence:oi873FWi6pHWxswSa"},{"__ref":"Sequence:bQgRsy23biR52poMf"},{"__ref":"Sequence:oLGCcbnvabyibnG9d"},{"__ref":"Sequence:2A7rrZ4ySx6R8mfoT"},{"__ref":"Sequence:ynMFrq9K5iNMfSZNg"}],"totalCount":42},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":12,\"view\":\"communitySequences\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:qhdHbCJ3PYesL9dde"},{"__ref":"Sequence:B9HWqQSt3NcLx34qc"},{"__ref":"Sequence:Ed7Ffv4LLK3GS3oj3"},{"__ref":"Sequence:gEvTvhr8hNRrdHC62"},{"__ref":"Sequence:pwazxmKw7qKo8hoWo"},{"__ref":"Sequence:KfCjeconYRdFbMxsy"},{"__ref":"Sequence:SybKaNSqyADrnMQ7H"},{"__ref":"Sequence:3kQJuSMxoiYWnvLcA"},{"__ref":"Sequence:4toN42rxApcqMb8uY"},{"__ref":"Sequence:oTMuc9C3KKdZ6FcCB"},{"__ref":"Sequence:xCmj2w2ZrcwxdH9z3"},{"__ref":"Sequence:LN5LaQKkuRv3AMzZY"}],"totalCount":211},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"globalEvent\":false,\"limit\":2,\"view\":\"events\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:drSKaciaB3JoBeoST"},{"__ref":"Post:mL88XQ4k75dgWxCpL"}],"totalCount":null}},"User:nmk3nLpQE89dMRzzN":{"_id":"nmk3nLpQE89dMRzzN","__typename":"User","slug":"eliezer_yudkowsky","createdAt":"2009-02-23T21:58:56.739Z","username":"Eliezer_Yudkowsky","displayName":"Eliezer Yudkowsky","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":144836,"afKarma":1831,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":951,"commentCount":7584,"sequenceCount":40,"afPostCount":18,"afCommentCount":116,"spamRiskScore":1,"tagRevisionCount":324,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:5g5TkQTe9rmPS5vvM_contents":{"_id":"5g5TkQTe9rmPS5vvM_contents","__typename":"Revision","version":"1.9.0","updateType":"minor","editedAt":"2020-07-01T21:50:13.355Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.<\/p><p>It is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin.<\/p><\/body><\/html>","commitMessage":"","wordCount":87,"htmlHighlight":"<html><head><\/head><body><p>This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.<\/p><p>It is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin.<\/p><\/body><\/html>","plaintextDescription":"This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.\n\nIt is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin."},"Collection:oneQyj4pw77ynzwAF":{"_id":"oneQyj4pw77ynzwAF","__typename":"Collection","title":"Rationality: A-Z"},"Sequence:5g5TkQTe9rmPS5vvM":{"_id":"5g5TkQTe9rmPS5vvM","__typename":"Sequence","createdAt":"2017-08-24T01:49:39.814Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:5g5TkQTe9rmPS5vvM_contents"},"gridImageId":"sequencesgrid/wwkkaskmbcajjogyv1hu","bannerImageId":"sequences/bkywjoighcyelqiphpom","canonicalCollectionSlug":"rationality","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":504,"userProfileOrder":null,"af":false,"postsCount":12,"readPostsCount":0,"title":"Predictably Wrong","canonicalCollection":{"__ref":"Collection:oneQyj4pw77ynzwAF"}},"User:qgdGA4ZEyW7zNdK84":{"_id":"qgdGA4ZEyW7zNdK84","__typename":"User","slug":"ruby","createdAt":"2014-04-03T03:38:23.914Z","username":"Ruby","displayName":"Ruby","profileImageId":null,"previousDisplayName":null,"fullName":"Ruben Bloom","karma":13259,"afKarma":137,"deleted":false,"isAdmin":true,"htmlBio":"<p>LessWrong Team<\/p><p>&nbsp;<\/p><p>I have signed no contracts or agreements whose existence I cannot mention.<\/p>","jobTitle":null,"organization":null,"postCount":163,"commentCount":1614,"sequenceCount":11,"afPostCount":3,"afCommentCount":33,"spamRiskScore":1,"tagRevisionCount":963,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:NBDFAKt3GbFwnwzQF_contents":{"_id":"NBDFAKt3GbFwnwzQF_contents","__typename":"Revision","version":"1.14.0","updateType":"minor","editedAt":"2022-07-14T00:23:22.928Z","userId":"qgdGA4ZEyW7zNdK84","html":"<p><i>Part 1 of 6 from the <\/i><a href=\"https://www.lesswrong.com/highlights\"><i>Sequence Highlights<\/i><\/a><i>.&nbsp;<\/i><\/p><p>Humans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality.&nbsp;<\/p>","commitMessage":"","wordCount":43,"htmlHighlight":"<p><i>Part 1 of 6 from the <\/i><a href=\"https://www.lesswrong.com/highlights\"><i>Sequence Highlights<\/i><\/a><i>.&nbsp;<\/i><\/p><p>Humans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality.&nbsp;<\/p>","plaintextDescription":"Part 1 of 6 from the Sequence Highlights. \n\nHumans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality. "},"Collection:62bf5f5dc581cd211cc67d49":{"_id":"62bf5f5dc581cd211cc67d49","__typename":"Collection","title":"Highlights from the Sequences"},"Sequence:NBDFAKt3GbFwnwzQF":{"_id":"NBDFAKt3GbFwnwzQF","__typename":"Sequence","createdAt":"2022-07-01T22:07:11.265Z","userId":"qgdGA4ZEyW7zNdK84","user":{"__ref":"User:qgdGA4ZEyW7zNdK84"},"contents":{"__ref":"Revision:NBDFAKt3GbFwnwzQF_contents"},"gridImageId":"sequencesgrid/vuzt0hjdrboxywfd4wbt","bannerImageId":"sequences/rdl8pwokejuqyxipg6vx","canonicalCollectionSlug":"highlights","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":true,"noindex":false,"curatedOrder":502,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":0,"title":"Thinking Better on Purpose","canonicalCollection":{"__ref":"Collection:62bf5f5dc581cd211cc67d49"}},"Revision:PtgH6ALi5CoJnPmGS_contents":{"_id":"PtgH6ALi5CoJnPmGS_contents","__typename":"Revision","version":"1.8.0","updateType":"minor","editedAt":"2022-10-14T21:21:45.337Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Harry: You can't DO that!<\/p><p>Minerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—<\/p><p>Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?<\/p><p>Minerva: Magic.<\/p><p>Harry: Magic isn't enough to do that! You'd have to be a god!<\/p><p>—Harry's first encounter with magic<\/p>","commitMessage":"","wordCount":82,"htmlHighlight":"<p>Harry: You can't DO that!<\/p><p>Minerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—<\/p><p>Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?<\/p><p>Minerva: Magic.<\/p><p>Harry: Magic isn't enough to do that! You'd have to be a god!<\/p><p>—Harry's first encounter with magic<\/p>","plaintextDescription":"Harry: You can't DO that!\n\nMinerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—\n\nHarry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?\n\nMinerva: Magic.\n\nHarry: Magic isn't enough to do that! You'd have to be a god!\n\n—Harry's first encounter with magic"},"Collection:ywQvGBSojSQZTMpLh":{"_id":"ywQvGBSojSQZTMpLh","__typename":"Collection","title":"Harry Potter and the Methods of Rationality"},"Sequence:PtgH6ALi5CoJnPmGS":{"_id":"PtgH6ALi5CoJnPmGS","__typename":"Sequence","createdAt":"2017-08-23T21:44:40.795Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:PtgH6ALi5CoJnPmGS_contents"},"gridImageId":"sequences/i9dkgkhw14vwar63i4xn","bannerImageId":"sequences/cjcnbiwocxsxp1qnoywt","canonicalCollectionSlug":"hpmor","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":502,"userProfileOrder":null,"af":false,"postsCount":21,"readPostsCount":0,"title":"The Methods of Rationality","canonicalCollection":{"__ref":"Collection:ywQvGBSojSQZTMpLh"}},"User:BCmzFRdQhqLPREvat":{"_id":"BCmzFRdQhqLPREvat","__typename":"User","slug":"ricraz","createdAt":"2013-07-14T15:42:06.397Z","username":"ricraz","displayName":"Richard_Ngo","profileImageId":null,"previousDisplayName":null,"fullName":"Richard Ngo","karma":16582,"afKarma":2678,"deleted":false,"isAdmin":false,"htmlBio":"<p>Former AI safety research engineer, now AI governance researcher at OpenAI. Blog: <a href=\"https://thinkingcomplete.com\">thinkingcomplete.com<\/a><\/p>","jobTitle":null,"organization":null,"postCount":157,"commentCount":995,"sequenceCount":7,"afPostCount":53,"afCommentCount":357,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:mzgtmmTKKn5MuCzFJ_contents":{"_id":"mzgtmmTKKn5MuCzFJ_contents","__typename":"Revision","version":"1.4.0","updateType":"minor","editedAt":"2022-12-24T07:52:34.985Z","userId":"grecHJcgkb3KW5wnM","html":"<p>In this report (also <a href=\"https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing\">available here as a PDF<\/a>) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles.<\/p>","commitMessage":"","wordCount":138,"htmlHighlight":"<p>In this report (also <a href=\"https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing\">available here as a PDF<\/a>) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles.<\/p>","plaintextDescription":"In this report (also available here as a PDF) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles."},"Sequence:mzgtmmTKKn5MuCzFJ":{"_id":"mzgtmmTKKn5MuCzFJ","__typename":"Sequence","createdAt":"2020-09-28T13:58:47.550Z","userId":"BCmzFRdQhqLPREvat","user":{"__ref":"User:BCmzFRdQhqLPREvat"},"contents":{"__ref":"Revision:mzgtmmTKKn5MuCzFJ_contents"},"gridImageId":"sequencesgrid/r68kkaexxymt3ckkc6pp","bannerImageId":"sequences/zxck6do8omxqiussiz5k","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":499,"userProfileOrder":1,"af":true,"postsCount":7,"readPostsCount":0,"title":"AGI safety from first principles","canonicalCollection":null},"User:XgYW5s8njaYrtyP7q":{"_id":"XgYW5s8njaYrtyP7q","__typename":"User","slug":"scottalexander","createdAt":"2009-02-28T15:53:46.032Z","username":"Yvain","displayName":"Scott Alexander","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":42640,"afKarma":73,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":217,"commentCount":1577,"sequenceCount":15,"afPostCount":1,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":19,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:XsMTxdQ6fprAQMoKi_contents":{"_id":"XsMTxdQ6fprAQMoKi_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-07-01T21:46:04.937Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","commitMessage":"","wordCount":20,"htmlHighlight":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","plaintextDescription":"A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them."},"Collection:2izXHCrmJ684AnZ5X":{"_id":"2izXHCrmJ684AnZ5X","__typename":"Collection","title":"The Codex"},"Sequence:XsMTxdQ6fprAQMoKi":{"_id":"XsMTxdQ6fprAQMoKi","__typename":"Sequence","createdAt":"2017-08-24T01:21:12.377Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:XsMTxdQ6fprAQMoKi_contents"},"gridImageId":"sequencesgrid/rfpef83ejiwbsi1pmroz","bannerImageId":"sequences/i345prxcdiiwgczlrsya","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":499,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":0,"title":"Argument and Analysis","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"User:Q7NW4XaWQmfPfdcFj":{"_id":"Q7NW4XaWQmfPfdcFj","__typename":"User","slug":"abramdemski","createdAt":"2009-03-12T06:07:25.510Z","username":"abramdemski","displayName":"abramdemski","profileImageId":null,"previousDisplayName":null,"fullName":"Abram Demski","karma":17902,"afKarma":3353,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":213,"commentCount":1951,"sequenceCount":9,"afPostCount":101,"afCommentCount":604,"spamRiskScore":1,"tagRevisionCount":87,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:Rm6oQRJJmhGCcLvxh_contents":{"_id":"Rm6oQRJJmhGCcLvxh_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2019-11-28T08:22:39.871Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency.<\/p>","commitMessage":null,"wordCount":20,"htmlHighlight":"<p>This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency.<\/p>","plaintextDescription":"This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency."},"Sequence:Rm6oQRJJmhGCcLvxh":{"_id":"Rm6oQRJJmhGCcLvxh","__typename":"Sequence","createdAt":"2018-10-29T13:26:42.043Z","userId":"Q7NW4XaWQmfPfdcFj","user":{"__ref":"User:Q7NW4XaWQmfPfdcFj"},"contents":{"__ref":"Revision:Rm6oQRJJmhGCcLvxh_contents"},"gridImageId":"sequencesgrid/mxpqfzoorr921qviypmq","bannerImageId":"sequences/eoxmiqgdxndzkbhsws1z","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":495,"userProfileOrder":null,"af":true,"postsCount":7,"readPostsCount":0,"title":"Embedded Agency","canonicalCollection":null},"User:2aoRX3ookcCozcb3m":{"_id":"2aoRX3ookcCozcb3m","__typename":"User","slug":"robbbb","createdAt":"2012-08-10T00:50:11.669Z","username":"RobbBB","displayName":"Rob Bensinger","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":21767,"afKarma":1379,"deleted":false,"isAdmin":true,"htmlBio":"<p>Communications @ MIRI. Unless otherwise indicated, my posts and comments here reflect my own views, and not necessarily my employer's. (Though we agree about an awful lot.)<\/p>","jobTitle":null,"organization":null,"postCount":123,"commentCount":2212,"sequenceCount":5,"afPostCount":12,"afCommentCount":189,"spamRiskScore":1,"tagRevisionCount":117,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:v55BhXbpJuaExkpcD_contents":{"_id":"v55BhXbpJuaExkpcD_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-06-16T04:35:35.951Z","userId":"2aoRX3ookcCozcb3m","html":"<p>A collection of MIRI write-ups and conversations about alignment released in 2022, following the <a href=\"https://www.lesswrong.com/s/n945eovrA3oDueqtq\">Late 2021 MIRI Conversations<\/a>.<\/p>","commitMessage":"","wordCount":18,"htmlHighlight":"<p>A collection of MIRI write-ups and conversations about alignment released in 2022, following the <a href=\"https://www.lesswrong.com/s/n945eovrA3oDueqtq\">Late 2021 MIRI Conversations<\/a>.<\/p>","plaintextDescription":"A collection of MIRI write-ups and conversations about alignment released in 2022, following the Late 2021 MIRI Conversations."},"Sequence:v55BhXbpJuaExkpcD":{"_id":"v55BhXbpJuaExkpcD","__typename":"Sequence","createdAt":"2022-06-15T13:22:48.792Z","userId":"2aoRX3ookcCozcb3m","user":{"__ref":"User:2aoRX3ookcCozcb3m"},"contents":{"__ref":"Revision:v55BhXbpJuaExkpcD_contents"},"gridImageId":"sequencesgrid/hxbqvswdmhyoomidbpyu","bannerImageId":"sequences/bnagpl4ipkzivsuvj8di","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":494,"userProfileOrder":null,"af":true,"postsCount":23,"readPostsCount":0,"title":"2022 MIRI Alignment Discussion","canonicalCollection":null},"Revision:n945eovrA3oDueqtq_contents":{"_id":"n945eovrA3oDueqtq_contents","__typename":"Revision","version":"1.7.0","updateType":"minor","editedAt":"2022-07-06T23:27:31.966Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.<\/p><p>Short summaries of each post, and links to audio versions, are available <a href=\"https://intelligence.org/late-2021-miri-conversations/\">here<\/a>. There are also two related posts released shortly before this sequence:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/CpvyhFy9WvCNsifkY/discussion-with-eliezer-yudkowsky-on-agi-interventions\">Discussion with Eliezer Yudkowsky on AGI Interventions<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/cCMihiwtZx7kdcKgt/comments-on-carlsmith-s-is-power-seeking-ai-an-existential\">Comments [by Nate Soares] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"<\/a><\/li><\/ul><p>Rob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.<\/p><p>⠀<\/p>","commitMessage":"","wordCount":90,"htmlHighlight":"<p>This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.<\/p><p>Short summaries of each post, and links to audio versions, are available <a href=\"https://intelligence.org/late-2021-miri-conversations/\">here<\/a>. There are also two related posts released shortly before this sequence:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/CpvyhFy9WvCNsifkY/discussion-with-eliezer-yudkowsky-on-agi-interventions\">Discussion with Eliezer Yudkowsky on AGI Interventions<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/cCMihiwtZx7kdcKgt/comments-on-carlsmith-s-is-power-seeking-ai-an-existential\">Comments [by Nate Soares] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"<\/a><\/li><\/ul><p>Rob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.<\/p><p>⠀<\/p>","plaintextDescription":"This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.\n\nShort summaries of each post, and links to audio versions, are available here. There are also two related posts released shortly before this sequence:\n\n * Discussion with Eliezer Yudkowsky on AGI Interventions\n * Comments [by Nate Soares] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"\n\nRob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.\n\n⠀"},"Sequence:n945eovrA3oDueqtq":{"_id":"n945eovrA3oDueqtq","__typename":"Sequence","createdAt":"2021-11-15T21:08:28.070Z","userId":"2aoRX3ookcCozcb3m","user":{"__ref":"User:2aoRX3ookcCozcb3m"},"contents":{"__ref":"Revision:n945eovrA3oDueqtq_contents"},"gridImageId":"sequencesgrid/gpk2pxurl1yymecllfoo","bannerImageId":"sequences/zenshq6ta1cmqiaisfka","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":400,"userProfileOrder":null,"af":true,"postsCount":15,"readPostsCount":0,"title":"2021 MIRI Conversations","canonicalCollection":null},"User:r38pkCm7wF4M44MDQ":{"_id":"r38pkCm7wF4M44MDQ","__typename":"User","slug":"raemon","createdAt":"2010-09-09T02:09:20.629Z","username":"Raemon","displayName":"Raemon","profileImageId":null,"previousDisplayName":null,"fullName":"Raymond Arnold","karma":52608,"afKarma":662,"deleted":false,"isAdmin":true,"htmlBio":"<p>LessWrong team member / moderator. I've been a LessWrong organizer since 2011, with roughly equal focus on the cultural, practical and intellectual aspects of the community. My first project was creating the Secular Solstice and helping groups across the world run their own version of it. More recently I've been interested in improving my own epistemic standards and helping others to do so as well.<\/p>","jobTitle":null,"organization":null,"postCount":460,"commentCount":7933,"sequenceCount":28,"afPostCount":3,"afCommentCount":203,"spamRiskScore":1,"tagRevisionCount":270,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:ZnSMHcWjRx6yT4H92_contents":{"_id":"ZnSMHcWjRx6yT4H92_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2023-05-07T17:41:30.975Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:<\/p><ul><li>Read this sequence of posts before discussing politics on LessWrong.<\/li><li>Generally, be extra careful and charitable when discussing politics.<\/li><li>Recent \"news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.<\/li><li>If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture.<\/li><\/ul>","commitMessage":"","wordCount":136,"htmlHighlight":"<p>Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:<\/p><ul><li>Read this sequence of posts before discussing politics on LessWrong.<\/li><li>Generally, be extra careful and charitable when discussing politics.<\/li><li>Recent \"news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.<\/li><li>If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture.<\/li><\/ul>","plaintextDescription":"Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:\n\n * Read this sequence of posts before discussing politics on LessWrong.\n * Generally, be extra careful and charitable when discussing politics.\n * Recent \"news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.\n * If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture."},"Sequence:ZnSMHcWjRx6yT4H92":{"_id":"ZnSMHcWjRx6yT4H92","__typename":"Sequence","createdAt":"2021-08-27T19:12:38.957Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:ZnSMHcWjRx6yT4H92_contents"},"gridImageId":"sequencesgrid/qu5jdoyzz4jov7siczag","bannerImageId":"sequences/vt1dmuiohcsfxdvsfear","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":true,"noindex":false,"curatedOrder":101,"userProfileOrder":null,"af":false,"postsCount":13,"readPostsCount":0,"title":"LessWrong Political Prerequisites","canonicalCollection":null},"User:ZQefXso7Pp4nnGPmi":{"_id":"ZQefXso7Pp4nnGPmi","__typename":"User","slug":"diffractor","createdAt":"2017-09-21T23:07:36.656Z","username":"Diffractor","displayName":"Diffractor","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":2226,"afKarma":684,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":68,"commentCount":116,"sequenceCount":2,"afPostCount":69,"afCommentCount":76,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"3oopbgcjYfvN8B2fp"},"Revision:CmrW8fCmSLK7E25sa_contents":{"_id":"CmrW8fCmSLK7E25sa_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2023-03-20T18:26:31.579Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning.&nbsp;<\/p><p>Infra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach.<\/p>","commitMessage":"","wordCount":70,"htmlHighlight":"<p>Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning.&nbsp;<\/p><p>Infra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach.<\/p>","plaintextDescription":"Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning. \n\nInfra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach."},"Sequence:CmrW8fCmSLK7E25sa":{"_id":"CmrW8fCmSLK7E25sa","__typename":"Sequence","createdAt":"2020-08-27T18:48:07.743Z","userId":"ZQefXso7Pp4nnGPmi","user":{"__ref":"User:ZQefXso7Pp4nnGPmi"},"contents":{"__ref":"Revision:CmrW8fCmSLK7E25sa_contents"},"gridImageId":"sequencesgrid/ek5uoqxjn8zl6l9unirr","bannerImageId":"sequences/ttxnyvceytmd5iigtc7z","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":101,"userProfileOrder":null,"af":true,"postsCount":16,"readPostsCount":0,"title":"Infra-Bayesianism","canonicalCollection":null},"User:uuYBzWLiixkbN3s7C":{"_id":"uuYBzWLiixkbN3s7C","__typename":"User","slug":"brienneyudkowsky","createdAt":"2013-05-13T00:07:08.935Z","username":"BrienneYudkowsky","displayName":"LoganStrohl","profileImageId":null,"previousDisplayName":null,"fullName":"Logan Strohl","karma":6202,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":60,"commentCount":298,"sequenceCount":3,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"EQNTWXLKMeWMp2FQS"},"Revision:evLkoqsbi79AnM5sz_contents":{"_id":"evLkoqsbi79AnM5sz_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2022-10-12T18:06:39.660Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”<\/p>","commitMessage":"","wordCount":66,"htmlHighlight":"<p>Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”<\/p>","plaintextDescription":"Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”"},"Sequence:evLkoqsbi79AnM5sz":{"_id":"evLkoqsbi79AnM5sz","__typename":"Sequence","createdAt":"2022-02-13T00:38:57.581Z","userId":"uuYBzWLiixkbN3s7C","user":{"__ref":"User:uuYBzWLiixkbN3s7C"},"contents":{"__ref":"Revision:evLkoqsbi79AnM5sz_contents"},"gridImageId":"sequencesgrid/xhjq89g5vufbwx0df0uf","bannerImageId":"sequences/doefofloenqkxfx0j1px","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":100,"userProfileOrder":null,"af":false,"postsCount":8,"readPostsCount":0,"title":"Intro to Naturalism","canonicalCollection":null},"User:xSfc2APSi8WzFxp7i":{"_id":"xSfc2APSi8WzFxp7i","__typename":"User","slug":"so8res","createdAt":"2012-01-10T05:50:18.713Z","username":"So8res","displayName":"So8res","profileImageId":null,"previousDisplayName":null,"fullName":"Nate Soares","karma":15995,"afKarma":1939,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":148,"commentCount":495,"sequenceCount":2,"afPostCount":32,"afCommentCount":28,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:pFatcKW3JJhTSxqAF_contents":{"_id":"pFatcKW3JJhTSxqAF_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-03-03T23:50:46.013Z","userId":"qgdGA4ZEyW7zNdK84","html":"<blockquote><p>My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges <i>and<\/i> reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.<\/p><\/blockquote><p>A sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.<\/p><blockquote><p>When all is said and done, Nature will not judge us by our actions; we will be measured only by what <i>actually happens.<\/i> Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.<\/p><\/blockquote><p>Originally posted on <a href=\"https://mindingourway.com/guilt/\">Minding Our Way<\/a>. There's also an <a href=\"https://pod.link/1498321446\">official audio version<\/a>.<\/p>","commitMessage":"","wordCount":208,"htmlHighlight":"<blockquote><p>My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges <i>and<\/i> reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.<\/p><\/blockquote><p>A sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.<\/p><blockquote><p>When all is said and done, Nature will not judge us by our actions; we will be measured only by what <i>actually happens.<\/i> Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.<\/p><\/blockquote><p>Originally posted on <a href=\"https://mindingourway.com/guilt/\">Minding Our Way<\/a>. There's also an <a href=\"https://pod.link/1498321446\">official audio version<\/a>.<\/p>","plaintextDescription":"> My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges and reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.\n\nA sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.\n\n> When all is said and done, Nature will not judge us by our actions; we will be measured only by what actually happens. Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.\n\nOriginally posted on Minding Our Way. There's also an official audio version."},"Sequence:pFatcKW3JJhTSxqAF":{"_id":"pFatcKW3JJhTSxqAF","__typename":"Sequence","createdAt":"2022-03-02T07:22:26.188Z","userId":"xSfc2APSi8WzFxp7i","user":{"__ref":"User:xSfc2APSi8WzFxp7i"},"contents":{"__ref":"Revision:pFatcKW3JJhTSxqAF_contents"},"gridImageId":"sequencesgrid/m0lpxsua2jmtwbmwlttp","bannerImageId":"sequences/ojux53txivllnxot2xok","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":50,"userProfileOrder":null,"af":false,"postsCount":46,"readPostsCount":0,"title":"Replacing Guilt","canonicalCollection":null},"User:AThTtkDufXp3rmMDa":{"_id":"AThTtkDufXp3rmMDa","__typename":"User","slug":"evhub","createdAt":"2017-01-17T06:05:22.405Z","username":"evhub","displayName":"evhub","profileImageId":null,"previousDisplayName":null,"fullName":"Evan Hubinger","karma":12624,"afKarma":4266,"deleted":false,"isAdmin":false,"htmlBio":"<p>Evan Hubinger (he/him/his) (<a href=\"mailto:evanjhub@gmail.com\">evanjhub@gmail.com<\/a>)<\/p><p>I am a research scientist at <a href=\"https://www.anthropic.com/\">Anthropic<\/a> where I lead the <a href=\"https://www.alignmentforum.org/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic\">Alignment Stress-Testing team<\/a>. My posts and comments are my own and do not represent Anthropic's positions, policies, strategies, or opinions.<\/p><p>Previously: <a href=\"https://intelligence.org/\">MIRI<\/a>, OpenAI<\/p><p>See: “<a href=\"https://www.lesswrong.com/posts/7jn5aDadcMH6sFeJe/why-i-m-joining-anthropic\">Why I'm joining Anthropic<\/a>”<\/p><p>Selected work:<\/p><ul><li>\"<a href=\"https://www.alignmentforum.org/posts/ZAsJv7xijKTfZkMtr/sleeper-agents-training-deceptive-llms-that-persist-through\">Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training<\/a>\"<\/li><li>“<a href=\"https://www.lesswrong.com/s/n3utvGrgC2SGi9xQX\">Conditioning Predictive Models<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/posts/A9NxPTwbw6r6Awuwt/how-likely-is-deceptive-alignment\">How likely is deceptive alignment?<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/posts/FDJnZt8Ks2djouQTZ/how-do-we-become-confident-in-the-safety-of-a-machine\">How do we become confident in the safety of a machine learning system?<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/posts/fRsjBseRuvRhMPPE5/an-overview-of-11-proposals-for-building-safe-advanced-ai\">An overview of 11 proposals for building safe advanced AI<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB\">Risks from Learned Optimization<\/a>”<\/li><\/ul>","jobTitle":null,"organization":null,"postCount":70,"commentCount":739,"sequenceCount":1,"afPostCount":65,"afCommentCount":522,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Revision:n3utvGrgC2SGi9xQX_contents":{"_id":"n3utvGrgC2SGi9xQX_contents","__typename":"Revision","version":"0.4.0","updateType":"minor","editedAt":"2024-01-19T06:56:12.155Z","userId":"XtphY3uYHwruKqDyG","html":"<p><em>This is the Conditioning Predictive Models Sequence based on the paper “<a href=\"https://arxiv.org/abs/2302.00805\">Conditioning Predictive Models: Risks and Strategies<\/a>” by Evan Hubinger, Adam Jermyn, Johannes Treutlein, Rubi Hudson, and Kate Woolverton. Each post in the sequence corresponds to a different section of the paper.<\/em><\/p>\n<h1>Abstract<\/h1>\n<p>Our intention is to provide a definitive reference on what it would take to safely make use of generative/predictive models in the absence of a solution to the <a href=\"https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\">Eliciting Latent Knowledge<\/a> problem.<\/p>\n<p>Furthermore, we believe that large language models can be understood as such predictive models of the world, and that such a conceptualization raises significant opportunities for their safe yet powerful use via carefully conditioning them to predict desirable outputs.<\/p>\n<p>Unfortunately, such approaches also raise a variety of potentially fatal safety problems, particularly surrounding situations where predictive models predict the output of other AI systems, potentially unbeknownst to us. There are numerous potential solutions to such problems, however, primarily via carefully conditioning models to predict the things we want—e.g. humans—rather than the things we don’t—e.g. malign AIs.<\/p>\n<p>Furthermore, due to the simplicity of the prediction objective, we believe that predictive models present the easiest <a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/pL56xPoniLvtMDQ4J\">inner alignment<\/a> problem that we are aware of.<\/p>\n<p>As a result, we think that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models.<\/p>\n","commitMessage":"","wordCount":229,"htmlHighlight":"<p><em>This is the Conditioning Predictive Models Sequence based on the paper “<a href=\"https://arxiv.org/abs/2302.00805\">Conditioning Predictive Models: Risks and Strategies<\/a>” by Evan Hubinger, Adam Jermyn, Johannes Treutlein, Rubi Hudson, and Kate Woolverton. Each post in the sequence corresponds to a different section of the paper.<\/em><\/p>\n<h1>Abstract<\/h1>\n<p>Our intention is to provide a definitive reference on what it would take to safely make use of generative/predictive models in the absence of a solution to the <a href=\"https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\">Eliciting Latent Knowledge<\/a> problem.<\/p>\n<p>Furthermore, we believe that large language models can be understood as such predictive models of the world, and that such a conceptualization raises significant opportunities for their safe yet powerful use via carefully conditioning them to predict desirable outputs.<\/p>\n<p>Unfortunately, such approaches also raise a variety of potentially fatal safety problems, particularly surrounding situations where predictive models predict the output of other AI systems, potentially unbeknownst to us. There are numerous potential solutions to such problems, however, primarily via carefully conditioning models to predict the things we want—e.g. humans—rather than the things we don’t—e.g. malign AIs.<\/p>\n<p>Furthermore, due to the simplicity of the prediction objective, we believe that predictive models present the easiest <a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/pL56xPoniLvtMDQ4J\">inner alignment<\/a> problem that we are aware of.<\/p>\n<p>As a result, we think that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models.<\/p>","plaintextDescription":"This is the Conditioning Predictive Models Sequence based on the paper “Conditioning Predictive Models: Risks and Strategies” by Evan Hubinger, Adam Jermyn, Johannes Treutlein, Rubi Hudson, and Kate Woolverton. Each post in the sequence corresponds to a different section of the paper.\n\n\nAbstract\nOur intention is to provide a definitive reference on what it would take to safely make use of generative/predictive models in the absence of a solution to the Eliciting Latent Knowledge problem.\n\nFurthermore, we believe that large language models can be understood as such predictive models of the world, and that such a conceptualization raises significant opportunities for their safe yet powerful use via carefully conditioning them to predict desirable outputs.\n\nUnfortunately, such approaches also raise a variety of potentially fatal safety problems, particularly surrounding situations where predictive models predict the output of other AI systems, potentially unbeknownst to us. There are numerous potential solutions to such problems, however, primarily via carefully conditioning models to predict the things we want—e.g. humans—rather than the things we don’t—e.g. malign AIs.\n\nFurthermore, due to the simplicity of the prediction objective, we believe that predictive models present the easiest inner alignment problem that we are aware of.\n\nAs a result, we think that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models."},"Sequence:n3utvGrgC2SGi9xQX":{"_id":"n3utvGrgC2SGi9xQX","__typename":"Sequence","createdAt":"2023-02-01T20:45:11.592Z","userId":"AThTtkDufXp3rmMDa","user":{"__ref":"User:AThTtkDufXp3rmMDa"},"contents":{"__ref":"Revision:n3utvGrgC2SGi9xQX_contents"},"gridImageId":"sequencesgrid/gdwaqd3wg9zngxrbwbqm","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":30,"userProfileOrder":null,"af":true,"postsCount":7,"readPostsCount":0,"title":"Conditioning Predictive Models","canonicalCollection":null},"User:pWHLps2yEJTSNNBLk":{"_id":"pWHLps2yEJTSNNBLk","__typename":"User","slug":"janus-1","createdAt":"2021-09-25T11:56:33.908Z","username":"janus","displayName":"janus","profileImageId":null,"previousDisplayName":null,"fullName":"janus","karma":3310,"afKarma":523,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":8,"commentCount":150,"sequenceCount":2,"afPostCount":6,"afCommentCount":50,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:f2YA4eGskeztcJsqT_contents":{"_id":"f2YA4eGskeztcJsqT_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-01-19T06:55:25.277Z","userId":"XtphY3uYHwruKqDyG","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:f2YA4eGskeztcJsqT":{"_id":"f2YA4eGskeztcJsqT","__typename":"Sequence","createdAt":"2023-05-19T13:51:20.142Z","userId":"pWHLps2yEJTSNNBLk","user":{"__ref":"User:pWHLps2yEJTSNNBLk"},"contents":{"__ref":"Revision:f2YA4eGskeztcJsqT_contents"},"gridImageId":"sequencesgrid/iwls9nubn9dkangx3q5t","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":25,"userProfileOrder":null,"af":true,"postsCount":6,"readPostsCount":0,"title":"Cyborgism","canonicalCollection":null},"User:wsicf4AeB4yhMyHej":{"_id":"wsicf4AeB4yhMyHej","__typename":"User","slug":"scasper","createdAt":"2019-12-01T05:50:05.417Z","username":"scasper","displayName":"scasper","profileImageId":null,"previousDisplayName":null,"fullName":"Stephen Casper","karma":1829,"afKarma":527,"deleted":false,"isAdmin":false,"htmlBio":"<p><a href=\"https://stephencasper.com/\">https://stephencasper.com/<\/a><\/p>","jobTitle":null,"organization":null,"postCount":37,"commentCount":115,"sequenceCount":1,"afPostCount":24,"afCommentCount":47,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:a6ne2ve5uturEEQK7_contents":{"_id":"a6ne2ve5uturEEQK7_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2024-01-19T06:55:55.626Z","userId":"XtphY3uYHwruKqDyG","html":"<p>Interpretability research is popular, and interpretability tools play a role in almost every agenda for making AI safe. However, for all the interpretability work that exists, there is a significant gap between the research and engineering applications. If one of our main goals for interpretability research is to help us with aligning highly intelligent AI systems in high stakes settings, shouldn’t we be seeing tools that are more helpful on real world problems?<\/p><p>This 12-post sequence argues for taking an engineering approach to interpretability research. And from this lens, it analyzes existing work and proposes directions for moving forward.&nbsp;<\/p>","commitMessage":"","wordCount":99,"htmlHighlight":"<p>Interpretability research is popular, and interpretability tools play a role in almost every agenda for making AI safe. However, for all the interpretability work that exists, there is a significant gap between the research and engineering applications. If one of our main goals for interpretability research is to help us with aligning highly intelligent AI systems in high stakes settings, shouldn’t we be seeing tools that are more helpful on real world problems?<\/p><p>This 12-post sequence argues for taking an engineering approach to interpretability research. And from this lens, it analyzes existing work and proposes directions for moving forward.&nbsp;<\/p>","plaintextDescription":"Interpretability research is popular, and interpretability tools play a role in almost every agenda for making AI safe. However, for all the interpretability work that exists, there is a significant gap between the research and engineering applications. If one of our main goals for interpretability research is to help us with aligning highly intelligent AI systems in high stakes settings, shouldn’t we be seeing tools that are more helpful on real world problems?\n\nThis 12-post sequence argues for taking an engineering approach to interpretability research. And from this lens, it analyzes existing work and proposes directions for moving forward. "},"Sequence:a6ne2ve5uturEEQK7":{"_id":"a6ne2ve5uturEEQK7","__typename":"Sequence","createdAt":"2023-02-09T16:19:47.632Z","userId":"wsicf4AeB4yhMyHej","user":{"__ref":"User:wsicf4AeB4yhMyHej"},"contents":{"__ref":"Revision:a6ne2ve5uturEEQK7_contents"},"gridImageId":"sequencesgrid/o6bsfz6il5u2kep6vksv","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":25,"userProfileOrder":null,"af":true,"postsCount":13,"readPostsCount":0,"title":"The Engineer’s Interpretability Sequence","canonicalCollection":null},"Revision:dDMzozPbe4aJRkfTr_contents":{"_id":"dDMzozPbe4aJRkfTr_contents","__typename":"Revision","version":"1.4.0","updateType":"minor","editedAt":"2024-04-19T21:59:04.883Z","userId":"BCmzFRdQhqLPREvat","html":"<p>This sequence collects a number of stories I've written, starting in mid-2023, with a unifying theme of exploring different aspects of possible futures. I find fiction a valuable format for exploring these ideas because it forces concreteness, not only about the future itself, but also about how people (or AIs) experience that future. My fiction is broadly divided into three categories:<\/p><ol><li><a href=\"https://narrativeark.substack.com/t/short-stories\"><u>Traditional short stories<\/u><\/a>, mostly focusing on the human element of the future. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-witness\"><i><u>The Witness<\/u><\/i><\/a>.<\/li><li><a href=\"https://narrativeark.substack.com/t/vignettes-and-fables\"><u>Vignettes and fables<\/u><\/a> in which I explore interesting ideas more directly. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-ants-and-grasshopperhtml\"><i><u>The Ants and the Grasshopper<\/u><\/i><\/a>.<\/li><li>“<a href=\"https://narrativeark.substack.com/t/ai-autofiction\"><u>AI autofiction<\/u><\/a>” in which I describe how the world might look from the perspective of future AIs; these typically assume more technical knowledge. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/succession\"><i><u>Succession<\/u><\/i><\/a><i><u>.<\/u><\/i><\/li><\/ol><p>You can browse each category on my substack using the links above.<\/p>","commitMessage":"","wordCount":142,"htmlHighlight":"<p>This sequence collects a number of stories I've written, starting in mid-2023, with a unifying theme of exploring different aspects of possible futures. I find fiction a valuable format for exploring these ideas because it forces concreteness, not only about the future itself, but also about how people (or AIs) experience that future. My fiction is broadly divided into three categories:<\/p><ol><li><a href=\"https://narrativeark.substack.com/t/short-stories\"><u>Traditional short stories<\/u><\/a>, mostly focusing on the human element of the future. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-witness\"><i><u>The Witness<\/u><\/i><\/a>.<\/li><li><a href=\"https://narrativeark.substack.com/t/vignettes-and-fables\"><u>Vignettes and fables<\/u><\/a> in which I explore interesting ideas more directly. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-ants-and-grasshopperhtml\"><i><u>The Ants and the Grasshopper<\/u><\/i><\/a>.<\/li><li>“<a href=\"https://narrativeark.substack.com/t/ai-autofiction\"><u>AI autofiction<\/u><\/a>” in which I describe how the world might look from the perspective of future AIs; these typically assume more technical knowledge. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/succession\"><i><u>Succession<\/u><\/i><\/a><i><u>.<\/u><\/i><\/li><\/ol><p>You can browse each category on my substack using the links above.<\/p>","plaintextDescription":"This sequence collects a number of stories I've written, starting in mid-2023, with a unifying theme of exploring different aspects of possible futures. I find fiction a valuable format for exploring these ideas because it forces concreteness, not only about the future itself, but also about how people (or AIs) experience that future. My fiction is broadly divided into three categories:\n\n 1. Traditional short stories, mostly focusing on the human element of the future. I recommend starting with The Witness.\n 2. Vignettes and fables in which I explore interesting ideas more directly. I recommend starting with The Ants and the Grasshopper.\n 3. “AI autofiction” in which I describe how the world might look from the perspective of future AIs; these typically assume more technical knowledge. I recommend starting with Succession.\n\nYou can browse each category on my substack using the links above."},"Sequence:dDMzozPbe4aJRkfTr":{"_id":"dDMzozPbe4aJRkfTr","__typename":"Sequence","createdAt":"2023-07-06T02:23:42.313Z","userId":"BCmzFRdQhqLPREvat","user":{"__ref":"User:BCmzFRdQhqLPREvat"},"contents":{"__ref":"Revision:dDMzozPbe4aJRkfTr_contents"},"gridImageId":"sequencesgrid/v2gocvypckw2doyt5aex","bannerImageId":"sequences/fetzeibutgxnex2mtn49","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":20,"userProfileOrder":null,"af":false,"postsCount":22,"readPostsCount":0,"title":"Stories","canonicalCollection":null},"User:vRcer5FTqagjMkcDz":{"_id":"vRcer5FTqagjMkcDz","__typename":"User","slug":"steve2152","createdAt":"2018-08-13T02:14:22.599Z","username":"steve2152","displayName":"Steven Byrnes","profileImageId":null,"previousDisplayName":null,"fullName":"Steve Byrnes","karma":18719,"afKarma":3126,"deleted":false,"isAdmin":false,"htmlBio":"<p>I'm an AGI safety / AI alignment researcher in Boston with a particular focus on brain algorithms. Research Fellow at <a href=\"https://astera.org/\">Astera<\/a>. See <a href=\"https://sjbyrnes.com/agi.html\">https://sjbyrnes.com/agi.html<\/a> for a summary of my research and sorted list of writing. Physicist by training. Email: <a href=\"mailto:steven.byrnes@gmail.com\">steven.byrnes@gmail.com<\/a>. <a href=\"https://www.admonymous.co/steve47285\">Leave me anonymous feedback here<\/a><u>. I’m also at:<\/u> <a href=\"https://www.greaterwrong.com/users/steve2152?show=posts&amp;format=rss\"><u>RSS feed<\/u><\/a> , <a href=\"https://twitter.com/steve47285\"><u>Twitter<\/u><\/a> , <a href=\"https://sigmoid.social/@SteveByrnes\"><u>Mastodon<\/u><\/a> , <a href=\"https://www.threads.net/@steve.byrnes.0\"><u>Threads<\/u><\/a> , <a href=\"https://bsky.app/profile/stevebyrnes.bsky.social\"><u>Bluesky<\/u><\/a> , <a href=\"https://github.com/sbyrnes321/\"><u>GitHub<\/u><\/a> , <a href=\"https://en.wikipedia.org/wiki/User:Sbyrnes321\"><u>Wikipedia<\/u><\/a> , <a href=\"http://physics.stackexchange.com/users/3811/steve-b\"><u>Physics-StackExchange<\/u><\/a> , <a href=\"https://www.linkedin.com/in/steven-byrnes-005a304/\"><u>LinkedIn<\/u><\/a><\/p>","jobTitle":null,"organization":null,"postCount":146,"commentCount":2083,"sequenceCount":3,"afPostCount":61,"afCommentCount":543,"spamRiskScore":1,"tagRevisionCount":4,"reviewedByUserId":"3oopbgcjYfvN8B2fp"},"Revision:6uDBPacS6zDipqbZ9_contents":{"_id":"6uDBPacS6zDipqbZ9_contents","__typename":"Revision","version":"0.16.0","updateType":"minor","editedAt":"2024-06-10T14:28:03.903Z","userId":"vRcer5FTqagjMkcDz","html":"<p>Let’s say a thought pops into your mind: “I could open the window right now”. Maybe you then immediately stand up and go open the window. Or maybe you don’t. (“Nah, I’ll keep it closed,” you might say to yourself.) I claim that there’s a final-common-pathway signal in your brain that cleaves those two possibilities: when this special signal is positive, then the current “thought” will stick around, and potentially lead to actions and/or direct-follow-up thoughts; and when this signal is negative, then the current “thought” will get thrown out, and your brain will go fishing (partly randomly) for a new thought to replace it. I call this final-common-pathway signal by the name&nbsp;<strong>“valence”<\/strong>. Thus, the “valence” of a “thought” is roughly the extent to which the thought feels demotivating / aversive (negative valence) versus motivating / appealing (positive valence).<\/p><p>I claim that valence plays an absolutely central role in the brain—I think it’s one of the most important ingredients in the brain’s Model-Based Reinforcement Learning system, which in turn is one of the most important algorithms in your brain.<\/p><p>Thus, unsurprisingly, I see valence as a shining light that illuminates many aspects of psychology and everyday mental life. This series explores that idea. Here’s the outline:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction\"><strong>Post 1 (<\/strong><i><strong>Introduction<\/strong><\/i><strong>)<\/strong><\/a> will give some background on how I’m thinking about valence from the perspective of brain algorithms, including exactly what I’m talking about, and how it relates to the “wanting versus liking” dichotomy. (The thing I’m talking about is closer to “motivational valence” than “hedonic valence”, although neither term is&nbsp;<i>great<\/i>.)<\/li><li><a href=\"https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity\"><strong>Post 2 (<\/strong><i><strong>Valence &amp; Normativity<\/strong><\/i><strong>)<\/strong><\/a> will talk about the intimate relationship between valence and the universe of desires, preferences, values, goals, etc.—i.e. the “normative” side of the “positive-versus-normative” dichotomy, or equivalently the “ought” side of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem\"><u>Hume’s<\/u><\/a> “is-versus-ought”. I’ll start with simple cases: for example, if the idea of doing a certain thing right now feels unappealing (negative valence), then we’re less likely to do it. Then I’ll move on to more interesting cases, including what it means to like or dislike a broad concept like “religion”, and ego-syntonic versus ego-dystonic desires, and a descriptive account of moral reasoning and value formation.<\/li><li><a href=\"https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs\"><strong>Post 3 (<\/strong><i><strong>Valence &amp; Beliefs<\/strong><\/i><strong>)<\/strong><\/a> is the complement of Post 2, in that it covers the relationship between valence and the universe of beliefs, expectations, concepts, etc.—i.e. the “positive” side of the “positive-versus-normative” dichotomy, or equivalently the “is” side of “is-versus-ought”. The role of valence here is less foundational than it is on the normative side, but it’s still quite important. I’ll talk specifically about motivated reasoning, the halo effect (a.k.a. affect heuristic), and some related phenomena.<\/li><li><a href=\"https://www.lesswrong.com/posts/LaeP39jJpfPyoiSZm/valence-series-4-valence-and-liking-admiring\"><strong>Post 4 (<\/strong><i><strong>Valence &amp; Liking / Admiring<\/strong><\/i><strong>)<\/strong><\/a> argues that when my brain assigns a positive valence to a person I know, that corresponds to a familiar everyday phenomenon that I call “liking / admiring”. I argue that this has close ties to social status, mirroring, deference, self-esteem, self-concepts, and more. I also argue that there’s an “innate drive to be liked / admired” which is critically important in human affairs, and I speculate a bit on how it works in the brain.<\/li><li><a href=\"https://www.lesswrong.com/posts/txj4wigyjLNbcoZ9o/valence-series-5-valence-disorders-in-mental-health-and\"><strong>Post 5 (<\/strong><i><strong>‘Valence Disorders’ in Mental Health &amp; Personality<\/strong><\/i><strong>)<\/strong><\/a> notes that, given the central role of valence in brain algorithms, it follows that if something creates&nbsp;<i>systematic&nbsp;<\/i>impacts on valence, it should lead to a characteristic suite of major downstream effects on mental life. I’ll propose three specific hypotheses along these lines:<ul><li>(A) If the valence of every thought is shifted negative, that leads to a suite of symptoms strongly overlapping with depression;<\/li><li>(B) If the valence of every thought is shifted positive, that leads to a suite of symptoms strongly overlapping with mania;<\/li><li>(C) If the valence of every thought is “extremized”—very positive or very negative, but rarely in between—that leads to a suite of symptoms similar to narcissistic personality disorder.<\/li><\/ul><\/li><li><a href=\"https://www.lesswrong.com/posts/xLmzMjxgZDaLyxZKb/valence-series-appendix-a-hedonic-tone-dis-pleasure-dis\"><strong>Appendix A <\/strong><i><strong>(Hedonic tone / (dis)pleasure / (dis)liking)<\/strong><\/i><\/a> has some more details about the hedonic tone (i.e., the “liking” side of the “wanting-versus-liking” dichotomy, in contrast to valence which is more about “wanting”). This appendix thus elaborates on the very brief discussion in &nbsp;<a href=\"https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_2_Valence__as_I_m_using_the_term__is_different_from__hedonic_valence____pleasantness\"><u>§1.5.2<\/u><\/a>. I suggest that “hedonic tone” is a different brain signal from “valence”, but centrally involved in the valence-calculation algorithm.<\/li><li><i><strong>Valence and AI alignment<\/strong><\/i><strong> deserves a post too, but actually I already wrote that one a while ago: see&nbsp;<\/strong><a href=\"https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi\"><strong><u>Plan for mediocre alignment of brain-like [model-based RL] AGI<\/u><\/strong><\/a><strong>.<\/strong> Check it out if you’re interested. I won’t discuss AI further in this series, with some minor exceptions, including a section at the very end of the Post 5.<\/li><\/ul><p><i>Thanks to Tsvi Benson-Tilsen,&nbsp;Seth Herd, Aysja Johnson, Justis Mills,&nbsp;Charlie Steiner, Adele Lopez, and Garrett Baker for critical comments on earlier drafts. Banner image by DALL-E 3.<\/i><\/p>","commitMessage":"","wordCount":799,"htmlHighlight":"<p>Let’s say a thought pops into your mind: “I could open the window right now”. Maybe you then immediately stand up and go open the window. Or maybe you don’t. (“Nah, I’ll keep it closed,” you might say to yourself.) I claim that there’s a final-common-pathway signal in your brain that cleaves those two possibilities: when this special signal is positive, then the current “thought” will stick around, and potentially lead to actions and/or direct-follow-up thoughts; and when this signal is negative, then the current “thought” will get thrown out, and your brain will go fishing (partly randomly) for a new thought to replace it. I call this final-common-pathway signal by the name&nbsp;<strong>“valence”<\/strong>. Thus, the “valence” of a “thought” is roughly the extent to which the thought feels demotivating / aversive (negative valence) versus motivating / appealing (positive valence).<\/p><p>I claim that valence plays an absolutely central role in the brain—I think it’s one of the most important ingredients in the brain’s Model-Based Reinforcement Learning system, which in turn is one of the most important algorithms in your brain.<\/p><p>Thus, unsurprisingly, I see valence as a shining light that illuminates many aspects of psychology and everyday mental life. This series explores that idea. Here’s the outline:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction\"><strong>Post 1 (<\/strong><i><strong>Introduction<\/strong><\/i><strong>)<\/strong><\/a> will give some background on how I’m thinking about valence from the perspective of brain algorithms, including exactly what I’m talking about, and how it relates to the “wanting versus liking” dichotomy. (The thing I’m talking about is closer to “motivational valence” than “hedonic valence”, although neither term is&nbsp;<i>great<\/i>.)<\/li><li><a href=\"https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity\"><strong>Post 2 (<\/strong><i><strong>Valence &amp; Normativity<\/strong><\/i><strong>)<\/strong><\/a> will talk about the intimate relationship between valence and the universe of desires, preferences, values, goals, etc.—i.e. the “normative” side of the “positive-versus-normative” dichotomy, or equivalently the “ought” side of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem\"><u>Hume’s<\/u><\/a> “is-versus-ought”. I’ll start with simple cases: for example, if the idea of doing a certain thing right now feels unappealing (negative valence), then we’re less likely to do it. Then I’ll move on to more interesting cases, including what it means to like or dislike a broad concept like “religion”, and ego-syntonic versus ego-dystonic desires, and a descriptive account of moral reasoning and value formation.<\/li><li><a href=\"https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs\"><strong>Post 3 (<\/strong><i><strong>Valence &amp; Beliefs<\/strong><\/i><strong>)<\/strong><\/a> is the complement of Post 2, in t<\/li><\/ul>... ","plaintextDescription":"Let’s say a thought pops into your mind: “I could open the window right now”. Maybe you then immediately stand up and go open the window. Or maybe you don’t. (“Nah, I’ll keep it closed,” you might say to yourself.) I claim that there’s a final-common-pathway signal in your brain that cleaves those two possibilities: when this special signal is positive, then the current “thought” will stick around, and potentially lead to actions and/or direct-follow-up thoughts; and when this signal is negative, then the current “thought” will get thrown out, and your brain will go fishing (partly randomly) for a new thought to replace it. I call this final-common-pathway signal by the name “valence”. Thus, the “valence” of a “thought” is roughly the extent to which the thought feels demotivating / aversive (negative valence) versus motivating / appealing (positive valence).\n\nI claim that valence plays an absolutely central role in the brain—I think it’s one of the most important ingredients in the brain’s Model-Based Reinforcement Learning system, which in turn is one of the most important algorithms in your brain.\n\nThus, unsurprisingly, I see valence as a shining light that illuminates many aspects of psychology and everyday mental life. This series explores that idea. Here’s the outline:\n\n * Post 1 (Introduction) will give some background on how I’m thinking about valence from the perspective of brain algorithms, including exactly what I’m talking about, and how it relates to the “wanting versus liking” dichotomy. (The thing I’m talking about is closer to “motivational valence” than “hedonic valence”, although neither term is great.)\n * Post 2 (Valence & Normativity) will talk about the intimate relationship between valence and the universe of desires, preferences, values, goals, etc.—i.e. the “normative” side of the “positive-versus-normative” dichotomy, or equivalently the “ought” side of Hume’s “is-versus-ought”. I’ll start with simple cases: for example, if the idea of doing"},"Sequence:6uDBPacS6zDipqbZ9":{"_id":"6uDBPacS6zDipqbZ9","__typename":"Sequence","createdAt":"2023-12-04T13:57:10.054Z","userId":"vRcer5FTqagjMkcDz","user":{"__ref":"User:vRcer5FTqagjMkcDz"},"contents":{"__ref":"Revision:6uDBPacS6zDipqbZ9_contents"},"gridImageId":"sequencesgrid/lalel10qzujyi47rqiww","bannerImageId":"sequences/o0ucggb2f6dfdntl8aut","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":15,"userProfileOrder":null,"af":false,"postsCount":6,"readPostsCount":0,"title":"Valence","canonicalCollection":null},"User:jHzwoFd2MhZt9eeqJ":{"_id":"jHzwoFd2MhZt9eeqJ","__typename":"User","slug":"joe-carlsmith","createdAt":"2017-11-08T21:40:51.838Z","username":"joekc","displayName":"Joe Carlsmith","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":4264,"afKarma":479,"deleted":false,"isAdmin":false,"htmlBio":"<p>Senior research analyst at Open Philanthropy. Doctorate in philosophy from the University of Oxford. Opinions my own.<\/p>","jobTitle":null,"organization":null,"postCount":93,"commentCount":67,"sequenceCount":2,"afPostCount":23,"afCommentCount":14,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:BbAvHtorCZqp97X9W_contents":{"_id":"BbAvHtorCZqp97X9W_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2024-06-19T17:20:26.585Z","userId":"jHzwoFd2MhZt9eeqJ","html":"<p>This series examines a set of interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power. They’re old questions – but I think that we will have to grapple with them in new ways as increasingly powerful AI systems come online.<\/p><p>The series covers a lot of ground, but I’m hoping the individual essays can be read fairly well on their own. The first essay includes a brief summary of the essays released thus far. There's also a full PDF of the series <a href=\"https://jc.gatspress.com/pdf/otherness_full.pdf\">here<\/a>, and full audio <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/15266490-first-half-of-full-audio-for-otherness-and-control-in-the-age-of-agi\">here<\/a>.&nbsp;<\/p>","commitMessage":"","wordCount":100,"htmlHighlight":"<p>This series examines a set of interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power. They’re old questions – but I think that we will have to grapple with them in new ways as increasingly powerful AI systems come online.<\/p><p>The series covers a lot of ground, but I’m hoping the individual essays can be read fairly well on their own. The first essay includes a brief summary of the essays released thus far. There's also a full PDF of the series <a href=\"https://jc.gatspress.com/pdf/otherness_full.pdf\">here<\/a>, and full audio <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/15266490-first-half-of-full-audio-for-otherness-and-control-in-the-age-of-agi\">here<\/a>.&nbsp;<\/p>","plaintextDescription":"This series examines a set of interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power. They’re old questions – but I think that we will have to grapple with them in new ways as increasingly powerful AI systems come online.\n\nThe series covers a lot of ground, but I’m hoping the individual essays can be read fairly well on their own. The first essay includes a brief summary of the essays released thus far. There's also a full PDF of the series here, and full audio here. "},"Sequence:BbAvHtorCZqp97X9W":{"_id":"BbAvHtorCZqp97X9W","__typename":"Sequence","createdAt":"2024-01-02T22:38:25.534Z","userId":"jHzwoFd2MhZt9eeqJ","user":{"__ref":"User:jHzwoFd2MhZt9eeqJ"},"contents":{"__ref":"Revision:BbAvHtorCZqp97X9W_contents"},"gridImageId":"sequencesgrid/sqq40tz8m2jsvyrj8s4r","bannerImageId":"sequences/k02fhen4orb3kodl36nv","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":10,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":0,"title":"Otherness and control in the age of AGI","canonicalCollection":null},"User:n6LYNw2uGfYnD4pX2":{"_id":"n6LYNw2uGfYnD4pX2","__typename":"User","slug":"lsusr","createdAt":"2019-08-03T22:27:09.960Z","username":"lsusr","displayName":"lsusr","profileImageId":null,"previousDisplayName":null,"fullName":"Lsusr","karma":16660,"afKarma":25,"deleted":false,"isAdmin":false,"htmlBio":"<p>Here is a <a href=\"https://www.lsusr.com/\">list of all my public writings and videos.<\/a><\/p>\n<p>If you want to do a dialogue with me, but I didn't check your name, just send me a message instead. Ask for what you want!<\/p>\n","jobTitle":null,"organization":null,"postCount":271,"commentCount":1518,"sequenceCount":15,"afPostCount":0,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":2,"reviewedByUserId":"3oopbgcjYfvN8B2fp"},"Revision:TF77XsD5PbucbJsG3_contents":{"_id":"TF77XsD5PbucbJsG3_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-03-09T22:15:49.216Z","userId":"n6LYNw2uGfYnD4pX2","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:TF77XsD5PbucbJsG3":{"_id":"TF77XsD5PbucbJsG3","__typename":"Sequence","createdAt":"2020-11-30T08:12:20.977Z","userId":"n6LYNw2uGfYnD4pX2","user":{"__ref":"User:n6LYNw2uGfYnD4pX2"},"contents":{"__ref":"Revision:TF77XsD5PbucbJsG3_contents"},"gridImageId":"sequencesgrid/whqbkvzjopvlh7paq73r","bannerImageId":"sequences/wt6zrk3cpnvpdv7pxnar","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":10,"userProfileOrder":null,"af":false,"postsCount":13,"readPostsCount":0,"title":"Luna Lovegood","canonicalCollection":null},"User:kdeMdATaSc2MZKmdH":{"_id":"kdeMdATaSc2MZKmdH","__typename":"User","slug":"holdenkarnofsky","createdAt":"2009-12-30T00:19:32.818Z","username":"HoldenKarnofsky","displayName":"HoldenKarnofsky","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":6995,"afKarma":471,"deleted":false,"isAdmin":true,"htmlBio":"","jobTitle":null,"organization":null,"postCount":48,"commentCount":98,"sequenceCount":1,"afPostCount":8,"afCommentCount":34,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:yYxggfHYRrqnJXuRx_contents":{"_id":"yYxggfHYRrqnJXuRx_contents","__typename":"Revision","version":"0.2.0","updateType":"minor","editedAt":"2024-05-29T19:05:52.787Z","userId":"XtphY3uYHwruKqDyG","html":"<p>I think we have good reason to believe that the <strong>21st century could be the most important century ever for humanity.<\/strong> I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.<\/p><p>A bit more specifically,<a href=\"https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP\"><strong><sup><u>1<\/u><\/sup><\/strong><\/a> I think there is a good chance that:<\/p><ol><li>During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.<\/li><li>Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.<\/li><\/ol><p>I think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.<\/p><p>I believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind.<\/p>","commitMessage":"","wordCount":242,"htmlHighlight":"<p>I think we have good reason to believe that the <strong>21st century could be the most important century ever for humanity.<\/strong> I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.<\/p><p>A bit more specifically,<a href=\"https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP\"><strong><sup><u>1<\/u><\/sup><\/strong><\/a> I think there is a good chance that:<\/p><ol><li>During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.<\/li><li>Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.<\/li><\/ol><p>I think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.<\/p><p>I believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind.<\/p>","plaintextDescription":"I think we have good reason to believe that the 21st century could be the most important century ever for humanity. I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.\n\nA bit more specifically,1 I think there is a good chance that:\n\n 1. During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.\n 2. Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.\n\nI think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.\n\nI believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind."},"Sequence:yYxggfHYRrqnJXuRx":{"_id":"yYxggfHYRrqnJXuRx","__typename":"Sequence","createdAt":"2021-08-30T21:41:37.485Z","userId":"kdeMdATaSc2MZKmdH","user":{"__ref":"User:kdeMdATaSc2MZKmdH"},"contents":{"__ref":"Revision:yYxggfHYRrqnJXuRx_contents"},"gridImageId":"sequencesgrid/nsphhanrutzgofgj5xvu","bannerImageId":"sequences/vb9fvlizrpmm56tajkmk","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":4,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"The Most Important Century","canonicalCollection":null},"User:gb44edJjXhte8DA3A":{"_id":"gb44edJjXhte8DA3A","__typename":"User","slug":"paulfchristiano","createdAt":"2010-07-28T17:04:08.586Z","username":"paulfchristiano","displayName":"paulfchristiano","profileImageId":null,"previousDisplayName":null,"fullName":"Paul Christiano","karma":27447,"afKarma":6070,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":157,"commentCount":2274,"sequenceCount":1,"afPostCount":78,"afCommentCount":825,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:EmDuGeRw749sD3GKd_contents":{"_id":"EmDuGeRw749sD3GKd_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-05-26T04:28:48.055Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification.<\/p>","commitMessage":null,"wordCount":16,"htmlHighlight":"<p>This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification.<\/p>","plaintextDescription":"This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification."},"Sequence:EmDuGeRw749sD3GKd":{"_id":"EmDuGeRw749sD3GKd","__typename":"Sequence","createdAt":"2018-10-29T13:26:36.619Z","userId":"gb44edJjXhte8DA3A","user":{"__ref":"User:gb44edJjXhte8DA3A"},"contents":{"__ref":"Revision:EmDuGeRw749sD3GKd_contents"},"gridImageId":"sequencesgrid/prcccqtc5w7ytolilruu","bannerImageId":"sequences/bamysbymxal5tqccjawg","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":3,"userProfileOrder":null,"af":true,"postsCount":23,"readPostsCount":0,"title":"Iterated Amplification","canonicalCollection":null},"User:du6SPHKnnPrPmxWNT":{"_id":"du6SPHKnnPrPmxWNT","__typename":"User","slug":"rohinmshah","createdAt":"2015-05-26T23:46:04.336Z","username":"rohinmshah","displayName":"Rohin Shah","profileImageId":null,"previousDisplayName":null,"fullName":"Rohin Shah","karma":14851,"afKarma":5352,"deleted":false,"isAdmin":false,"htmlBio":"<p>Research Scientist at Google DeepMind. Creator of the Alignment Newsletter. <a href=\"http://rohinshah.com/\">http://rohinshah.com/<\/a><\/p>","jobTitle":null,"organization":null,"postCount":205,"commentCount":2183,"sequenceCount":2,"afPostCount":105,"afCommentCount":1363,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:4dHMdK5TLN6xcqtyc_contents":{"_id":"4dHMdK5TLN6xcqtyc_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-09-23T04:25:25.157Z","userId":"XtphY3uYHwruKqDyG","html":"<p>This is a sequence investigating the feasibility of one approach to AI alignment: value learning.<\/p>","commitMessage":"","wordCount":15,"htmlHighlight":"<p>This is a sequence investigating the feasibility of one approach to AI alignment: value learning.<\/p>","plaintextDescription":"This is a sequence investigating the feasibility of one approach to AI alignment: value learning."},"Sequence:4dHMdK5TLN6xcqtyc":{"_id":"4dHMdK5TLN6xcqtyc","__typename":"Sequence","createdAt":"2018-10-29T18:23:24.873Z","userId":"du6SPHKnnPrPmxWNT","user":{"__ref":"User:du6SPHKnnPrPmxWNT"},"contents":{"__ref":"Revision:4dHMdK5TLN6xcqtyc_contents"},"gridImageId":"sequencesgrid/x0pxuhnauzakdnrqijhe","bannerImageId":"sequences/x4nn0v3suj8bbf0tr9b3","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":2,"userProfileOrder":null,"af":true,"postsCount":19,"readPostsCount":0,"title":"Value Learning","canonicalCollection":null},"User:vAyu6PoTQHg8fzFNJ":{"_id":"vAyu6PoTQHg8fzFNJ","__typename":"User","slug":"cfar-2017","createdAt":"2022-06-24T17:44:49.041Z","username":"CFAR 2017","displayName":"CFAR!Duncan","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":1609,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":27,"commentCount":7,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:KAv8z6oJCTxjR8vdR_contents":{"_id":"KAv8z6oJCTxjR8vdR_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2022-09-23T22:16:10.468Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.&nbsp;&nbsp;<\/p><p>This is the result of the first five years or so of that research and development.<\/p>","commitMessage":"","wordCount":49,"htmlHighlight":"<p>The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.&nbsp;&nbsp;<\/p><p>This is the result of the first five years or so of that research and development.<\/p>","plaintextDescription":"The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.  \n\nThis is the result of the first five years or so of that research and development."},"Sequence:KAv8z6oJCTxjR8vdR":{"_id":"KAv8z6oJCTxjR8vdR","__typename":"Sequence","createdAt":"2022-06-28T20:53:06.291Z","userId":"vAyu6PoTQHg8fzFNJ","user":{"__ref":"User:vAyu6PoTQHg8fzFNJ"},"contents":{"__ref":"Revision:KAv8z6oJCTxjR8vdR_contents"},"gridImageId":"sequencesgrid/prnzteddh56bhbv5nmae","bannerImageId":"sequences/vq4k8iz6x7kdwrk41xo1","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":28,"readPostsCount":0,"title":"CFAR Handbook","canonicalCollection":null},"User:MEu8MdhruX5jfGsFQ":{"_id":"MEu8MdhruX5jfGsFQ","__typename":"User","slug":"johnswentworth","createdAt":"2011-02-19T16:54:09.598Z","username":"johnswentworth","displayName":"johnswentworth","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":48091,"afKarma":6224,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":341,"commentCount":3054,"sequenceCount":8,"afPostCount":119,"afCommentCount":680,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"EQNTWXLKMeWMp2FQS"},"Revision:xEFeCwk3pdYdeG2rL_contents":{"_id":"xEFeCwk3pdYdeG2rL_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-23T22:15:25.152Z","userId":"r38pkCm7wF4M44MDQ","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:xEFeCwk3pdYdeG2rL":{"_id":"xEFeCwk3pdYdeG2rL","__typename":"Sequence","createdAt":"2020-01-25T23:15:50.589Z","userId":"MEu8MdhruX5jfGsFQ","user":{"__ref":"User:MEu8MdhruX5jfGsFQ"},"contents":{"__ref":"Revision:xEFeCwk3pdYdeG2rL_contents"},"gridImageId":"sequencesgrid/mrcucooleoeaj8ybccb3","bannerImageId":"sequences/cwsk9pkbwwvfzhkvvgrk","canonicalCollectionSlug":"","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":0,"title":"Gears Which Turn The World","canonicalCollection":null},"User:N9zj5qpTfqmbn9dro":{"_id":"N9zj5qpTfqmbn9dro","__typename":"User","slug":"zvi","createdAt":"2009-03-31T20:54:54.077Z","username":"Zvi","displayName":"Zvi","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":44317,"afKarma":146,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":778,"commentCount":1447,"sequenceCount":3,"afPostCount":2,"afCommentCount":6,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:kNANcHLNtJt5qeuSS_contents":{"_id":"kNANcHLNtJt5qeuSS_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-23T22:15:04.353Z","userId":"r38pkCm7wF4M44MDQ","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:kNANcHLNtJt5qeuSS":{"_id":"kNANcHLNtJt5qeuSS","__typename":"Sequence","createdAt":"2019-12-31T20:35:02.123Z","userId":"N9zj5qpTfqmbn9dro","user":{"__ref":"User:N9zj5qpTfqmbn9dro"},"contents":{"__ref":"Revision:kNANcHLNtJt5qeuSS_contents"},"gridImageId":"sequencesgrid/y7bhrihn26iisjvhu61y","bannerImageId":"sequences/pu8r1gxicerwcbjlfg6i","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":20,"readPostsCount":0,"title":"Immoral Mazes","canonicalCollection":null},"Revision:hBFDRZCPLcrRDubgm_contents":{"_id":"hBFDRZCPLcrRDubgm_contents","__typename":"Revision","version":"1.5.0","updateType":"minor","editedAt":"2022-10-22T22:02:09.456Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions. <\/p><p>Unfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.<\/p><p>But the core skill of doublecrux –&nbsp;noticing what would actually change your mind –&nbsp;is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share. <\/p><p>This sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating.<\/p>","commitMessage":"","wordCount":131,"htmlHighlight":"<p>Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions. <\/p><p>Unfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.<\/p><p>But the core skill of doublecrux –&nbsp;noticing what would actually change your mind –&nbsp;is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share. <\/p><p>This sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating.<\/p>","plaintextDescription":"Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions.\n\nUnfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.\n\nBut the core skill of doublecrux – noticing what would actually change your mind – is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share.\n\nThis sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating."},"Sequence:hBFDRZCPLcrRDubgm":{"_id":"hBFDRZCPLcrRDubgm","__typename":"Sequence","createdAt":"2019-07-28T01:26:44.221Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:hBFDRZCPLcrRDubgm_contents"},"gridImageId":"sequencesgrid/sbiiwhliynfuouklvwph","bannerImageId":"sequences/mfjwxg5bqke2ooeq3eiz","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Keep your beliefs cruxy and your frames explicit","canonicalCollection":null},"Revision:r9tYkB2a8Fp4DN8yB_contents":{"_id":"r9tYkB2a8Fp4DN8yB_contents","__typename":"Revision","version":"1.8.0","updateType":"minor","editedAt":"2021-07-23T06:12:38.425Z","userId":"AThTtkDufXp3rmMDa","html":"<p><em>This is a sequence version of the paper “<a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.<\/em><\/p>\n<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,<\/em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?<\/p>\n","commitMessage":"","wordCount":163,"htmlHighlight":"<p><em>This is a sequence version of the paper “<a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.<\/em><\/p>\n<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,<\/em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?<\/p>","plaintextDescription":"This is a sequence version of the paper “Risks from Learned Optimization in Advanced Machine Learning Systems” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.\n\nThe goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as mesa-optimization, a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?"},"Sequence:r9tYkB2a8Fp4DN8yB":{"_id":"r9tYkB2a8Fp4DN8yB","__typename":"Sequence","createdAt":"2019-05-31T02:18:02.737Z","userId":"AThTtkDufXp3rmMDa","user":{"__ref":"User:AThTtkDufXp3rmMDa"},"contents":{"__ref":"Revision:r9tYkB2a8Fp4DN8yB_contents"},"gridImageId":"sequencesgrid/rzdw9faewnetbmumls9y","bannerImageId":"sequences/ahlmdailzfoxjcczzbub","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":true,"postsCount":5,"readPostsCount":0,"title":"Risks from Learned Optimization","canonicalCollection":null},"Revision:d3WgHDBAPYYScp5Em_contents":{"_id":"d3WgHDBAPYYScp5Em_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-10-13T07:26:27.113Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the <a href=\"https://wiki.lesswrong.com/wiki/Complexity_of_value\">complexity of value<\/a> thesis.<\/p><p>Also forms part of the fully general answer to religious theodicy.<\/p><p>Sequence by <a href=\"https://www.lesswrong.com/users/eliezer_yudkowsky\">Eliezer Yudkowsky<\/a>, imported from <a href=\"https://wiki.lesswrong.com/wiki/The_Fun_Theory_Sequence\">the wiki<\/a>. Overlaps with <a href=\"https://www.lesswrong.com/s/9bvAELWc8y2gYjRav\">Value Theory<\/a>.<\/p>","commitMessage":"","wordCount":62,"htmlHighlight":"<p>A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the <a href=\"https://wiki.lesswrong.com/wiki/Complexity_of_value\">complexity of value<\/a> thesis.<\/p><p>Also forms part of the fully general answer to religious theodicy.<\/p><p>Sequence by <a href=\"https://www.lesswrong.com/users/eliezer_yudkowsky\">Eliezer Yudkowsky<\/a>, imported from <a href=\"https://wiki.lesswrong.com/wiki/The_Fun_Theory_Sequence\">the wiki<\/a>. Overlaps with <a href=\"https://www.lesswrong.com/s/9bvAELWc8y2gYjRav\">Value Theory<\/a>.<\/p>","plaintextDescription":"A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the complexity of value thesis.\n\nAlso forms part of the fully general answer to religious theodicy.\n\nSequence by Eliezer Yudkowsky, imported from the wiki. Overlaps with Value Theory."},"Sequence:d3WgHDBAPYYScp5Em":{"_id":"d3WgHDBAPYYScp5Em","__typename":"Sequence","createdAt":"2018-09-22T01:17:01.044Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:d3WgHDBAPYYScp5Em_contents"},"gridImageId":"sequencesgrid/ncfkdhspgrfhhjpbisaj","bannerImageId":"sequences/kusdtqumjqf6bymmhaso","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":29,"readPostsCount":0,"title":"Fun Theory","canonicalCollection":null},"Revision:qWoFR4ytMpQ5vw3FT_contents":{"_id":"qWoFR4ytMpQ5vw3FT_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-07-06T20:02:30.941Z","userId":"nmk3nLpQE89dMRzzN","html":"<blockquote>&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.&quot;<br/>      -- (Hugo nominee) Peter Watts, &quot;<a href=\"http://www.rifters.com/crawl/?p=266\">In Praise of Baby-Eating<\/a>&quot;<\/blockquote><p><\/p><p><em>Three Worlds Collide<\/em> is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.<\/p><p>(PDF is <a href=\"http://robinhanson.typepad.com/files/three-worlds-collide.pdf\">here<\/a>. Old contents post with comments is <a href=\"https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8\">here<\/a>.)<\/p>","commitMessage":null,"wordCount":102,"htmlHighlight":"<blockquote>&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.&quot;<br/>      -- (Hugo nominee) Peter Watts, &quot;<a href=\"http://www.rifters.com/crawl/?p=266\">In Praise of Baby-Eating<\/a>&quot;<\/blockquote><p><\/p><p><em>Three Worlds Collide<\/em> is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.<\/p><p>(PDF is <a href=\"http://robinhanson.typepad.com/files/three-worlds-collide.pdf\">here<\/a>. Old contents post with comments is <a href=\"https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8\">here<\/a>.)<\/p>","plaintextDescription":"> \"The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.\"\n>       -- (Hugo nominee) Peter Watts, \"In Praise of Baby-Eating\"\n\n\n\nThree Worlds Collide is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.\n\n(PDF is here. Old contents post with comments is here.)"},"Sequence:qWoFR4ytMpQ5vw3FT":{"_id":"qWoFR4ytMpQ5vw3FT","__typename":"Sequence","createdAt":"2018-07-06T20:02:30.941Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:qWoFR4ytMpQ5vw3FT_contents"},"gridImageId":"sequencesgrid/sio9b8jw1apesuispocg","bannerImageId":"sequences/evlaa0fe6nysqqhhqwyd","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":8,"readPostsCount":0,"title":"Three Worlds Collide","canonicalCollection":null},"Revision:HXkpm9b8o964jbQ89_contents":{"_id":"HXkpm9b8o964jbQ89_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-09T22:33:08.727Z","userId":"N9zj5qpTfqmbn9dro","html":"<p>A series of meditations on freedom to do the things you care about.<\/p><blockquote>Some things are fundamentally Out to Get You.<\/blockquote><blockquote>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.<\/blockquote><blockquote>When something is out to get you, if you aren&#x27;t careful, it can take all your resources - your time, you money, your attention.<\/blockquote><blockquote>This matters, more deeply than you might realize. It&#x27;s not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you. <\/blockquote><blockquote>Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.<\/blockquote><p><\/p>","commitMessage":null,"wordCount":146,"htmlHighlight":"<p>A series of meditations on freedom to do the things you care about.<\/p><blockquote>Some things are fundamentally Out to Get You.<\/blockquote><blockquote>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.<\/blockquote><blockquote>When something is out to get you, if you aren&#x27;t careful, it can take all your resources - your time, you money, your attention.<\/blockquote><blockquote>This matters, more deeply than you might realize. It&#x27;s not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you. <\/blockquote><blockquote>Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.<\/blockquote><p><\/p>","plaintextDescription":"A series of meditations on freedom to do the things you care about.\n\n> Some things are fundamentally Out to Get You.\n\n> They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.\n\n> When something is out to get you, if you aren't careful, it can take all your resources - your time, you money, your attention.\n\n> This matters, more deeply than you might realize. It's not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you.\n\n> Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.\n\n"},"Sequence:HXkpm9b8o964jbQ89":{"_id":"HXkpm9b8o964jbQ89","__typename":"Sequence","createdAt":"2018-04-09T22:33:08.727Z","userId":"N9zj5qpTfqmbn9dro","user":{"__ref":"User:N9zj5qpTfqmbn9dro"},"contents":{"__ref":"Revision:HXkpm9b8o964jbQ89_contents"},"gridImageId":"sequencesgrid/rqnuxewffasun6tvdkng","bannerImageId":"sequences/ecwup5jjh2nq00uf0mi0","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":15,"readPostsCount":0,"title":"Slack and the Sabbath ","canonicalCollection":null},"Revision:ZNNi2uNx9E6iwGKKG_contents":{"_id":"ZNNi2uNx9E6iwGKKG_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","commitMessage":null,"wordCount":156,"htmlHighlight":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","plaintextDescription":"This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.\n\nParts of this sequence draw heavily upon material from The Art of Strategy by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it's probably a bad idea to pick a legal fight with people who write books called The Art of Strategy.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.\n\nSpecial thanks to Luke for his book recommendation and his strong encouragement to write this."},"Sequence:ZNNi2uNx9E6iwGKKG":{"_id":"ZNNi2uNx9E6iwGKKG","__typename":"Sequence","createdAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:ZNNi2uNx9E6iwGKKG_contents"},"gridImageId":"sequencesgrid/vitugifyyh2upm9ucjzh","bannerImageId":"sequences/zvybkycf2vyasr4zwptr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":0,"title":"Introduction to Game Theory","canonicalCollection":null},"Revision:G2GDw3m4MJ5ixSM92_contents":{"_id":"G2GDw3m4MJ5ixSM92_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-09-21T21:34:27.910Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","commitMessage":"","wordCount":19,"htmlHighlight":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","plaintextDescription":"A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour."},"Sequence:G2GDw3m4MJ5ixSM92":{"_id":"G2GDw3m4MJ5ixSM92","__typename":"Sequence","createdAt":"2018-02-22T18:10:39.949Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:G2GDw3m4MJ5ixSM92_contents"},"gridImageId":"sequencesgrid/djfksyoldrjt4ef5jts3","bannerImageId":"sequences/ad7shnab6qq5v6cqxpme","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"The Blue-Minimizing Robot","canonicalCollection":null},"User:c8gC5wARE3fPwu94u":{"_id":"c8gC5wARE3fPwu94u","__typename":"User","slug":"alkjash","createdAt":"2017-10-06T20:42:59.929Z","username":"alkjash","displayName":"alkjash","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":4913,"afKarma":4,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":82,"commentCount":274,"sequenceCount":4,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:qRxTKm7DAftSuTGvj_contents":{"_id":"qRxTKm7DAftSuTGvj_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-23T22:17:16.410Z","userId":"r38pkCm7wF4M44MDQ","html":"<p><em>If all you have is a hammer, everything looks like a nail.<\/em><\/p><p>Thirty days of instrumental rationality practice.<\/p><p>Key word: systematic.<\/p>","commitMessage":"","wordCount":19,"htmlHighlight":"<p><em>If all you have is a hammer, everything looks like a nail.<\/em><\/p><p>Thirty days of instrumental rationality practice.<\/p><p>Key word: systematic.<\/p>","plaintextDescription":"If all you have is a hammer, everything looks like a nail.\n\nThirty days of instrumental rationality practice.\n\nKey word: systematic."},"Sequence:qRxTKm7DAftSuTGvj":{"_id":"qRxTKm7DAftSuTGvj","__typename":"Sequence","createdAt":"2018-02-22T16:29:33.789Z","userId":"c8gC5wARE3fPwu94u","user":{"__ref":"User:c8gC5wARE3fPwu94u"},"contents":{"__ref":"Revision:qRxTKm7DAftSuTGvj_contents"},"gridImageId":"sequencesgrid/chv9ct9cisa2fne7htnk","bannerImageId":"sequences/ihwuzf8j8n5xfqdiften","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":34,"readPostsCount":0,"title":"Hammertime","canonicalCollection":null},"Revision:pC6DYFLPMTCbEwH8W_contents":{"_id":"pC6DYFLPMTCbEwH8W_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-02-22T16:02:57.918Z","userId":"c8gC5wARE3fPwu94u","html":"<p>How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write <em>Hamlet<\/em>?<\/p><p>Babble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.<\/p><p>Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.<\/p><p>It is time to reclaim your birthright, hero: go forth and babble!<\/p>","commitMessage":null,"wordCount":113,"htmlHighlight":"<p>How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write <em>Hamlet<\/em>?<\/p><p>Babble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.<\/p><p>Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.<\/p><p>It is time to reclaim your birthright, hero: go forth and babble!<\/p>","plaintextDescription":"How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write Hamlet?\n\nBabble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.\n\nTwo Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.\n\nIt is time to reclaim your birthright, hero: go forth and babble!"},"Sequence:pC6DYFLPMTCbEwH8W":{"_id":"pC6DYFLPMTCbEwH8W","__typename":"Sequence","createdAt":"2018-02-22T16:02:57.918Z","userId":"c8gC5wARE3fPwu94u","user":{"__ref":"User:c8gC5wARE3fPwu94u"},"contents":{"__ref":"Revision:pC6DYFLPMTCbEwH8W_contents"},"gridImageId":"sequencesgrid/nhvoi5fvxxzthqhu2ctt","bannerImageId":"sequences/dncaedgak01s1ssja5nf","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":5,"readPostsCount":0,"title":"Babble and Prune","canonicalCollection":null},"Revision:SqFbMbtxGybdS2gRs_contents":{"_id":"SqFbMbtxGybdS2gRs_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-04-19T19:13:02.750Z","userId":"XtphY3uYHwruKqDyG","html":"<p>These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.<\/p>","commitMessage":null,"wordCount":27,"htmlHighlight":"<p>These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.<\/p>","plaintextDescription":"These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed."},"Sequence:SqFbMbtxGybdS2gRs":{"_id":"SqFbMbtxGybdS2gRs","__typename":"Sequence","createdAt":"2018-01-22T08:55:37.700Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:SqFbMbtxGybdS2gRs_contents"},"gridImageId":"sequencesgrid/i2ogsvmipbdolntkew4a","bannerImageId":"sequences/kx9ydblgnzt7f16remz3","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"Highly Advanced Epistemology 101 for Beginners","canonicalCollection":null},"User:SdZmP36R37riQrHAw":{"_id":"SdZmP36R37riQrHAw","__typename":"User","slug":"lukeprog","createdAt":"2009-03-19T08:07:34.230Z","username":"lukeprog","displayName":"lukeprog","profileImageId":null,"previousDisplayName":null,"fullName":"Luke Muehlhauser","karma":36650,"afKarma":3,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":458,"commentCount":4086,"sequenceCount":3,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":58,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:yFvZa9wkv5JoqhM8F_contents":{"_id":"yFvZa9wkv5JoqhM8F_contents","__typename":"Revision","version":null,"updateType":"minor","editedAt":"2024-10-10T20:32:26.958Z","userId":null,"html":null,"commitMessage":"","wordCount":null,"htmlHighlight":"","plaintextDescription":""},"Sequence:yFvZa9wkv5JoqhM8F":{"_id":"yFvZa9wkv5JoqhM8F","__typename":"Sequence","createdAt":"2017-11-25T22:42:52.100Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:yFvZa9wkv5JoqhM8F_contents"},"gridImageId":"sequencesgrid/yxlirutmux2fjqnnjhoc","bannerImageId":"sequences/q1spaabxeuy2wkgpafwa","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":0,"title":"Rationality and Philosophy","canonicalCollection":null},"User:pnFbJAtNHGDK8PHQx":{"_id":"pnFbJAtNHGDK8PHQx","__typename":"User","slug":"annasalamon","createdAt":"2009-02-27T04:25:14.013Z","username":"AnnaSalamon","displayName":"AnnaSalamon","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":17519,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":88,"commentCount":950,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":19,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:XipJ7DMjYyriAm7fr_contents":{"_id":"XipJ7DMjYyriAm7fr_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-25T21:06:47.500Z","userId":"pnFbJAtNHGDK8PHQx","html":"<p>Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply &quot;intuiting&quot; the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. <\/p><p>For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb&#x27;s problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.<\/p>","commitMessage":null,"wordCount":66,"htmlHighlight":"<p>Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply &quot;intuiting&quot; the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. <\/p><p>For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb&#x27;s problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.<\/p>","plaintextDescription":"Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply \"intuiting\" the answers to decision problems by ad-hoc methods is not conducive to thorough analysis.\n\nFor this, we formulate decision theories. This sequence, themed with an analysis of Newcomb's problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing."},"Sequence:XipJ7DMjYyriAm7fr":{"_id":"XipJ7DMjYyriAm7fr","__typename":"Sequence","createdAt":"2017-11-25T21:06:47.500Z","userId":"pnFbJAtNHGDK8PHQx","user":{"__ref":"User:pnFbJAtNHGDK8PHQx"},"contents":{"__ref":"Revision:XipJ7DMjYyriAm7fr_contents"},"gridImageId":"sequencesgrid/qpreo6bc9vxwyf2l1dzo","bannerImageId":"sequences/nrxkrnabxv7q0szgjjcr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Decision Theory: Newcomb's Problem","canonicalCollection":null},"Revision:oi873FWi6pHWxswSa_contents":{"_id":"oi873FWi6pHWxswSa_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-24T03:37:56.045Z","userId":"SdZmP36R37riQrHAw","html":"<p>A <u><a href=\"https://wiki.lesswrong.com/wiki/Sequence\">sequence<\/a><\/u> summarizing scientifically-backed advice for &quot;<u><a href=\"https://wiki.lesswrong.com/wiki/Winning\">winning<\/a><\/u>&quot; at everyday life: in one&#x27;s productivity, in one&#x27;s relationships, in one&#x27;s emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.<\/p>","commitMessage":null,"wordCount":35,"htmlHighlight":"<p>A <u><a href=\"https://wiki.lesswrong.com/wiki/Sequence\">sequence<\/a><\/u> summarizing scientifically-backed advice for &quot;<u><a href=\"https://wiki.lesswrong.com/wiki/Winning\">winning<\/a><\/u>&quot; at everyday life: in one&#x27;s productivity, in one&#x27;s relationships, in one&#x27;s emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.<\/p>","plaintextDescription":"A sequence summarizing scientifically-backed advice for \"winning\" at everyday life: in one's productivity, in one's relationships, in one's emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature."},"Sequence:oi873FWi6pHWxswSa":{"_id":"oi873FWi6pHWxswSa","__typename":"Sequence","createdAt":"2017-11-24T03:37:56.045Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:oi873FWi6pHWxswSa_contents"},"gridImageId":"sequencesgrid/yp01lueog8rjaybsizux","bannerImageId":"sequences/l6y9o00lif4qenrdel5w","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"The Science of Winning at Life","canonicalCollection":null},"Revision:bQgRsy23biR52poMf_contents":{"_id":"bQgRsy23biR52poMf_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-22T02:58:02.903Z","userId":"SdZmP36R37riQrHAw","html":"<p>Years ago, I wrote an unfinished sequence of posts called &quot;<a href=\"https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics<\/a>.&quot; My last post, <a href=\"https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">Pluralistic Moral Reductionism<\/a>, said I would next explore &quot;empathic metaethics,&quot; but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic metaethics&quot; in <a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort\">section 6.1.2<\/a> of a report prepared for my employer, the <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy Project<\/a>. With my employer&#x27;s permission, I&#x27;ve adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics.<\/p>","commitMessage":null,"wordCount":87,"htmlHighlight":"<p>Years ago, I wrote an unfinished sequence of posts called &quot;<a href=\"https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics<\/a>.&quot; My last post, <a href=\"https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">Pluralistic Moral Reductionism<\/a>, said I would next explore &quot;empathic metaethics,&quot; but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic metaethics&quot; in <a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort\">section 6.1.2<\/a> of a report prepared for my employer, the <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy Project<\/a>. With my employer&#x27;s permission, I&#x27;ve adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics.<\/p>","plaintextDescription":"Years ago, I wrote an unfinished sequence of posts called \"No-Nonsense Metaethics.\" My last post, Pluralistic Moral Reductionism, said I would next explore \"empathic metaethics,\" but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on \"empathic metaethics\" in section 6.1.2 of a report prepared for my employer, the Open Philanthropy Project. With my employer's permission, I've adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics."},"Sequence:bQgRsy23biR52poMf":{"_id":"bQgRsy23biR52poMf","__typename":"Sequence","createdAt":"2017-11-22T02:58:02.903Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:bQgRsy23biR52poMf_contents"},"gridImageId":"sequencesgrid/kvoeqrfluqd0jv5fvwez","bannerImageId":"sequences/p5ywbc6j8355jbcptyrz","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":5,"readPostsCount":0,"title":"No-Nonsense Metaethics","canonicalCollection":null},"Revision:oLGCcbnvabyibnG9d_contents":{"_id":"oLGCcbnvabyibnG9d_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-07T03:42:59.852Z","userId":"nmk3nLpQE89dMRzzN","html":"<p>Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal.<\/p>","commitMessage":null,"wordCount":34,"htmlHighlight":"<p>Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal.<\/p>","plaintextDescription":"Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal."},"Sequence:oLGCcbnvabyibnG9d":{"_id":"oLGCcbnvabyibnG9d","__typename":"Sequence","createdAt":"2017-11-07T03:42:59.852Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:oLGCcbnvabyibnG9d_contents"},"gridImageId":"sequencesgrid/vbhv0s06jdmonk6garvf","bannerImageId":"sequences/gl1xzufmu65v6cn66wrm","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":0,"title":"Inadequate Equilibria","canonicalCollection":null},"User:hbQoLoK5tpmFAJGr4":{"_id":"hbQoLoK5tpmFAJGr4","__typename":"User","slug":"scott-garrabrant","createdAt":"2017-09-22T02:21:16.385Z","username":"Scott Garrabrant","displayName":"Scott Garrabrant","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":8267,"afKarma":1569,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":74,"commentCount":416,"sequenceCount":4,"afPostCount":99,"afCommentCount":192,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Revision:2A7rrZ4ySx6R8mfoT_contents":{"_id":"2A7rrZ4ySx6R8mfoT_contents","__typename":"Revision","version":"0.3.0","updateType":"minor","editedAt":"2021-01-19T23:18:25.404Z","userId":"XtphY3uYHwruKqDyG","html":"<p>Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames.<\/p>","commitMessage":"","wordCount":34,"htmlHighlight":"<p>Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames.<\/p>","plaintextDescription":"Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames."},"Sequence:2A7rrZ4ySx6R8mfoT":{"_id":"2A7rrZ4ySx6R8mfoT","__typename":"Sequence","createdAt":"2020-10-22T13:42:07.868Z","userId":"hbQoLoK5tpmFAJGr4","user":{"__ref":"User:hbQoLoK5tpmFAJGr4"},"contents":{"__ref":"Revision:2A7rrZ4ySx6R8mfoT_contents"},"gridImageId":"sequencesgrid/a9iwqgsxkqznfrtskanw","bannerImageId":"sequences/jtgjfl0vc1igtmdwambt","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":0,"userProfileOrder":null,"af":true,"postsCount":13,"readPostsCount":0,"title":"Cartesian Frames","canonicalCollection":null},"User:iPdmf2tiNRtfJbvdQ":{"_id":"iPdmf2tiNRtfJbvdQ","__typename":"User","slug":"alicorn","createdAt":"2009-03-17T18:52:42.458Z","username":"Alicorn","displayName":"Alicorn","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":30513,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":81,"commentCount":5197,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:ynMFrq9K5iNMfSZNg_contents":{"_id":"ynMFrq9K5iNMfSZNg_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-05-02T19:07:37.622Z","userId":"XtphY3uYHwruKqDyG","html":"<p><u><a href=\"https://wiki.lesswrong.com/wiki/Luminosity\">Luminosity<\/a><\/u>, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an <u><a href=\"https://wiki.lesswrong.com/wiki/Emotion\">emotion<\/a><\/u>, a <u><a href=\"https://wiki.lesswrong.com/wiki/Belief\">belief<\/a><\/u> or <u><a href=\"https://wiki.lesswrong.com/wiki/Alief\">alief<\/a><\/u>, a disposition, a <u><a href=\"https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1\">quale<\/a><\/u>, a memory - anything that might happen or be stored in your brain. What&#x27;s going on in your head?<\/p>","commitMessage":null,"wordCount":52,"htmlHighlight":"<p><u><a href=\"https://wiki.lesswrong.com/wiki/Luminosity\">Luminosity<\/a><\/u>, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an <u><a href=\"https://wiki.lesswrong.com/wiki/Emotion\">emotion<\/a><\/u>, a <u><a href=\"https://wiki.lesswrong.com/wiki/Belief\">belief<\/a><\/u> or <u><a href=\"https://wiki.lesswrong.com/wiki/Alief\">alief<\/a><\/u>, a disposition, a <u><a href=\"https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1\">quale<\/a><\/u>, a memory - anything that might happen or be stored in your brain. What&#x27;s going on in your head?<\/p>","plaintextDescription":"Luminosity, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an emotion, a belief or alief, a disposition, a quale, a memory - anything that might happen or be stored in your brain. What's going on in your head?"},"Sequence:ynMFrq9K5iNMfSZNg":{"_id":"ynMFrq9K5iNMfSZNg","__typename":"Sequence","createdAt":"2018-02-22T18:50:08.321Z","userId":"iPdmf2tiNRtfJbvdQ","user":{"__ref":"User:iPdmf2tiNRtfJbvdQ"},"contents":{"__ref":"Revision:ynMFrq9K5iNMfSZNg_contents"},"gridImageId":"sequencesgrid/ozdf0thhtehmpmbf9dys","bannerImageId":"sequences/pkhcwvrxma1bl0g4cuto","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":0,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"Living Luminously","canonicalCollection":null},"Revision:qhdHbCJ3PYesL9dde_contents":{"_id":"qhdHbCJ3PYesL9dde_contents","__typename":"Revision","version":"1.6.0","updateType":"minor","editedAt":"2024-10-10T15:33:45.199Z","userId":"vRcer5FTqagjMkcDz","html":"<p>This is a rather ambitious series of blog posts, in that I’ll attempt to explain what’s the deal with consciousness, free will, hypnotism, enlightenment, hallucinations, flow states, dissociation, akrasia, delusions, and more.<\/p><p><i>(I’m serializing the series weekly, but you can <\/i><a href=\"mailto:steven.byrnes@gmail.com\"><i><u>email<\/u><\/i><\/a><i> or&nbsp;<\/i><a href=\"https://www.lesswrong.com/users/steve2152#:~:text=4-,Message,-Subscribe\"><i><u>DM<\/u><\/i><\/a><i> me if you want to read the whole thing right now.)<\/i><\/p><p>The starting point for this whole journey is very simple:<\/p><ul><li>The brain has a predictive (a.k.a. self-supervised) learning algorithm.<\/li><li>This algorithm builds generative models (a.k.a. “intuitive models”) that can predict incoming data.<\/li><li>It turns out that, in order to predict incoming data, the algorithm winds up not only building generative models capturing properties of trucks and shoes and birds, but also building generative models capturing properties&nbsp;<i>of the brain algorithm itself<\/i>.<\/li><\/ul><p>Those latter models, which I call&nbsp;<i>“intuitive self-models”<\/i>, wind up including ingredients like conscious awareness, deliberate actions, and the sense of applying one’s will.<\/p><p>That’s a simple idea, but exploring its consequences will take us to all kinds of strange places—plenty to fill up an eight-post series! Here’s the outline:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/FtwMA5fenkHeomz52/intuitive-self-models-1-preliminaries\"><strong>Post 1 (<\/strong><i><strong>Preliminaries<\/strong><\/i><strong>)<\/strong><\/a> gives some background on the brain’s predictive learning algorithm, how to think about the “intuitive models” built by that algorithm, how intuitive&nbsp;<i>self<\/i>-models come about, and the relation of this whole series to Philosophy Of Mind.<\/li><li><a href=\"https://www.lesswrong.com/posts/73xBjgoHuiKvJ5WRk/intuitive-self-models-2-conscious-awareness\"><strong><u>Post 2 (<\/u><\/strong><i><strong><u>Conscious Awareness<\/u><\/strong><\/i><strong><u>)<\/u><\/strong><\/a> proposes that our intuitive self-models include an ingredient called “conscious awareness”, and that this ingredient is built by the predictive learning algorithm to represent a serial aspect of cortex computation. I’ll discuss ways in which this model is veridical (faithful to the algorithmic phenomenon that it’s modeling), and ways that it isn’t. I’ll also talk about how intentions and decisions fit into that framework.<\/li><li><a href=\"https://www.lesswrong.com/posts/7tNq4hiSWW9GdKjY8/intuitive-self-models-3-the-homunculus\"><strong><u>Post 3 (<\/u><\/strong><i><strong><u>The Homunculus<\/u><\/strong><\/i><strong><u>)<\/u><\/strong><\/a> focuses more specifically on the intuitive self-model that almost everyone reading this post is experiencing right now (as opposed to the other possibilities covered later in the series), which I call the&nbsp;<i>Conventional Intuitive Self-Model<\/i>. In particular, I propose that a key player in that model is a certain entity that’s conceptualized as actively causing acts of free will. Following&nbsp;<a href=\"https://en.wikipedia.org/wiki/Consciousness_Explained\"><u>Dennett<\/u><\/a>, I call this entity “the homunculus”, and relate that to intuitions around free will and sense-of-self.<\/li><li><a href=\"https://www.lesswrong.com/posts/QAjmr323LZGQBEvd5/intuitive-self-models-4-trance\"><strong><u>Post 4 (<\/u><\/strong><i><strong><u>Trance<\/u><\/strong><\/i><strong><u>)<\/u><\/strong><\/a> builds a framework to systematize the various types of trance, from everyday “flow states”, to intense possession rituals with amnesia. I try to explain why these states have the properties they do, and to reverse-engineer the various tricks that people use to induce trance in practice.<\/li><li><strong><u>Post 5 (<\/u><\/strong><i><strong><u>Dissociative Identity Disorder<\/u><\/strong><\/i><strong><u>)<\/u><\/strong> (a.k.a. “multiple personality disorder”) is a brief opinionated tour of this controversial psychiatric diagnosis. Is it real? Is it iatrogenic? Why is it related to borderline personality disorder (BPD) and trauma? What do we make of the wild claim that each “alter” can’t remember the lives of the other “alters”?<\/li><li><strong><u>Post 6 (<\/u><\/strong><i><strong><u>Awakening / Enlightenment / PNSE<\/u><\/strong><\/i><strong><u>)<\/u><\/strong> is a type of intuitive self-model, typically accessed via extensive meditation practice. It’s quite different from the conventional intuitive self-model. I offer a hypothesis about what exactly the difference is, and why that difference has the various downstream effects that it has.<\/li><li><strong><u>Post 7&nbsp;<\/u><\/strong><i><strong><u>(Hearing Voices, and Other Hallucinations)<\/u>&nbsp;<\/strong><\/i>talks about factors contributing to hallucinations—although I argue&nbsp;<i>against<\/i> drawing a deep distinction between hallucinations versus “normal” inner speech and imagination. I discuss both psychological factors like schizophrenia and BPD; and cultural factors, including some critical discussion of Julian Jaynes’s&nbsp;<i>Origin of Consciousness In The Breakdown Of The Bicameral Mind<\/i>.<\/li><li><strong><u>Post 8&nbsp;<\/u><\/strong><i><strong><u>(De-homunculus-ifying Motivation)<\/u><\/strong><\/i> suggests that the way people normally talk about motivation and goals is excessively tied to the Conventional Intuitive Self-Model (CISM). This leads to muddled thinking even within the CISM, and leads to straight-up nonsense when applied to other intuitive self-models. I offer an alternative framework that I think works better.<\/li><\/ul>","commitMessage":"","wordCount":637,"htmlHighlight":"<p>This is a rather ambitious series of blog posts, in that I’ll attempt to explain what’s the deal with consciousness, free will, hypnotism, enlightenment, hallucinations, flow states, dissociation, akrasia, delusions, and more.<\/p><p><i>(I’m serializing the series weekly, but you can <\/i><a href=\"mailto:steven.byrnes@gmail.com\"><i><u>email<\/u><\/i><\/a><i> or&nbsp;<\/i><a href=\"https://www.lesswrong.com/users/steve2152#:~:text=4-,Message,-Subscribe\"><i><u>DM<\/u><\/i><\/a><i> me if you want to read the whole thing right now.)<\/i><\/p><p>The starting point for this whole journey is very simple:<\/p><ul><li>The brain has a predictive (a.k.a. self-supervised) learning algorithm.<\/li><li>This algorithm builds generative models (a.k.a. “intuitive models”) that can predict incoming data.<\/li><li>It turns out that, in order to predict incoming data, the algorithm winds up not only building generative models capturing properties of trucks and shoes and birds, but also building generative models capturing properties&nbsp;<i>of the brain algorithm itself<\/i>.<\/li><\/ul><p>Those latter models, which I call&nbsp;<i>“intuitive self-models”<\/i>, wind up including ingredients like conscious awareness, deliberate actions, and the sense of applying one’s will.<\/p><p>That’s a simple idea, but exploring its consequences will take us to all kinds of strange places—plenty to fill up an eight-post series! Here’s the outline:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/FtwMA5fenkHeomz52/intuitive-self-models-1-preliminaries\"><strong>Post 1 (<\/strong><i><strong>Preliminaries<\/strong><\/i><strong>)<\/strong><\/a> gives some background on the brain’s predictive learning algorithm, how to think about the “intuitive models” built by that algorithm, how intuitive&nbsp;<i>self<\/i>-models come about, and the relation of this whole series to Philosophy Of Mind.<\/li><li><a href=\"https://www.lesswrong.com/posts/73xBjgoHuiKvJ5WRk/intuitive-self-models-2-conscious-awareness\"><strong><u>Post 2 (<\/u><\/strong><i><strong><u>Conscious Awareness<\/u><\/strong><\/i><strong><u>)<\/u><\/strong><\/a> proposes that our intuitive self-models include an ingredient called “conscious awareness”, and that this ingredient is built by the predictive learning algorithm to represent a serial aspect of cortex computation. I’ll discuss ways in which this model is veridical (faithful to the algorithmic phenomenon that it’s modeling), and ways that it isn’t. I’ll also talk about how intentions and decisions fit into that framework.<\/li><li><a href=\"https://www.lesswrong.com/posts/7tNq4hiSWW9GdKjY8/intuitive-self-models-3-the-homunculus\"><strong><u>Post 3 (<\/u><\/strong><i><strong><u>The Homunculus<\/u><\/strong><\/i><strong><u>)<\/u><\/strong><\/a> focuses more specifically on the intuitive self-model that almost everyone reading this post is experiencing right now (as opposed to the other possibilities covered later in the series), which I call the&nbsp;<i>Conventional Intuitive Self-Model<\/i>. In particular, I propose that a key player in that model is a certain entity that’s conceptualized as actively causing acts of free will. Following&nbsp;<a href=\"https://en.wikipedia.org/wiki/Consciousness_Explained\"><u>Dennett<\/u><\/a>, I call this entity “the homunculus”, and relate that to intuitions around free will and sense-of<\/li><\/ul>... ","plaintextDescription":"This is a rather ambitious series of blog posts, in that I’ll attempt to explain what’s the deal with consciousness, free will, hypnotism, enlightenment, hallucinations, flow states, dissociation, akrasia, delusions, and more.\n\n(I’m serializing the series weekly, but you can email or DM me if you want to read the whole thing right now.)\n\nThe starting point for this whole journey is very simple:\n\n * The brain has a predictive (a.k.a. self-supervised) learning algorithm.\n * This algorithm builds generative models (a.k.a. “intuitive models”) that can predict incoming data.\n * It turns out that, in order to predict incoming data, the algorithm winds up not only building generative models capturing properties of trucks and shoes and birds, but also building generative models capturing properties of the brain algorithm itself.\n\nThose latter models, which I call “intuitive self-models”, wind up including ingredients like conscious awareness, deliberate actions, and the sense of applying one’s will.\n\nThat’s a simple idea, but exploring its consequences will take us to all kinds of strange places—plenty to fill up an eight-post series! Here’s the outline:\n\n * Post 1 (Preliminaries) gives some background on the brain’s predictive learning algorithm, how to think about the “intuitive models” built by that algorithm, how intuitive self-models come about, and the relation of this whole series to Philosophy Of Mind.\n * Post 2 (Conscious Awareness) proposes that our intuitive self-models include an ingredient called “conscious awareness”, and that this ingredient is built by the predictive learning algorithm to represent a serial aspect of cortex computation. I’ll discuss ways in which this model is veridical (faithful to the algorithmic phenomenon that it’s modeling), and ways that it isn’t. I’ll also talk about how intentions and decisions fit into that framework.\n * Post 3 (The Homunculus) focuses more specifically on the intuitive self-model that almost everyone reading this p"},"Sequence:qhdHbCJ3PYesL9dde":{"_id":"qhdHbCJ3PYesL9dde","__typename":"Sequence","createdAt":"2024-09-18T21:35:41.271Z","userId":"vRcer5FTqagjMkcDz","user":{"__ref":"User:vRcer5FTqagjMkcDz"},"contents":{"__ref":"Revision:qhdHbCJ3PYesL9dde_contents"},"gridImageId":"sequencesgrid/gforsnvfonkxbjkfbj8m","bannerImageId":"sequences/vuq8qwuxedtzr63hlwvm","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Intuitive Self-Models","canonicalCollection":null},"User:R3oCodp9iDmWhhPiA":{"_id":"R3oCodp9iDmWhhPiA","__typename":"User","slug":"sdm","createdAt":"2019-10-26T16:33:00.312Z","username":"SDM","displayName":"Sammy Martin","profileImageId":null,"previousDisplayName":null,"fullName":"Samuel Dylan Martin","karma":2153,"afKarma":359,"deleted":false,"isAdmin":false,"htmlBio":"<p>AI Governance researcher with Polaris Ventures, formerly of the MTAIR project, TFI and Center on Long-term Risk, Graduate researcher at Kings and AI MSc at Edinburgh. Interested in philosophy, longtermism and AI Alignment.<\/p>","jobTitle":null,"organization":null,"postCount":13,"commentCount":277,"sequenceCount":1,"afPostCount":6,"afCommentCount":67,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:B9HWqQSt3NcLx34qc_contents":{"_id":"B9HWqQSt3NcLx34qc_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-09-13T15:54:06.845Z","userId":"R3oCodp9iDmWhhPiA","html":"<p>In this sequence, we investigate how to think strategically about the AI alignment and deployment problems. We focus on quantifying the hard to quantify - our uncertainty about AI alignment difficulty, and on reasoning about exactly how this uncertainty affects our strategic decision-making in the near term.<\/p>","commitMessage":"","wordCount":47,"htmlHighlight":"<p>In this sequence, we investigate how to think strategically about the AI alignment and deployment problems. We focus on quantifying the hard to quantify - our uncertainty about AI alignment difficulty, and on reasoning about exactly how this uncertainty affects our strategic decision-making in the near term.<\/p>","plaintextDescription":"In this sequence, we investigate how to think strategically about the AI alignment and deployment problems. We focus on quantifying the hard to quantify - our uncertainty about AI alignment difficulty, and on reasoning about exactly how this uncertainty affects our strategic decision-making in the near term."},"Sequence:B9HWqQSt3NcLx34qc":{"_id":"B9HWqQSt3NcLx34qc","__typename":"Sequence","createdAt":"2024-09-13T15:49:44.723Z","userId":"R3oCodp9iDmWhhPiA","user":{"__ref":"User:R3oCodp9iDmWhhPiA"},"contents":{"__ref":"Revision:B9HWqQSt3NcLx34qc_contents"},"gridImageId":"sequencesgrid/osc2ogpwhlw5rkmj8uyl","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":true,"postsCount":2,"readPostsCount":0,"title":"The AI Alignment and Deployment Problems","canonicalCollection":null},"User:oezgprZbqzzq6RuqJ":{"_id":"oezgprZbqzzq6RuqJ","__typename":"User","slug":"michaelstjules","createdAt":"2019-08-31T04:59:46.433Z","username":"MichaelStJules","displayName":"MichaelStJules","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":524,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":14,"commentCount":236,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"XtphY3uYHwruKqDyG"},"Revision:Ed7Ffv4LLK3GS3oj3_contents":{"_id":"Ed7Ffv4LLK3GS3oj3_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2024-08-15T04:28:34.215Z","userId":"oezgprZbqzzq6RuqJ","html":"<p>We may be making important conceptual or methodological errors in prioritization between moral patients. In <a href=\"https://www.lesswrong.com/s/Ed7Ffv4LLK3GS3oj3\">this sequence<\/a>, I illustrate and address several:<\/p><ol><li><a href=\"https://www.lesswrong.com/posts/W4nYYs85a7jkEKFxd/types-of-subjective-welfare\">Types of subjective welfare<\/a>: I review types of subjective welfare, interpersonal comparisons with them and common grounds between them.<\/li><li><a href=\"https://www.lesswrong.com/posts/y62PAa3ATxtxDrFAJ/solution-to-the-two-envelopes-problem-for-moral-weights\">Solution to the two envelopes problem for moral weights<\/a>: The welfare concepts we value directly are human-based, so we should normalize nonhuman welfare by human welfare. This would increase the priority for nonhumans.<\/li><li><a href=\"https://www.lesswrong.com/posts/Xa9gF8sycMmJpALnQ/which-animals-realize-which-types-of-subjective-welfare\">Which animals realize which types of subjective welfare?<\/a>: I argue that many nonhuman animals may have access to (simple versions of) types of subjective welfare people may expect to require language or higher self-awareness. This would support further prioritizing them.<\/li><li><a href=\"https://www.lesswrong.com/posts/tezCJXcRanhzRvJnj/increasingly-vague-interpersonal-welfare-comparisons\">Increasingly vague interpersonal welfare comparisons<\/a>: I illustrate that interpersonal welfare comparisons can be vague, and more vague the more different two beings are.<\/li><li><a href=\"https://www.lesswrong.com/posts/qgpuDpvererifr8ou/gradations-of-moral-weight\">Gradations of moral weight<\/a>: I build a model for moral weight assignments given vagueness and gradations in capacities. I explore whether other moral patients could have greater moral weights than humans through (more sophisticated) capacities we don’t have.<\/li><li><a href=\"https://www.lesswrong.com/posts/qnCnJWqB7wDXDQGZ8/pleasure-and-suffering-are-not-conceptual-opposites\">Pleasure and suffering are not conceptual opposites<\/a>: Suffering is probably (at least) unpleasantness + desire (motivational salience), not just unpleasantness. So suffering is not the opposite of pleasure.<\/li><\/ol><p>For more detailed summaries, see the individual posts.<\/p>","commitMessage":"","wordCount":217,"htmlHighlight":"<p>We may be making important conceptual or methodological errors in prioritization between moral patients. In <a href=\"https://www.lesswrong.com/s/Ed7Ffv4LLK3GS3oj3\">this sequence<\/a>, I illustrate and address several:<\/p><ol><li><a href=\"https://www.lesswrong.com/posts/W4nYYs85a7jkEKFxd/types-of-subjective-welfare\">Types of subjective welfare<\/a>: I review types of subjective welfare, interpersonal comparisons with them and common grounds between them.<\/li><li><a href=\"https://www.lesswrong.com/posts/y62PAa3ATxtxDrFAJ/solution-to-the-two-envelopes-problem-for-moral-weights\">Solution to the two envelopes problem for moral weights<\/a>: The welfare concepts we value directly are human-based, so we should normalize nonhuman welfare by human welfare. This would increase the priority for nonhumans.<\/li><li><a href=\"https://www.lesswrong.com/posts/Xa9gF8sycMmJpALnQ/which-animals-realize-which-types-of-subjective-welfare\">Which animals realize which types of subjective welfare?<\/a>: I argue that many nonhuman animals may have access to (simple versions of) types of subjective welfare people may expect to require language or higher self-awareness. This would support further prioritizing them.<\/li><li><a href=\"https://www.lesswrong.com/posts/tezCJXcRanhzRvJnj/increasingly-vague-interpersonal-welfare-comparisons\">Increasingly vague interpersonal welfare comparisons<\/a>: I illustrate that interpersonal welfare comparisons can be vague, and more vague the more different two beings are.<\/li><li><a href=\"https://www.lesswrong.com/posts/qgpuDpvererifr8ou/gradations-of-moral-weight\">Gradations of moral weight<\/a>: I build a model for moral weight assignments given vagueness and gradations in capacities. I explore whether other moral patients could have greater moral weights than humans through (more sophisticated) capacities we don’t have.<\/li><li><a href=\"https://www.lesswrong.com/posts/qnCnJWqB7wDXDQGZ8/pleasure-and-suffering-are-not-conceptual-opposites\">Pleasure and suffering are not conceptual opposites<\/a>: Suffering is probably (at least) unpleasantness + desire (motivational salience), not just unpleasantness. So suffering is not the opposite of pleasure.<\/li><\/ol><p>For more detailed summaries, see the individual posts.<\/p>","plaintextDescription":"We may be making important conceptual or methodological errors in prioritization between moral patients. In this sequence, I illustrate and address several:\n\n 1. Types of subjective welfare: I review types of subjective welfare, interpersonal comparisons with them and common grounds between them.\n 2. Solution to the two envelopes problem for moral weights: The welfare concepts we value directly are human-based, so we should normalize nonhuman welfare by human welfare. This would increase the priority for nonhumans.\n 3. Which animals realize which types of subjective welfare?: I argue that many nonhuman animals may have access to (simple versions of) types of subjective welfare people may expect to require language or higher self-awareness. This would support further prioritizing them.\n 4. Increasingly vague interpersonal welfare comparisons: I illustrate that interpersonal welfare comparisons can be vague, and more vague the more different two beings are.\n 5. Gradations of moral weight: I build a model for moral weight assignments given vagueness and gradations in capacities. I explore whether other moral patients could have greater moral weights than humans through (more sophisticated) capacities we don’t have.\n 6. Pleasure and suffering are not conceptual opposites: Suffering is probably (at least) unpleasantness + desire (motivational salience), not just unpleasantness. So suffering is not the opposite of pleasure.\n\nFor more detailed summaries, see the individual posts."},"Sequence:Ed7Ffv4LLK3GS3oj3":{"_id":"Ed7Ffv4LLK3GS3oj3","__typename":"Sequence","createdAt":"2024-08-15T04:19:27.540Z","userId":"oezgprZbqzzq6RuqJ","user":{"__ref":"User:oezgprZbqzzq6RuqJ"},"contents":{"__ref":"Revision:Ed7Ffv4LLK3GS3oj3_contents"},"gridImageId":"sequencesgrid/krq7ksuxdb5pye3lrzps","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":" Welfare and moral weights","canonicalCollection":null},"User:mfgrYb4LMk7NWXsSB":{"_id":"mfgrYb4LMk7NWXsSB","__typename":"User","slug":"tailcalled","createdAt":"2015-01-27T20:50:11.327Z","username":"tailcalled","displayName":"tailcalled","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":7211,"afKarma":74,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":100,"commentCount":2049,"sequenceCount":1,"afPostCount":0,"afCommentCount":6,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:gEvTvhr8hNRrdHC62_contents":{"_id":"gEvTvhr8hNRrdHC62_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2024-09-01T12:46:06.044Z","userId":"mfgrYb4LMk7NWXsSB","html":"<p>What is wrong with <a href=\"https://slatestarcodex.com/2013/07/25/i-myself-am-a-scientismist/\">scientism<\/a>, <a href=\"https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions\">reductionism<\/a>, academia, and much of society? Everyone probably has their own theory, but my theory is that they fail to take linear diffusion of sparse lognormals into account.<\/p><p>&nbsp;<\/p><p>The sequence is temporarily on halt because I ran out of backlog for it, but there will be more later. In the meantime, you can read the following posts:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/YZvyQn2dAw4tL2xQY/rationalists-are-missing-a-core-piece-for-agent-like\">Rationalists are missing a core piece of agent-like structure (energy vs information-overload)<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/BcrPdMipzqecg4JdQ/the-causal-backbone-conjecture\">The causal backbone conjecture<\/a><\/li><\/ul>","commitMessage":"","wordCount":80,"htmlHighlight":"<p>What is wrong with <a href=\"https://slatestarcodex.com/2013/07/25/i-myself-am-a-scientismist/\">scientism<\/a>, <a href=\"https://www.lesswrong.com/posts/6i3zToomS86oj9bS6/mysterious-answers-to-mysterious-questions\">reductionism<\/a>, academia, and much of society? Everyone probably has their own theory, but my theory is that they fail to take linear diffusion of sparse lognormals into account.<\/p><p>&nbsp;<\/p><p>The sequence is temporarily on halt because I ran out of backlog for it, but there will be more later. In the meantime, you can read the following posts:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/YZvyQn2dAw4tL2xQY/rationalists-are-missing-a-core-piece-for-agent-like\">Rationalists are missing a core piece of agent-like structure (energy vs information-overload)<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/BcrPdMipzqecg4JdQ/the-causal-backbone-conjecture\">The causal backbone conjecture<\/a><\/li><\/ul>","plaintextDescription":"What is wrong with scientism, reductionism, academia, and much of society? Everyone probably has their own theory, but my theory is that they fail to take linear diffusion of sparse lognormals into account.\n\n \n\nThe sequence is temporarily on halt because I ran out of backlog for it, but there will be more later. In the meantime, you can read the following posts:\n\n * Rationalists are missing a core piece of agent-like structure (energy vs information-overload)\n * The causal backbone conjecture"},"Sequence:gEvTvhr8hNRrdHC62":{"_id":"gEvTvhr8hNRrdHC62","__typename":"Sequence","createdAt":"2024-08-07T20:04:16.793Z","userId":"mfgrYb4LMk7NWXsSB","user":{"__ref":"User:mfgrYb4LMk7NWXsSB"},"contents":{"__ref":"Revision:gEvTvhr8hNRrdHC62_contents"},"gridImageId":"sequencesgrid/j21eqgktvcnbri2bcask","bannerImageId":"sequences/u11psqhcqxqtlimopvpu","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Linear Diffusion of Sparse Lognormals: Causal Inference Against Scientism","canonicalCollection":null},"User:ezbRa3dntKWQ5995r":{"_id":"ezbRa3dntKWQ5995r","__typename":"User","slug":"niplav","createdAt":"2019-02-12T20:56:58.309Z","username":"niplav","displayName":"niplav","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":3390,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"<p>I operate by <a href=\"https://www.lesswrong.com/tag/crockers-rules\">Crocker's rules<\/a>.<\/p><p><a href=\"https://niplav.site/index.html\">Website<\/a>.<\/p>","jobTitle":null,"organization":null,"postCount":34,"commentCount":667,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":26,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:pwazxmKw7qKo8hoWo_contents":{"_id":"pwazxmKw7qKo8hoWo_contents","__typename":"Revision","version":"0.2.0","updateType":"minor","editedAt":"2024-07-31T17:17:44.014Z","userId":"ezbRa3dntKWQ5995r","html":"<p>Posts by <a href=\"https://www.lesswrong.com/users/stuart_armstrong\">Stuart Armstrong<\/a> on <a href=\"https://www.lesswrong.com/tag/acausal-trade\">acausal trade<\/a>.<\/p>\n","commitMessage":"","wordCount":7,"htmlHighlight":"<p>Posts by <a href=\"https://www.lesswrong.com/users/stuart_armstrong\">Stuart Armstrong<\/a> on <a href=\"https://www.lesswrong.com/tag/acausal-trade\">acausal trade<\/a>.<\/p>","plaintextDescription":"Posts by Stuart Armstrong on acausal trade."},"Sequence:pwazxmKw7qKo8hoWo":{"_id":"pwazxmKw7qKo8hoWo","__typename":"Sequence","createdAt":"2024-07-31T17:00:45.386Z","userId":"ezbRa3dntKWQ5995r","user":{"__ref":"User:ezbRa3dntKWQ5995r"},"contents":{"__ref":"Revision:pwazxmKw7qKo8hoWo_contents"},"gridImageId":"sequencesgrid/a740dwayvur42i3oma3d","bannerImageId":"sequences/ablok71iszejjth72jcv","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":8,"readPostsCount":0,"title":"Acausal Trade","canonicalCollection":null},"User:87rpwTAs3SSijxmoY":{"_id":"87rpwTAs3SSijxmoY","__typename":"User","slug":"max-harms","createdAt":"2024-05-15T16:06:14.657Z","username":"max-harms","displayName":"Max Harms","profileImageId":null,"previousDisplayName":null,"fullName":"Max Harms","karma":433,"afKarma":175,"deleted":false,"isAdmin":false,"htmlBio":"<p>Also known as Raelifin: <a href=\"https://www.lesswrong.com/users/raelifin\">https://www.lesswrong.com/users/raelifin<\/a><\/p>\n","jobTitle":null,"organization":null,"postCount":9,"commentCount":37,"sequenceCount":1,"afPostCount":9,"afCommentCount":33,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Revision:KfCjeconYRdFbMxsy_contents":{"_id":"KfCjeconYRdFbMxsy_contents","__typename":"Revision","version":"1.0.0","updateType":"initial","editedAt":"2024-06-08T00:54:54.354Z","userId":"87rpwTAs3SSijxmoY","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:KfCjeconYRdFbMxsy":{"_id":"KfCjeconYRdFbMxsy","__typename":"Sequence","createdAt":"2024-06-08T00:54:54.248Z","userId":"87rpwTAs3SSijxmoY","user":{"__ref":"User:87rpwTAs3SSijxmoY"},"contents":{"__ref":"Revision:KfCjeconYRdFbMxsy_contents"},"gridImageId":"sequencesgrid/kdwavysy3pj1dqm0l1jk","bannerImageId":"sequences/sq3ogkwtm4fg95rreebo","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":true,"postsCount":7,"readPostsCount":0,"title":"CAST: Corrigibility As Singular Target","canonicalCollection":null},"User:xZnmhCDCr6biEpEey":{"_id":"xZnmhCDCr6biEpEey","__typename":"User","slug":"joe-rogero","createdAt":"2023-06-01T19:47:11.996Z","username":"Joe Rogero","displayName":"Joe Rogero","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":72,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":3,"commentCount":5,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Revision:SybKaNSqyADrnMQ7H_contents":{"_id":"SybKaNSqyADrnMQ7H_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2024-06-08T18:29:30.070Z","userId":"xZnmhCDCr6biEpEey","html":"<p>An attempt to summarize Leopold Aschenbrenner's recent report, <a href=\"https://situational-awareness.ai/\">Situational Awareness<\/a>.&nbsp;<\/p><p><strong>Disclaimer<\/strong>: As of a few weeks ago, I work for the Machine Intelligence Research Institute. Some of MIRI's basic views regarding AI policy can be found <a href=\"https://intelligence.org/2023/12/06/written-statement-of-miri-ceo-malo-bourgon-to-the-ai-insight-forum/\">here<\/a>, and Rob Bensinger wrote a short response to the piece <a href=\"https://forum.effectivealtruism.org/posts/RTHFCRLv34cewwMr6/response-to-aschenbrenner-s-situational-awareness\">here<\/a>. I consider Rob's response representative of the typical MIRI take on Leopold's writeup, whereas I'm thinking of this sequence as \"my own personal take, which may or may not overlap with MIRI's.\" My questions and opinions (which I relegate to the end of each post in the sequence) don't necessarily reflect MIRI's views.&nbsp;<\/p>","commitMessage":"","wordCount":101,"htmlHighlight":"<p>An attempt to summarize Leopold Aschenbrenner's recent report, <a href=\"https://situational-awareness.ai/\">Situational Awareness<\/a>.&nbsp;<\/p><p><strong>Disclaimer<\/strong>: As of a few weeks ago, I work for the Machine Intelligence Research Institute. Some of MIRI's basic views regarding AI policy can be found <a href=\"https://intelligence.org/2023/12/06/written-statement-of-miri-ceo-malo-bourgon-to-the-ai-insight-forum/\">here<\/a>, and Rob Bensinger wrote a short response to the piece <a href=\"https://forum.effectivealtruism.org/posts/RTHFCRLv34cewwMr6/response-to-aschenbrenner-s-situational-awareness\">here<\/a>. I consider Rob's response representative of the typical MIRI take on Leopold's writeup, whereas I'm thinking of this sequence as \"my own personal take, which may or may not overlap with MIRI's.\" My questions and opinions (which I relegate to the end of each post in the sequence) don't necessarily reflect MIRI's views.&nbsp;<\/p>","plaintextDescription":"An attempt to summarize Leopold Aschenbrenner's recent report, Situational Awareness. \n\nDisclaimer: As of a few weeks ago, I work for the Machine Intelligence Research Institute. Some of MIRI's basic views regarding AI policy can be found here, and Rob Bensinger wrote a short response to the piece here. I consider Rob's response representative of the typical MIRI take on Leopold's writeup, whereas I'm thinking of this sequence as \"my own personal take, which may or may not overlap with MIRI's.\" My questions and opinions (which I relegate to the end of each post in the sequence) don't necessarily reflect MIRI's views. "},"Sequence:SybKaNSqyADrnMQ7H":{"_id":"SybKaNSqyADrnMQ7H","__typename":"Sequence","createdAt":"2024-06-06T19:28:53.823Z","userId":"xZnmhCDCr6biEpEey","user":{"__ref":"User:xZnmhCDCr6biEpEey"},"contents":{"__ref":"Revision:SybKaNSqyADrnMQ7H_contents"},"gridImageId":"sequencesgrid/srkofmpkmr2b5to0uimt","bannerImageId":"sequences/bxzkrxafwihxrm3w4nom","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":2,"readPostsCount":0,"title":"Situational Awareness Summarized","canonicalCollection":null},"User:YyYKuEEDwNZXzhEFn":{"_id":"YyYKuEEDwNZXzhEFn","__typename":"User","slug":"strivingforlegibility","createdAt":"2023-11-23T04:25:50.013Z","username":"StrivingForLegibility","displayName":"StrivingForLegibility","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":354,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":28,"commentCount":30,"sequenceCount":4,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"gXeEWGjTWyqgrQTzR"},"Revision:3kQJuSMxoiYWnvLcA_contents":{"_id":"3kQJuSMxoiYWnvLcA_contents","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2024-08-07T01:34:51.178Z","userId":"YyYKuEEDwNZXzhEFn","html":"<p>This is a companion sequence to the main <a href=\"https://www.lesswrong.com/s/4toN42rxApcqMb8uY\">Geometric Utilitarianism<\/a> sequence, where I go into more mathematical detail about the results described there. Check out <a href=\"https://www.lesswrong.com/posts/gJGYDsyxj3rZDp86E/geometric-utilitarianism-and-why-it-matters\">Geometric Utilitarianism (And Why It Matters)<\/a> to hear more about what Geometric Utilitarianism is and why I think it's interesting and useful!<\/p>","commitMessage":"","wordCount":47,"htmlHighlight":"<p>This is a companion sequence to the main <a href=\"https://www.lesswrong.com/s/4toN42rxApcqMb8uY\">Geometric Utilitarianism<\/a> sequence, where I go into more mathematical detail about the results described there. Check out <a href=\"https://www.lesswrong.com/posts/gJGYDsyxj3rZDp86E/geometric-utilitarianism-and-why-it-matters\">Geometric Utilitarianism (And Why It Matters)<\/a> to hear more about what Geometric Utilitarianism is and why I think it's interesting and useful!<\/p>","plaintextDescription":"This is a companion sequence to the main Geometric Utilitarianism sequence, where I go into more mathematical detail about the results described there. Check out Geometric Utilitarianism (And Why It Matters) to hear more about what Geometric Utilitarianism is and why I think it's interesting and useful!"},"Sequence:3kQJuSMxoiYWnvLcA":{"_id":"3kQJuSMxoiYWnvLcA","__typename":"Sequence","createdAt":"2024-05-31T19:13:35.594Z","userId":"YyYKuEEDwNZXzhEFn","user":{"__ref":"User:YyYKuEEDwNZXzhEFn"},"contents":{"__ref":"Revision:3kQJuSMxoiYWnvLcA_contents"},"gridImageId":"sequencesgrid/hbkqht1s3tlwe1gus2oi","bannerImageId":"sequences/bskhhipvg9fxrqaiv5it","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"The Math of Geometric Utilitarianism","canonicalCollection":null},"Revision:4toN42rxApcqMb8uY_contents":{"_id":"4toN42rxApcqMb8uY_contents","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2024-08-07T01:35:02.514Z","userId":"YyYKuEEDwNZXzhEFn","html":"<p>Do you like using numbers to represent <a href=\"https://en.wikipedia.org/wiki/Probability_theory\">uncertainty<\/a> and <a href=\"https://en.wikipedia.org/wiki/Utility\">preference<\/a>, but also care about things like fairness and consent? Are you an altruist on a budget, looking to <a href=\"https://www.lesswrong.com/tag/effective-altruism/\">do the most good<\/a> with some of your resources, but want to pursue other goals too? Are you looking for a way to align systems to the interests of many people? Geometric Utilitarianism might be right for you!<\/p>","commitMessage":"","wordCount":66,"htmlHighlight":"<p>Do you like using numbers to represent <a href=\"https://en.wikipedia.org/wiki/Probability_theory\">uncertainty<\/a> and <a href=\"https://en.wikipedia.org/wiki/Utility\">preference<\/a>, but also care about things like fairness and consent? Are you an altruist on a budget, looking to <a href=\"https://www.lesswrong.com/tag/effective-altruism/\">do the most good<\/a> with some of your resources, but want to pursue other goals too? Are you looking for a way to align systems to the interests of many people? Geometric Utilitarianism might be right for you!<\/p>","plaintextDescription":"Do you like using numbers to represent uncertainty and preference, but also care about things like fairness and consent? Are you an altruist on a budget, looking to do the most good with some of your resources, but want to pursue other goals too? Are you looking for a way to align systems to the interests of many people? Geometric Utilitarianism might be right for you!"},"Sequence:4toN42rxApcqMb8uY":{"_id":"4toN42rxApcqMb8uY","__typename":"Sequence","createdAt":"2024-05-31T19:07:38.481Z","userId":"YyYKuEEDwNZXzhEFn","user":{"__ref":"User:YyYKuEEDwNZXzhEFn"},"contents":{"__ref":"Revision:4toN42rxApcqMb8uY_contents"},"gridImageId":"sequencesgrid/kwhpr6papjsvaa5bg6dg","bannerImageId":"sequences/juwi1rqy7argohyswagf","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":3,"readPostsCount":0,"title":"Geometric Utilitarianism","canonicalCollection":null},"User:2gSkegMMWi3DPdmhQ":{"_id":"2gSkegMMWi3DPdmhQ","__typename":"User","slug":"daystareld","createdAt":"2014-11-07T02:44:08.618Z","username":"DaystarEld","displayName":"DaystarEld","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":664,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":8,"commentCount":58,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:oTMuc9C3KKdZ6FcCB_contents":{"_id":"oTMuc9C3KKdZ6FcCB_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-05-24T16:20:58.779Z","userId":"2gSkegMMWi3DPdmhQ","html":"<p>Procedural Executive Function is my name for a frame of understanding executive function as a series of steps, which I believe can be individually understood and zero'd in on when people fail to act on their ostensible goals.<\/p><p>This sequence goes over what PEF is, and how to problem-solve what's going wrong when Executive Dysfunction occurs, from the philosophical base of \"how sure are you that you actually want to do the thing you think you want to do?\" to the final problem solving steps involved in actually accomplishing your goals.<\/p>","commitMessage":"","wordCount":91,"htmlHighlight":"<p>Procedural Executive Function is my name for a frame of understanding executive function as a series of steps, which I believe can be individually understood and zero'd in on when people fail to act on their ostensible goals.<\/p><p>This sequence goes over what PEF is, and how to problem-solve what's going wrong when Executive Dysfunction occurs, from the philosophical base of \"how sure are you that you actually want to do the thing you think you want to do?\" to the final problem solving steps involved in actually accomplishing your goals.<\/p>","plaintextDescription":"Procedural Executive Function is my name for a frame of understanding executive function as a series of steps, which I believe can be individually understood and zero'd in on when people fail to act on their ostensible goals.\n\nThis sequence goes over what PEF is, and how to problem-solve what's going wrong when Executive Dysfunction occurs, from the philosophical base of \"how sure are you that you actually want to do the thing you think you want to do?\" to the final problem solving steps involved in actually accomplishing your goals."},"Sequence:oTMuc9C3KKdZ6FcCB":{"_id":"oTMuc9C3KKdZ6FcCB","__typename":"Sequence","createdAt":"2024-05-23T12:28:38.796Z","userId":"2gSkegMMWi3DPdmhQ","user":{"__ref":"User:2gSkegMMWi3DPdmhQ"},"contents":{"__ref":"Revision:oTMuc9C3KKdZ6FcCB_contents"},"gridImageId":"sequencesgrid/afhsthmxkh51qxnbnkyg","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Procedural Executive Function","canonicalCollection":null},"User:AsgAGsXJStna24q9H":{"_id":"AsgAGsXJStna24q9H","__typename":"User","slug":"euanmclean","createdAt":"2022-05-27T16:48:15.968Z","username":"euanmclean","displayName":"EuanMcLean","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":426,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"<p>into digital sentience<\/p>","jobTitle":null,"organization":null,"postCount":5,"commentCount":6,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:xCmj2w2ZrcwxdH9z3_contents":{"_id":"xCmj2w2ZrcwxdH9z3_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-06-04T11:30:52.243Z","userId":"AsgAGsXJStna24q9H","html":"<p>I conducted 17 semi-structured interviews of AI safety experts about their big picture strategic view of the AI safety landscape: how will human-level AI play out, how things might go wrong, and what should the AI safety community be doing. While many respondents held “traditional” views (e.g. the main threat is misaligned AI takeover), there was more opposition to these standard views than I expected, and the field seems more split on many important questions than someone outside the field may infer.<\/p>\n<p>This sequence summarises the main findings from these interviews.<\/p>\n","commitMessage":"","wordCount":91,"htmlHighlight":"<p>I conducted 17 semi-structured interviews of AI safety experts about their big picture strategic view of the AI safety landscape: how will human-level AI play out, how things might go wrong, and what should the AI safety community be doing. While many respondents held “traditional” views (e.g. the main threat is misaligned AI takeover), there was more opposition to these standard views than I expected, and the field seems more split on many important questions than someone outside the field may infer.<\/p>\n<p>This sequence summarises the main findings from these interviews.<\/p>","plaintextDescription":"I conducted 17 semi-structured interviews of AI safety experts about their big picture strategic view of the AI safety landscape: how will human-level AI play out, how things might go wrong, and what should the AI safety community be doing. While many respondents held “traditional” views (e.g. the main threat is misaligned AI takeover), there was more opposition to these standard views than I expected, and the field seems more split on many important questions than someone outside the field may infer.\n\nThis sequence summarises the main findings from these interviews."},"Sequence:xCmj2w2ZrcwxdH9z3":{"_id":"xCmj2w2ZrcwxdH9z3","__typename":"Sequence","createdAt":"2024-05-23T11:24:53.944Z","userId":"AsgAGsXJStna24q9H","user":{"__ref":"User:AsgAGsXJStna24q9H"},"contents":{"__ref":"Revision:xCmj2w2ZrcwxdH9z3_contents"},"gridImageId":"sequencesgrid/pd0fyvvdyqt7l5nqewng","bannerImageId":"sequences/yaqewves0az1oagxkk0t","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Big Picture AI Safety","canonicalCollection":null},"User:QH4oRvu3e85mSxtj8":{"_id":"QH4oRvu3e85mSxtj8","__typename":"User","slug":"j-bostock","createdAt":"2021-01-13T15:49:14.305Z","username":"Jemist","displayName":"J Bostock","profileImageId":null,"previousDisplayName":null,"fullName":"Jonathan Bostock","karma":1313,"afKarma":14,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":63,"commentCount":113,"sequenceCount":4,"afPostCount":2,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"gXeEWGjTWyqgrQTzR"},"Revision:LN5LaQKkuRv3AMzZY_contents":{"_id":"LN5LaQKkuRv3AMzZY_contents","__typename":"Revision","version":"1.0.0","updateType":"initial","editedAt":"2024-04-23T15:42:49.411Z","userId":"QH4oRvu3e85mSxtj8","html":"<p>Deriving traditional thermodynamics from the principles of information theory alone.<\/p>","commitMessage":"","wordCount":10,"htmlHighlight":"<p>Deriving traditional thermodynamics from the principles of information theory alone.<\/p>","plaintextDescription":"Deriving traditional thermodynamics from the principles of information theory alone."},"Sequence:LN5LaQKkuRv3AMzZY":{"_id":"LN5LaQKkuRv3AMzZY","__typename":"Sequence","createdAt":"2024-04-23T15:42:49.295Z","userId":"QH4oRvu3e85mSxtj8","user":{"__ref":"User:QH4oRvu3e85mSxtj8"},"contents":{"__ref":"Revision:LN5LaQKkuRv3AMzZY_contents"},"gridImageId":"sequencesgrid/ndkwvkl6bin8cmzscjzl","bannerImageId":"sequences/uftmlqxbkv1vkww55ynq","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":3,"readPostsCount":0,"title":"Statistical Mechanics","canonicalCollection":null},"Revision:B4HLTcpsB4NkxKFtN":{"_id":"B4HLTcpsB4NkxKFtN","__typename":"Revision","htmlHighlight":"<p>Meet inside The Shops at Waterloo Town Square - we will congregate in the indoor seating area next to the Your Independent Grocer with the trees sticking out in the middle of the benches (<a href=\"https://files.strawcdn.com/straw/lWBDkHCvHdLljndwhVRQ.jpg\">pic<\/a>) at 7:00 pm for 15 minutes, and then head over to my nearby apartment's amenity room. If you've been around a few times, feel free to meet up at the front door of the apartment at 7:30 instead.<\/p><h2>Topic<\/h2><p>Weirdly appropriately for the last meetup before Thanksgiving, we're discussing Nate Soares' <a href=\"https://www.lesswrong.com/s/pFatcKW3JJhTSxqAF\">Replacing Guilt sequence<\/a>. It's a series intended to remove guilt-based motivation and replace it with something healthier and stronger, and I keep meaning to read more of it because the parts that I have read have been universally quite helpful. It's a pretty long series and we'll only really be scratching the surface, but hopefully this will give you something like a toehold to explore the rest of the sequence in your own time.<\/p><p><a href=\"https://pod.link/1498321446\">For those who prefer audio, there are podcast versions of all the articles in the sequence.<\/a><\/p><h2>Readings<\/h2><p>We'll be using our tried-and-true partitioned book club format:<\/p><ol><li>Everyone read the 2 minute introduction post: <a href=\"https://mindingourway.com/replacing-guilt/\">https://mindingourway.com/replacing-guilt/<\/a><\/li><li>Go to the <a href=\"https://jstrieb.github.io/link-lock/#eyJ2IjoiMC4wLjEiLCJlIjoidTdMK1c3dDZOYUpXTlI0THFiQkp4dTlrVzU5cGlJd0tMUHF1bk13bEhQUjZFSS9BYjc2SUhYN2oxS3RLRkx0QjZORlozSGxtMlQwa1R4ZEtZOEdKdUd5ZkhmN1VGWVMxdm9TUWhZb0g3TVREK00rSkwwVzYwT3laelNRL3dra1FyWkc4RmdnK012NzRpYmdlS1hJczVvVFcxekRkbzVBWHVDSWdnZnpCYURCM2VlMCsiLCJoIjoic2FtZSBhcyB0aGUgZGlzY29yZCBpbnYiLCJzIjoiUlpwell1WmU0aDhpZ3lQK2p0ckFnUT09IiwiaSI6InFjVnNRekZ1RHlwNStweUoifQ==\">spreadsheet<\/a> (same password as the discord invitation) and claim a block of posts to read or listen to. Optionally, read/listen to more of the posts because all of them are pretty good.&nbsp;<ol><li>If this is your first meetup or you can't access the spreadsheet for some reason, read or listen to <a href=\"https://www.lesswrong.com/s/pFatcKW3JJhTSxqAF/p/sG4paay6CeGbyYZZo\">Don't Steer With Guilt<\/a> and the three next posts in the sequence (Update From the Suckerpunch, Be a New Homunculus, and Not Yet Gods). Or any three posts that you find particularly interesting. Or just show up and listen to the summary from other folks.<\/li><\/ol><\/li><li>Prepare a ~5 minute summary of useful ideas you encounter for the block you've claimed to share with the group.<\/li><\/ol><h2>Mini-Workshop<\/h2><p>After our summaries and initial discussion, we'll break into small groups and do a quick exercise<\/p><ol><li>Think about a personal situation where you've used guilt based motivation.<\/li><li>Working in small groups, apply the principles from the sequence to your situation.<\/li><li>Optionally, share back with the big group afterwards.<\/li><\/ol>","plaintextDescription":"Meet inside The Shops at Waterloo Town Square - we will congregate in the indoor seating area next to the Your Independent Grocer with the trees sticking out in the middle of the benches (pic) at 7:00 pm for 15 minutes, and then head over to my nearby apartment's amenity room. If you've been around a few times, feel free to meet up at the front door of the apartment at 7:30 instead.\n\n\nTopic\nWeirdly appropriately for the last meetup before Thanksgiving, we're discussing Nate Soares' Replacing Guilt sequence. It's a series intended to remove guilt-based motivation and replace it with something healthier and stronger, and I keep meaning to read more of it because the parts that I have read have been universally quite helpful. It's a pretty long series and we'll only really be scratching the surface, but hopefully this will give you something like a toehold to explore the rest of the sequence in your own time.\n\nFor those who prefer audio, there are podcast versions of all the articles in the sequence.\n\n\nReadings\nWe'll be using our tried-and-true partitioned book club format:\n\n 1. Everyone read the 2 minute introduction post: https://mindingourway.com/replacing-guilt/\n 2. Go to the spreadsheet (same password as the discord invitation) and claim a block of posts to read or listen to. Optionally, read/listen to more of the posts because all of them are pretty good. \n    1. If this is your first meetup or you can't access the spreadsheet for some reason, read or listen to Don't Steer With Guilt and the three next posts in the sequence (Update From the Suckerpunch, Be a New Homunculus, and Not Yet Gods). Or any three posts that you find particularly interesting. Or just show up and listen to the summary from other folks.\n 3. Prepare a ~5 minute summary of useful ideas you encounter for the block you've claimed to share with the group.\n\n\nMini-Workshop\nAfter our summaries and initial discussion, we'll break into small groups and do a quick exercise\n\n 1. Think about a personal ","wordCount":372,"version":"1.1.0"},"Revision:Ng8Gice9KNkncxqcj_description":{"_id":"Ng8Gice9KNkncxqcj_description","__typename":"Revision","htmlHighlight":"<p><strong>Rationality<\/strong> is the art of thinking in ways that result in <a href=\"https://www.lesswrong.com/tag/world-modeling\">accurate beliefs<\/a> and <a href=\"https://www.lesswrong.com/tag/decision-theory\">good decisions<\/a>. It is the primary topic of LessWrong.<br><br>Rationality is not only about avoiding the vices of <a href=\"https://www.lesswrong.com/tag/self-deception\">self-deception<\/a> and obfuscation (the failure to <a href=\"https://www.lesswrong.com/tag/conversation-topic\">communicate clearly<\/a>), but also about the virtue of <a href=\"https://www.lesswrong.com/tag/curiosity\">curiosity<\/a>, seeing the world more clearly than before, and <a href=\"https://www.lesswrong.com/tag/ambition\">achieving things<\/a> <a href=\"https://www.lesswrong.com/tag/skill-building\">previously unreachable<\/a> <a href=\"https://www.lesswrong.com/tag/coordination-cooperation\">to you<\/a>. The study of rationality on LessWrong includes a theoretical understanding of ideal cognitive algorithms, as well as building a practice that uses these idealized algorithms to inform <a href=\"https://www.lesswrong.com/tag/heuristics-and-biases\">heuristics<\/a>, <a href=\"https://www.lesswrong.com/tag/habits\">habits<\/a>, and <a href=\"https://www.lesswrong.com/tag/techniques\">techniques<\/a>, to successfully reason and make decisions in the real world.<\/p><p>Topics covered in rationality include (but are not limited to): normative and theoretical explorations of <a href=\"https://www.lesswrong.com/tag/solomonoff-induction\">ideal<\/a> <a href=\"https://www.lesswrong.com/tag/probability-and-statistics\">reasoning<\/a>; the <a href=\"https://www.lesswrong.com/tag/evolutionary-psychology\">capabilities and limitations<\/a> <a href=\"https://www.lesswrong.com/tag/neuroscience\">of our brain<\/a>, <a href=\"https://www.lesswrong.com/tag/dual-process-theory-system-1-and-system-2\">mind and psychology<\/a>; applied advice such as <a href=\"https://www.lesswrong.com/tag/introspection\">introspection<\/a> techniques and <a href=\"https://www.lesswrong.com/tag/group-rationality\">how to achieve truth collaboratively<\/a>; practical techniques and methodologies for figuring out what’s true ranging from rough quantitative modeling to full research guides.<\/p><p>Note that content about <i>how the world is <\/i>can be found under <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a>, and practical advice about <i>how to change the world<\/i> is categorized under <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a> or <a href=\"/tag/practical\">Practical<\/a>.<\/p><hr><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\"><p><strong>Theory / Concepts<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/anticipated-experiences?showPostCount=true&amp;useTagName=true\"><u>Anticipated Experiences<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/aumann-s-agreement-theorem?showPostCount=true&amp;useTagName=true\">Aumann's Agreement Theorem<\/a><br><a href=\"http://www.lesswrong.com/tag/bayes-theorem?showPostCount=true&amp;useTagName=true\"><u>Bayes Theorem<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/bounded-rationality?showPostCount=true&amp;useTagName=true\">Bounded Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/conservation-of-expected-evidence?showPostCount=true&amp;useTagName=true\">Conservation of Expected<\/a><br><a href=\"http://www.lesswrong.com/tag/contrarianism?showPostCount=true&amp;useTagName=true\">Contrarianism<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemology?showPostCount=true&amp;useTagName=true\"><u>Epistemology<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\"><u>Gears-Level<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/hansonian-pre-rationality?useTagName=true&amp;showPostCount=true\">Hansonian Pre-Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/law-thinking?showPostCount=true&amp;useTagName=true\">Law-Thinking<\/a><br><a href=\"http://www.lesswrong.com/tag/map-and-territory?showPostCount=true&amp;useTagName=true\">Map and Territory<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"http://www.lesswrong.com/tag/occam-s-razor?showPostCount=true&amp;useTagName=true\">Occam's razor<\/a><br><a href=\"https://www.lesswrong.com/tag/robust-agents?showPostCount=true&amp;useTagName=true\">Robust Agents<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/truth-semantics-and-meaning?showPostCount=true&amp;useTagName=true\">Truth, Semantics, &amp; Meaning<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/alief?showPostCount=true&amp;useTagName=true\"><u>Alief<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/betting?showPostCount=true&amp;useTagName=true\">Betting<\/a><br><a href=\"http://www.lesswrong.com/tag/cached-thoughts?showPostCount=true&amp;useTagName=true\">Cached Thoughts<\/a><br><a href=\"http://www.lesswrong.com/tag/calibration?showPostCount=true&amp;useTagName=true\">Calibration<\/a><br><a href=\"https://www.lesswrong.com/tag/dark-arts?showPostCount=true&amp;useTagName=true\">Dark Arts<\/a><br><a href=\"http://www.lesswrong.com/tag/empiricism?showPostCount=true&amp;useTagName=true\">Empiricism<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemic-modesty?showPostCount=true&amp;useTagName=true\">Epistemic Modesty<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/identity?showPostCount=true&amp;useTagName=true\">Identity<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/introspection?showPostCount=true&amp;useTagName=true\"><u>Introspection<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/intuition?showPostCount=true&amp;useTagName=true\">Intuition<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\"><u>Practice &amp; Philosophy of Science<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><br><a href=\"http://www.lesswrong.com/tag/taking-ideas-seriously?showPostCount=true&amp;useTagName=true\">Taking Ideas Seriously<\/a><br><a href=\"https://www.lesswrong.com/tag/value-of-information?showPostCount=true&amp;useTagName=true\">Value of Information<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Failure Modes<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/affect-heuristic?showPostCount=true&amp;useTagName=true\">Affect Heuristic<\/a><br><a href=\"https://www.lesswrong.com/tag/bucket-errors?showPostCount=true&amp;useTagName=true\">Bucket Errors<\/a><br><a href=\"https://www.lesswrong.com/tag/compartmentalization?showPostCount=true&amp;useTagName=true\">Compartmentalization<\/a><br><a href=\"https://www.lesswrong.com/tag/confirmation-bias?showPostCount=true&amp;useTagName=true\"><u>Confirmation Bias<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/logical-fallacies?showPostCount=true&amp;useTagName=true\">Fallacies<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodhart’s Law<\/a><br><a href=\"http://www.lesswrong.com/tag/groupthink?showPostCount=true&amp;useTagName=true\"><u>Groupthink<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/heuristics-and-biases?showPostCount=true&amp;useTagName=true\">Heuristics and Biases<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-projection-fallacy?showPostCount=true&amp;useTagName=true\">Mind Projection Fallacy<\/a><br><a href=\"https://www.lesswrong.com/tag/motivated-reasoning?showPostCount=true&amp;useTagName=true\"><u>Motivated Reasoning<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true&amp;useTagName=true\">Pica<\/a><br><a href=\"https://www.lesswrong.com/tag/pitfalls-of-rationality?showPostCount=true&amp;useTagName=true\">Pitfalls of Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/rationalization?showPostCount=true&amp;useTagName=true\">Rationalization<\/a>&nbsp;<br><a href=\"https://www.lesswrong.com/tag/self-deception?showPostCount=true&amp;useTagName=true\">Self-Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/sunk-cost-fallacy?showPostCount=true&amp;useTagName=true\">Sunk-Cost Fallacy<\/a><\/p><\/td><\/tr><tr><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top\" rowspan=\"2\"><p><strong>Communication<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true\"><u>Conversation<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/decoupling-vs-contextualizing?showPostCount=true&amp;useTagName=true\"><u>Decoupling vs Contextualizing<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/disagreement?showPostCount=true&amp;useTagName=true\"><u>Disagreement<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"http://www.lesswrong.com/tag/double-crux?showPostCount=true&amp;useTagName=true\"><u>Double-Crux<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/good-explanations-advice?showPostCount=true&amp;useTagName=true\">Good Explanations (Advice)<\/a><br><a href=\"http://www.lesswrong.com/tag/ideological-turing-tests?showPostCount=true&amp;useTagName=true\">Ideological Turing Tests<\/a><br><a href=\"https://www.lesswrong.com/tag/inferential-distance?showPostCount=true&amp;useTagName=true\">Inferential Distance<\/a><br><a href=\"https://www.lesswrong.com/tag/information-cascades?showPostCount=true&amp;useTagName=true\">Information Cascades<\/a><br><a href=\"https://www.lesswrong.com/tag/memetic-immune-system?showPostCount=true&amp;useTagName=true\">Memetic Immune System<\/a><br><a href=\"https://www.lesswrong.com/tag/philosophy-of-language?showPostCount=true&amp;useTagName=true\"><u>Philos<\/u><\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>... "},"Tag:Ng8Gice9KNkncxqcj":{"_id":"Ng8Gice9KNkncxqcj","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Ng8Gice9KNkncxqcj_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Rationality","shortName":null,"slug":"rationality","core":true,"postCount":3828,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":100,"createdAt":"2020-06-14T22:24:17.072Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:drSKaciaB3JoBeoST":{"_id":"drSKaciaB3JoBeoST","__typename":"SocialPreviewType","imageUrl":""},"Localgroup:NiM9cQJ5qXqhdmP5p":{"_id":"NiM9cQJ5qXqhdmP5p","__typename":"Localgroup","name":"Kitchener-Waterloo Rationality","organizerIds":["gYxdDBQ3AZbde8HgZ"]},"Revision:gYxdDBQ3AZbde8HgZ_biography":{"_id":"gYxdDBQ3AZbde8HgZ_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2023-05-11T17:43:08.429Z","userId":"gYxdDBQ3AZbde8HgZ","html":"","commitMessage":"","wordCount":0,"htmlHighlight":"","plaintextDescription":""},"User:gYxdDBQ3AZbde8HgZ":{"_id":"gYxdDBQ3AZbde8HgZ","__typename":"User","biography":{"__ref":"Revision:gYxdDBQ3AZbde8HgZ_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"jenn","createdAt":"2019-09-02T19:45:07.238Z","username":"pixx","displayName":"jenn","previousDisplayName":null,"fullName":null,"karma":834,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":110,"commentCount":25,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Post:drSKaciaB3JoBeoST":{"_id":"drSKaciaB3JoBeoST","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:B4HLTcpsB4NkxKFtN"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:drSKaciaB3JoBeoST"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2024-10-06T16:40:19.569Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"B4HLTcpsB4NkxKFtN","commentCount":0,"voteCount":1,"baseScore":5,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":1,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.027940839529037476,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2024-10-06T16:40:19.569Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"gYxdDBQ3AZbde8HgZ","location":"75 King Street South, Waterloo, ON, Canada","googleLocation":{"url":"https://maps.google.com/?q=75+King+St+S,+Waterloo,+ON+N2J+1P2,+Canada&ftid=0x882bf4129699410f:0x68b5691c410abad4","icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","name":"75 King St S","types":["street_address"],"geometry":{"location":{"lat":43.46363059999999,"lng":-80.52343259999999},"viewport":{"east":-80.52137144999999,"west":-80.52411964999999,"north":43.4650976302915,"south":43.4623996697085}},"place_id":"ChIJD0GZlhL0K4gR1LoKQRxptWg","vicinity":"Waterloo","plus_code":{"global_code":"86MXFF7G+FJ","compound_code":"FF7G+FJ Waterloo, ON, Canada"},"reference":"ChIJD0GZlhL0K4gR1LoKQRxptWg","utc_offset":-240,"adr_address":"<span class=\"street-address\">75 King St S<\/span>, <span class=\"locality\">Waterloo<\/span>, <span class=\"region\">ON<\/span> <span class=\"postal-code\">N2J 1P2<\/span>, <span class=\"country-name\">Canada<\/span>","formatted_address":"75 King St S, Waterloo, ON N2J 1P2, Canada","html_attributions":[],"address_components":[{"types":["street_number"],"long_name":"75","short_name":"75"},{"types":["route"],"long_name":"King Street South","short_name":"King St S"},{"types":["locality","political"],"long_name":"Waterloo","short_name":"Waterloo"},{"types":["administrative_area_level_3","political"],"long_name":"Waterloo","short_name":"Waterloo"},{"types":["administrative_area_level_2","political"],"long_name":"Waterloo Regional Municipality","short_name":"Waterloo Regional Municipality"},{"types":["administrative_area_level_1","political"],"long_name":"Ontario","short_name":"ON"},{"types":["country","political"],"long_name":"Canada","short_name":"CA"},{"types":["postal_code"],"long_name":"N2J 1P2","short_name":"N2J 1P2"}],"icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","utc_offset_minutes":-240,"icon_background_color":"#7B9EB0"},"onlineEvent":false,"globalEvent":false,"startTime":"2024-10-10T23:00:00.000Z","endTime":"2024-10-11T02:30:00.000Z","localStartTime":"2024-10-10T19:00:00.000Z","localEndTime":"2024-10-10T22:30:00.000Z","eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":true,"eventImageId":null,"eventType":null,"types":["LW","SSC"],"groupId":"NiM9cQJ5qXqhdmP5p","reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":0,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2024-10-06T16:17:02.383Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":{"__ref":"Localgroup:NiM9cQJ5qXqhdmP5p"},"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:gYxdDBQ3AZbde8HgZ"},"coauthors":[],"slug":"replacing-guilt-1","title":"Replacing Guilt","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:GHTLeDCz2tw3FBrnT":{"_id":"GHTLeDCz2tw3FBrnT","__typename":"Revision","htmlHighlight":"<p>Please read one of the articles listed on the page below to discuss. If you can't, come anyway :-)<\/p>\n<p>English: <a href=\"https://www.rationality-freiburg.de/events/2024-10-11-acx-meetup-fall-2024/\">https://www.rationality-freiburg.de/events/2024-10-11-acx-meetup-fall-2024/<\/a><\/p>\n<p>Deutsch: <a href=\"https://www.rationality-freiburg.de/de/termine/2024-10-11-acx-meetup-herbst-2024/\">https://www.rationality-freiburg.de/de/termine/2024-10-11-acx-meetup-herbst-2024/<\/a><\/p>","plaintextDescription":"Please read one of the articles listed on the page below to discuss. If you can't, come anyway :-)\n\nEnglish: https://www.rationality-freiburg.de/events/2024-10-11-acx-meetup-fall-2024/\n\nDeutsch: https://www.rationality-freiburg.de/de/termine/2024-10-11-acx-meetup-herbst-2024/","wordCount":23,"version":"1.0.0"},"SocialPreviewType:mL88XQ4k75dgWxCpL":{"_id":"mL88XQ4k75dgWxCpL","__typename":"SocialPreviewType","imageUrl":""},"Localgroup:fFZZ2Ywzsab86EESY":{"_id":"fFZZ2Ywzsab86EESY","__typename":"Localgroup","name":"Rationality Freiburg","organizerIds":["yLipGJQRLnS9Yndog","5TDkMstKmzAdaBYfn"]},"Revision:yLipGJQRLnS9Yndog_biography":{"_id":"yLipGJQRLnS9Yndog_biography","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-07T10:28:55.287Z","userId":"yLipGJQRLnS9Yndog","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"User:yLipGJQRLnS9Yndog":{"_id":"yLipGJQRLnS9Yndog","__typename":"User","biography":{"__ref":"Revision:yLipGJQRLnS9Yndog_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"omark","createdAt":"2022-04-16T12:36:07.679Z","username":"omark","displayName":"omark","previousDisplayName":null,"fullName":null,"karma":87,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":52,"commentCount":17,"sequenceCount":0,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"User:5TDkMstKmzAdaBYfn":{"_id":"5TDkMstKmzAdaBYfn","__typename":"User","slug":"bibhu-kar","createdAt":"2022-10-17T11:33:27.048Z","username":"bibhu-kar","displayName":"Bibhu kar","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":0,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":0,"commentCount":0,"sequenceCount":0,"afPostCount":0,"afCommentCount":0,"spamRiskScore":0.8,"tagRevisionCount":0,"reviewedByUserId":null},"Post:mL88XQ4k75dgWxCpL":{"_id":"mL88XQ4k75dgWxCpL","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:GHTLeDCz2tw3FBrnT"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:mL88XQ4k75dgWxCpL"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2024-08-24T11:56:56.291Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":null,"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"GHTLeDCz2tw3FBrnT","commentCount":0,"voteCount":1,"baseScore":2,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":1,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.000879142782650888,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2024-08-24T11:56:56.291Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"yLipGJQRLnS9Yndog","location":"Rehlingstraße 9, 79100 Freiburg im Breisgau, Germany","googleLocation":{"url":"https://maps.google.com/?q=Rehlingstra%C3%9Fe+9,+79100+Freiburg+im+Breisgau,+Germany&ftid=0x47911b5fabb533ed:0x5415e57216228c8d","icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","name":"Rehlingstraße 9","types":["premise"],"geometry":{"location":{"lat":47.9895238,"lng":7.8397408},"viewport":{"east":7.841159130291502,"west":7.838461169708498,"north":47.9909020802915,"south":47.9882041197085}},"place_id":"ChIJ7TO1q18bkUcRjYwiFnLlFVQ","vicinity":"Süd","reference":"ChIJ7TO1q18bkUcRjYwiFnLlFVQ","utc_offset":120,"adr_address":"<span class=\"street-address\">Rehlingstraße 9<\/span>, <span class=\"postal-code\">79100<\/span> <span class=\"locality\">Freiburg im Breisgau<\/span>, <span class=\"country-name\">Germany<\/span>","formatted_address":"Rehlingstraße 9, 79100 Freiburg im Breisgau, Germany","html_attributions":[],"address_components":[{"types":["street_number"],"long_name":"9","short_name":"9"},{"types":["route"],"long_name":"Rehlingstraße","short_name":"Rehlingstraße"},{"types":["sublocality_level_1","sublocality","political"],"long_name":"Süd","short_name":"Süd"},{"types":["locality","political"],"long_name":"Freiburg im Breisgau","short_name":"Freiburg im Breisgau"},{"types":["administrative_area_level_3","political"],"long_name":"Kreisfreie Stadt Freiburg im Breisgau","short_name":"Kreisfreie Stadt Freiburg im Breisgau"},{"types":["administrative_area_level_2","political"],"long_name":"Freiburg","short_name":"Freiburg"},{"types":["administrative_area_level_1","political"],"long_name":"Baden-Württemberg","short_name":"BW"},{"types":["country","political"],"long_name":"Germany","short_name":"DE"},{"types":["postal_code"],"long_name":"79100","short_name":"79100"}],"icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","utc_offset_minutes":120,"icon_background_color":"#7B9EB0"},"onlineEvent":false,"globalEvent":false,"startTime":"2024-10-11T16:00:00.000Z","endTime":"2024-10-11T18:30:00.000Z","localStartTime":"2024-10-11T18:00:00.000Z","localEndTime":"2024-10-11T20:30:00.000Z","eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":true,"eventImageId":null,"eventType":"discussion","types":["LW","SSC"],"groupId":"fFZZ2Ywzsab86EESY","reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":0,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2024-08-24T11:56:56.443Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":{"__ref":"Localgroup:fFZZ2Ywzsab86EESY"},"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:yLipGJQRLnS9Yndog"},"coauthors":[{"__ref":"User:5TDkMstKmzAdaBYfn"}],"slug":"freiburg-acx-meetup-fall-2024","title":"Freiburg - ACX Meetup Fall 2024","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":[{"userId":"5TDkMstKmzAdaBYfn","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false}}</script>
<script>window.__APOLLO_FOREIGN_STATE__ = {}</script>

<script src="The%20Library%20%E2%80%94%20LessWrong_files/api.js"></script><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom"></iframe><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-aebpua169o9x" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="The%20Library%20%E2%80%94%20LessWrong_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M18.601 8.39897C18.269 8.06702 17.7309 8.06702 17.3989 8.39897L12 13.7979L6.60099 8.39897C6.26904 8.06702 5.73086 8.06702 5.39891 8.39897C5.06696 8.73091 5.06696 9.2691 5.39891 9.60105L11.3989 15.601C11.7309 15.933 12.269 15.933 12.601 15.601L18.601 9.60105C18.9329 9.2691 18.9329 8.73091 18.601 8.39897Z" fill="white"></path>
</svg>
</div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    0% {
      opacity: 0;
      transform: scale(0);
    }
    40% {
      opacity: 1;
    }
    100% {
      transform: scale(1);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #f5f5f5;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }


  .intercom-lightweight-app-launcher:hover {
    transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    transform: scale(1.1)
  }

  .intercom-lightweight-app-launcher:active {
    transform: scale(0.85);
    transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
  }


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1, 1, 1);
    transform-origin: bottom right;

    
        width: 400px;
        height: calc(100% - 104px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 84px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 16px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    border-bottom: none;
    background: #f5f5f5

    
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    height: 80px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
    
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div><a href="https://www.lesswrong.com/s/ix7grGajtrJJYXsY3"></a></body></html>