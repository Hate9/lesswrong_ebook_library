<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<link rel="preload" as="style" href="codex_files/allStyles.css"><link rel="stylesheet" type="text/css" href="codex_files/icon.css"><link rel="stylesheet" type="text/css" href="codex_files/reset-min.css"><link rel="stylesheet" type="text/css" href="codex_files/css.css"><link rel="stylesheet" type="text/css" href="codex_files/jvr1gjm.css"><link rel="stylesheet" type="text/css" href="codex_files/tqv5rhd.css"><script type="text/javascript" async="" charset="utf-8" src="codex_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-C0eb2CrhokW3SgZMDSrT/ioPvOCBoj1s7JouJ8IrLFB+j5cW9qY3JDWtShxtCryz"></script><script async="" src="codex_files/google-analytics_analytics.js"></script><script>window.publicInstanceSettings = {"forumType":"LessWrong","title":"LessWrong","siteNameWithArticle":"LessWrong","sentry":{"url":"https://1ab1949fc8d04608b43132f37bb2a1b0@sentry.io/1301611","environment":"production","release":"69f0f3c5d57b596e8249571383f8a280eff9bb23"},"debug":false,"aboutPostId":"bJ2haLkcGeLtTWaD5","faqPostId":"2rWKkWuPrgTMpLRbp","contactPostId":"ehcYkvyz7dh9L7Wt8","expectedDatabaseId":"production","tagline":"A community blog devoted to refining the art of rationality","faviconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","faviconWithBadge":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_with_badge.ico","forumSettings":{"headerTitle":"LESSWRONG","shortForumTitle":"LW","tabTitle":"LessWrong"},"analytics":{"environment":"lesswrong.com"},"cluster":{"enabled":true,"numWorkers":2},"testServer":false,"fmCrosspost":{"siteName":"the EA Forum","baseUrl":"https://forum.effectivealtruism.org/"},"allowTypeIIIPlayer":true,"hasRejectedContentSection":true,"hasCuratedPosts":true,"performanceMetricLogging":{"enabled":true,"batchSize":100},"reviewBotId":"tBchiz3RM7rPwujrJ","recombee":{"databaseId":"lightcone-infrastructure-lesswrong-prod-2","publicApiToken":"sb95OJbQ7mKLQAm1abPog2m5vCPj7XqZlVYdHGyANcjzqaHT5fX6HEgB0vCfiLav"},"homepagePosts":{"feeds":[{"name":"forum-classic","label":"Latest","description":"The classic LessWrong frontpage algorithm that combines karma with time discounting, plus any tag-based weighting if applied.","showToLoggedOut":true},{"name":"recombee-hybrid","label":"Enriched","description":"An equal mix of Latest and Recommended.","showSparkleIcon":true,"defaultTab":true,"showToLoggedOut":true},{"name":"recombee-lesswrong-custom","label":"Recommended","description":"Personalized recommendations from the history of LessWrong, using a machine learning model that takes into account posts you've read and/or voted on.","showSparkleIcon":true,"showToLoggedOut":true},{"name":"forum-subscribed-authors","label":"Subscribed","description":"Posts and comments by people you've explicitly subscribed to.","isInfiniteScroll":true},{"name":"vertex-default","label":"Vertex","description":"Experimental feed for Google Vertex recommendations.","showLabsIcon":true,"adminOnly":true},{"name":"forum-bookmarks","label":"Bookmarks","description":"A list of posts you saved because you wanted to have them findable later."},{"name":"forum-continue-reading","label":"Resume Reading","description":"Further posts in post sequences that you started reading.","disabled":true}]}}</script><link rel="shortcut icon" href="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico"><script>window.publicSettings = {"forum":{"numberOfDays":10,"postInterval":30,"numberOfWeeks":4,"numberOfYears":4,"maxPostsPerDay":5,"numberOfMonths":4},"type3":{"cutoffDate":"2023-07-01","explicitlyAllowedPostIds":["SvKSwT6xYfYahH4XN","2weRdcvqANDq3zdPH","Zm7WAJMTaFvuh2Wc7","HcjL8ydHxPezj6wrt","pgGiqLQg2KWsaz5RE","jFzovY2CERF5bd2EW","sm6npdgZArSn4afeZ","CfX6pGepdjQYELSpK","NyFuuKQ8uCEDtd2du","LCjtqsQWapoSfDHqK","MxyRNd6qJsYAcXKuw","reG3g4wwzwJcKnFfh","zfeWGvTrS6wKQeeoF","oHsMeXehPy4jHcmwy","ofL22R6KZsfrvdmwg","655TmdcwAgryPGPWS","hhrv8aAcmkzJxvP58","iqQJiKcephtMgzJgN","mnpkM57R6ZbjnwrYw","6mRv7Cr57AJAtRFHv","ak9wY2t9K3K4GxCXv","Ay6GBGNcCgP55dRQ7","aH4mjhgqNPyYvJT85","JpoLCHytYiCm7fwNA","efMgZujzfjP9B9H4R","BjLxPLsev54LFCS3A","HTGCGASf9xfB6edAh","H6LnGwjKiGvDyR5yo","qL8Z9TBCNWQyN6yLq","F4xwRTrFQyazHufjD","LY7Nca846X8kcT8Jk","K9aLcuxAPyf5jGyFX","2AuvBPw6Rb7yxkvKc","muhtBvbh4etjkKXd9","ALEYMFAuFSCz8v5YE","CJxSgaqG6y7z6Rbij","k5TpDCEHeK4qwnJt8","4Y2J7NtuweW2B8JvB","BpYDqQNZ2NZNCqPp6","oMiogKLkK8L59WzDe","TyQSMmoJpRG3HBv5S","8KHR3tfa4SJjMSkXd","g4pi2jfQHFF6mPdjw","znEhB9hJtwXica5s3","Sd2r7H8bCmd9ChGbX","P2nYKqwmHdYKARTG8","FW3DEYbKPZJh5A8Bj","K3hFLRn7MvYacL466","ouSpHCCPgsXkwxAGb","w9SuQtRJLbDpeir6L","yPQGYn9rSme9RRpiQ","BD6WYC4GT6dnWaJRN","c8khnHoRTSGjmHLLf","TaPr4YSBbiakeKdwX","pyNPXST7feDX45ygt","ERPL3v2Y976W7XG3j","XpXQ4KNzLa9ZHYw8p","PBhrHw5X8sDmHDWkX","8KhThQXzsAEZ59iko","iYJo382hY28K7eCrP","KrEwDMN4YXp5YWD45","rNJ39yQmzTnseh8nL","hMQPyLDbg3bA7P6aN","3Jqz6JE8K6vyQ9hJ5","SQAfPKZBAAKYMjx25","Y345zuBetHqGnotwm","pZerSnxv6FPqvgoYu","3bPH2az479gzxDMbf","QXShCBvPydkwafekn","iLMkKDKmfbMkDuQBm","iNCg6mjw584r9BWZK","9oqF382ASmjaGBo7z","DdNB42JgBzbbvmAum","JP7eZYHB7aY6fA4TR","snwX7hXgLFikqDBr6","CsKrQdQJJCFPjfKjF","vhxywjnBH6ioRnnt3","A4MK9RQqSAJZjanQD","PCpzG9NJeviXM5YSq","KCcdhZK7omEMwBdju","kdmCm5NQTpqhJmGm6","2p8BWvcJvKkXGMsch","FLnDFnXyWrKr6eiT6","2gWs8SScqeDFidqyv","2HafkDSNdtMzptzcN","cTQRGJTQ2eGKm5G9g","qaHHJ3kkCQS4nsoGJ","gS8Jmcfoa9FAh92YK","eRhFaibbTeGbjdaaf","xij43oLTBRnEQv2bT","BZMc9Xzqw5WcCMHrr","2jZykdLg9fBGqKd46","gBChm3THPGFcrq5eH","9HSwh2mE3tX6xvZ2W","tEHJXNhw6t87foqJL","T5McDuWDeCvDZKeSj","PeTL97v92LxRJBsrM","Cq45AuedYnzekp3LX","pfmZ5cYQCahABGZzi","3wBj8BPquskZAbXu9","xPJKZyPCvap4Fven8","BPKvZuLRyiJBjfNbg","um7w5RogAHhxGy8Ti","CcyGR3pp3FCDuW6Pf","BfaAADSQ88cuxLQoD","ckuuDa8DmJ4pdFeD8","pczHfyxmnFhtKthqR","dymK5c7BkpgXH4acw","B4AyJXYPpGbBmxQzd","xNBRkPNHAGQ6EQaLS","88TN6y9M5xxAHHNwW","Lt8Rn4rkYwqiTXGPy","QdXrkWoK2Pp6XhNuQ","NjzBrtvDS4jXi5Krp","ZWC3n9c6v4s35rrZ3","Fy2b55mLtghd4fQpx","eaczwARbFnrisFx8E","KLjQedNYNEP4tW73W","DSnamjnW7Ad8vEEKd","7iDtkfyn322nPzTP4","eaSJtg8Kvc56bFBdt","AmaWMMWPzuQ62Ernf","jkf2YjuH8Z2E7hKBA","BroeiXGh9PrKZEkJ5","9Tw5RqnEzqEtaoEkq","EMJ3egz48BtZS8Pws","MkKcnPdTZ3pQ9F5yC","kjArXFinD3deRZNRu","Q8zqoBWBBHD2RjDuS","ePA4NDzZkunz98tLx","4xKeNKFXFB458f5N8","irbREZtZzPi7WEYex","QxZs5Za4qXBegXCgu","ZmQv4DFx6y4jFbhLy","M7rwT264CSYY6EdR3","z3cTkXbA7jgwGWPcv","9thqSN8HDLM3LTxK5","MtNnFg4uN32YPoKNa","Ep2Z42hYqj68QZz6w","ibk7q8msSYxZXmfCf","EgDpZS4HHeh5vqJPe","5dhWhjfxn4tPfFQdi","Wh8HAK6LR5CAoPCCC","Yy7mgec8tsbTAuTqb","azoP7WeKYYfgCozoh","Zh9AiXNjQaYXjmNaC","bJiyYJeCyh4HcKHub","aPrCzeFfbBmRsvzby","vXCK3kptLLggEfojX","M2LWXsJxKS626QNEA","LQp9cZPzJncFKh5c8","CZnBQtvDw33rmWpBD","miHttwTgajY2sjY3L","K2JBqDeETX2yEgyyZ","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","mja6jZ6k9gAwki9Nu","qjSHfbjmSyMnGR9DS","Sx26Aj3xuMzmnKE4A","P3uavjFmZD5RopJKk","pJJdcZgB6mPNWoSWr","oGezscrQvPDgGvrbt","AYbhqi65SWzHzy7Xx","E4cKD9iTWHaE7f3AJ","x9FNKTEt68Rz6wQ6P","HAEPbGaMygJq8L59k","znBJwbuT3f5eWgM4E","yJfBzcDL9fBHJfZ6P","YAkpzvjC768Jm2TYb","LTtNXM9shNM9AC2mp","9hR2RmpJmxT8dyPo4","WQWhXzALcrzrJtqRh","p7WXmG6Fbo3eaSwm3","KheBaeW8Pi7LwewoF","A2Qam9Bd9xpbb2wLQ","asmZvCPHcB4SkSCMW","euJm4RwkAptZnP89i","r8stxYL29NF9w53am","6yTShbTdtATxKonY5","yDRX2fdkm3HqfTpav","EhEZoTFzys9EDmEXn","YSWa8rYeD3aDaofSP","rwkkcgSpnAyE8oNo3","HmfxSWnqnK265GEFM","Ltey8BS83qSkd9M3u","atcJqdhCxTZiJSxo2","pC47ZTsPNAkjavkXs","wJnm5cBiZGmKn595f","GrtbTAPfkJa4D6jjH","LgavAYtzFQZKg95WC","reitXJgJXFzKpdKyd","ZiQqsgGX6a42Sfpii","neQ7eXuaXpiYw7SBy","hQHuXuRGZxxWXaPgg","9kcTNWopvXFncXgPy","baTWMegR42PAsH9qJ","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","R6M4vmShiowDn56of","6Fpvch8RR29qLEWNH","N6WM6hs7RQMKDhYjB","pdaGN6pQyQarFHXF4","SA9hDewwsYgnuscae","i9xyZBS3qzA8nFXNQ","bx3gkHJehRCYZAF3r","Jk9yMXpBLMWNTFLzh","JvZhhzycHu2Yd57RN","vzfz4AS6wbooaTeQk","gHefoxiznGfsbiAu9","sbcmACvB6DqYXYidL","kipMvuaK3NALvFHc9","xdwbX9pFEr7Pomaxv","XvN2QQpKTuEzgkZHY","uFNgRumrDTpBfQGrs","ii4xtogen7AyYmN6B","kpPnReyBC54KESiSn","FRv7ryoqtvSuqBxuT","u8GMcpEN9Z6aQiCvp","B2CfMNfay2P8f2yyc","JD7fwtRQ27yc8NoqS","mRwJce3npmzbKfxws","3rxMBRCYEmHCNDLhu","FWvzwCDRgcjb9sigb","KrJfoZzpSDpnrv9va","LpM3EAakwYdS6aRKf","Cf2xxC3Yx9g6w7yXN","qHCDysDnvhteW7kRd","mELQFMi9egPn5EAjK","qDmnyEMtJkE9Wrpau","4ZvJab25tDebB8FGE","4QemtxDFaGXyGSrGD","Psr9tnQFuEXiuqGcR","qmXqHKpgRfg83Nif9","ximou2kyQorm6MPjX","eccTPEonRe4BAvNpD","2cYebKxNp47PapHTL","pv7Qpu8WSge8NRbpB","PqMT9zGrNsGJNfiFR","B9kP6x5rpmuCzpfWb","zB4f7QqKhBHa5b37a","qc7P2NwfxQMC3hdgm","RcifQCKkRc9XTjxC2","YABJKJ3v97k9sbxwg","bNXdnRTpSXk9p4zmi","fRsjBseRuvRhMPPE5","MzKKi7niyEqkBPnyu","NQgWL7tvAPgN2LTLn","cujpciCqNbawBihhQ","wEebEiPpEwjYvnyqq","AqbWna2S85pFTsHH4","Nwgdq6kHke5LY692J","8xLtE3BwgegJ7WBbf","SWxnP5LZeJzuT3ccd","Tr7tAyt5zZpdTwTQK","ax695frGJEzGxFBK4","FkgsxrGf3QxhfLWHG","vJ7ggyjuP4u2yHNcP","X5RyaEDHNq5qutSHK","xhD6SHAAE9ghKZ9HS","AyNHoTWWAJ5eb99ji","F5ktR95qqpmGXXmLq","znfkdCoHMANwqc2WE","jbE85wCkRr9z7tqmD","4K5pJnKBGkqqTbyxx","yeADMcScw8EW9yxpH","9QxnfMYccz9QRgZ5z","X2i9dQQK3gETCyqh2","4XRjPocTprL4L8tmB","D6trAzh6DApKPhbv4","BcYfsi7vmhDvzQGiF","i42Dfoh4HtsCAfXxL","zp5AEENssb8ZDnoZR","KwdcMts8P8hacqwrX","RQpNHSiWaXTvDxt6R","nSjavaKcBrtNktzGa","hNqte2p48nqKux3wS","7im8at9PmhbT4JHsW","SwcyMEgLyd4C3Dern","AHhCrJ2KpTjsCSwbt","rz73eva3jv267Hy7B","E4zGWYzh6ZiG85b2z","hvGoYXi2kgnS3vxqb","D4hHASaZuLCW92gMy","v7c47vjta3mavY3QC","G5TwJ9BGxcgh5DsmQ","YRgMCXMbkKBZgMz4M","ham9i5wf4JCexXnkN","a4jRN9nbD79PAhWTB","xJyY5QkQvNJpZLJRo","ivpKSjM4D6FbqF4pZ","p7x32SEt43ZMC9r7r","f886riNJcArmpFahm","xhE4TriBSPywGuhqi","ThvvCE2HsLohJYd7b","diruo47z32eprenTg","JJFphYfMsdFMuprBy","ZDZmopKquzHYPRNxq","KkwtLtroaNToWs2H6","vKErZy7TFhjxtyBuG","3L46WGauGpr7nYubu","CSZnj2YNMKGfsMbZA","G2Lne2Fi7Qra5Lbuf","x6hpkYyzMG6Bf8T3W","aFaKhG86tTrKvtAnT","PrCmeuBPC4XLDQz8C","dYspinGtiba5oDCcv","9cbEPEuCa9E7uHMXT","N5Jm6Nj4HkNKySA5Z","asmZvCPHcB4SkSCMW","duxy4Hby5qMsv42i8","Djs38EWYZG8o7JMWY","A8iGaZ3uHNNGgJeaD","XYYyzgyuRH5rFN64K","2jfiMgKkh7qw9z8Do","JPan54R525D68NoEt","o4cgvYmNZnfS4xhxL","CeZXDmp8Z363XaM6b","DQKgYhEYP86PLW7tZ","niQ3heWwF6SydhS7R","gvK5QWRLk3H8iqcNy","fnkbdwckdfHS2H22Q","YicoiQurNBxSp7a65","JBFHzfPkXHB2XfDGj","tj8QP2EFdP8p54z6i","9fB4gvoooNYa4t56S","zTfSXQracE7TW8x4w","YcdArE79SDxwWAuyF","8xRSjC76HasLnMGSf","CvKnhXTu9BPcdKE4W","DtcbfwSrcewFubjxp","NxF5G6CJiof6cemTw","4ZwGqkMTyAvANYEDw","EF5M6CmKRd6qZk27Z","cCMihiwtZx7kdcKgt","Qz6w4GYZpgeDp6ATB","TPjbTXntR54XSZ3F2","x3fNwSe5aWZb5yXEG","bnY3L48TtDrKTzGRb","ZFtesgbY9XwtqqyZ5","S7csET9CgBtpi7sCh","tTWL6rkfEuQN9ivxj","L6Ktf952cwdMJnzWm","P6fSj3t4oApQQTB7E","4s2gbwMHSdh2SByyZ","sTwW3QLptTQKuyRXx","EYd63hYSzadcNnZTD","tF8z9HBoBn783Cirz","hyShz2ABiKX56j5tJ","YN6daWakNnkXEeznB","6DuJxY8X45Sco4bS2","TMFNQoRZxM4CuRCY6","q3JY4iRzjq56FyjGF","diutNaWF669WgEt3v","5okDRahtDewnWfFmz","r3NHPD3dLFNk9QE2Y","ALkH4o53ofm862vxc","N9oKuQKuf7yvCCtfq","WjsyEBHgSstgfXTvm","2G8j8D5auZKKAjSfY","rBkZvbGDQZhEymReM","nNqXfnjiezYukiMJi","36Dhz325MZNq3Cs6B","f2GF3q6fgyx8TqZcn","byewoxJiAfwE6zpep","nEBbw2Bc2CnN2RMxy","w4aeAFzSAguvqA5qu","xFotXGEotcKouifky","rzqACeBGycZtqCfaX","DoPo4PDjgSySquHX8","o3RLHYviTE4zMb9T9","5gfqG3Xcopscta3st","GNhMPAWcfBCASy8e6","uXH4r6MmKPedk8rMA","Gg9a4y8reWKtLe3Tn","bBdfbWfWxHN9Chjcq","sT6NxFxso6Z9xjS7o","k9dsbn8LZ6tTesDS3","exa5kmvopeRyfJgCy","YTJp5WBcktBimdxBG","X79Rc5cA5mSWBexnd","SvKpaPbZ2tibeDpgh","rQKstXH8ZMAdN5iqD","vQKbgEKjGZcpbCqDs","Z9cbwuevS9cqaR96h","pHHaNkG8xDcaq5DJF","sjRG35aq5fosJ6mdG","pPWiLGsWCtN92vLwu","D5BP9CxKHkcjA7gLv","57sq9qA3wurjres4K","t2LGSDwT7zSnAGybG","7Pq9KwZhG6vejmYpo","g3PwPgcdcWiP33pYn","zcriHTKgKNehSSdyG","kvLPC5YWgSujcHSkY","HnC29723hm6kJT7KP","CRiJuJxgArjBMJLvK","dyJfGeWo5GX2u6NGi","QLmSFeFexgTLsNeeA","kmT47aLQmqzcw329Y","givHhuPu6G43g8kWN","83DimRqppcaoyYAsy","vvzfFcbmKgEsDBRHh","FfNEt8mpi6qanNmXg","MrAfiomDNWCzxjei5","73kwTFKgi4AagxFHJ","iBBK4j6RWC7znEiDv","W8vSrHAM9qoWdzFoP","Rx9GLepCxctXDqCPc","4X9JLr2SpB6v68twG","yxTP9FckrwoMjxPc4","FuZ7MoR3dJEJuoRbN","xRyLxfytmLFZ6qz5s","mwGAyWmsSqzMz4WMd","xxC3Ka7axphW8kJ9E","KT8Mf3ey6uwQAkWek","GDT6tKH5ajphXHGny","ZXaRHHLsxaTTQQsZb","CHdsSaQGAvtkXBzmJ","HAEPbGaMygJq8L59k","SmDziGM9hBjW9DKmf","8NKu9WES7KeKRWEKK","NfdHG6oHBJ8Qxc26s","LTtNXM9shNM9AC2mp","uKp6tBFStnsvrot5t","baTWMegR42PAsH9qJ","Xqcorq5EyJBpZcCrN","7cAsBPGh98pGyrhz9","ZbgCx2ntD5eu8Cno9","9kcTNWopvXFncXgPy","HxWdXMqoQtjDhhNGA","xwBuoE9p8GE7RAuhd","inedT6KkbLSDwZvfd","sWLLdG6DWJEy3CH7n","dhj9dhiwhq3DX6W8z","yLLkWMDbC9ZNKbjDG","P3Yt66Wh5g7SbkKuT","brXr7PJ2W4Na2EW2q","45mNHCMaZgsvfDXbw","7izSBpNJSEXSAbaFh","pfoZSkZ389gnz5nZm","jfG6vdJZCwTQmG7kb","sGnPTfjE5JthAStqg","gvA4j8pGYG4xtaTkw","PZtsoaoSLpKjjbMqM","jnDibtfvWNHLucf4D","GrtbTAPfkJa4D6jjH","zEWJBFFMvQ835nq6h","64FdKLwmea8MCLWkE","Dx9LoqsEh3gHNJMDk","FMkQtPvzsriQAow5q","XuLG6M7sHuenYWbfC","PGv9THs68ArPur7yP","NcGBmDEe5qXB7dFBF","tEDXpFgsHsm5T8sWz","7gsehrZnvXo2YGiT7","x4n4jcoDP7xh5LWLq","boBZkTqPdboX5u7g9","CJw2tNHaEimx6nwNy","CcC8MocynqKPmMPwL","Rrt7uPJ8r3sYuLrXo","rwjv8bZfSuE9ZAigH","khYYedgupgrHonWNc","wrkEnGrTTrM2mnmGa","f9s7pHub6hbsX7YKT","YduZEfz8usGbJXN4x","55SHk8kh9dDvaDTCC","SFG9Cm7mf5eP4juKs","eLRSCC7r4KinuxqZX","oW6mbA3XHzcfJTwNq","kWMkDoy3izRTobZFe","LtsJLfnP4YwhGdaCf","w9kwayt5SWqBQe8Nx","h5CGM5qwivGk2f5T9","iPGpENE4ARKbzzQmt","PQ3nutgxfTgvq69Xt","3zZjF3YKJ257x79mu","9Qwignbzu4ddXLTsT","aiCtrN9EF2FjKz5sv","JcpwEKbmNHdwhpq5n","idipkijjz5PoxAwju","F7RgpHHDpZYBjZGia","xWTSHJASRaLABgHWc","Fg8dtE8HHkDoiGcwt","zPJE7MDtL25RpN7Cc","qqhdj3W3vSfB5E9ss","9SE67uz98kh6x2CxR","gR6H3egpRPNYnoTrA","qPoaA5ZSedivA4xJa","H6L7fuEN9qXDanQ6W","gfexKxsBDM6v2sCMo","7uJnA3XDpTgemRH2c","stb3Jjumzhv49zCEb","XjMkPyaPYTf7LrKiT","XuyRMxky6G8gq7a69","huRxRzwcvwTzvtEPY","8bWbNwiSGbGi9jXPS","sq3WkpyqGANT7hGRP","AyfDnnAdjG7HHeD3d","WmfapdnpFfHWzkdXY","8rYxw9xZfwy86jkpG","zFhhDCxz87yKwqYQf","doiMq8aH2yiZaCJsT","MQzbaHoiQutiHkx2M","ra9Pt2JkEDnKW4jsc","9YDk52NPrfq7nqLvd","KTEciTeFwL2tTujZk","6bSjRezJDxR2omHKE","r5H6YCmnn8DMtBtxt","JbcWQCxKWn3y49bNB","R4FX6wDmppvZ2JqpB","9vnWFwng8QzEnBT8z","XCtFBWoMeFwG8myYh","6uwLq8kofo4Tzxfe2","G993PFTwqqdQv4eTg","DWgWbXRfXLGHPgZJM","K7wtTqTEoKXC9Kb24","hmai5Lru5kWXpH7Ju","w4jjwDPa853m9P4ag","xvAkpCSdqgtYhEceo","6vMBpZtoRw4ia2JrK","Wzjjynmp8gMmdX6dt","CsN6WxwDnPzxAFhps","CLXkgEerPi9MpJCem","BKjJJH2cRpJcAnP7T","qXtbBAxmFkAQLQEJE","jES7mcPvKpfmzMTgC","D7epkkJb3CqDTYgX9","FpcgSoJDNNEZ4BQfj","mF8dkhZF9hAuLHXaD","camG6t6SxzfasF42i","HALKHS4pMbfghxsjD","HDXLTFnSndhpLj2XZ","fgYQjTktBmNZvMqce","fwNskn4dosKng9BCB","B5auLtDfQrvwEkw4Q","z7YvA5osMotdL5F4w","Hoh6umyMWSqzPGMJZ","vHSrtmr3EBohcw6t8","nsCwdYJEpmW5Hw5Xm","LKAXgTen4Xbqb8eZY","22GrdspteQc8EonMn","TSaJ9Zcvc3KWh3bjX","sJK6HN5vTPPnuuNgQ","mh3xapTix6fFtd3xM","JBnaLpsrYXLXjFocu","uR8c2NPp4bWHQ5u45","d4YGxMpzmvxknHfbe","wcNEXDHowiWkRxDNv","scNCmwaduCgJmCBYh","LsXtcLyzyfGg3gT5R","McN9BNtNcbYNfdCB5","4tzEAgdbNTwB6nKyL","sCFGEhwcB8MX3FQf5","G4uMdBzgDsxMsTNmr","34Gkqus9vusXRevR8","7MCqRnZzvszsxgtJi","HXxHcRCxR4oHrAsEr","cmrtpfG7hGEL9Zh9f","oHk9T3jbx2J5zJ39P","sYt3ZCrBq2QAf3rak","r8stxYL29NF9w53am","zymnWfGwf6BdDt64c","yyDrMYBfvYtKbmPmm","4gevjbK77NQS6hybY","jnjjzkH8Fdzg4D6EK","XKfQF73YnyMRiRf9a","gYfgWSxCpFdk2cZfE","CQsEwAyJP6NYvKZw6","JiLcxpWzCrnwkndsT","gpk8dARHBi7Mkmzt9","GrbeyZzp6NwzSWpds","9MZdwQ7u53oaRiBYX","gFyJgnu5vAbzELBM8","ouQNu3hhfKLBRuwR7","m5AH78nscsGjMbBwv","oKYWbXioKaANATxKY","cq5x4XDnLcBrYbb66","KjdP2WjWng6skwbY7","wfpdejMWog4vEDLDg","7F5jo5LD9FD7DpxCX","kDjKF2yFhFEWe4hgC","pWi5WmvDcN4Hn7Bo6","NGc3Yjecg9pDMznWq","xxvKhjpcTAJwvtbWM","DJnvFsZ2maKxPi7v7","zo9zKcz47JxDErFzQ","fyZBtNB3Ki3fM4a6Y","H4kadKrC2xLK24udn","BxersHYN2qcFoonwg","Ck5cgNS2Eozc8mBeJ","wr9dH2GjztvCz6pYX","EzAt4SbtQcXtDNhHK","syeBtmGoKvjJTH6sH","eWqFy8wESHbxNod7i","8cWMX6L8St8k9pPRC","jP583FwKepjiWbeoQ","rMfpnorsMoRwyn4iP","TKk7rShf9d5ePN7vR","fNJvYD6XqnX82i4jA","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","3GAnfeG9KmsbsWeTj","JKgGvJCzNoBQss2bq","JjGs6mDZxeCWkg3ii","AzKx6EjaoaMuk595v","duAkuSqJhGDcfMaTA","pXLqpguHJzxSjDdx7","FbJYEn6eWA5JnGeGP","8GiTowD6XqTNzgCz7","qfDgEreMoSEtmLTws","96N8BT9tJvybLbn5z","SCs4KpcShb23hcTni","bDMoMvw2PYgijqZCC","nqwzrpkPvviLHWXaE","YuZXRxWSqaCoZHEXr","6YYmkpumigAmh3efu","SgszmZwrDHwG3qurr","9EyzaH3jzH3PyQtM5","eR7Su77N2nK3e5YRZ","GSBCw94DsxLgDat6r","cpdsMuAHSWhWnKdog","avvXAvGhhGgkJDDso","KnPN7ett8RszE79PH","ptmmK9PWgYTuWToaZ","XNhfw5Bqsi4SGNNBk","PKy8NuNPknenkDY74","3yqf6zJSwBF34Zbys","YpyW97jRbtvBAncAr","LwcKYR8bykM6vDHyo","H6hMugfY3tDQGfqYL","iyRpsScBa6y4rduEt","mLuQfS7gmfr4nwTdv","TrvkWBwYvvJjSqSCj","yXHcqrCpiHC5tDuEc","HKfBeWN8ufNdFgzG6","P8yeoeJ2bwmnD93mZ","kxW6q5YdTGWh5sWby","ksatPnddyZjHwZWwG","st7DiQP23YQSxumCt","tE7y8FZe7wSSzoRaS","L4HQ3gnSrBETRdcGu","eqxqgFxymP8hXDTt5","uKWXktrR7KpbgZAs4","h4vWsBBjASgiQ2pn6","DXBziiT2RFLcmLY9J","k42G2aaNhRNB7hdCJ","XSKQLeQnBupFo7GGC","BnDF5kejzQLqd5cjH","AMmqk74zWmvP8tXEJ","NQQzXpahhkb6f6ZCe","Tk5ovpucaqweCu4tu","9WX59u7g2sdKqnjDm","Xht9swezkGZLAxBrd","8c8AZq5hgifmnHKSN","nMNi86hgNjaNnh8iu","s3rAKTkdSHb6Hwwoz","rqnbrJhDKCoZvNGEZ","Ea8pt2dsrS6D4P54F","uN3wjp2K6TEQ2oAML","DAc4iuy4D3EiNBt9B","jqCz2X49FRn5Bgb5b","8hxvfZiqH24oqyr6y","puYfAEJJomeodeSsi","S54HKhxQyttNLATKu","igSPcmvTigCHxWt8x","4esQ684vtR9zcjHgW","yGaw4NqRha8hgx5ny","eHnupDgggBqDqT5eg","k7oxdbNaGATZbtEg3","bbGEiSmNiTpPrFhcQ","Z6dmoLyfBdmo6HEss","QcXuwQvvPkqcKZmXS","7FJRnxbRtT7Sbzizs","oBTkthd7h8sDpkiu2","cmiRk9XtT9Psnd3Yr","G6npMHwgRGSQDKavX","hwxj4gieR7FWNwYfa","yGycR8tFA3JJbvApp","jxy7rBcQink8a7C9b","vQNJrJqebXEWjJfnz","kjmpq33kHg7YpeRYW","FwYMuD2sNcaEpE5on","4rwABGAd9kZG8nf2P","GkXKvkLAcTm5ackCq","TrmMcujGZt5JAtMGg","gBpYo7mt2zNBmtBJd","aNRYQFnMQbA7uu99u","YMokuZdoY9tEDHjzv","MG8Yhsxqu9JY4xRPr","zEvqFtT4AtTztfYC4","fzeoYhKoYPR3tDYFT","8npC4KRcAJtGdErTq","AYbhqi65SWzHzy7Xx","N99KgncSXewWqkzMA","2KacvW34BbXFmDBtQ","tSgcorrgBnrCH8nL3","NHuLAS3oKZWr2X9hP","9hR2RmpJmxT8dyPo4","fwSDKTZvraSdmwFsj","Cf2zBkoocqcjnrNFD","MPj7t2w3nk4s9EYYh","TTPux7QFBpKxZtMKE","shcSdHGPhnLQkpSbX","M4w2rdYgCKctbADMn","hMjFMSQZb4swKugfv","mkrvsNi8cYGSjGqkh","DXcezGmnBcAYL2Y2u","Aq8BQMXRZX3BoFd4c","FoJSa8mgLPT83g9e8","Xt85tj6GQJCuuXT68","JAAHjm4iZ2j5Exfo2","sAiHxHkQrsYsRpKFP","6phFYpNQH9SmWL9Jt","Rkxj7TFxhbm59AKJh","rNFzvii8LtCL5joJo","Hw26MrLuhGWH7kBLm","Zvu6ZP47dMLHXMiG3","HByDKLLdaWEcA2QQD","7qhtuQLCCvmwCPfXK","FgjcHiWvADgsocE34","Lp4Q9kSGsJHLfoHX3","3xF66BNSC5caZuKyC","BseaxjsiDPKvGtDrm","Q924oPJzK92FifuFg","oJwJzeZ6ar2Hr7KAX","H7Rs8HqrwBDque8Ru","gEKHX8WKrXGM4roRC","FKB7iEergZaC7PvQf","suxvE2ddnYMPJN9HD","iETtCZcfmRyHp69w4","mz3hwS4c9bc9EHAm9","KFLdfuw35qkgjzWer","RApxEu3A4GnvGoEe2","XLbDQL2qYi9FDozvL","p4XpZWcQksSiCPG72","mB95aqTSJLNR9YyjH","2NaAhMPGub8F2Pbr7","BbM47qBPzdSRruY4z","dYnHLWMXCYdm9xu5j","qHpazCw3ryvBojGSa","wyYubb3eC5FS365nk","wmjPGE8TZKNLSKzm4","CBWSDdzjqfnexBurB","gBnSRErajRtvhMnDr","BfBF6T6HA82zBxPrv","dbDHEQyKqnMDDqq2G","doPejjd84w8BmERqj","PT8vSxsusqWuN7JXp","dKxX76SCfCvceJXHv","DSzpr8Y9299jdDLc9","hnLutdvjC8kPScPAj","vit9oWGj6WgXpRhce","CsKboswS3z5iaiutC","kjQXzkTGuixoJtQnq","RgJicDmXHDxcJ9Fsw","L6iFpR9ZyTmzHvYci","Z5ZBPEgufmDsm7LAv","PRAyQaiMWg2La7XQy","x6Kv7nxKHfLGtPJej","3pjv6uDvY9sqmsnvY","Aet2mbnK7GDDfrEQu","scL68JtnSr3iakuc6","3SG4WbNPoP8fsuZgs","XfpJ6WQBDcEcC8Mu4","iprqfLaDLCGoJFeiZ","frApEhpyKQAcFvbXJ","znBJwbuT3f5eWgM4E","cR7Zfrc4BtnFes46y","hbmsW2k9DxED5Z4eJ","SzecSPYxqRa5GCaSF","hxaq9MCaSrwWPmooZ","FSmPtu7foXwNYpWiB","WQWhXzALcrzrJtqRh","jYNT3Qihn2aAYaaPb","gebzzEwn2TaA6rGkc","WhHFvzFsYfMxgYCdo","tjxgbovwc5Ft7wrtc","2brqzQWfmNx5Agdrx","QaDwBio8MLqRvTREH","Jko7pt7MwwTBrfG3A","A9tJFJY7DsGTFKKkh","Wnqua6eQkewL3bqsF","DJB82jKwgJE5NsWgT","5b6YcFbEBCZbX6YSK","zk6RK3xFaDeJHsoym","FQqcejhNWGG8vHDch","srge9MCLHSiwzaX6r","DJRe5obJd7kqCkvRr","D8ds9idKWbwzCseCh","hTMFt3h7QqA2qecn7","9LXxgXySTFsnookkw","CHtwDXy63BsLkQx4n","u5RLu5F3zKTB3Qjnu","4tke3ibK9zfnvh9sE","2WngsveoLhFubuLMH","ADwayvunaJqBLzawa","NG6FrXgmqPd5Wn3mh","Ww5xKq5brC4xAJY7o","HL6x8zHo9BkuK3tic","PKBXczqhry7iK3Ruw","oBBzqkZwkxDvsKBGB","HuFZJkGptWDtRbkWs","iQWk5jYeDg5ACCmpx","RdpqsQ6xbHzyckW9m","sizjfDgCgAsuLJQmm","X3p8mxE5dHYDZNxCm","wZGpoZgDANdkwTrwt","uAc7bWgpEhrGwFcv7","3nDR23ksSQJ98WNDm","sMsvcdxbK2Xqx8EHr","evYFijNMdjfbPaCho","Psp8ZpYLCDJjshpRb","Zupr296Zy74wpihXT","68dHanLWsS6SEyZp9","x9FNKTEt68Rz6wQ6P","DWHkxqX4t79aThDkg","xLm9mgJRPvmPGpo7Q","6LzKRP88mhL9NKNrS","XYDsYSbBjqgPAgcoQ","eRohP4gbxuBuhqTbe","Wpf3Gsa8A89mmjkk8","PfcQguFpT8CDHcozj","XPwEptSSFRCnfHqFk","pohTfSGsNQZYbGpCy","zcPLNNw4wgBX5k8kQ","2meuc3kPRkBcRpj3R","bzhGBHrGrFfQss4Df","2269iGRnWruLHsZ5r","kj37Hzb2MsALwLqWt","Qz9GvoPbnFwGrHHQB","pJJdcZgB6mPNWoSWr","dtmmP4YdJEfK9y4Rc","QPqm5aj2meRmE7kR8","2oybbEw697CQgcRE5","TYTEJxzeK3jBMq2TZ","K4eDzqS2rbcBDsCLZ","FcRt3xAF4ynojfj6G","gMXsyhPiEJbGerF6F","9sguwESkteCgqFMbj","mvPfao35Moah8py46","kuDKtwwbsksAW4BG2","pL56xPoniLvtMDQ4J","ENBzEkoyvdakz4w5d","wM4bcDxEh75NDkhjo","YAkpzvjC768Jm2TYb","ExssKjAaXEEYcnzPd","n3LAgnHg6ashQK3fF","GMCs73dCPTL8dWYGq","8gapy2nLy4wysXSGL","dgFcJtHaYfaoByAK9","HhWhaSzQr6xmBki8F","CpvyhFy9WvCNsifkY","aan3jPEEwPhrcGZjj","mhA4vkeaRn9cpxkag","iA25AvZqAr6G8mAXR","C4tR3BEpuWviT7Sje","FghubkDy6Dp6mnxk7","RKz7pc6snBttndxXz","jiJquD34sa9Lyo5wc","c8EeJtqnsKyXdLtc5","ZGGGBR9sDgtLgMDaA","uM6mENiJi2pNPpdnC","o9dnstYoc7cwpgdhg","YSWa8rYeD3aDaofSP","pC47ZTsPNAkjavkXs","QtyKq4BDyuJ3tysoK","bYrF8rXFYwPqnfxTp","KbyRPCAsWv5GtfrbG","c2RzFadrxkzyRAFXa","9ZodFr54FtpLThHZh","xmoYza9vgcRvWD5PA","sbb9bZgojmEa7Yjrc","6yTShbTdtATxKonY5","BHYBdijDcAKQ6e45Z","qGEqpy7J78bZh3awf","KJbQyFbXiiYDDWbaS","PYtus925Gcg7cqTEq","yTvBSFrXhZfL8vr5a","Aud7CL7uhz55KL8jG","bXTNKjsD4y3fabhwR","AmNjHo8xXMKnZEWRS","CHD5m9fnosr7L3dto","MN4NRkMw7ggt9587K","CDXDnruBJe23rpdfC","y5GftLezdozEHdXkL","d6yNW5T6J9rtnGizc","pT48swb8LoPowiAzR","27AWRKbKyXuzQoaSk","vNHf7dx5QZA4SLSZb","KwbJFexa4MEdhJbs4","mja6jZ6k9gAwki9Nu","fW9n8bEuMpLwkxCx6","muXfZr5EYCfZqLmsb","5PBWgHiCiiJHjPRSn","PAYMMgPi2L3MPP967","RaxaXBNmStYe289gC","DMxe4XKXnjyMEAAGw","xF7gBJYsy6qenmmCS","gMszBSAX23uqYhytR","HbXXd2givHBBLxr3d","Z5wF8mdonsM2AuGgt","utySCY9nJt9xGYGGQ","gCz7cB6JG66EhweSS","krHDNc7cDvfEL8z9a","aNAFrGbzXddQBMDqh","sksP9Lkv9wqaAhXsA","p3s8RvkcyTwzu27ps","8ccTZ9ZxpJrvnxt4F","p7WXmG6Fbo3eaSwm3","CPBmbgYZpsGqkiz2R","yDRX2fdkm3HqfTpav","WbLAA8qZQNdbRgKte","75dnjiD8kv2khe9eQ","JZZENevaLzLLeC3zn","MgFDzAfCku9MSDLuw","PQtEqmyqHWDa2vf5H","zbqLuTgTCu365MNu9","P3uavjFmZD5RopJKk","8gqrbnW758qjHFTrH","pZaPhGg2hmmPwByHc","4hLcbXaqudM9wSeor","WxW6Gc6f2z3mzmqKs","j9HoG56Y6KuopSzdn","GhFoAxG49RXFzze5Y","rD57ysqawarsbry6v","LCfaLXcWnk8pujnX4","tAXrD8Y6hcJ8dt6Nt","af9MjBqF2hgu3EN6r","FRRb6Gqem8k69ocbi","LbyxFk8JmPKPAQBvL","PHmYhE4sKnwzYgvkh","fZJRxYLtNNzpbWZAA","kgmkdf3C7EkDX7dnT","Gs29k3beHiqWFZqnn","MMAK6eeMCH3JGuqeZ","cdB5f2adKoLGW8Ytc","5e49dHLDJoDpeXGnh","Ccsx339LE9Jhoii9K","PHnMDhfiadQt6Gj23","Jo89KvfAs9z7owoZp","fri4HdDkwhayCYFaE","tD9zEiHfkvakpnNam","xggxWfyzZmnz7hydm","JgBBuDf5uZHmpEMDs","vbcjYg6h3XzuqaaN8","hRohhttbtpY3SHmmD","6KzFwcDy7hsCkzJKY","F2DZXsMdhGyX4FPAd","esRZaPXSHgWzyB2NL","AqsjZwxHNqH64C2b6","4psQW7vRwt7PE5Pnj","voLHQgNncnjjgAPH7","aaHDA4X6cTzFrvuSX","LHtMNz7ua8zu4rSZr","zjMKpSB2Xccn9qi5t","BAzCGCys4BkzGDCWR","goC9qv4PWf2cjfnbm","Z2CuyKtkCmWGQtAEh","c3iQryHA4tnAvPZEv","vwLxd6hhFvPbvKmBH","Js34Ez9nrDeJCTYQL","fJvjin8ETkzhFdadC","W59Nb72sYJhMJKGB8","xiPMaYGTm2xfsB8WF","oPEWyxJjRo4oKHzMu","PjfsbKrK5MnJDDoFr","sBBGxdvhKcppQWZZE","vwM7hnT9ysE3suwfk","BzYmJYECAc3xyCTt6","uiyWHaTrz3ML7JqDX","vZssZr2wq7YrG3FMa","73QyjLymEak4L8RDC","6vcxuRHzeM99jYcYd","bG4PR9uSsZqHg2gYY","HoQ5Rp7Gs6rebusNP","9iA87EfNKnREgdTJN","QEYWkRoCn4fZxXQAY","kAgJJa3HLSZxsuSrf","FZaDFYbnRoHmde7F6","BNfL58ijGawgpkh9b","4gDbqL3Tods8kHDqs","DwqgLXn5qYC7GqExF","atcJqdhCxTZiJSxo2","zRn6cLtxyNodudzhw","P32AuYu9MqM2ejKKY","K2JBqDeETX2yEgyyZ","3FoMuCLqZggTxoC3S","LcEzxX2FNTKbB6KXS","o5F2p3krzT4JgzqQc","cy3BhHrGinZCp3LXE","zsG9yKcriht2doRhM","WYmmC3W6ZNhEgAmWG","EL4HNa92Z95FKL9R2","EKu66pFKDHFYPaZ6q","Pa5NqtxHBkGuCh98G","JKj5Krff5oKMb8TjT","vwt3wKXWaCvqZyF74","4basF9w9jaPZpoC8R","Bfq6ncLfYdtCb6sat","jDQm7YJxLnMnSNHFu","FDJnZt8Ks2djouQTZ","f3o9ydY7iPjFF2fyk","KnQs55tjxWopCzKsk","Ww2dxwWpSfkQB4NZb","ZawRiFR8ytvpqfBPX","ZGzDNfNCXzfx6hYAH","rFjhz5Ks685xHbMXW","Mrz2srZWc7EzbADSo","B4DuwmtqF3HhNwvua","zQKgKjecvR4W7oJw5","BSpdshJWGAW6TuNzZ","JHcTP4Ad8QAmRTCZm","GGn8MBiY8Xz6NdNdH","hQysqfSEzciRazx8k","AtfQFj8umeyBBkkxa","r99tazGiLgzqFX7ka","uFYQaGCRwt3wKtyZP","BFamedwSgRdGGKXQQ","teaxCFgtmCQ3E9fy8","ka8eveZpT7hXLhRTM","euJm4RwkAptZnP89i","LLRtjkvh9AackwuNB","yPLr2tnXbiFXkMWvk","ervaGwJ2ZcwqfCcLx","4AHXDwcGab5PhKhHT","NuueGqPZdotjMQKLu","qjSHfbjmSyMnGR9DS","xtzvtJBNofk4FPAtt","SkcM4hwgH3AP6iqjs","Br4xDbYu4Frwrb64a","HvcZmKS43SLCbJvRb","BEtzRE2M5m9YEAQpX","EhEZoTFzys9EDmEXn","bmoQ2wy7Nd7EiJdpg","pYcFPMBtQveAjcSfH","zb3hWt99i9Fm93KPq","W9rJv26sxs4g2B9bL","Dod9AWz8Rp4Svdpof","hQHuXuRGZxxWXaPgg","zB3ukZJqt3pQDw9jz","KheBaeW8Pi7LwewoF","Ek7M3xGAoXDdQkPZQ","guDcrPqLsnhEjrPZj","7XbcDaeigMaxW43EB","ttGbpJQ8shBi8hDhh","wJnm5cBiZGmKn595f","puhPJimawPuNZ5wAR","eoHbneGvqDu25Hasc","gHgs2e2J5azvGFatb","x5ASTMPKPowLKpLpZ","EhAbh2pQoAXkm9yor","jfq2BH5kfQqu2vYv3","Mf2MCkYgSZSJRz5nM","mXgsd5o9uuYaQKHMz","YM6Qgiz9RT7EmeFpp","PcfHSSAMNFMgdqFyB","uX3HjXo6BWos3Zgy5","nzmCvRvPm4xJuqztv","CMt3ijXYuCynhPWXa","Ndtb22KYBxpBsagpj","yFJ7vCjefBxnTchmG","SQ9cZtfrzDJmw9A2m","PJLABqQ962hZEqhdB","HmfxSWnqnK265GEFM","i3BTagvt3HbPMx6PN","ZEgQGAjQm5rTAnGuM","ctpkTaqTKbmm6uRgC","qEweugBipR5P2cMyK","xnPFYBuaGhpq869mY","YtvZxRpZjcFNwJecS","ido3qfidfDJbigTEQ","85J8hjEn48FicYfvp","N6vZEnCn6A95Xn39p","tJQsxD34maYw2g5E4","96TBXaHwLbFyeAxrg","ixZLTmFfnKRbaStA5","2x7fwbwb35sG8QmEt","oaqKjHbgsoqEXBMZ2","t2NN6JwMFaqANuLqH","J9pNx22bj5RuiRjAj","AN2cBr6xKWCB8dRQG","G5eMM3Wp3hbCuKKPE","y5jAuKqkShdjMNZab","vADtvr9iDeYsCDfxd","x4GmqcwjFTnWeRiud","5ntgky9ShzKKWu7us","z8usYeKX7dtTWsEnk","3S4nyoNEEuvNsbXt8","EEv9JeuY5xfuDDSgF","ASpGaS3HGEQCbJbjS","AXXaXJvf7WcTessog","QL7J9wmS6W2fWpofd","osYFcQtxnRKB4F4HA","MajyZJrsf8fAywWgY","bvqC4Ci7rXq4sN9df","GctJD5oCDRxCspEaZ","A9NxPTwbw6r6Awuwt","dKTh9Td3KaJ8QW6gw","oTX2LXHqXqYg2u4g6","LuXb6CZG4x7pDRBP8","hamma4XgeNrsvAJv5","BfTW9jmDzujYkhjAb","DoHcgTvyxdorAMquE","EbFABnst8LsidYs5Y","Sdx6A6yLByRRs8iLY","qbHLGo5vu8HD3JqEM","48WeP7oTec3kBEada","LgavAYtzFQZKg95WC","5QpufhoH2ASnppsjs","Kz9zMgWB5C27Pmdkh","qy5dF7bQcFjSKaW58","wkuDgmpxwbu2M2k3w","JcpzFpPBSmzuksmWM","zMxrkFrB6ka4Lb7fM","PX7AdEkpuChKqrNoj","ui6mDLdqXkaXiDMJ5","uXn3LyA8eNqpvdoZw","FwiPfF8Woe5JrzqEu","hzuSDMx7pd2uxFc5w","mHqQxwKuzZS69CXX5","yKXKcyoBzWtECzXrE","zHS4FJhByRjqsuH4o","a5JAiTdytou3Jg749","HEn2qiMxk5BggN83J","tYAvXXgSwHCzNTK8f","WXvt8bxYnwBYpy9oT","kLR5H4pbaBjzZxLv6","CtXaFo3hikGMWW4C9","4DBBQkEQvNEWafkek","qwdupkFd6kmeZHYXy","EHbJ69JDs4suovpLw","w5F4w8tNZc6LcBKRP","xqkGmfikqapbJ2YMj","yRAo2KEGWenKYZG9K","scwoBEju75C45W5n3","qJgz2YapqpFEDTLKn","aSQy7yHj6nPD44RNo","Ltey8BS83qSkd9M3u","9Yc7Pp7szcjPgPsjf","hN2aRnu798yas5b2k","ERWeEA8op6s6tYCKy","yJfBzcDL9fBHJfZ6P","BZ6XaCwN4QGgH9CxF","3nMpdmt8LrzxQnkGp","TNHQLZK5pHbxdnz4e","F6ZTtBXn2cFLmWPdM","neQ7eXuaXpiYw7SBy","k2SNji3jXaLGhBeYP","WsSybGTqpBoHpXJyQ","jtMXj24Masrnq3SpS","jqTeghCJ2anMHPPjG","B7P97C27rvHPz3s9B","uK6sQCNMw8WKzJeCQ","hurF9uFGkJYXzpHEE","xEHy9oivifjgFbnvc","33KewgYhNSxFpbpXg","c5GHf2kMGhA4Tsj4g","dC7mP5nSwvpL65Qu5","hpjou9ZnLZkSJR7sd","bshZiaLefDejvPKuS","AvjbBjAAbKBk73v5F","XqvnWFtRD2keJdwjX","KJ9MFBPwXGwNpadf2","37sHjeisS9uJufi4u","5iZTwGHv2tNfFmeDa","gziZACDg6EBpGZbJe","RYcoJdvmoBbi5Nax7","9o3QBg2xJXcRCxGjS","vs3kzjLhbdKsndnBy","bZ2w99pEAeAbKnKqo","bjjbp5i5G8bekJuxv","vwqLfDfsHmiavFAGP","Yp2vYb4zHXEeoTkJc","z6QQJbtpkEAX3Aojj","ubPAo3zGeJNqtZDqT","pfibDHFZ3waBo6pAc","cumc876woKaZLmQs5","Ty2tjPwv8uyPK9vrz","ZiQqsgGX6a42Sfpii","ybYBCK9D7MZCcdArB","pNcFYZnPdXyL2RfgA","rEBXN3x6kXgD4pLxs","no5jDTut5Byjqb4j5","qCsxiojX7BSLuuBgQ","uyBeAN5jPEATMqKkX","aHaqgTNnFzD7NGLMx","bQ6zpf6buWgP939ov","mkbGjzxD8d8XqKHzA","CKpByWmsZ8WmpHtYa","midXmMb2Xg37F2Kgn","reitXJgJXFzKpdKyd","LFNXiQuGrar3duBzJ","KcvJXhKqx4itFNWty","RWu8eZqbwgB9zaerh","EFQ3F6kmt4WHXRqik","FfPukic3Qskd9ZAkk","A2Qam9Bd9xpbb2wLQ","t9svvNPNmFf5Qa3TA","n5TqCuizyJDfAPjkr","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","Kyc5dFDzBg4WccrbK","RWo4LwFzpHNQCTcYt","vbWBJGWyWyKyoxLBe","PsEppdvgRisz5xAHG","tscc3e5eujrsEeFN4","GG2rtBReAm6o3mrtn","E4cKD9iTWHaE7f3AJ","yCWPkLi8wJvewPbEp","AcKRB8wDpdaN6v6ru","LbrPTJ4fmABEdEnLf","rtM3jFaoQn3eoAiPh","eDicGjD9yte6FLSie","xg3hXCYQPJkwHyik2","bJ2haLkcGeLtTWaD5","PBRWb2Em5SNeWYwwB","7hFeMWC6Y5eaSixbD","aMHq4mA2PHSM2TMoH","wpZJvgQ4HvJE2bysy","2brqzQWfmNx5Agdrx","GLMFmFvXGyAcG25ni","NLBbCQeNLFvBJJkrt","bYrF8rXFYwPqnfxTp","v7c47vjta3mavY3QC","3MvaoZbGPxtRFCijw","TappK5n3kZmQzWEWD","tSemJckYr29Gnxod2","WdkLDpBGMCWhfByAY","EctieqKwDQcQHhqZy","hNqte2p48nqKux3wS","qw3Z79HELMsmLkL9F","zwDz9pgT43fRczkB4","Fafzj3wMvoCW4WjeF","kxW6q5YdTGWh5sWby","G5eMM3Wp3hbCuKKPE","kSiT2XjfTnDHKx44W","DSzpr8Y9299jdDLc9","wZGpoZgDANdkwTrwt","qajfiXo5qRThZQG7s","rRzZzBBQ36CrqhZTY","aP36QcAsxyuEispq6","TxcRbCYHaeL59aY7E","MFNJ7kQttCuCXHp8P","PQ3nutgxfTgvq69Xt","JJFphYfMsdFMuprBy","ythFNoiAotjvuEGkg","GZSzMqr8hAB2dR8pk","BBQ5HEnL3ShefQxEj","fzeoYhKoYPR3tDYFT","bXuAXCbzw9hsJSuEN","mbCccXJuuRBZdXdpH","m7THsgXyxxiEXgyHv","xtHd6sfdr2bZHa6Pb","pfaTqpWFghfrbvzaD","u8GMcpEN9Z6aQiCvp","gBpYo7mt2zNBmtBJd","rkpDX7j7va6c8Q7cZ","NGkBfd8LTqcpbQn5Z","GEPX7jgLMB8vR2qaK"]},"locale":"en-US","mapbox":{"apiKey":"pk.eyJ1IjoiaGFicnlrYSIsImEiOiJjaWxvcnhidzgwOGlodHJrbmJ2bmVmdjRtIn0.inr-_5rWOOslGQxY8iDFOA"},"petrov":{"afterTime":1727400080403,"beforeTime":1727376805595,"petrovPostId":"6LJ6xcHEjKF9zWKzs","petrovServerUrl":"https://forum.effectivealtruism.org/graphql","petrovGamePostId":"KTEciTeFwL2tTujZk"},"reacts":{"addNewReactKarmaThreshold":10,"downvoteExistingReactKarmaThreshold":20,"addNameToExistingReactKarmaThreshold":5},"stripe":{"publicKey":"pk_live_51HtKAwA2QvoATZCZiy9f2nc6hA52YS1BE81cFu9FEV1IKar0Bwx6hIpxxxYHnhaxO9KM7kRYofZId3sUUI7Q0NeO00tGni3Wza"},"algolia":{"appId":"fakeAppId","searchKey":"fakeSearchKey","indexPrefix":"test_"},"llmChat":{"userIds":["McgHKH6MMYSnPwQcm","6Fx2vQtkYSZkaCvAg","MEu8MdhruX5jfGsFQ","YaNNYeR5HjKLDBefQ","hBEAsEpoNHaZfefxR","NFmcwmaFeTWfgrvBN","ZnpELPxzzD2CiigNy","Q7NW4XaWQmfPfdcFj","NXeHNNSFHGESrYkPv","QDNJ93vrjoaRBesk2","iMBN2523tmh4Yicc3","5iPRfSnjako6iM6LG","aBHfQ4C5fSM4TPyTn","n4M37rPXGyL6p8ivK","e9ToWWzhwWp5GSE7P","TCjNiBLBPyhZq5BuM","XLwKyCK7JmC292ZCC","S3ydcLKdejjkodNut","ENgxBL95Sc7MRwYty","KCExMGwS2ETzN3Ksr","XGEcH5rmq4yGvD82A","YFiFbXgjBpDKZT93g","dZMo8p7fGCgPMfdfD","Pdca6FNZBrXj9z28n","LHbu27FubhwFv8ZJt","gYxdDBQ3AZbde8HgZ","5JqkvjdNcxwN8D86a","6c2KCEXTGogBZ9KoE","haTrhurXNmNN8EiXc"]},"logoUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1498011194/LessWrong_Logo_skglnw.svg","ckEditor":{"uploadUrl":"https://39669.cke-cs.com/easyimage/upload/","webSocketUrl":"39669.cke-cs.com/ws"},"recombee":{"enabled":true},"hasEvents":true,"logRocket":{"apiKey":"mtnxzn/lesswrong","sampleDensity":5},"reCaptcha":{"apiKey":"6LfFgqEUAAAAAHKdMgzGO-1BRBhHw1x6_8Ly1cXc"},"siteImage":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg","cloudinary":{"cloudName":"lesswrong-2-0","uploadPresetBanner":"navcjwf7","uploadPresetGridImage":"tz0mgw2s","uploadPresetSocialPreview":"nn5tppry"},"googleMaps":{"apiKey":"AIzaSyA3C48rl26gynG3qIuNuS-3Bh_Zz9jFXkY"},"adminAccount":{"email":"team@lesswrong.com","username":"LessWrong"},"annualReview":{"end":"2024-02-01T08:00:00Z","start":"2023-12-04T00:10:00Z","reviewPhaseEnd":"2024-01-15T08:00:00Z","votingPhaseEnd":"2024-02-01T08:00:00Z","nominationPhaseEnd":"2023-12-17T08:00:00Z","votingResultsPostId":"TSaJ9Zcvc3KWh3bjX","announcementPostPath":"/posts/B6CxEApaatATzown6/the-lesswrong-2022-review","reviewWinnerSectionsInfo":{"modeling":{"tag":"World Modeling","order":2,"title":"World","coords":{"leftXPct":0.05,"leftYPct":0,"rightXPct":0.57,"rightYPct":0,"middleXPct":0.31,"middleYPct":0,"leftFlipped":true,"leftWidthPct":0.26,"rightWidthPct":0.26,"middleWidthPct":0.26},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753450/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_15ba02c3-b268-45f1-a780-322bbaa6fc22_eu9l0l.png"},"ai safety":{"tag":"AI","order":5,"title":"Technical AI Safety","coords":{"leftXPct":0.2,"leftYPct":0.3,"rightXPct":0.554,"rightYPct":0.3,"middleXPct":0.467,"middleYPct":0.3,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,fl_progressive,q_auto/v1708570131/lwbot_topographic_watercolor_artwork_of_a_giant_robot_hand_gent_e4e9f305-9611-4787-8768-d7af3d702ed4_ta2ii9.png"},"practical":{"tag":"Practical","order":3,"title":"Practical","coords":{"leftXPct":0.2,"leftYPct":0.05,"rightXPct":0.634,"rightYPct":0.05,"middleXPct":0.417,"middleYPct":0.05,"leftFlipped":false,"leftWidthPct":0.217,"rightWidthPct":0.217,"middleWidthPct":0.217},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708974564/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_4f6449e2-569b-48a3-b878-a400315b3ef0_hqutxe.png"},"ai strategy":{"tag":"AI","order":4,"title":"AI Strategy","coords":{"leftXPct":0,"leftYPct":0,"rightXPct":0.66,"rightYPct":0,"middleXPct":0.33,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753570/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_8dda30ee-71d6-4b24-80c7-a8499a5b25c6_uacvgk.png"},"rationality":{"tag":"Rationality","order":0,"title":"Rationality","coords":{"leftXPct":0.12,"leftYPct":0,"rightXPct":0.72,"rightYPct":0,"middleXPct":0.42,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.3,"rightFlipped":true,"rightWidthPct":0.3,"middleWidthPct":0.3},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753260/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_09275054-eb84-43c4-9cfa-4a05e1818c9e_rmov5i.png"},"optimization":{"tag":"World Optimization","order":1,"title":"Optimization","coords":{"leftXPct":0.1,"leftYPct":0.2,"rightXPct":0.7,"rightYPct":0.2,"middleXPct":0.4,"middleYPct":0.2,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753382/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_242eda7f-95a9-4c3b-8090-991a1b11286f_xcjhxq.png"}},"reviewWinnerYearGroupsInfo":{"2018":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008323/ruby37_green_on_white_aquarelle_sketch_by_thomas_schaller_of_ri_7a3fa89a-ac7a-466f-929f-b396cb4d9bd5_p8rh9t.png"},"2019":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008331/ruby37_blue_on_white_aquarelle_sketch_by_thomas_schaller_of_gre_f421cc99-2bb5-4357-b164-d05c2f4fe84e_aib1co.png"},"2020":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.01,"rightXPct":0.72,"rightYPct":0.01,"middleXPct":0.34,"middleYPct":0.01,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008346/ruby37_aquarelle_sketch_of_futuristic_landscape_by_thomas_schal_f07d5805-9fb0-4dcc-9295-7f063624e28c_slcokh.png"},"2021":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.545,"rightYPct":0.1,"middleXPct":0.278,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/a_270/q_auto,f_auto/ohabryka_Topographic_aquarelle_book_cover_by_Thomas_W._Schaller_f9c9dbbe-4880-4f12-8ebb-b8f0b900abc1_m4k6dy_734413"},"2022":{"tag":null,"coords":{"leftXPct":0,"leftYPct":0.1,"rightXPct":0.79,"rightYPct":0.1,"middleXPct":0.43,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008351/ruby37_aquarelle_sketch_of_a_woman_focusing_hard_studying_in_an_2ac568ef-408e-4561-acc8-84c76bb42fba_gwt8uq.png"}},"showReviewOnFrontPageIfActive":true},"googleVertex":{"enabled":true},"intercomAppId":"wtb8z7sj","commentInterval":15,"googleDocImport":{"enabled":true},"moderationEmail":"team@lesswrong.com","timeDecayFactor":1.15,"googleTagManager":{"apiKey":"GTM-TRC765W"},"textReplacements":{"Less Wrong":"Down Bad","Alignment Forum":"Standards Committee","Artificial Intelligence":"Fake News"},"alternateHomePage":false,"gatherTownMessage":"Schelling social hours on Tues 1pm and Thurs 6pm PT","bookDisplaySetting":false,"gardenOpenToPublic":false,"karmaRewarderId100":"iqWr6C3oEB4yWpzn5","legacyRouteAcronym":"lw","maxRenderQueueSize":3,"recommendationsTab":{"manuallyStickiedPostIds":[]},"frontpageScoreBonus":0,"karmaRewarderId1000":"mBBmKWkmw8bgJmGiG","defaultVisibilityTags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10}],"enableGoodHeartProject":false,"maxDocumentsPerRequest":5000,"defaultSequenceBannerId":"sequences/vnyzzznenju0hzdv6pqb.jpg","defaultModeratorComments":[{"id":"FfMok764BCY6ScqWm","label":"Option A"},{"id":"yMHoNoYZdk5cKa3wQ","label":"Option B"}],"newUserIconKarmaThreshold":50,"dialogueMatchmakingEnabled":true,"hideUnreviewedAuthorComments":"2023-04-04T18:54:35.895Z","gatherTownUserTrackingIsBroken":true,"postModerationWarningCommentId":"sLay9Tv65zeXaQzR4","commentModerationWarningCommentId":"LbGNE5Ssnvs6MYnLu","performanceMetricLoggingEnax5bled":true,"firstCommentAcknowledgeMessageCommentId":"QgwD7PkQHFp3nfhjj"}</script><script>window.tabId = "GCcm3zWx7zg83jQSb"</script><script>window.isReturningVisitor = false</script><script async="" src="codex_files/bundle.js"></script><title>The Codex — LessWrong</title><meta data-react-helmet="true" http-equiv="Accept-CH" content="DPR, Viewport-Width, Width"><meta data-react-helmet="true" charset="utf-8"><meta data-react-helmet="true" name="description" content="The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously."><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"><meta data-react-helmet="true" name="twitter:image:src" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/c_crop,g_custom/c_fill,dpr_auto,q_auto,f_auto,g_auto:faces/ItFKgn4_rrr58y_zurh8d"><meta data-react-helmet="true" name="twitter:description" content="The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously."><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:url" content="https://www.lesswrong.com/codex"><meta data-react-helmet="true" property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/c_crop,g_custom/c_fill,dpr_auto,q_auto,f_auto,g_auto:faces/ItFKgn4_rrr58y_zurh8d"><meta data-react-helmet="true" property="og:description" content="The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously."><meta data-react-helmet="true" http-equiv="delegate-ch" content="sec-ch-dpr https://res.cloudinary.com;"><link data-react-helmet="true" rel="canonical" href="codex_files/codex.html"><link data-react-helmet="true" rel="alternate" type="application/rss+xml" href="https://www.lesswrong.com/feed.xml"><meta name="twitter:card" content="summary"><script>window.themeOptions = {"name":"default"}</script><style id="jss-insertion-point"></style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: rgba(0, 0, 0, 0.54);
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(0, 0, 0, 0.26);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-moz-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-moz-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-moz-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(0,0,0,0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(0, 0, 0, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-contained {
  color: rgba(0, 0, 0, 0.87);
  box-shadow: 0px 1px 5px 0px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 3px 1px -2px rgba(0,0,0,0.12);
  background-color: #e0e0e0;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
  box-shadow: none;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:hover {
  background-color: #d5d5d5;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #e0e0e0;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-containedPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(0,0,0,0.2),0px 12px 17px 2px rgba(0,0,0,0.14),0px 5px 22px 4px rgba(0,0,0,0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: rgba(0, 0, 0, 0.54);
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiPopover">
.MuiPopover-paper {
  outline: none;
  position: absolute;
  min-width: 16px;
  max-width: calc(100% - 32px);
  overflow-y: auto;
  overflow-x: hidden;
  min-height: 16px;
  max-height: calc(100% - 32px);
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(0, 0, 0, 0.12);
}
</style><style data-jss="">
.jss77 {
  top: 0;
  left: 0;
  bottom: 0;
  z-index: 1199;
  position: fixed;
}
.jss78 {
  right: auto;
}
.jss79 {
  left: auto;
  right: 0;
}
.jss80 {
  right: 0;
  bottom: auto;
}
.jss81 {
  top: auto;
  right: 0;
  bottom: 0;
}
</style><link id="main-styles" rel="stylesheet" type="text/css" onerror="window.missingMainStylesheet=true" href="codex_files/allStyles.css"><script async="" src="codex_files/wtb8z7sj"></script></head>
<body class="abTestNoEffect_group2 collectionsPageABTest_originalLayoutGroup booksProgressBarABTest_control welcomeBoxABTest_welcomeBox twoLineEventsSidebar_expanded dialogueFacilitationMessages_optIn frontpageDialogueReciprocityRecommendations_noShow showOpinionsInReciprocity_show showRecommendedContentInMatchForm_show checkNotificationMessageContent_v4 newFrontpagePostFeedsWithRecommendationsOptIn_classicFrontpage">
<script>0</script><div id="react-app"><div class="wrapper Layout-wrapper" id="wrapper"><div></div><span></span><div class="IntercomWrapper-intercomFrame" id="intercom-outer-frame"></div><noscript class="noscript-warning"> This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. </noscript><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TRC765W" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div class="Header-root"><div style="height:64px" class="Header-headroom headroom-wrapper"><div class="headroom headroom--unfixed headroom-disable-animation"><header class="Header-appBar"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><div class="Header-hideSmDown"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><div class="Header-hideMdUp"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M3 9h14V7H3v2zm0 4h14v-2H3v2zm0 4h14v-2H3v2zm16 0h2v-2h-2v2zm0-10v2h2V7h-2zm0 6h2v-2h-2v2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><h2 class="Typography-root Typography-title Header-title"><div class="Header-hideSmDown"><div class="Header-titleSubtitleContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LESSWRONG</a><span class="HeaderSubtitle-subtitle"><a href="https://www.lesswrong.com/codex">SlateStarCodex</a></span></div></div><div class="Header-hideMdUp"><a class="Header-titleLink" href="https://www.lesswrong.com/">LW</a></div></h2><div class="Header-rightHeaderItems"><div class="SearchBar-root"><div class="SearchBar-rootChild"><div class="SearchBar-searchInputArea SearchBar-searchInputAreaSmall"><div><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root SearchBar-searchIcon SearchBar-searchIconSmall" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><div></div></div></div></div><div class="UsersAccountMenu-root"><button tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat" type="button"><span class="MuiButton-label"><span class="UsersAccountMenu-userButton">Login</span></span><span class="MuiTouchRipple-root"></span></button></div></div></div></header><div class="jss77 jss78" style="width: 20px;"></div></div></div></div><div class="Layout-standaloneNavFlex"><div class="Layout-searchResultsArea"></div><div class="Layout-main"><div class="flash-messages FlashMessages-root"></div><div class="CollectionsPage-root"><div class="ToCColumn-root ToCColumn-tocActivated"><div class="ToCColumn-header"></div><div class="ToCColumn-toc"><div class="ToCColumn-stickyBlockScroller"><div class="ToCColumn-stickyBlock"><div><div class="TableOfContentsRow-root TableOfContentsRow-level0 TableOfContentsRow-highlighted"><a href="#" class="TableOfContentsRow-link TableOfContentsRow-title TableOfContentsRow-highlightDot">The Codex</a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="#jF58hKP9ZLzgy22Jr" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Good and Bad Reasoning</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#XsMTxdQ6fprAQMoKi" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Argument and Analysis</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#NHXY86jBahi968uW4" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Categorisation and Concepts</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#TQW9brvXJ5Fajorr4" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Probability and Predictions</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="#YhQ39PPHNrRCgYXcs" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>The Institution of Science</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#BQBqPowfxjvoee8jw" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Studies and Statistics</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#B384FrQNrxSq4hZoS" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Research and Reviews</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#k5MPpr72eiGknaS7F" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Hypotheses and Hunches</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="#kcCvSNNZd8pfQvf9E" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Designing the World</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#rNuPrZvabXe2MaZv8" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Politics and Pragmatics</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#zfXAcwLnGocsCsriG" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Economics and Efficiency</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#TKDT2Mt6dDMH8AsZW" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Futurism and Forecasting</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#xmDeR64CivZiTAcLx" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Community and Cooperation</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="#2tPEd5Gdm3iewB53M" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Epilogue</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="#WnTvZdXz2q9ySfr4o" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Parables and Prayers</span></a></div></div></div></div></div><div class="ToCColumn-gap1"></div><div class="ToCColumn-content"><div class="CollectionsPage-section"><h1 class="Typography-root Typography-display3 CollectionsPage-title">The Codex</h1><div class="CollectionsPage-description ContentStyles-base content ContentStyles-postBody"><div><p>The
 Codex is a collection of essays written by Scott Alexander that discuss
 how good reasoning works, how to learn from the institution of science,
 and different ways society has been and could be designed. It also 
contains several short interludes containing fictional tales and 
real-life stories. The essays contained have been widely read within the
 rationality and effective altruism communities, and have a strong bias 
towards actually reading the scientific papers being discussed, 
analysing the arguments closely, and taking the conclusions seriously.</p></div></div><a tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat CollectionsPage-startReadingButton" role="button" href="https://www.lesswrong.com/codex/eight-short-studies-on-excuses"><span class="MuiButton-label">Start Reading</span><span class="MuiTouchRipple-root"></span></a></div><div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="jF58hKP9ZLzgy22Jr" class="Typography-root Typography-display1 SectionTitle-title">Good and Bad Reasoning</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class=""><a href="https://www.lesswrong.com/posts/gFMH3Cqw4XxwL69iy/eight-short-studies-on-excuses"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/Kbm6QnJv9dgWsPHQP/schelling-fences-on-slippery-slopes"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/9kcTNWopvXFncXgPy/intellectual-hipsters-and-meta-contrarianism"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/DSzpr8Y9299jdDLc9/cardiologists-and-chinese-robbers"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/PQ3nutgxfTgvq69Xt/all-debates-are-bravery-debates"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/2brqzQWfmNx5Agdrx/the-virtue-of-silence"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/G5eMM3Wp3hbCuKKPE/proving-too-much"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/fzeoYhKoYPR3tDYFT/beware-isolated-demands-for-rigor"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/AYbhqi65SWzHzy7Xx/transhumanist-fables"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/wJnm5cBiZGmKn595f/and-i-show-you-how-deep-the-rabbit-hole-goes"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/895quRDaK6gR2rM82/diseased-thinking-dissolving-questions-about-disease"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/aMHq4mA2PHSM2TMoH/the-categories-were-made-for-man-not-man-for-the-categories"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/4xKeNKFXFB458f5N8/ethnic-tension-and-meaningless-arguments"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/BZMc9Xzqw5WcCMHrr/the-moral-of-the-story"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/9HSwh2mE3tX6xvZ2W/the-pyramid-and-the-garden"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/CcyGR3pp3FCDuW6Pf/on-overconfidence"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/9Tw5RqnEzqEtaoEkq/if-it-s-worth-doing-it-s-worth-doing-with-made-up-statistics"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/r8aAqSBeeeMNRtiYK/techniques-for-probability-estimates"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/GrtbTAPfkJa4D6jjH/confidence-levels-inside-and-outside-an-argument"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/2gWs8SScqeDFidqyv/the-logician-and-the-god-emperor"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/FLnDFnXyWrKr6eiT6/reverse-psychology"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText"><span class="LWTooltip-root">0 / 22 posts read</span><span class="LWTooltip-root"><a class="BooksProgressBar-loginText">login to track progress</a></span></div></div><div class="LargeSequencesItem-root" id="XsMTxdQ6fprAQMoKi"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/rfpef83ejiwbsi1pmroz.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi">Argument and Analysis</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">88<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/gFMH3Cqw4XxwL69iy">Eight Short Studies On Excuses</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/Kbm6QnJv9dgWsPHQP">Schelling fences on slippery slopes</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/9kcTNWopvXFncXgPy">Intellectual Hipsters and Meta-Contrarianism</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/DSzpr8Y9299jdDLc9">Cardiologists and Chinese Robbers</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/PQ3nutgxfTgvq69Xt">All Debates Are Bravery Debates</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/2brqzQWfmNx5Agdrx">The Virtue of Silence</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/G5eMM3Wp3hbCuKKPE">Proving Too Much</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/fzeoYhKoYPR3tDYFT">Beware Isolated Demands For Rigor</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/AYbhqi65SWzHzy7Xx">Transhumanist Fables</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/wJnm5cBiZGmKn595f">…And I Show You How Deep The Rabbit Hole Goes</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="NHXY86jBahi968uW4"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/NHXY86jBahi968uW4"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/bgpjay2m1labmbqdtjmi.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/NHXY86jBahi968uW4">Categorisation and Concepts</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>"The
 essay “How An Algorithm Feels From The Inside” is a gift that keeps on 
giving. You can get a reputation as a daring and original thinker just 
by copy-pasting it at different arguments with a couple of appropriate 
words substituted for one another, mad-libs like. It is the solution to 
something like 25% of extant philosophical problems."</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">73<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/895quRDaK6gR2rM82">Diseased thinking: dissolving questions about disease</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/aMHq4mA2PHSM2TMoH">The Categories Were Made For Man, Not Man For The Categories</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/yCWPkLi8wJvewPbEp">The noncentral fallacy - the worst argument in the world?</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/4xKeNKFXFB458f5N8">Ethnic Tension And Meaningless Arguments</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/BZMc9Xzqw5WcCMHrr">The Moral Of The Story</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="TQW9brvXJ5Fajorr4"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/dyq1iu03mw0qo54n6byk.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4">Probability and Predictions</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>Nearly everyone is very very very overconfident. We know this from <span><span><span><a href="http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf"><span>experiments</span></a></span></span></span>
 where people answer true/false trivia questions, then are asked to 
state how confident they are in their answer. If people’s confidence was
 well-calibrated, someone who said they were 99% confident (ie only 1% 
chance they’re wrong) would get the question wrong only 1% of the time. 
In fact, people who say they are 99% confident get the question wrong 
about 20% of the time.</p><p>It gets worse. People who say there’s only a
 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a 
million? Wrong 5% of the time. They’re not just overconfident, they are <i>fifty thousand times</i> as confident as they should be.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">57<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/9HSwh2mE3tX6xvZ2W">The Pyramid And The Garden</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/CcyGR3pp3FCDuW6Pf">On Overconfidence</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/9Tw5RqnEzqEtaoEkq">If It’s Worth Doing, It’s Worth Doing With Made-Up Statistics</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/r8aAqSBeeeMNRtiYK">Techniques for probability estimates</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/GrtbTAPfkJa4D6jjH">Confidence levels inside and outside an argument</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/2gWs8SScqeDFidqyv">The Logician And The God-Emperor</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/FLnDFnXyWrKr6eiT6">Reverse Psychology</a></span></div></div></div></div></div></div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="YhQ39PPHNrRCgYXcs" class="Typography-root Typography-display1 SectionTitle-title">The Institution of Science</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class=""><a href="https://www.lesswrong.com/posts/ythFNoiAotjvuEGkg/beware-the-man-of-one-study"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/kdmCm5NQTpqhJmGm6/debunked-and-well-refuted"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/CsKrQdQJJCFPjfKjF/noisy-poll-results-and-reptilian-muslim-climatologists-from"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/SQAfPKZBAAKYMjx25/two-dark-side-statistics-papers"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/bXuAXCbzw9hsJSuEN/the-control-group-is-out-of-control"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/ckuuDa8DmJ4pdFeD8/the-cowpox-of-doubt"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/Sd2r7H8bCmd9ChGbX/how-common-are-science-failures"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/ERPL3v2Y976W7XG3j/learning-to-love-scientific-consensus"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/gBChm3THPGFcrq5eH/my-irb-nightmare"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/hMQPyLDbg3bA7P6aN/the-study-of-anglophysics"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/c8khnHoRTSGjmHLLf/marijuana-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/g4pi2jfQHFF6mPdjw/wheat-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/znEhB9hJtwXica5s3/ssris-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/CfX6pGepdjQYELSpK/alcoholics-anonymous-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/ALEYMFAuFSCz8v5YE/prescriptions-paradoxes-and-perversities"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/FW3DEYbKPZJh5A8Bj/guns-and-states"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/K9aLcuxAPyf5jGyFX/teachers-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/oHsMeXehPy4jHcmwy/antidepressant-pharmacogenomics-much-more-than-you-wanted-to"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/jFzovY2CERF5bd2EW/a-story-with-zombies"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/pfmZ5cYQCahABGZzi/asches-to-asches"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/xPJKZyPCvap4Fven8/the-atomic-bomb-considered-as-hungarian-high-school-science"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/KrEwDMN4YXp5YWD45/it-s-bayes-all-the-way-up"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/P2nYKqwmHdYKARTG8/why-are-transgender-people-immune-to-optical-illusions"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/HTGCGASf9xfB6edAh/the-case-of-the-suffocating-woman"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText"><span class="LWTooltip-root">0 / 24 posts read</span><span class="LWTooltip-root"><a class="BooksProgressBar-loginText">login to track progress</a></span></div></div><div class="LargeSequencesItem-root" id="BQBqPowfxjvoee8jw"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/zukiyrvljrwfe5bql7ek.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw">Studies and Statistics</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p><br>Aquinas famously <span><span><span><a href="http://en.wikipedia.org/wiki/Homo_unius_libri"><span>said</span></a></span></span></span>: beware the man of one book. I would add: beware the man of one study.</p><p>For
 example, take medical research. Suppose a certain drug is weakly 
effective against a certain disease. After a few years, a bunch of 
different research groups have gotten their hands on it and done all 
sorts of different studies. In the best case scenario the average study 
will find the true result – that it’s weakly effective.</p><p>But there 
are also about 5 studies that find that the drug is very good, and 5 
studies missing the sign entirely and finding that the drug is actively 
bad. There’s even 1 study finding that the drug is very bad, maybe 
seriously dangerous.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">140<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/ythFNoiAotjvuEGkg">Beware The Man Of One Study</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/kdmCm5NQTpqhJmGm6">Debunked And Well-Refuted</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/CsKrQdQJJCFPjfKjF">Noisy Poll Results And Reptilian Muslim Climatologists from Mars</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/SQAfPKZBAAKYMjx25">Two Dark Side Statistics Papers</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/bXuAXCbzw9hsJSuEN">The Control Group Is Out Of Control</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/ckuuDa8DmJ4pdFeD8">The Cowpox of Doubt</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/Sd2r7H8bCmd9ChGbX">How Common Are Science Failures?</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/ERPL3v2Y976W7XG3j">Learning To Love Scientific Consensus</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/gBChm3THPGFcrq5eH">My IRB Nightmare</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/hMQPyLDbg3bA7P6aN">The Study of Anglophysics</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="B384FrQNrxSq4hZoS"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/ggdn92agzidnk0voif2z.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS">Research and Reviews</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>Synthesising
 scientific knowledge to answer a policy question is difficult. This 
sequence is a series of attempts to do just that, with intricate and 
winding literature reviews.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">191<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="ChapterTitle-root">Much More Than You Wanted to Know</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/c8khnHoRTSGjmHLLf">Marijuana: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/g4pi2jfQHFF6mPdjw">Wheat: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/znEhB9hJtwXica5s3">SSRIs: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/CfX6pGepdjQYELSpK">Alcoholics Anonymous: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/ALEYMFAuFSCz8v5YE">Prescriptions, Paradoxes, and Perversities</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/FW3DEYbKPZJh5A8Bj">Guns And States</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/K9aLcuxAPyf5jGyFX">Teachers: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/oHsMeXehPy4jHcmwy">Antidepressant Pharmacogenomics: Much More Than You Wanted To Know</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/jFzovY2CERF5bd2EW">A Story With Zombies</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/pfmZ5cYQCahABGZzi">Asches to Asches</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="k5MPpr72eiGknaS7F"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/byzxi4zdrlvodk0ph46r.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F">Hypotheses and Hunches</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">52<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/xPJKZyPCvap4Fven8">The Atomic Bomb Considered As Hungarian High School Science Fair Project</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/KrEwDMN4YXp5YWD45">It’s Bayes All The Way Up</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/P2nYKqwmHdYKARTG8">Why Are Transgender People Immune To Optical Illusions?</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/HTGCGASf9xfB6edAh">The Case Of The Suffocating Woman</a></span></div></div></div></div></div></div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="kcCvSNNZd8pfQvf9E" class="Typography-root Typography-display1 SectionTitle-title">Designing the World</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class=""><a href="https://www.lesswrong.com/posts/GLMFmFvXGyAcG25ni/i-can-tolerate-anything-except-the-outgroup"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/Y345zuBetHqGnotwm/book-review-albion-s-seed"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/BpYDqQNZ2NZNCqPp6/albion-s-seed-genotyped"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/2HafkDSNdtMzptzcN/society-is-fixed-biology-is-mutable"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/BPKvZuLRyiJBjfNbg/a-philosopher-walks-into-a-coffee-shop"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/8KHR3tfa4SJjMSkXd/the-witching-hour"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/Fafzj3wMvoCW4WjeF/against-tulip-subsidies"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/BBQ5HEnL3ShefQxEj/considerations-on-cost-disease"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/ofL22R6KZsfrvdmwg/highlights-from-the-comments-on-cost-disease"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/oMiogKLkK8L59WzDe/the-price-of-glee-in-china"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/efMgZujzfjP9B9H4R/things-probably-matter"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/m7THsgXyxxiEXgyHv/how-the-west-was-won"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/iLMkKDKmfbMkDuQBm/the-lizard-people-of-alpha-draconis-1-decided-to-build-an"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/kSiT2XjfTnDHKx44W/a-modern-myth"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/sm6npdgZArSn4afeZ/ai-researchers-on-ai-risk"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/pgGiqLQg2KWsaz5RE/should-ai-be-open"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/qL8Z9TBCNWQyN6yLq/ssc-journal-club-ai-timelines"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/LY7Nca846X8kcT8Jk/where-the-falling-einstein-meets-the-rising-mouse"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/mnpkM57R6ZbjnwrYw/don-t-fear-the-filter"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/pZerSnxv6FPqvgoYu/book-review-age-of-em"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/ak9wY2t9K3K4GxCXv/ascended-economy"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/muhtBvbh4etjkKXd9/g-k-chesterton-on-ai-risk"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/Wh8HAK6LR5CAoPCCC/repost-the-demiurge-s-older-brother"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/rkpDX7j7va6c8Q7cZ/in-favor-of-niceness-community-and-civilization"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/qajfiXo5qRThZQG7s/guided-by-the-beauty-of-our-weapons"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/xtHd6sfdr2bZHa6Pb/the-ideology-is-not-the-movement"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/aP36QcAsxyuEispq6/archipelago-and-atomic-communitarianism"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/TxcRbCYHaeL59aY7E/meditations-on-moloch"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/ouSpHCCPgsXkwxAGb/five-planets-in-search-of-a-sci-fi-story"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/qaHHJ3kkCQS4nsoGJ/it-was-you-who-made-my-blue-eyes-blue"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText"><span class="LWTooltip-root">0 / 31 posts read</span><span class="LWTooltip-root"><a class="BooksProgressBar-loginText">login to track progress</a></span></div></div><div class="LargeSequencesItem-root" id="rNuPrZvabXe2MaZv8"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/acfvxltz0mnyd7jqdq76.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8">Politics and Pragmatics</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">91<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/GLMFmFvXGyAcG25ni">I Can Tolerate Anything Except The Outgroup</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/Y345zuBetHqGnotwm">Book Review: Albion’s Seed</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/BpYDqQNZ2NZNCqPp6">Albion’s Seed, Genotyped</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/2HafkDSNdtMzptzcN">Society Is Fixed, Biology Is Mutable</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/BPKvZuLRyiJBjfNbg">A Philosopher Walks Into A Coffee Shop</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/8KHR3tfa4SJjMSkXd">The Witching Hour</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="zfXAcwLnGocsCsriG"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/hxgrnxobgf692eqpd8mz.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG">Economics and Efficiency</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">163<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="ChapterTitle-root">Marginally Important Econ Questions</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/Fafzj3wMvoCW4WjeF">Against Tulip Subsidies</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/BBQ5HEnL3ShefQxEj">Considerations On Cost Disease</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/ofL22R6KZsfrvdmwg">Highlights From The Comments On Cost Disease</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/oMiogKLkK8L59WzDe">The Price Of Glee In China</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/efMgZujzfjP9B9H4R">Things Probably Matter</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/m7THsgXyxxiEXgyHv">How The West Was Won</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/iLMkKDKmfbMkDuQBm">The Lizard People Of Alpha Draconis 1 Decided To Build An Ansible</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/kSiT2XjfTnDHKx44W">A Modern Myth</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="TKDT2Mt6dDMH8AsZW"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/lel3jdh48of1dhtwfo4i.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW">Futurism and Forecasting</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">156<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/LTtNXM9shNM9AC2mp">Superintelligence FAQ</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/sm6npdgZArSn4afeZ">AI Researchers On AI Risk</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/pgGiqLQg2KWsaz5RE">Should AI Be Open?</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/qL8Z9TBCNWQyN6yLq">SSC Journal Club: AI Timelines</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/LY7Nca846X8kcT8Jk">Where The Falling Einstein Meets The Rising Mouse</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/mnpkM57R6ZbjnwrYw">Don’t Fear The Filter</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/pZerSnxv6FPqvgoYu">Book Review: Age of Em</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/ak9wY2t9K3K4GxCXv">Ascended Economy?</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/muhtBvbh4etjkKXd9">G.K. Chesterton On AI Risk</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/Wh8HAK6LR5CAoPCCC">[REPOST] The Demiurge’s Older Brother</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="xmDeR64CivZiTAcLx"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/u0ackeoho1tquuiozpt4.jpg"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx">Community and Cooperation</a></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">189<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/rkpDX7j7va6c8Q7cZ">In Favor of Niceness, Community, and Civilization</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/qajfiXo5qRThZQG7s">Guided By The Beauty Of Our Weapons</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/xtHd6sfdr2bZHa6Pb">The Ideology Is Not The Movement</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/aP36QcAsxyuEispq6">Archipelago and Atomic Communitarianism</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/TxcRbCYHaeL59aY7E">Meditations On Moloch</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/ouSpHCCPgsXkwxAGb">Five Planets In Search Of A Sci-Fi Story</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/qaHHJ3kkCQS4nsoGJ">It Was You Who Made My Blue Eyes Blue</a></span></div></div></div></div></div></div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="2tPEd5Gdm3iewB53M" class="Typography-root Typography-display1 SectionTitle-title">Epilogue</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class=""><a href="https://www.lesswrong.com/posts/JP7eZYHB7aY6fA4TR/burdens"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/zwDz9pgT43fRczkB4/the-parable-of-the-talents"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/qw3Z79HELMsmLkL9F/nobody-is-perfect-everything-is-commensurable"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/Lt8Rn4rkYwqiTXGPy/answer-to-job"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/SvKSwT6xYfYahH4XN/universal-love-said-the-cactus-person"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class=""><a href="https://www.lesswrong.com/posts/MFNJ7kQttCuCXHp8P/the-goddess-of-everything-else"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText"><span class="LWTooltip-root">0 / 6 posts read</span><span class="LWTooltip-root"><a class="BooksProgressBar-loginText">login to track progress</a></span></div></div><div class="LargeSequencesItem-root" id="WnTvZdXz2q9ySfr4o"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="codex_files/opwbi6lh0ud7r7dlyghc.png"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o">Parables and Prayers</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">69<!-- --> min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/JP7eZYHB7aY6fA4TR">Burdens</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/zwDz9pgT43fRczkB4">The Parable Of The Talents</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/qw3Z79HELMsmLkL9F">Nobody Is Perfect, Everything Is Commensurable</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/Lt8Rn4rkYwqiTXGPy">Answer to Job</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/SvKSwT6xYfYahH4XN">Universal Love, Said The Cactus Person</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width:12px"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/MFNJ7kQttCuCXHp8P">The Goddess of Everything Else</a></span></div></div></div></div></div></div></div></div><div class="ToCColumn-gap2"></div><div class="ToCColumn-gap3"></div></div></div><div class="Footer-root"></div></div></div></div></div>

<script>window.ssrRenderedAt = "2024-10-10T21:04:20.086Z"</script>
<script>window.ssrMetadata = {"renderedAt":"2024-10-10T21:04:20.086Z","cacheFriendly":false,"timezone":"Atlantic/Reykjavik"}</script>
<script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","currentUser":null,"unreadNotificationCounts":{"__typename":"NotificationCounts","unreadNotifications":0,"unreadPrivateMessages":0,"faviconBadgeNumber":0,"checkedAt":"2024-10-10T21:04:20.098Z"},"collection({\"input\":{\"selector\":{\"documentId\":\"2izXHCrmJ684AnZ5X\"}}})":{"__typename":"SingleCollectionOutput","result":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}}},"User:nmk3nLpQE89dMRzzN":{"_id":"nmk3nLpQE89dMRzzN","__typename":"User","slug":"eliezer_yudkowsky","createdAt":"2009-02-23T21:58:56.739Z","username":"Eliezer_Yudkowsky","displayName":"Eliezer Yudkowsky","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":144836,"afKarma":1831,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":951,"commentCount":7584,"sequenceCount":40,"afPostCount":18,"afCommentCount":116,"spamRiskScore":1,"tagRevisionCount":324,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:2izXHCrmJ684AnZ5X_contents":{"_id":"2izXHCrmJ684AnZ5X_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-22T21:28:44.333Z","userId":"nmk3nLpQE89dMRzzN","html":"<p>The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously.<\/p>","commitMessage":null,"wordCount":83,"htmlHighlight":"<p>The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously.<\/p>","plaintextDescription":"The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously."},"Revision:nKkCGrfLoqofKXXQD_contents":{"_id":"nKkCGrfLoqofKXXQD_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:22:08.473Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:MWjJejhD8punq5v2t":{"_id":"MWjJejhD8punq5v2t","__typename":"Revision","htmlHighlight":"<html><head><\/head><body><p><strong>The Clumsy Game-Player<\/strong><\/p><p>You and a partner are playing an Iterated Prisoner's Dilemma. Both of you have publicly pre-committed to the tit-for-tat strategy. By iteration 5, you're going happily along, raking up the bonuses of cooperation, when your partner unexpectedly presses the \"defect\" button.<\/p><p>\"Uh, sorry,\" says your partner. \"My finger slipped.\"<\/p><p>\"I still have to punish you just in case,\" you say. \"I'm going to defect next turn, and we'll see how you like it.\"<\/p><p>\"Well,\" said your partner, \"knowing that, I guess I'll defect next turn too, and we'll both lose out. But hey, it was just a slipped finger. By not trusting me, you're costing us both the benefits of one turn of cooperation.\"<\/p><p>\"True\", you respond \"but if I don't do it, you'll feel free to defect whenever you feel like it, using the 'finger slipped' excuse.\"<\/p><p>\"How about this?\" proposes your partner. \"I promise to take extra care that my finger won't slip again. You promise that if my finger does slip again, you will punish me terribly, defecting for a bunch of turns. That way, we trust each other again, and we can still get the benefits of cooperation next turn.\"<\/p><p>You don't believe that your partner's finger really slipped, not for an instant. But the plan still seems like a good one. You accept the deal, and you continue cooperating until the experimenter ends the game.<\/p><p>After the game, you wonder what went wrong, and whether you could have played better. You decide that there was no better way to deal with your partner's \"finger-slip\" - after all, the plan you enacted gave you maximum possible utility under the circumstances. But you wish that you'd pre-committed, at the beginning, to saying \"and I will punish finger slips equally to deliberate defections, so make sure you're careful.\"<\/p><p>&nbsp;<\/p><p><strong>The Lazy Student<\/strong><\/p><p>You are a perfectly utilitarian school teacher, who attaches exactly the same weight to others' welfare as to your own. You have to have the reports of all fifty students in your class ready by the time midterm grades go out on January 1st. You don't want to have to work during Christmas vacation, so you set a deadline that all reports must be in by December 15th or you won't grade them and the students will fail the class. Oh, and your class is Economics 101, and as part of a class project all your students have to behave as selfish utility-maximizing agents for the year.<\/p><p>It costs your students 0 utility to tur<\/p><\/body><\/html>... ","plaintextDescription":"The Clumsy Game-Player\n\nYou and a partner are playing an Iterated Prisoner's Dilemma. Both of you have publicly pre-committed to the tit-for-tat strategy. By iteration 5, you're going happily along, raking up the bonuses of cooperation, when your partner unexpectedly presses the \"defect\" button.\n\n\"Uh, sorry,\" says your partner. \"My finger slipped.\"\n\n\"I still have to punish you just in case,\" you say. \"I'm going to defect next turn, and we'll see how you like it.\"\n\n\"Well,\" said your partner, \"knowing that, I guess I'll defect next turn too, and we'll both lose out. But hey, it was just a slipped finger. By not trusting me, you're costing us both the benefits of one turn of cooperation.\"\n\n\"True\", you respond \"but if I don't do it, you'll feel free to defect whenever you feel like it, using the 'finger slipped' excuse.\"\n\n\"How about this?\" proposes your partner. \"I promise to take extra care that my finger won't slip again. You promise that if my finger does slip again, you will punish me terribly, defecting for a bunch of turns. That way, we trust each other again, and we can still get the benefits of cooperation next turn.\"\n\nYou don't believe that your partner's finger really slipped, not for an instant. But the plan still seems like a good one. You accept the deal, and you continue cooperating until the experimenter ends the game.\n\nAfter the game, you wonder what went wrong, and whether you could have played better. You decide that there was no better way to deal with your partner's \"finger-slip\" - after all, the plan you enacted gave you maximum possible utility under the circumstances. But you wish that you'd pre-committed, at the beginning, to saying \"and I will punish finger slips equally to deliberate defections, so make sure you're careful.\"\n\n \n\nThe Lazy Student\n\nYou are a perfectly utilitarian school teacher, who attaches exactly the same weight to others' welfare as to your own. You have to have the reports of all fifty students in your class ready by the tim","wordCount":3049,"version":"1.1.0"},"Revision:b8FHrKqyXuYGWc6vn_description":{"_id":"b8FHrKqyXuYGWc6vn_description","__typename":"Revision","htmlHighlight":"<p><strong>Game theory<\/strong> is the formal study of how rational actors interact to pursue incentives. It investigates situations of conflict and cooperation.<\/p>\n<p><em>See also:<\/em> <a href=\"https://www.lesswrong.com/tag/coordination-cooperation?showPostCount=true&amp;useTagName=true\">Coalition/coordination<\/a>, <a href=\"https://www.lesswrong.com/tag/coalitional-instincts?showPostCount=true&amp;useTagName=true\">Coalitional Instincts<\/a>, <a href=\"https://www.lesswrong.com/tag/decision-theory\">Decision theory<\/a>, <a href=\"https://www.lesswrong.com/tag/moloch?showPostCount=true&amp;useTagName=true\">Moloch<\/a>, <a href=\"https://www.lesswrong.com/tag/utility-functions\">Utility functions<\/a>, <a href=\"https://lesswrong.com/tag/decision-theory\">Decision Theory<\/a>, <a href=\"https://lesswrong.com/tag/prisoner-s-dilemma\">Prisoner's Dilemma<\/a><\/p>\n<p>Game theory is an extremely powerful and robust tool in analyzing much more complex situations, such as: mergers and acquisitions, political economy, voting systems, war bargaining and biological evolution. Eight game-theorists have won the Nobel Prize in Economic Sciences.<\/p>\n<h2>References<\/h2>\n<ul>\n<li><a href=\"http://levine.sscnet.ucla.edu/general/whatis.htm\">Naïve introduction to Game Theory<\/a><\/li>\n<li><a href=\"http://plato.stanford.edu/entries/game-theory/\">Stanford Encyclopedia entry on Game Theory<\/a><\/li>\n<\/ul>"},"Tag:b8FHrKqyXuYGWc6vn":{"_id":"b8FHrKqyXuYGWc6vn","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:b8FHrKqyXuYGWc6vn_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Game Theory","shortName":null,"slug":"game-theory","core":false,"postCount":312,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T06:03:25.225Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:ZFrgTgzwEfStg26JL_description":{"_id":"ZFrgTgzwEfStg26JL_description","__typename":"Revision","htmlHighlight":"<p><strong>AI Risk<\/strong> is analysis of the risks associated with building powerful AI systems.<\/p><p><i>Related: <\/i><a href=\"https://www.lesswrong.com/tag/ai\"><i>AI<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/orthogonality-thesis\"><i>Orthogonality thesis<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/complexity-of-value\"><i>Complexity of value<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/goodhart-s-law\"><i>Goodhart's law<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/paperclip-maximizer\"><i>Paperclip maximiser<\/i><\/a><\/p>"},"Tag:ZFrgTgzwEfStg26JL":{"_id":"ZFrgTgzwEfStg26JL","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZFrgTgzwEfStg26JL_description"},"canVoteOnRels":null,"userId":"EQNTWXLKMeWMp2FQS","name":"AI Risk","shortName":null,"slug":"ai-risk","core":false,"postCount":1358,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-16T10:29:25.410Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:5f5c37ee1b5cdee568cfb0cb_description":{"_id":"5f5c37ee1b5cdee568cfb0cb_description","__typename":"Revision","htmlHighlight":"<p>An <strong>affective death spiral<\/strong> (or <strong>happy death spiral<\/strong>) occurs when positive attributes of a theory, person, or organization combine with the <a href=\"https://www.lesswrong.com/tag/halo-effect\">Halo effect<\/a> in a feedback loop, resulting in the subject of the affective death spiral being held in higher and higher regard. In effect, every positive thing said about the subject results in more than one additional nice thing to say about the subject on average. This cascades like a nuclear chain reaction. This process creates theories that are believed for their own sake and organizations that exist solely to perpetuate themselves, especially when combined with the social dynamics of <a href=\"https://www.lesswrong.com/tag/groupthink\">groupthink<\/a>. Affective death spirals are thus a primary cause of cultishness.<\/p><p>The same process can also occur with negative beliefs instead of positive, leading to a <strong>death spiral of hate<\/strong>.<\/p><h2>Blog posts<\/h2><ul><li><a href=\"http://lesswrong.com/lw/lm/affective_death_spirals/\">Affective Death Spirals<\/a><\/li><li><a href=\"http://lesswrong.com/lw/ln/resist_the_happy_death_spiral/\">Resist the Happy Death Spiral<\/a><\/li><li><a href=\"http://lesswrong.com/lw/ls/when_none_dare_urge_restraint/\">When None Dare Urge Restraint<\/a><\/li><li><a href=\"http://lesswrong.com/lw/lv/every_cause_wants_to_be_a_cult/\">Every Cause Wants To Be A Cult<\/a><\/li><li><a href=\"http://lesswrong.com/lw/lz/guardians_of_the_truth/\">Guardians of the Truth<\/a><\/li><li><a href=\"http://lesswrong.com/lw/m1/guardians_of_ayn_rand/\">Guardians of Ayn Rand<\/a><\/li><li><a href=\"http://lesswrong.com/lw/lr/evaporative_cooling_of_group_beliefs/\">Evaporative Cooling of Group Beliefs<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/affect-heuristic\">Affect heuristic<\/a>, <a href=\"https://www.lesswrong.com/tag/halo-effect\">Halo effect<\/a>, <a href=\"https://www.lesswrong.com/tag/motivated-skepticism\">Motivated skepticism<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/information-cascades\">Information cascade<\/a>, <a href=\"https://www.lesswrong.com/tag/groupthink\">Groupthink<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/in-group-bias\">In-group bias<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/religion\">Religion<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/death-spirals-and-the-cult-attractor\">Death Spirals and the Cult Attractor<\/a><\/li><\/ul>"},"Tag:5f5c37ee1b5cdee568cfb0cb":{"_id":"5f5c37ee1b5cdee568cfb0cb","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb0cb_description"},"canVoteOnRels":null,"userId":"RyiDJDCG6R7xyAXzp","name":"Affective Death Spiral","shortName":null,"slug":"affective-death-spiral","core":false,"postCount":12,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:51.767Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:Tg9aFPFCPBHxGABRr_description":{"_id":"Tg9aFPFCPBHxGABRr_description","__typename":"Revision","htmlHighlight":"<p>Life-hacks, eliminating trivial inconveniences, process improvements, purchases that save you a minute a day, etc<\/p><p>Found most often on posts under Practical<\/p>"},"Tag:Tg9aFPFCPBHxGABRr":{"_id":"Tg9aFPFCPBHxGABRr","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Tg9aFPFCPBHxGABRr_description"},"canVoteOnRels":null,"userId":"SsduPgHwY2zeZpmKT","name":"Life Improvements","shortName":null,"slug":"life-improvements","core":false,"postCount":84,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-31T08:03:23.331Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:FGfgzGpPTtKEqSrDm_description":{"_id":"FGfgzGpPTtKEqSrDm_description","__typename":"Revision","htmlHighlight":"<p><strong>More Dakka <\/strong>is the technique of throwing more resources at a problem to see if you get better results.&nbsp;<\/p><p>Originally, More Dakka is the <a href=\"https://tvtropes.org/pmwiki/pmwiki.php/Main/MoreDakka\">trope<\/a> of solving problems by unloading as many rounds of ammunition at them as possible. In the rationalist community it was popularized by <a href=\"https://www.lesswrong.com/posts/z8usYeKX7dtTWsEnk/more-dakka\">Zvi <\/a>to have the above meaning.<\/p>"},"Tag:FGfgzGpPTtKEqSrDm":{"_id":"FGfgzGpPTtKEqSrDm","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:FGfgzGpPTtKEqSrDm_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"More Dakka","shortName":null,"slug":"more-dakka","core":false,"postCount":25,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-01T06:55:40.609Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:Ng8Gice9KNkncxqcj_description":{"_id":"Ng8Gice9KNkncxqcj_description","__typename":"Revision","htmlHighlight":"<p><strong>Rationality<\/strong> is the art of thinking in ways that result in <a href=\"https://www.lesswrong.com/tag/world-modeling\">accurate beliefs<\/a> and <a href=\"https://www.lesswrong.com/tag/decision-theory\">good decisions<\/a>. It is the primary topic of LessWrong.<br><br>Rationality is not only about avoiding the vices of <a href=\"https://www.lesswrong.com/tag/self-deception\">self-deception<\/a> and obfuscation (the failure to <a href=\"https://www.lesswrong.com/tag/conversation-topic\">communicate clearly<\/a>), but also about the virtue of <a href=\"https://www.lesswrong.com/tag/curiosity\">curiosity<\/a>, seeing the world more clearly than before, and <a href=\"https://www.lesswrong.com/tag/ambition\">achieving things<\/a> <a href=\"https://www.lesswrong.com/tag/skill-building\">previously unreachable<\/a> <a href=\"https://www.lesswrong.com/tag/coordination-cooperation\">to you<\/a>. The study of rationality on LessWrong includes a theoretical understanding of ideal cognitive algorithms, as well as building a practice that uses these idealized algorithms to inform <a href=\"https://www.lesswrong.com/tag/heuristics-and-biases\">heuristics<\/a>, <a href=\"https://www.lesswrong.com/tag/habits\">habits<\/a>, and <a href=\"https://www.lesswrong.com/tag/techniques\">techniques<\/a>, to successfully reason and make decisions in the real world.<\/p><p>Topics covered in rationality include (but are not limited to): normative and theoretical explorations of <a href=\"https://www.lesswrong.com/tag/solomonoff-induction\">ideal<\/a> <a href=\"https://www.lesswrong.com/tag/probability-and-statistics\">reasoning<\/a>; the <a href=\"https://www.lesswrong.com/tag/evolutionary-psychology\">capabilities and limitations<\/a> <a href=\"https://www.lesswrong.com/tag/neuroscience\">of our brain<\/a>, <a href=\"https://www.lesswrong.com/tag/dual-process-theory-system-1-and-system-2\">mind and psychology<\/a>; applied advice such as <a href=\"https://www.lesswrong.com/tag/introspection\">introspection<\/a> techniques and <a href=\"https://www.lesswrong.com/tag/group-rationality\">how to achieve truth collaboratively<\/a>; practical techniques and methodologies for figuring out what’s true ranging from rough quantitative modeling to full research guides.<\/p><p>Note that content about <i>how the world is <\/i>can be found under <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a>, and practical advice about <i>how to change the world<\/i> is categorized under <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a> or <a href=\"/tag/practical\">Practical<\/a>.<\/p><hr><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\"><p><strong>Theory / Concepts<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/anticipated-experiences?showPostCount=true&amp;useTagName=true\"><u>Anticipated Experiences<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/aumann-s-agreement-theorem?showPostCount=true&amp;useTagName=true\">Aumann's Agreement Theorem<\/a><br><a href=\"http://www.lesswrong.com/tag/bayes-theorem?showPostCount=true&amp;useTagName=true\"><u>Bayes Theorem<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/bounded-rationality?showPostCount=true&amp;useTagName=true\">Bounded Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/conservation-of-expected-evidence?showPostCount=true&amp;useTagName=true\">Conservation of Expected<\/a><br><a href=\"http://www.lesswrong.com/tag/contrarianism?showPostCount=true&amp;useTagName=true\">Contrarianism<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemology?showPostCount=true&amp;useTagName=true\"><u>Epistemology<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\"><u>Gears-Level<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/hansonian-pre-rationality?useTagName=true&amp;showPostCount=true\">Hansonian Pre-Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/law-thinking?showPostCount=true&amp;useTagName=true\">Law-Thinking<\/a><br><a href=\"http://www.lesswrong.com/tag/map-and-territory?showPostCount=true&amp;useTagName=true\">Map and Territory<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"http://www.lesswrong.com/tag/occam-s-razor?showPostCount=true&amp;useTagName=true\">Occam's razor<\/a><br><a href=\"https://www.lesswrong.com/tag/robust-agents?showPostCount=true&amp;useTagName=true\">Robust Agents<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/truth-semantics-and-meaning?showPostCount=true&amp;useTagName=true\">Truth, Semantics, &amp; Meaning<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/alief?showPostCount=true&amp;useTagName=true\"><u>Alief<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/betting?showPostCount=true&amp;useTagName=true\">Betting<\/a><br><a href=\"http://www.lesswrong.com/tag/cached-thoughts?showPostCount=true&amp;useTagName=true\">Cached Thoughts<\/a><br><a href=\"http://www.lesswrong.com/tag/calibration?showPostCount=true&amp;useTagName=true\">Calibration<\/a><br><a href=\"https://www.lesswrong.com/tag/dark-arts?showPostCount=true&amp;useTagName=true\">Dark Arts<\/a><br><a href=\"http://www.lesswrong.com/tag/empiricism?showPostCount=true&amp;useTagName=true\">Empiricism<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemic-modesty?showPostCount=true&amp;useTagName=true\">Epistemic Modesty<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/identity?showPostCount=true&amp;useTagName=true\">Identity<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/introspection?showPostCount=true&amp;useTagName=true\"><u>Introspection<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/intuition?showPostCount=true&amp;useTagName=true\">Intuition<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\"><u>Practice &amp; Philosophy of Science<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><br><a href=\"http://www.lesswrong.com/tag/taking-ideas-seriously?showPostCount=true&amp;useTagName=true\">Taking Ideas Seriously<\/a><br><a href=\"https://www.lesswrong.com/tag/value-of-information?showPostCount=true&amp;useTagName=true\">Value of Information<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Failure Modes<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/affect-heuristic?showPostCount=true&amp;useTagName=true\">Affect Heuristic<\/a><br><a href=\"https://www.lesswrong.com/tag/bucket-errors?showPostCount=true&amp;useTagName=true\">Bucket Errors<\/a><br><a href=\"https://www.lesswrong.com/tag/compartmentalization?showPostCount=true&amp;useTagName=true\">Compartmentalization<\/a><br><a href=\"https://www.lesswrong.com/tag/confirmation-bias?showPostCount=true&amp;useTagName=true\"><u>Confirmation Bias<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/logical-fallacies?showPostCount=true&amp;useTagName=true\">Fallacies<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodhart’s Law<\/a><br><a href=\"http://www.lesswrong.com/tag/groupthink?showPostCount=true&amp;useTagName=true\"><u>Groupthink<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/heuristics-and-biases?showPostCount=true&amp;useTagName=true\">Heuristics and Biases<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-projection-fallacy?showPostCount=true&amp;useTagName=true\">Mind Projection Fallacy<\/a><br><a href=\"https://www.lesswrong.com/tag/motivated-reasoning?showPostCount=true&amp;useTagName=true\"><u>Motivated Reasoning<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true&amp;useTagName=true\">Pica<\/a><br><a href=\"https://www.lesswrong.com/tag/pitfalls-of-rationality?showPostCount=true&amp;useTagName=true\">Pitfalls of Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/rationalization?showPostCount=true&amp;useTagName=true\">Rationalization<\/a>&nbsp;<br><a href=\"https://www.lesswrong.com/tag/self-deception?showPostCount=true&amp;useTagName=true\">Self-Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/sunk-cost-fallacy?showPostCount=true&amp;useTagName=true\">Sunk-Cost Fallacy<\/a><\/p><\/td><\/tr><tr><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top\" rowspan=\"2\"><p><strong>Communication<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true\"><u>Conversation<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/decoupling-vs-contextualizing?showPostCount=true&amp;useTagName=true\"><u>Decoupling vs Contextualizing<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/disagreement?showPostCount=true&amp;useTagName=true\"><u>Disagreement<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"http://www.lesswrong.com/tag/double-crux?showPostCount=true&amp;useTagName=true\"><u>Double-Crux<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/good-explanations-advice?showPostCount=true&amp;useTagName=true\">Good Explanations (Advice)<\/a><br><a href=\"http://www.lesswrong.com/tag/ideological-turing-tests?showPostCount=true&amp;useTagName=true\">Ideological Turing Tests<\/a><br><a href=\"https://www.lesswrong.com/tag/inferential-distance?showPostCount=true&amp;useTagName=true\">Inferential Distance<\/a><br><a href=\"https://www.lesswrong.com/tag/information-cascades?showPostCount=true&amp;useTagName=true\">Information Cascades<\/a><br><a href=\"https://www.lesswrong.com/tag/memetic-immune-system?showPostCount=true&amp;useTagName=true\">Memetic Immune System<\/a><br><a href=\"https://www.lesswrong.com/tag/philosophy-of-language?showPostCount=true&amp;useTagName=true\"><u>Philos<\/u><\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>... "},"Tag:Ng8Gice9KNkncxqcj":{"_id":"Ng8Gice9KNkncxqcj","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Ng8Gice9KNkncxqcj_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Rationality","shortName":null,"slug":"rationality","core":true,"postCount":3828,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":100,"createdAt":"2020-06-14T22:24:17.072Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:fkABsGCJZ6y9qConW_description":{"_id":"fkABsGCJZ6y9qConW_description","__typename":"Revision","htmlHighlight":"<p><strong>Practical<\/strong> posts give direct, actionable advice on how to achieve goals and generally succeed. The art of rationality would be useless if it did not connect to the real world; we must take our ideas and abstractions and collide them with reality. Many places on the internet will give you advice; here, we value survey data, literature reviews, self-blinded trials, quantitative estimates, and theoretical models that aim to explain the phenomena.<\/p><p>Material that is directly about <i>how to think better<\/i> can be found at <a href=\"https://www.lessestwrong.com/tag/rationality\">Rationality<\/a>.<\/p><p>&nbsp;<\/p><h1><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Practical Sub-Topics<\/strong><\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:2px solid hsl(0, 0%, 90%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33%\" rowspan=\"2\"><p><strong>Domains of Well-being<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/careers?showPostCount=true&amp;useTagName=true\">Careers<\/a><br><a href=\"https://www.lesswrong.com/tag/emotions?showPostCount=true&amp;useTagName=true\">Emotions<\/a><br><a href=\"http://www.lesswrong.com/tag/exercise-physical?showPostCount=true&amp;useTagName=true\">Exercise (Physical)<\/a><br><a href=\"https://www.lesswrong.com/tag/financial-investing?showPostCount=true&amp;useTagName=true\">Financial Investing<\/a><br><a href=\"http://www.lesswrong.com/tag/gratitude?showPostCount=true&amp;useTagName=true\">Gratitude<\/a><br><a href=\"http://www.lesswrong.com/tag/happiness-1?showPostCount=true&amp;useTagName=true\">Happiness<\/a><br><a href=\"http://www.lesswrong.com/tag/human-bodies?showPostCount=true&amp;useTagName=true\">Human Bodies<\/a><br><a href=\"http://www.lesswrong.com/tag/nutrition?showPostCount=true&amp;useTagName=true\">Nutrition<\/a><br><a href=\"https://www.lesswrong.com/tag/parenting?showPostCount=true&amp;useTagName=true\">Parenting<\/a><br><a href=\"https://www.lesswrong.com/tag/slack?showPostCount=true&amp;useTagName=true\">Slack<\/a><br><a href=\"https://www.lesswrong.com/tag/sleep?showPostCount=true&amp;useTagName=true\">Sleep<\/a><br><a href=\"https://www.lesswrong.com/tag/well-being?showPostCount=true&amp;useTagName=true\">Well-being<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\" rowspan=\"2\"><p><strong>Skills, Tools, Techniques<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/cryonics?showPostCount=true&amp;useTagName=true\">Cryonics<\/a><br><a href=\"https://www.lesswrong.com/tag/emotions?showPostCount=true&amp;useTagName=true\">Emotions<\/a><br><a href=\"https://www.lesswrong.com/tag/goal-factoring?showPostCount=true&amp;useTagName=true\">Goal Factoring<\/a><br><a href=\"http://www.lesswrong.com/tag/habits?showPostCount=true&amp;useTagName=true\">Habits<\/a><br><a href=\"https://www.lesswrong.com/tag/hamming-questions?showPostCount=true&amp;useTagName=true\">Hamming Questions<\/a><br><a href=\"http://www.lesswrong.com/tag/life-improvements?showPostCount=true&amp;useTagName=true\">Life Improvements<\/a><br><a href=\"https://www.lesswrong.com/tag/meditation?showPostCount=true&amp;useTagName=true\">Meditation<\/a><br><a href=\"http://www.lesswrong.com/tag/more-dakka?showPostCount=true&amp;useTagName=true\">More Dakka<\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true\"><u>Pica<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/planning-and-decision-making?showPostCount=true&amp;useTagName=true\">Planning &amp; Decision-Making<\/a><br><a href=\"https://www.lesswrong.com/tag/self-experimentation?showPostCount=true&amp;useTagName=true\">Self Experimentation<\/a><br><a href=\"http://www.lesswrong.com/tag/skill-building?showPostCount=true&amp;useTagName=true\">Skill Building<\/a><br><a href=\"https://www.lesswrong.com/tag/software-tools?showPostCount=true&amp;useTagName=true\">Software Tools<\/a><br><a href=\"https://www.lesswrong.com/tag/spaced-repetition?showPostCount=true&amp;useTagName=true\">Spaced Repetition<\/a><br><a href=\"https://www.lesswrong.com/tag/virtues-instrumental?showPostCount=true&amp;useTagName=false\">Virtues (Instrumental)<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33%\"><p><strong>Productivity<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/akrasia?showPostCount=true&amp;useTagName=true\">Akrasia<\/a><br><a href=\"https://www.lesswrong.com/tag/motivations?showPostCount=true&amp;useTagName=true\">Motivations<\/a><br><a href=\"https://www.lesswrong.com/tag/prioritization?showPostCount=true&amp;useTagName=true\">Prioritization<\/a><br><a href=\"https://www.lesswrong.com/tag/procrastination?showPostCount=true&amp;useTagName=true\">Procrastination<\/a><br><a href=\"https://www.lesswrong.com/tag/productivity?showPostCount=true&amp;useTagName=true\">Productivity<\/a><br><a href=\"https://www.lesswrong.com/tag/willpower?showPostCount=true&amp;useTagName=true\">Willpower<\/a><\/p><\/td><\/tr><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><strong>Interpersonal<\/strong><br><a href=\"http://www.lesswrong.com/tag/circling?showPostCount=true&amp;useTagName=true\"><u>Circling<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true&amp;useTagName=true\">Conversation (topic)<\/a><br><a href=\"https://www.lesswrong.com/tag/communication-cultures?showPostCount=true&amp;useTagName=true\">Communication Cultures<\/a><br><a href=\"http://www.lesswrong.com/tag/relationships-interpersonal?showPostCount=true&amp;useTagName=false\"><u>Relationship<\/u><\/a><\/td><\/tr><\/tbody><\/table><\/figure>"},"Tag:fkABsGCJZ6y9qConW":{"_id":"fkABsGCJZ6y9qConW","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:fkABsGCJZ6y9qConW_description"},"canVoteOnRels":null,"userId":"oBSWiHjgproTiThmY","name":"Practical","shortName":null,"slug":"practical","core":true,"postCount":2979,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T06:06:46.947Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:gFMH3Cqw4XxwL69iy":{"_id":"gFMH3Cqw4XxwL69iy","__typename":"SocialPreviewType","imageUrl":""},"User:XgYW5s8njaYrtyP7q":{"_id":"XgYW5s8njaYrtyP7q","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"scottalexander","createdAt":"2009-02-28T15:53:46.032Z","username":"Yvain","displayName":"Scott Alexander","previousDisplayName":null,"fullName":null,"karma":42640,"afKarma":73,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":217,"commentCount":1577,"sequenceCount":15,"afPostCount":1,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":19,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Post:gFMH3Cqw4XxwL69iy":{"_id":"gFMH3Cqw4XxwL69iy","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:MWjJejhD8punq5v2t"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":12,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:b8FHrKqyXuYGWc6vn"},{"__ref":"Tag:ZFrgTgzwEfStg26JL"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb0cb"},{"__ref":"Tag:Tg9aFPFCPBHxGABRr"},{"__ref":"Tag:FGfgzGpPTtKEqSrDm"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:fkABsGCJZ6y9qConW"}],"socialPreviewData":{"__ref":"SocialPreviewType:gFMH3Cqw4XxwL69iy"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2010-04-20T23:01:15.252Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"FGfgzGpPTtKEqSrDm":1,"Ng8Gice9KNkncxqcj":7,"Tg9aFPFCPBHxGABRr":1,"ZFrgTgzwEfStg26JL":2,"b8FHrKqyXuYGWc6vn":17,"fkABsGCJZ6y9qConW":3,"5f5c37ee1b5cdee568cfb0cb":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"MWjJejhD8punq5v2t","commentCount":253,"voteCount":770,"baseScore":826,"extendedScore":{"reacts":{"hitsTheMark":[{"karma":54,"quotes":["But by accepting your excuse, I establish a precedent of accepting excuses that are approximately this good. And there are many other excuses approximately as good as yours."],"userId":"W68HdqGswDy9uuc7q","reactType":"created","displayName":"Richard Henage"}]},"agreement":0,"approvalVoteCount":762,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0011312130372971296,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-09-28T18:33:35.476Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":45,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":63,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2010-04-20T23:01:15.252Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"eight-short-studies-on-excuses","title":"Eight Short Studies On Excuses","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6391d9bcb4ac6367c1158d":{"_id":"5c6391d9bcb4ac6367c1158d","__typename":"Revision","htmlHighlight":"<p>Slippery slopes are themselves a slippery concept. Imagine trying to explain them to an alien: <br /><br />\"Well, we right-thinking people are quite sure that the Holocaust happened, so banning Holocaust denial would shut up some crackpots and improve the discourse. But it's one step on the road to things like banning unpopular political positions or religions, and we right-thinking people oppose that, so we won't ban Holocaust denial.\"<br /><br />And the alien might well respond: \"But you could just ban Holocaust denial, but not ban unpopular political positions or religions. Then you right-thinking people get the thing you want, but not the thing you don't want.\"<br /><br />This post is about some of the replies you might give the alien.<br /><br /><strong>Abandoning the Power of Choice<\/strong><br /><br />This is the boring one without any philosophical insight that gets mentioned only for completeness' sake. In this reply, giving up a certain point risks losing the ability to decide whether or not to give up other points.<br /><br />For example, if people gave up the right to privacy and allowed the government to monitor all phone calls, online communications, and public places, then if someone launched a military coup, it would be very difficult to resist them because there would be no way to secretly organize a rebellion. This is also brought up in arguments about gun control a lot.<br /><br />I'm not sure this is properly thought of as a slippery slope argument at all. It seems to be a more straightforward \"Don't give up useful tools for fighting tyranny\" argument.<br /><br /><strong>The Legend of Murder-Gandhi<\/strong><br /><br /><a href=\"http://yudkowsky.net/singularity\">Previously<\/a> <a href=\"/lw/2vj/gandhi_murder_pills_and_mental_illness/\">on Less Wrong's<\/a> <em>The Adventures of Murder-Gandhi<\/em>: Gandhi is offered a pill that will turn him into an unstoppable murderer. He refuses to take it, because in his current incarnation as a pacifist, he doesn't want others to die, and he knows that would be a consequence of taking the pill. Even if we offered him $1 million to take the pill, his abhorrence of violence would lead him to refuse.<br /><br />But suppose we offered Gandhi $1 million to take a different pill: one which would decrease his reluctance to murder by 1%. This sounds like a pretty good deal. Even a person with 1% less reluctance to murder than Gandhi is still pretty pacifist and not likely to go killing anybody. And he could donate the money to his favorite charity and perhaps save some lives. Gandhi accepts the offer.<br /><br />Now we iterate the process: every time Gandhi takes the 1%-more-likely-to-murder-... <\/p>","plaintextDescription":"Slippery slopes are themselves a slippery concept. Imagine trying to explain them to an alien:\n\n\"Well, we right-thinking people are quite sure that the Holocaust happened, so banning Holocaust denial would shut up some crackpots and improve the discourse. But it's one step on the road to things like banning unpopular political positions or religions, and we right-thinking people oppose that, so we won't ban Holocaust denial.\"\n\nAnd the alien might well respond: \"But you could just ban Holocaust denial, but not ban unpopular political positions or religions. Then you right-thinking people get the thing you want, but not the thing you don't want.\"\n\nThis post is about some of the replies you might give the alien.\n\nAbandoning the Power of Choice\n\nThis is the boring one without any philosophical insight that gets mentioned only for completeness' sake. In this reply, giving up a certain point risks losing the ability to decide whether or not to give up other points.\n\nFor example, if people gave up the right to privacy and allowed the government to monitor all phone calls, online communications, and public places, then if someone launched a military coup, it would be very difficult to resist them because there would be no way to secretly organize a rebellion. This is also brought up in arguments about gun control a lot.\n\nI'm not sure this is properly thought of as a slippery slope argument at all. It seems to be a more straightforward \"Don't give up useful tools for fighting tyranny\" argument.\n\nThe Legend of Murder-Gandhi\n\nPreviously on Less Wrong's The Adventures of Murder-Gandhi: Gandhi is offered a pill that will turn him into an unstoppable murderer. He refuses to take it, because in his current incarnation as a pacifist, he doesn't want others to die, and he knows that would be a consequence of taking the pill. Even if we offered him $1 million to take the pill, his abhorrence of violence would lead him to refuse.\n\nBut suppose we offered Gandhi $1 million to take a dif","wordCount":1855,"version":"1.0.0"},"Tag:qQMEMrXioExa4uhTB":{"_id":"qQMEMrXioExa4uhTB","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"uCfjEXpnchoqDWNoL","name":"Value Drift","shortName":null,"slug":"value-drift","core":false,"postCount":16,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-20T13:16:35.138Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:Kbm6QnJv9dgWsPHQP":{"_id":"Kbm6QnJv9dgWsPHQP","__typename":"SocialPreviewType","imageUrl":""},"Post:Kbm6QnJv9dgWsPHQP":{"_id":"Kbm6QnJv9dgWsPHQP","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6391d9bcb4ac6367c1158d"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:qQMEMrXioExa4uhTB"},{"__ref":"Tag:b8FHrKqyXuYGWc6vn"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:Kbm6QnJv9dgWsPHQP"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2012-03-16T23:44:05.322Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":2,"b8FHrKqyXuYGWc6vn":4,"qQMEMrXioExa4uhTB":11},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6391d9bcb4ac6367c1158d","commentCount":250,"voteCount":475,"baseScore":588,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":473,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0009521226747892797,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-02-02T02:18:55.546Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"highlights","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":30,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":64,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2012-03-16T23:44:05.322Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"schelling-fences-on-slippery-slopes","title":"Schelling fences on slippery slopes","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6391bcbcb4ac6367c10abe":{"_id":"5c6391bcbcb4ac6367c10abe","__typename":"Revision","htmlHighlight":"<p><strong>Related to: <\/strong><a href=\"/lw/154/why_real_men_wear_pink/\">Why Real Men Wear Pink<\/a>, <a href=\"/lw/1kr/that_other_kind_of_status/\">That Other Kind of Status<\/a>, <a href=\"http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBIQFjAA&amp;url=http%3A%2F%2Flesswrong.com%2Flw%2Fyp%2Fpretending_to_be_wise%2F&amp;rct=j&amp;q=Pretending%20to%20be%20wise&amp;ei=Q5KOTPuoEdO4jAeauvnWBg&amp;usg=AFQjCNGKvS__hFQHs2g5ra4dhSOaPE0DtQ&amp;sig2=gstUbI-cNPhT7CfA5Zo8og&amp;cad=rja\">Pretending to be Wise<\/a>, <a href=\"/lw/k6/the_outside_the_box_box/\">The \"Outside The Box\" Box<\/a><\/p>\n<blockquote>\n<p><em>WARNING: Beware of things that are fun to argue -- Eliezer Yudkowsky<\/em><\/p>\n<\/blockquote>\n<p>Science has inexplicably failed to come up with a precise definition of \"hipster\", but from my limited understanding a hipster is a person who deliberately uses unpopular, obsolete, or obscure styles and preferences in an attempt to be \"cooler\" than the mainstream. But why would being deliberately uncool be cooler than being cool?<br /><br />As <a href=\"/lw/154/why_real_men_wear_pink/\">previously discussed<\/a>, in certain situations refusing to signal can be a sign of high status. Thorstein Veblen invented the term \"conspicuous consumption\" to refer to the showy spending habits of the nouveau riche, who unlike the established money of his day took great pains to signal their wealth by buying fast cars, expensive clothes, and shiny jewelery. Why was such flashiness common among new money but not old? Because the old money was so secure in their position that it never even occurred to them that they might be confused with poor people, whereas new money, with their lack of aristocratic breeding, worried they might be mistaken for poor people if they didn't make it blatantly obvious that they had expensive things.<br /><br />The old money might have started off not buying flashy things for pragmatic reasons - they didn't need to, so why waste the money? But if F. Scott Fitzgerald is to be believed, the old money actively cultivated an air of superiority to the nouveau riche and their conspicuous consumption; not buying flashy objects becomes a matter of principle. This makes sense: the nouveau riche need to differentiate themselves from the poor, but the old money need to differentiate themselves from the nouveau riche.<br /><br />This process is called <a href=\"http://en.wikipedia.org/wiki/Countersignaling\">countersignaling<\/a>, and one can find its telltale patterns in many walks of life. Those who study human romantic attraction warn men not to \"come on too strong\", and this has similarities to the nouveau riche example. A total loser might come up to a woman without a hint of romance, promise her nothing, and demand sex. A more sophisticated man might buy roses for a woman, write her love poetry, hover on her every wish, et cetera; this signifies that he is not a total loser. But the most desirable men may deliberately avoid doing nice things for women in an attempt to signal they are so high status that they don't ne... <\/p>","plaintextDescription":"Related to: Why Real Men Wear Pink, That Other Kind of Status, Pretending to be Wise, The \"Outside The Box\" Box\n\n> WARNING: Beware of things that are fun to argue -- Eliezer Yudkowsky\n\nScience has inexplicably failed to come up with a precise definition of \"hipster\", but from my limited understanding a hipster is a person who deliberately uses unpopular, obsolete, or obscure styles and preferences in an attempt to be \"cooler\" than the mainstream. But why would being deliberately uncool be cooler than being cool?\n\nAs previously discussed, in certain situations refusing to signal can be a sign of high status. Thorstein Veblen invented the term \"conspicuous consumption\" to refer to the showy spending habits of the nouveau riche, who unlike the established money of his day took great pains to signal their wealth by buying fast cars, expensive clothes, and shiny jewelery. Why was such flashiness common among new money but not old? Because the old money was so secure in their position that it never even occurred to them that they might be confused with poor people, whereas new money, with their lack of aristocratic breeding, worried they might be mistaken for poor people if they didn't make it blatantly obvious that they had expensive things.\n\nThe old money might have started off not buying flashy things for pragmatic reasons - they didn't need to, so why waste the money? But if F. Scott Fitzgerald is to be believed, the old money actively cultivated an air of superiority to the nouveau riche and their conspicuous consumption; not buying flashy objects becomes a matter of principle. This makes sense: the nouveau riche need to differentiate themselves from the poor, but the old money need to differentiate themselves from the nouveau riche.\n\nThis process is called countersignaling, and one can find its telltale patterns in many walks of life. Those who study human romantic attraction warn men not to \"come on too strong\", and this has similarities to the nouveau riche exampl","wordCount":2282,"version":"1.0.0"},"Revision:2EFq8dJbxKNzforjM_description":{"_id":"2EFq8dJbxKNzforjM_description","__typename":"Revision","htmlHighlight":"<p><strong>Social Status <\/strong>is an abstraction to model how people relate to each other, how social hierarchies are formed, and how people facilitate trade in the absence of financial accounting (as well as a variety of other stuff). I mean, everyone knows what status is, but here is where we break that down into its components and really try to understand what's happening on a mechanistic level.<\/p><h2>See Also<\/h2><ul><li><a href=\"https://lessestwrong.com/tag/signaling\">Signaling<\/a><\/li><\/ul><h2>Notable Posts<\/h2><ul><li><a href=\"https://lessestwrong.com/lw/13s/the_nature_of_offense/\">The Nature of Offense<\/a> by <a href=\"http://weidai.com/\">Wei Dai<\/a> - People are <a href=\"https://lessestwrong.com/tag/offense\">offended<\/a> by grabs for status.<\/li><li><a href=\"https://lessestwrong.com/lw/154/why_real_men_wear_pink/\">Why Real Men Wear Pink<\/a> by <a href=\"https://wiki.lesswrong.com/wiki/Yvain\">Yvain<\/a><\/li><li><a href=\"http://www.overcomingbias.com/2009/08/actors-see-status.html\">Actors See Status<\/a> by <a href=\"https://lessestwrong.com/tag/robin-hanson\">Robin Hanson<\/a>, quoting <a href=\"https://en.wikipedia.org/wiki/Keith_Johnstone\">Keith Johnstone<\/a><\/li><li><a href=\"https://lessestwrong.com/lw/1kr/that_other_kind_of_status/\">That Other Kind of Status<\/a> by Yvain<\/li><\/ul><h2>External<\/h2><ul><li>Melting Asphault (by Kevin Simler) has many great posts on status<\/li><li>Elephant in the Brain by Simler and Hanson<\/li><li>Impro (book on improv covering status relations)<\/li><li>Writings by Venkatesh Rao such as Gervais Principle and something, something Psychopath<\/li><\/ul>"},"Tag:2EFq8dJbxKNzforjM":{"_id":"2EFq8dJbxKNzforjM","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:2EFq8dJbxKNzforjM_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Social Status","shortName":null,"slug":"social-status","core":false,"postCount":112,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T12:36:16.632Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:6Qic6PwwBycopJFNN_description":{"_id":"6Qic6PwwBycopJFNN_description","__typename":"Revision","htmlHighlight":"<p>A <strong>contrarian<\/strong> is a person who holds a contrary position, especially a position against the <a href=\"https://www.lesswrong.com/tag/consensus\">majority<\/a> <a href=\"https://en.wikipedia.org/wiki/Contrarian\">(from Wikipedia).<\/a><\/p>"},"Tag:6Qic6PwwBycopJFNN":{"_id":"6Qic6PwwBycopJFNN","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:6Qic6PwwBycopJFNN_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Contrarianism","shortName":null,"slug":"contrarianism","core":false,"postCount":32,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-31T17:49:08.150Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:Q6P8jLn8hH7kbuXRr_description":{"_id":"Q6P8jLn8hH7kbuXRr_description","__typename":"Revision","htmlHighlight":"<p><strong>Signaling<\/strong> is <a href=\"https://lesswrong.com/lw/did/what_is_signaling_really/\">defined<\/a> by <a href=\"https://wiki.lesswrong.com/wiki/Yvain\">Yvain<\/a> as \"a method of conveying information among not-necessarily-trustworthy parties by performing an action which is more likely or less costly if the information is true than if it is not true\". Some signaling is performed exclusively to impress others (to improve your <a href=\"https://lesswrong.com/tag/social-status\">status<\/a>), and in some cases <a href=\"http://www.overcomingbias.com/2007/01/excess_signalin.html\">isn't even worth that<\/a>. In other cases, signaling is a side-effect of an otherwise useful activity.<\/p><p>For example, if doing something is easy for one type of person and hard for another type of person, you might do that thing just to get people to think you're the former type of person, even if the thing isn't in itself worth doing. This could explain many facets of human behavior, and reveal opportunities for reducing waste.<\/p><p>Not all signaling is about abilities. Signaling can also be about personality, current emotional state, beliefs, loyalty to a particular group, status within a group, etc.<\/p><p><strong>Countersignaling<\/strong> is signaling that a naive observer might take to mean that one is the <em>opposite<\/em> of X, when in fact, one is X, used as a means to signal that one is, in fact, X. For example, aristocrats (\"old money\") may forgo gaudy bling in order to signal that they are not <em>nouveau riche<\/em> (new money), which may lead some people to incorrectly assume that they are not rich.<\/p>\n<h2>Blog posts<\/h2>\n<p>by <a href=\"https://lesswrong.com/tag/robin-hanson\">Robin Hanson<\/a><\/p>\n<ul>\n<li><a href=\"http://www.overcomingbias.com/2006/12/do_helping_prof.html\">Do Helping Professions Help More?<\/a> and <a href=\"http://www.overcomingbias.com/2006/12/gifts_hurt.html\">Gifts Hurt<\/a><\/li>\n<li><a href=\"http://www.overcomingbias.com/2007/01/excess_signalin.html\">Excess Signaling Example<\/a><\/li>\n<li><a href=\"http://www.overcomingbias.com/2009/01/a-tale-of-two-tradeoffs.html\">A Tale Of Two Tradeoffs<\/a><\/li>\n<li><a href=\"http://www.overcomingbias.com/2009/06/why-signals-are-shallow.html\">Why Signals Are Shallow<\/a> - \"We all want to affiliate with high status people, but since status is about common distant perceptions of quality, we often care more about what distant observers would think about our associates than about how we privately evaluate them.\"<\/li>\n<li><a href=\"http://www.overcomingbias.com/2009/06/signals-are-forever.html\">Signals Are Forever<\/a><\/li>\n<li><a href=\"https://lesswrong.com/lw/g7/least_signaling_activities/\">Least Signaling Activities?<\/a><\/li>\n<\/ul>\n<p>by others<\/p>\n<ul>\n<li><a href=\"https://lesswrong.com/lw/did/what_is_signaling_really/\">What Is Signaling, Really?<\/a> by <a href=\"https://wiki.lesswrong.com/wiki/Yvain\">Yvain<\/a><\/li>\n<li><a href=\"https://lesswrong.com/lw/1y3/think_before_you_speak_and_signal_it/\">Think Before You Speak (And Signal It)<\/a> by <a href=\"http://weidai.com/\">Wei Dai<\/a><\/li>\n<li><a href=\"https://lesswrong.com/lw/b2/declare_your_signaling_and_hidden_agendas/\">Declare Your Signaling and Hidden Agendas<\/a> by <a href=\"https://wiki.lesswrong.com/wiki/Kaj_Sotala\">Kaj Sotala<\/a><\/li>\n<li><a href=\"https://lesswrong.com/lw/8ev/modularity_signaling_and_belief_in_belief/\">Modularity, Signaling, and Belief in Belief<\/a> by Kaj Sotala<\/li>\n<\/ul>\n<h2>See also<\/h2>\n<ul>\n<li><a href=\"https://lesswrong.com/tag/social-status\">Status<\/a><\/li>\n<li><a href=\"https://lesswrong.com/tag/near-far-thinking\">Near/far thinking<\/a><\/li>\n<li><a href=\"https://wiki.lesswrong.com/wiki/Adaptation_executers\">Adaptation executers<\/a>, <a href=\"https://lesswrong.com/tag/superstimuli\">Superstimulus<\/a><\/li>\n<li><a href=\"https://lesswrong.com/tag/goodhart-s-law\">Goodhart's law<\/a><\/li>\n<\/ul>\n<h2>External links<\/h2>\n<ul>\n<li><a href=\"http://www.econtalk.org/archives/2008/05/hanson_on_signa.html\">Robin Hanson on Signaling (Econtalk Podcast)<\/a><\/li>\n<\/ul>"},"Tag:Q6P8jLn8hH7kbuXRr":{"_id":"Q6P8jLn8hH7kbuXRr","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Q6P8jLn8hH7kbuXRr_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Signaling","shortName":null,"slug":"signaling","core":false,"postCount":83,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-19T19:49:05.946Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Tag:gHCNhqxuJq2bZ2akb":{"_id":"gHCNhqxuJq2bZ2akb","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Social & Cultural Dynamics","shortName":null,"slug":"social-and-cultural-dynamics","core":false,"postCount":354,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-10T11:36:05.706Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Tag:yS7248NQSm5J6xLvn":{"_id":"yS7248NQSm5J6xLvn","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Intellectual Fashion","shortName":null,"slug":"intellectual-fashion","core":false,"postCount":3,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-18T22:06:01.978Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:3uE2pXvbcnS9nnZRE_description":{"_id":"3uE2pXvbcnS9nnZRE_description","__typename":"Revision","htmlHighlight":"<p><strong>World Modeling<\/strong> is getting curious about how the world works. It’s diving into wikipedia, it’s running a survey to get data from your friends, it’s dropping balls from different heights and measuring how long they take to fall. Empiricism, scholarship, googling, introspection, data-gathering, science. Applying your epistemology and curiosity, <i>finding out how the damn thing works,<\/i> and writing it down for the rest of us.<\/p><blockquote><p><i>The eleventh virtue is scholarship. Study many sciences and absorb their power as your own. Each field that you consume makes you larger. If you swallow enough sciences the gaps between them will diminish and your knowledge will become a unified whole. If you are gluttonous you will become vaster than mountains.<\/i><\/p><p>—<a href=\"https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/the-twelve-virtues-of-rationality\"><u>Twelve Virtues of Rationality<\/u><\/a><\/p><\/blockquote><hr><h1><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; World Modeling Sub-Topics<\/strong><\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Mathematical Sciences<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/abstraction?showPostCount=true&amp;useTagName=true\">Abstraction<\/a><br><a href=\"https://www.lesswrong.com/tag/anthropics?showPostCount=true&amp;useTagName=true\">Anthropics<\/a><br><a href=\"http://www.lesswrong.com/tag/category-theory?showPostCount=true&amp;useTagName=true\">Category Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/causality?showPostCount=true&amp;useTagName=true\">Causality<\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/information-theory?showPostCount=true&amp;useTagName=true\">Information Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/logic-and-mathematics?showPostCount=true&amp;useTagName=true\">Logic &amp; Mathematics<\/a><br><a href=\"https://www.lesswrong.com/tag/probability-and-statistics?showPostCount=true&amp;useTagName=false\">Probability &amp; Statistics<\/a><\/p><p><i>Specifics<\/i><br><a href=\"http://www.lesswrong.com/tag/prisoner-s-dilemma?showPostCount=true&amp;useTagName=true\">Prisoner's Dilemma<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33.33%\"><p><strong>General Science &amp; Eng<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/machine-learning?showPostCount=true&amp;useTagName=true\">Machine Learning<\/a><br><a href=\"https://www.lesswrong.com/tag/nanotechnology?showPostCount=true&amp;useTagName=true\">Nanotechnology<\/a><br><a href=\"https://www.lesswrong.com/tag/physics?showPostCount=true&amp;useTagName=true\">Physics<\/a><br><a href=\"https://www.lesswrong.com/tag/programming?showPostCount=true&amp;useTagName=true\">Programming<\/a><br><a href=\"http://www.lesswrong.com/tag/space-exploration-and-colonization?showPostCount=true&amp;useTagName=true\">Space Exploration &amp; Colonization<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/great-filter?showPostCount=true&amp;useTagName=true\">The Great Filter<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Meta / Misc<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/academic-papers?showPostCount=true&amp;useTagName=true\">Academic Papers<\/a><br><a href=\"https://www.lesswrong.com/tag/book-reviews?showPostCount=true&amp;useTagName=true\">Book Reviews<\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"https://www.lesswrong.com/tag/fact-posts?showPostCount=true&amp;useTagName=true\">Fact Posts<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><\/p><\/td><\/tr><tr><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><p><strong>Social &amp; Economic<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/economics?showPostCount=true&amp;useTagName=true\">Economics<\/a><br><a href=\"https://www.lesswrong.com/tag/financial-investing?showPostCount=true&amp;useTagName=true\">Financial Investing<\/a><br><a href=\"https://www.lesswrong.com/tag/history?showPostCount=true&amp;useTagName=true\">History<\/a><br><a href=\"https://www.lesswrong.com/tag/politics?showPostCount=true&amp;useTagName=true\">Politics<\/a><br><a href=\"https://www.lesswrong.com/tag/progress-studies?showPostCount=true&amp;useTagName=true\">Progress Studies<\/a><br><a href=\"https://www.lesswrong.com/tag/social-and-cultural-dynamics?showPostCount=true&amp;useTagName=true\">Social and Cultural Dynamics<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/conflict-vs-mistake?showPostCount=true&amp;useTagName=true\">Conflict vs Mistake Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/cost-disease?showPostCount=true&amp;useTagName=true\">Cost Disease<\/a><br><a href=\"https://www.lesswrong.com/tag/efficient-market-hypothesis?showPostCount=true&amp;useTagName=true\">Efficient Market Hypothesis<\/a><br><a href=\"https://www.lesswrong.com/tag/industrial-revolution?showPostCount=true&amp;useTagName=true\">Industrial Revolution<\/a><br><a href=\"https://www.lesswrong.com/tag/moral-mazes?showPostCount=true&amp;useTagName=true\">Moral Mazes<\/a><br><a href=\"https://www.lesswrong.com/tag/signaling?showPostCount=true&amp;useTagName=true\">Signaling<\/a><br><a href=\"https://www.lesswrong.com/tag/social-reality?showPostCount=true&amp;useTagName=true\">Social Reality<\/a><br><a href=\"https://www.lesswrong.com/tag/social-status?showPostCount=true&amp;useTagName=true\">Social Status<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:25px;padding:0px;vertical-align:top\"><p><strong>Biological &amp; Psychological<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aging?showPostCount=true&amp;useTagName=true\">Aging<\/a><br><a href=\"https://www.lesswrong.com/tag/biology?showPostCount=true&amp;useTagName=true\">Biology<\/a><br><a href=\"https://www.lesswrong.com/tag/consciousness?showPostCount=true&amp;useTagName=true\">Consciousness<\/a><br><a href=\"https://www.lesswrong.com/tag/evolution?showPostCount=true&amp;useTagName=true\">Evolution<\/a><br><a href=\"http://www.lesswrong.com/tag/evolutionary-psychology?showPostCount=true&amp;useTagName=true\">Evolutionary Psychology<\/a><br><a href=\"https://www.lesswrong.com/tag/medicine?showPostCount=true&amp;useTagName=true\">Medicine<\/a><br><a href=\"https://www.lesswrong.com/tag/neuroscience?showPostCount=true&amp;useTagName=true\">Neuroscience<\/a><br><a href=\"https://www.lesswrong.com/tag/qualia?showPostCount=true&amp;useTagName=true\">Qualia<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/coronavirus?showPostCount=true&amp;useTagName=true\">Coronavirus<\/a><br><a href=\"https://www.lesswrong.com/tag/general-intelligence?showPostCount=true&amp;useTagName=true\">General Intelligence<\/a><br><a href=\"http://www.lesswrong.com/tag/iq-g-factor?showPostCount=true&amp;useTagName=true\"><u>IQ / g-factor<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/neocortex?showPostCount=true&amp;useTagName=true\">Neocortex<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><p><strong>The Practice of Modeling<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/epistemic-review?showPostCount=true&amp;useTagName=true\">Epistemic Review<\/a><br><a href=\"https://www.lesswrong.com/tag/expertise?showPostCount=true&amp;useTagName=true\">Expertise<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\">Gears-Level Models<\/a><br><a href=\"http://www.lesswrong.com/tag/falsifiability?showPostCount=true&amp;useTagName=true\">Falsifiability<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasts-lists-of?showPostCount=true&amp;useTagName=true\">Forecasts (Lists of)<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/jargon-meta?showPostCount=true&amp;useTagName=true\">Jargon (meta)<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\">Practice and Philosophy of Science<\/a><br><a href=\"https://www.lesswrong.com/tag/prediction-markets?showPostCount=true&amp;useTagName=true\">Prediction Markets<\/a><br><a href=\"http://www.lesswrong.com/tag/reductionism?showPostCount=true&amp;useTagName=true\">Reductionism<\/a><br><a href=\"https://www.lesswrong.com/tag/replicability?showPostCount=true&amp;useTagName=true\">Replicability<\/a><br>&nbsp;<\/p><\/td><\/tr><\/tbody><\/table><\/figure><p>&nbsp;<\/p><h2>A definition by elimination<\/h2><p>Properly considered, the overwhelming majority of content LessWrong is about <i>modeling how the world is<\/i>, including almost all posts on Rationality and all practical advice. The intended usage of World Modeling is to capture all content describing how the world is that is not captured by the more specific major tags of <a href=\"https://www.lesswrong.com/tag/rationality\">Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a>, ... <\/p>"},"Tag:3uE2pXvbcnS9nnZRE":{"_id":"3uE2pXvbcnS9nnZRE","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3uE2pXvbcnS9nnZRE_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"World Modeling","shortName":null,"slug":"world-modeling","core":true,"postCount":5001,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":27,"createdAt":"2020-06-14T22:24:50.898Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:9kcTNWopvXFncXgPy":{"_id":"9kcTNWopvXFncXgPy","__typename":"SocialPreviewType","imageUrl":""},"Post:9kcTNWopvXFncXgPy":{"_id":"9kcTNWopvXFncXgPy","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6391bcbcb4ac6367c10abe"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:2EFq8dJbxKNzforjM"},{"__ref":"Tag:6Qic6PwwBycopJFNN"},{"__ref":"Tag:Q6P8jLn8hH7kbuXRr"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:yS7248NQSm5J6xLvn"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:9kcTNWopvXFncXgPy"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2010-09-13T21:36:33.236Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"2EFq8dJbxKNzforjM":8,"3uE2pXvbcnS9nnZRE":1,"6Qic6PwwBycopJFNN":7,"Q6P8jLn8hH7kbuXRr":4,"gHCNhqxuJq2bZ2akb":3,"yS7248NQSm5J6xLvn":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6391bcbcb4ac6367c10abe","commentCount":367,"voteCount":350,"baseScore":364,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":349,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0005232195253483951,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-03-03T14:34:00.450Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":14,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":41,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2010-09-13T21:36:33.236Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"intellectual-hipsters-and-meta-contrarianism","title":"Intellectual Hipsters and Meta-Contrarianism","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16f55":{"_id":"5c6392dcbcb4ac6367c16f55","__typename":"Revision","htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><strong>I.<\/strong><\/p><p>It takes a special sort of person to be a cardiologist. This is not always a good thing.<\/p><p>You may have read about one or another of the “cardiologist caught falsifying test results and performing dangerous unnecessary surgeries to make more money” stories, but you might not have realized just how common it really is. <a href=\"http://www.healthbeatblog.com/2010/12/stent-scandal-a-shocking-story-but-not-news/\">Maryland cardiologist<\/a> performs over 500 dangerous unnecessary surgeries to make money. <a href=\"http://www.wboc.com/story/6190314/prmc-cardiologist-resigns-amidst-scandal\">Unrelated Maryland cardiologist<\/a> performs another 25 in a separate incident. <a href=\"http://www.sfgate.com/health/article/A-heart-surgery-scandal-revisits-Redding-in-print-2616602.php\">California cardiologist<\/a> does “several hundred” dangerous unnecessary surgeries and gets raided by the FBI. <a href=\"http://philadelphia.cbslocal.com/2013/04/03/philadelphia-doctor-resigns-after-investigation-finds-stents-in-patients-that-didnt-need-them/\">Philadelphia cardiologist<\/a>, same. North Carolina cardiologist, <a href=\"http://www.register-herald.com/news/raleigh-general-investigating-unnecessary-heart-procedures/article_74eec998-4624-571f-adb3-87f3d1c2598e.html\">same<\/a>. <a href=\"http://www.forbes.com/sites/larryhusten/2013/02/17/400-patients-sue-kentucky-hospital-and-11-cardiologists-over-unnecessary-procedures/\">11 Kentucky cardiologists<\/a>, same. Actually just a couple of miles from my own hospital, <a href=\"http://www.mlive.com/news/jackson/index.ssf/2013/07/lawsuit_alleges_jackson_cardio.html\">a Michigan cardiologist<\/a> was found to have done $4 million worth of the same. Etc, etc, etc.<\/p><p>My point is not just about the number of cardiologists who perform dangerous unnecessary surgeries for a quick buck. It’s not even just about the <a href=\"http://www.bloomberg.com/news/articles/2014-03-06/mount-sinai-cath-lab-takes-nyc-heart-emergencies-by-appointment\">cardiology insurance fraud<\/a>, <a href=\"http://www.nj.com/news/index.ssf/2009/09/three_cardiologists_linked_to.html\">cardiology kickback schemes<\/a>, or <a href=\"http://blogs.nature.com/news/2014/02/evidence-of-misconduct-cardiologist.html\">cardiology research data falsification conspiracies<\/a>. That could all just be attributed to some distorted incentives in cardiology as a field. My point is that it takes a special sort of person to be a cardiologist.<\/p><p>Consider the sexual harassment. <a href=\"http://www.nytimes.com/2014/11/02/us/handling-of-sexual-harassment-case-poses-larger-questions-at-yale.html\">Head of Yale cardiology department<\/a> fired for sexual harassment with “rampant bullying”. <a href=\"https://news.google.com/newspapers?nid=1320&amp;dat=19910628&amp;id=GUpWAAAAIBAJ&amp;sjid=SOoDAAAAIBAJ&amp;pg=3248,9902116&amp;hl=en\">Stanford cardiologist<\/a> charged with sexually harassing students. <a href=\"http://articles.baltimoresun.com/1994-06-08/news/1994159047_1_singal-cardiologist-harassment\">Baltimore cardiologist<\/a> found guilty of sexual harassment. <a href=\"http://mynewsla.com/crime/2015/06/18/jury-awards-alleged-groping-victim-200000/\">LA cardiologist<\/a> fined $200,000 for groping med tech. <a href=\"http://www.eeoc.gov/eeoc/newsroom/release/6-21-12.cfm\">Three different Pennsylvania cardiologists<\/a> sexually harassing the same woman. <a href=\"http://www.azcentral.com/news/articles/2010/01/19/20100119lewis0119-on.html\">Arizona cardiologist<\/a> suspended on 19 (!) different counts of sexual abuse. One of the <a href=\"http://www.stuff.co.nz/national/health/18971/Doctor-in-penis-prank-revealed\">“world’s leading cardiologists”<\/a> fired for sending pictures of his genitals to a female friend. <a href=\"http://www.nydailynews.com/news/national/cardiologist-racks-135-000-bill-trips-scores-strip-club-article-1.1764962\">New York cardiologist<\/a> in trouble for refusing to pay his $135,000 bill at a strip club. <a href=\"http://www.newyorkemploymentattorney-blog.com/2014/04/complaint-filed-with-eeoc-accuses-manhattan-cardiologist-of-sexual-harassment.html\">Manhattan cardiologist<\/a> taking naked pictures of patients, then using them to sexually abuse employees. <a href=\"http://newyork.cbslocal.com/2011/01/22/li-doctor-gets-jail-for-toilet-spying/\">New York cardiologist<\/a> secretly installs spycam in office bathroom. Just to shake things up, a <a href=\"http://www.chapmanlawgroup.com/case_study/bom-complaint-sexualharassment/\">Florida cardiologist<\/a> was falsely accused of sexual harassment as part of feud with another cardiologist.<\/p><p>And yeah, you can argue that if you put high-status men in an office with a lot of subordinates, sexual harassment will be depressingly common just as a result of the environment. But there’s also the T<\/p><\/div><\/div><\/div><\/div>... ","plaintextDescription":"I.\n\nIt takes a special sort of person to be a cardiologist. This is not always a good thing.\n\nYou may have read about one or another of the “cardiologist caught falsifying test results and performing dangerous unnecessary surgeries to make more money” stories, but you might not have realized just how common it really is. Maryland cardiologist performs over 500 dangerous unnecessary surgeries to make money. Unrelated Maryland cardiologist performs another 25 in a separate incident. California cardiologist does “several hundred” dangerous unnecessary surgeries and gets raided by the FBI. Philadelphia cardiologist, same. North Carolina cardiologist, same. 11 Kentucky cardiologists, same. Actually just a couple of miles from my own hospital, a Michigan cardiologist was found to have done $4 million worth of the same. Etc, etc, etc.\n\nMy point is not just about the number of cardiologists who perform dangerous unnecessary surgeries for a quick buck. It’s not even just about the cardiology insurance fraud, cardiology kickback schemes, or cardiology research data falsification conspiracies. That could all just be attributed to some distorted incentives in cardiology as a field. My point is that it takes a special sort of person to be a cardiologist.\n\nConsider the sexual harassment. Head of Yale cardiology department fired for sexual harassment with “rampant bullying”. Stanford cardiologist charged with sexually harassing students. Baltimore cardiologist found guilty of sexual harassment. LA cardiologist fined $200,000 for groping med tech. Three different Pennsylvania cardiologists sexually harassing the same woman. Arizona cardiologist suspended on 19 (!) different counts of sexual abuse. One of the “world’s leading cardiologists” fired for sending pictures of his genitals to a female friend. New York cardiologist in trouble for refusing to pay his $135,000 bill at a strip club. Manhattan cardiologist taking naked pictures of patients, then using them to sexually abuse emp","wordCount":1765,"version":"1.0.0"},"Revision:dJ6eJxJrCEget7Wb6_description":{"_id":"dJ6eJxJrCEget7Wb6_description","__typename":"Revision","htmlHighlight":"<p>A <strong>fallacy<\/strong> is generally considered to be an error in reasoning. It refers both to the failure to apply logic to a line of thought, and to the use of problematic arguments. The term can be applied when dealing both with informal and formal logic, although it usual refers to the former.<\/p><p><i>Related:<\/i> <a href=\"http://lesswrong.com/tag/disagreement\">Disagreement<\/a>, <a href=\"https://www.lesswrong.com/tag/heuristics-and-biases\">Heuristics &amp; Biases<\/a><\/p><h2>Informal vs Formal Fallacy<\/h2><p>An <i><strong>informal fallacy<\/strong><\/i> refers to a flawed argument, where the premises do not support the conclusion. It can, however, have a valid logical format. This type of fallacy is commonly divided in two main groups: <i>material fallacies<\/i> and <i>verbal fallacies<\/i>.<\/p><p>Material fallacies, concerned with the content of the argument, can be divivided following <a href=\"http://en.wikipedia.org/wiki/Aristotle\">Aristotle<\/a>'s taxonomy from his work Organon. One such example is the famous Straw Man fallacy:<\/p><ol><li>Person A has position X: We should focus our efforts on <a href=\"https://wiki.lesswrong.com/wiki/Friendly_AI\">Friendly AI<\/a> research.<\/li><li>Person B distorts position X to something close, but different, Y: So you think we should just give up on webdesign?!<\/li><li>Person B attacks position Y: That's stupid, websites are such a great way of spreading information!<\/li><\/ol><p>Verbal fallacies, on the other hand, deal with the way the words are used. These include examples such as Equivocation - using words ambiguously or with double meanings - and Proof by Verbosity, where one overwhelms his listener with lots of material in an complicated way.<\/p><p>A <i><strong>formal fallacy<\/strong><\/i>, contrasting with informal fallacies, refers to a pattern of reasoning which is wrong due to a flaw in the logical structure of the argument. As such, this deductive fallacy does not imply any information about the premises or the conclusion - its their connection that's wrongly stated. Both can be correct and the argument can be wrong because the conclusion doesn't follow from the premises as it is said to.<\/p><h2>False Fallacies &amp; Awareness<\/h2><p>Matters can be further complicated by arguing parties incorrectly claiming that an assertion is false due to a fallacy. For example, if one party was to declare “Albert Einstein has claimed that time and space are relative qualities of the Universe.”, another party might responded by saying that this is an ‘’’argument from authority’’’. However, Albert Einstein’s claims are based on detailed mathematical models that identify him as an expert in this field of inquiry, rather than a casual observer. We are thus facing a kind of meta-fallacy which is wrong by itself.<\/p><p>Recognizing fallaci... <\/p>"},"Tag:dJ6eJxJrCEget7Wb6":{"_id":"dJ6eJxJrCEget7Wb6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:dJ6eJxJrCEget7Wb6_description"},"canVoteOnRels":null,"userId":"DHabT2kQgNzrz88LM","name":"Fallacies","shortName":null,"slug":"fallacies","core":false,"postCount":83,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-29T19:54:43.714Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:DSzpr8Y9299jdDLc9":{"_id":"DSzpr8Y9299jdDLc9","__typename":"SocialPreviewType","imageUrl":""},"Post:DSzpr8Y9299jdDLc9":{"_id":"DSzpr8Y9299jdDLc9","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f55"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:dJ6eJxJrCEget7Wb6"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:DSzpr8Y9299jdDLc9"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-09-16T19:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":2,"dJ6eJxJrCEget7Wb6":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f55","commentCount":8,"voteCount":135,"baseScore":146,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":135,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00033862306736409664,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-02-27T03:14:17.003Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":13,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"cardiologists-and-chinese-robbers","title":"Cardiologists and Chinese Robbers","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:gnRdRz4mNJXuj7o49":{"_id":"gnRdRz4mNJXuj7o49","__typename":"Revision","htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>“<em>I don’t practice what I preach because I’m not the kind of person I’m preaching to.<\/em>” <\/p><p>— Bob Dobbs<\/p><p><\/p><p><strong>I.<\/strong><\/p><p>I read Atlas Shrugged probably about a decade ago, and felt turned off by its promotion of selfishness as a moral ideal. I thought that was basically just being a jerk. After all, if there’s one thing the world doesn’t need (I thought) it’s more selfishness.<\/p><p>Then I talked to a friend who told me Atlas Shrugged had changed his life. That he’d been raised in a really strict family that had told him that ever enjoying himself was selfish and made him a bad person, that he had to be working at every moment to make his family and other people happy or else let them shame him to pieces. And the revelation that it was sometimes okay to consider your own happiness gave him the strength to stand up to them and turn his life around, while still keeping the basic human instinct of helping others when he wanted to and he felt they deserved it (as, indeed, do Rand characters).<\/p><p><strong>II.<\/strong><\/p><p>The religious and the irreligious alike enjoy making fun of Reddit’s r/atheism, which combines an extreme strawmanning of religious positions with childish insults and distasteful triumphalism. Recently the moderators themselves have become a bit embarrassed by it and instituted some rules intended to tone things down, leading to <a href=\"http://www.reddit.com/r/atheism/comments/1fzaai/65_of_responding_users_now_reject_banning_image/\">some<\/a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzd0r/at_the_moment_15_of_the_top_25_posts_on_ratheism/\">of<\/a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzn3n/i_for_one_am_eternally_grateful_that_there_is/\">the<\/a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzhtl/fixed_approach_thread_to_remove_ujij_and_utuber/\">most<\/a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzl0h/jij_if_you_want_a_different_ratheism_go_start/\">impressive<\/a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzlmn/this_sub_is_now_useless_to_mobile_users_thanks_a/\">Internet<\/a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzow2/remove_jij_give_the_sub_back_to_its_creator_skeen/\">drama<\/a> I have ever seen. In its midst, some people started talking about what the old strawmanning triumphalist r/atheism meant to them (see for example <a href=\"http://www.reddit.com/r/atheism/comments/1fraqe/why_i_dont_like_the_changes/\">here<\/a>).<\/p><p>A lot of them were raised in religious families where they would have been disowned if they had admitted to their atheism. Some of them were disowned for admitting to atheism, or lost boyfriends/girlfriends, or were terrified they might go to Hell. And then they found r/atheism, and saw people making fun of religion, and insulting it, in really REALLY offensive ways. And no one was striking them down with lightning. No one was shouting them down. No one was doing much of anything at all. And to see this taboo violated in the most shocking possible way with no repercussions sort of broke the spell for them, like as long as people were behaving respectfully to religion, even respectfully disagreeing, it still had this aura of invincibility about it, but if some perfectly normal person can post a a stupid comic where Jesus has gay sex with Mohammed, then there’s this whole other world o<\/p><\/div><\/div><\/div><\/div>... ","plaintextDescription":"“I don’t practice what I preach because I’m not the kind of person I’m preaching to.”\n\n— Bob Dobbs\n\n\n\nI.\n\nI read Atlas Shrugged probably about a decade ago, and felt turned off by its promotion of selfishness as a moral ideal. I thought that was basically just being a jerk. After all, if there’s one thing the world doesn’t need (I thought) it’s more selfishness.\n\nThen I talked to a friend who told me Atlas Shrugged had changed his life. That he’d been raised in a really strict family that had told him that ever enjoying himself was selfish and made him a bad person, that he had to be working at every moment to make his family and other people happy or else let them shame him to pieces. And the revelation that it was sometimes okay to consider your own happiness gave him the strength to stand up to them and turn his life around, while still keeping the basic human instinct of helping others when he wanted to and he felt they deserved it (as, indeed, do Rand characters).\n\nII.\n\nThe religious and the irreligious alike enjoy making fun of Reddit’s r/atheism, which combines an extreme strawmanning of religious positions with childish insults and distasteful triumphalism. Recently the moderators themselves have become a bit embarrassed by it and instituted some rules intended to tone things down, leading to some of the most impressive Internet drama I have ever seen. In its midst, some people started talking about what the old strawmanning triumphalist r/atheism meant to them (see for example here).\n\nA lot of them were raised in religious families where they would have been disowned if they had admitted to their atheism. Some of them were disowned for admitting to atheism, or lost boyfriends/girlfriends, or were terrified they might go to Hell. And then they found r/atheism, and saw people making fun of religion, and insulting it, in really REALLY offensive ways. And no one was striking them down with lightning. No one was shouting them down. No one was doing much of anyth","wordCount":1858,"version":"1.1.0"},"SocialPreviewType:PQ3nutgxfTgvq69Xt":{"_id":"PQ3nutgxfTgvq69Xt","__typename":"SocialPreviewType","imageUrl":""},"Post:PQ3nutgxfTgvq69Xt":{"_id":"PQ3nutgxfTgvq69Xt","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:gnRdRz4mNJXuj7o49"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:fkABsGCJZ6y9qConW"}],"socialPreviewData":{"__ref":"SocialPreviewType:PQ3nutgxfTgvq69Xt"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-06-09T19:00:57.196Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"fkABsGCJZ6y9qConW":1,"gHCNhqxuJq2bZ2akb":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"gnRdRz4mNJXuj7o49","commentCount":4,"voteCount":103,"baseScore":109,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":103,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.000195999993593432,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2020-07-20T04:34:03.248Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":8,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":11,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"all-debates-are-bravery-debates","title":"All Debates Are Bravery Debates","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16d8a":{"_id":"5c6392dcbcb4ac6367c16d8a","__typename":"Revision","htmlHighlight":"<p>Leah Libresco writes a couple of essays (<A HREF=\"http://www.patheos.com/blogs/unequallyyoked/2013/06/a-terrible-consequence-of-consequentialism.html\">1<\/A>, <A HREF=\"http://www.patheos.com/blogs/unequallyyoked/2013/06/a-dicey-way-out-of-dilemmas.html\">2<\/A>) on an ethical dilemma reported in the New York Times. In the course of a confidential medical history, a doctor hears her patient is suffering from stress-related complaints after having sent an innocent man to prison. The doctor wants to know whether it is ethical to report the matter to the police. The Times&#8217; columnist says yes &#8211; it would save the poor prisoner. Leah says no &#8211; violating medical confidentiality creates an expectation that medical confidentiality will be violated in the future, thus dooming patients who are too afraid to talk about drug use or gay sex or other potentially embarrassing but important medical risk factors.<\/p><p>But both sides are ignoring the much bigger dilemma lurking one meta-level up: is it ethical to debate this dilemma in the <i>New York Times<\/i>?<\/p><p>Let&#8217;s look more closely at that phrase &#8220;violating medical confidentiality creates an expectation that medical confidentiality will be violated in the future.&#8221; There&#8217;s a very abstruse angels-and-clockwork interpretation of &#8220;creates an expectation&#8221; where, by making the decision to violate confidentiality, you are altering the Platonic machinery of the Universe in a way that allows other beings who know your source code to determine that you will do this. But most people don&#8217;t have the <A HREF=\"http://lesswrong.com/lw/gu1/decision_theory_faq/\">decision theory<\/A> to understand this, and anyway most doctors do not publish their source code online.<\/p><p>The way &#8220;creates an expectation&#8221; pans out in <i>our<\/i> universe is that somebody hears that a doctor violated medical confidentiality, and that person tells someone else, and that person tells someone else, until eventually someone who was going to tell their doctor about having gay sex with drugs remembers having heard the story and decides not to.<\/p><p>How exactly would people hear about this doctor who revealed the innocence of the prisoner? Through the ensuing court case? Nah. Most people wouldn&#8217;t obsessively read the minutes of every single case at the local courthouse <A HREF=\"http://slatestarcodex.com/2013/06/11/lies-damned-lies-and-facebook-part-3-of-%e2%88%9e/\">unless of course it has something to do with gender<\/A>. Really, the only way that someone could hear about a doctor violating medical confidentiality is if she, like, somehow got a description of her intention to do so published in meticulous detail in the <i>New York Times<\/i>.<\/p><p>Oh, <i>right<\/i>.<\/p><p>The entire negative effect of the doctor breaking her pro... <\/p>","plaintextDescription":"Leah Libresco writes a couple of essays (1, 2) on an ethical dilemma reported in the New York Times. In the course of a confidential medical history, a doctor hears her patient is suffering from stress-related complaints after having sent an innocent man to prison. The doctor wants to know whether it is ethical to report the matter to the police. The Times’ columnist says yes – it would save the poor prisoner. Leah says no – violating medical confidentiality creates an expectation that medical confidentiality will be violated in the future, thus dooming patients who are too afraid to talk about drug use or gay sex or other potentially embarrassing but important medical risk factors.\n\nBut both sides are ignoring the much bigger dilemma lurking one meta-level up: is it ethical to debate this dilemma in the New York Times?\n\nLet’s look more closely at that phrase “violating medical confidentiality creates an expectation that medical confidentiality will be violated in the future.” There’s a very abstruse angels-and-clockwork interpretation of “creates an expectation” where, by making the decision to violate confidentiality, you are altering the Platonic machinery of the Universe in a way that allows other beings who know your source code to determine that you will do this. But most people don’t have the decision theory to understand this, and anyway most doctors do not publish their source code online.\n\nThe way “creates an expectation” pans out in our universe is that somebody hears that a doctor violated medical confidentiality, and that person tells someone else, and that person tells someone else, until eventually someone who was going to tell their doctor about having gay sex with drugs remembers having heard the story and decides not to.\n\nHow exactly would people hear about this doctor who revealed the innocence of the prisoner? Through the ensuing court case? Nah. Most people wouldn’t obsessively read the minutes of every single case at the local courthouse unless","wordCount":1122,"version":"1.0.0"},"Revision:WqwdcinHrjoNE6qiS_description":{"_id":"WqwdcinHrjoNE6qiS_description","__typename":"Revision","htmlHighlight":"<blockquote><p>Silence is a <i>hard<\/i> virtue. All the other virtues have the advantage that, when you practice them, people will praise you. Sometimes if your moral system is very different from your friends’ people will attack you for your virtues, but <a href=\"http://slatestarcodex.com/2013/04/06/polyamory-is-boring/#comment-14095\">getting attacked by sufficiently horrible people<\/a> can sometimes be just as gratifying as praise. But if you stay silent, there’s no praise <i>and<\/i> no attacks. By definition, no one even knows you made a courageous moral choice.<\/p><\/blockquote><p>— <a href=\"https://www.lesswrong.com/posts/2brqzQWfmNx5Agdrx/the-virtue-of-silence\">Scott Alexander, 2013<\/a><\/p><p>Below is the space where a long list of posts would be tagged with 'Virtue of Silence', but the posts were (wisely) not written.<\/p>"},"Tag:WqwdcinHrjoNE6qiS":{"_id":"WqwdcinHrjoNE6qiS","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:WqwdcinHrjoNE6qiS_description"},"canVoteOnRels":null,"userId":"EQNTWXLKMeWMp2FQS","name":"Virtue of Silence","shortName":null,"slug":"virtue-of-silence","core":false,"postCount":2,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2023-04-01T20:12:07.526Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:8uNFGxejo5hykCEez_description":{"_id":"8uNFGxejo5hykCEez_description","__typename":"Revision","htmlHighlight":"<p><strong>Virtues<\/strong> are traits that one <i>ought<\/i> to possess, for the benefit of the world or oneself.<\/p><p>On LessWrong the focus is often on epistemic virtues, as in Eliezer Yudowsky's essay <a href=\"https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/twelve-virtues-of-rationality\"><strong>Twelve Virtues of Rationality<\/strong><\/a> which offers this list of virtues (roughly summarized):<\/p><ul><li><a href=\"https://www.lesswrong.com/tag/curiosity\"><strong>Curiosity<\/strong><\/a> - the burning desire to pursue truth;<\/li><li><strong>Relinquishment<\/strong> - not being attached to mistaken beliefs;<\/li><li><strong>Lightness<\/strong> - updating your beliefs with ease;<\/li><li><a href=\"https://www.lesswrong.com/tag/evenness\"><strong>Evenness<\/strong><\/a> - not privileging particular hypotheses in the pursuit of truth;<\/li><li><strong>Argument<\/strong> - the will to let one's beliefs be challenged;<\/li><li><a href=\"https://www.lesswrong.com/tag/empiricism\"><strong>Empiricism<\/strong><\/a> - grounding oneself in observation and prediction;<\/li><li><a href=\"https://www.lesswrong.com/tag/occam-s-razor\"><strong>Simplicity<\/strong><\/a> - elimination of unnecessary detail in modeling the world;<\/li><li><a href=\"https://www.lesswrong.com/tag/humility\"><strong>Humility<\/strong><\/a> - recognition of one's fallibility;<\/li><li><a href=\"https://www.lesswrong.com/tag/perfectionism\"><strong>Perfectionism<\/strong><\/a> - seeking perfection even if it's not attainable;<\/li><li><strong>Precision<\/strong> - seeking narrower statements and not overcorrect;<\/li><li><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning\"><strong>Scholarship<\/strong><\/a> - the study of multiple domains and perspectives;<\/li><li><a href=\"https://www.lesswrong.com/tag/twelfth-virtue\"><strong>The nameless virtue<\/strong><\/a> - seeking truth and not the virtues for themselves.<\/li><\/ul><p><strong>See Also: <\/strong><a href=\"https://www.lesswrong.com/tag/courage\">Courage<\/a>, <a href=\"https://www.lesswrong.com/tag/trust\">Trust<\/a>, <a href=\"https://www.lesswrong.com/tag/honesty\">Honesty<\/a>, <a href=\"https://www.lesswrong.com/tag/agency\">Agency<\/a>, <a href=\"https://www.lesswrong.com/tag/altruism\">Altruism<\/a>, <a href=\"https://www.lesswrong.com/tag/ambition\">Ambition<\/a>, <a href=\"https://www.lesswrong.com/tag/stoicism-letting-go-making-peace\">Stoicism / Letting Go / Making Peace<\/a>, <a href=\"https://www.lesswrong.com/tag/attention\">Attention<\/a>, <a href=\"https://www.lesswrong.com/tag/gratitude\">Gratitude<\/a><\/p><p><strong>Sequences:<\/strong><br><a href=\"https://www.lesswrong.com/s/xqgwpmwDYsn8osoje\">Notes On Virtues<\/a> by <a href=\"https://www.lesswrong.com/users/david_gross\">David_Gross<\/a><\/p>"},"Tag:8uNFGxejo5hykCEez":{"_id":"8uNFGxejo5hykCEez","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:8uNFGxejo5hykCEez_description"},"canVoteOnRels":null,"userId":"B5EreDfjALzEbSo6R","name":"Virtues","shortName":null,"slug":"virtues","core":false,"postCount":114,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-24T18:38:54.405Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:2brqzQWfmNx5Agdrx":{"_id":"2brqzQWfmNx5Agdrx","__typename":"SocialPreviewType","imageUrl":""},"Post:2brqzQWfmNx5Agdrx":{"_id":"2brqzQWfmNx5Agdrx","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16d8a"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":4,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:WqwdcinHrjoNE6qiS"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:8uNFGxejo5hykCEez"}],"socialPreviewData":{"__ref":"SocialPreviewType:2brqzQWfmNx5Agdrx"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-06-14T19:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"8uNFGxejo5hykCEez":4,"WqwdcinHrjoNE6qiS":10,"gHCNhqxuJq2bZ2akb":4},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16d8a","commentCount":4,"voteCount":100,"baseScore":126,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":100,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00022715600789524615,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-04-11T22:41:25.591Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":13,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":14,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-virtue-of-silence","title":"The Virtue of Silence","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16eef":{"_id":"5c6392dcbcb4ac6367c16eef","__typename":"Revision","htmlHighlight":"<p>The fallacy of <a href=\"http://en.wikipedia.org/wiki/Proving_too_much\">Proving Too Much<\/a> is when you challenge an argument because, in addition to proving its intended conclusion, it also proves obviously false conclusions. For example, if someone says &#8220;You can&#8217;t be an atheist, because it&#8217;s impossible to disprove the existence of God&#8221;, you can answer &#8220;That argument proves too much. If we accept it, we must also accept that you can&#8217;t disbelieve in Bigfoot, since it&#8217;s impossible to disprove his existence as well.&#8221;<\/p><p>I love this tactic <i>so much<\/i>. I only learned it had a name quite recently, but it&#8217;s been my default style of argument for years. It neatly cuts through complicated issues that might otherwise be totally irresolvable.<\/p><p>Because here is a fundamental principle of the <a href=\"http://wiki.lesswrong.com/wiki/Dark_arts\">Dark Arts<\/a> &#8211; you don&#8217;t need an argument that can&#8217;t be disproven, only an argument that can&#8217;t be disproven in the amount of time your opponent has available.<\/p><p>In a presidential debate, where your opponent has three minutes, that means all you need to do is come up with an argument whose disproof is <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferentially distant<\/a> enough from your audience that it will take your opponent more than three minutes to explain it, or your audience more than three minutes&#8217; worth of mental effort to understand the explanation.<\/p><p>The <a href=\"http://lesswrong.com/lw/e95/the_noncentral_fallacy_the_worst_argument_in_the/\">noncentral fallacy<\/a> is the easiest way to do this. &#8220;Martin Luther King was a criminal!&#8221; &#8220;Although what you say is technically correct, categories don&#8217;t work in the way your statement is impl &#8211; &#8221; &#8220;Oh, sorry, time&#8217;s up.&#8221;<\/p><p>But pretty much anything that assumes a classical Aristotelian view of concepts/objects is gold here. The same is true of any deontological rules your audience might be attached to.<\/p><p>I tend to get stuck in the position of having argue against those Dark Artsy tactics pretty often. And the great thing about Proving Too Much is that it can demolish an entire complicated argument based on all sorts of hard-to-tease-apart axioms in a split second. For example, <i>After Virtue<\/i> gave (though it does not endorse) this example of deontological reasoning:<\/p>\n<blockquote><p>I cannot will that my mother should have had an abortion when she was pregnant with me, except perhaps if it had been certain that the embryo was dead or gravely damaged. But if I cannot will this in my own case, how can I consistently deny to others the right to<\/p><\/blockquote>... ","plaintextDescription":"The fallacy of Proving Too Much is when you challenge an argument because, in addition to proving its intended conclusion, it also proves obviously false conclusions. For example, if someone says “You can’t be an atheist, because it’s impossible to disprove the existence of God”, you can answer “That argument proves too much. If we accept it, we must also accept that you can’t disbelieve in Bigfoot, since it’s impossible to disprove his existence as well.”\n\nI love this tactic so much. I only learned it had a name quite recently, but it’s been my default style of argument for years. It neatly cuts through complicated issues that might otherwise be totally irresolvable.\n\nBecause here is a fundamental principle of the Dark Arts – you don’t need an argument that can’t be disproven, only an argument that can’t be disproven in the amount of time your opponent has available.\n\nIn a presidential debate, where your opponent has three minutes, that means all you need to do is come up with an argument whose disproof is inferentially distant enough from your audience that it will take your opponent more than three minutes to explain it, or your audience more than three minutes’ worth of mental effort to understand the explanation.\n\nThe noncentral fallacy is the easiest way to do this. “Martin Luther King was a criminal!” “Although what you say is technically correct, categories don’t work in the way your statement is impl – ” “Oh, sorry, time’s up.”\n\nBut pretty much anything that assumes a classical Aristotelian view of concepts/objects is gold here. The same is true of any deontological rules your audience might be attached to.\n\nI tend to get stuck in the position of having argue against those Dark Artsy tactics pretty often. And the great thing about Proving Too Much is that it can demolish an entire complicated argument based on all sorts of hard-to-tease-apart axioms in a split second. For example, After Virtue gave (though it does not endorse) this example of deontological ","wordCount":662,"version":"1.0.0"},"SocialPreviewType:G5eMM3Wp3hbCuKKPE":{"_id":"G5eMM3Wp3hbCuKKPE","__typename":"SocialPreviewType","imageUrl":""},"Post:G5eMM3Wp3hbCuKKPE":{"_id":"G5eMM3Wp3hbCuKKPE","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16eef"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":3,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:dJ6eJxJrCEget7Wb6"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:G5eMM3Wp3hbCuKKPE"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-04-14T00:05:09.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":2,"dJ6eJxJrCEget7Wb6":8},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16eef","commentCount":7,"voteCount":88,"baseScore":115,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":88,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00020436602062545717,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-07-09T13:45:37.736Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":8,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":14,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"proving-too-much","title":"Proving Too Much","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16f1a":{"_id":"5c6392dcbcb4ac6367c16f1a","__typename":"Revision","htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><strong>I.<\/strong><\/p><p>From Identity, Personal Identity, and the Self by John Perry:<\/p><blockquote><p>&quot;There is something about practical things that knocks us off our philosophical high horses. Perhaps Heraclitus really thought he couldn’t step in the same river twice. Perhaps he even received tenure for that contribution to philosophy. But suppose some other ancient had claimed to have as much right as Heraclitus did to an ox Heraclitus had bought, on the grounds that since the animal had changed, it wasn’t the same one he had bought and so was up for grabs. Heraclitus would have quickly come up with some ersatz, watered-down version of identity of practical value for dealing with property rights, oxen, lyres, vineyards, and the like. And then he might have wondered if that watered-down vulgar sense of identity might be a considerably more valuable concept than a pure and philosophical sort of identity that nothing has.<\/p><\/blockquote><p>Okay, but I can think of something worse than that.<\/p><p>Imagine Heraclitus as a cattle rustler in the Old West. Every time a rancher catches him at his nefarious business, he patiently explains to them that identity doesn’t exist, and therefore the same argument against private property as made above. Flummoxed, they’re unable to think of a response before he rides off into the sunset.<\/p><p>But then when Heraclitus himself needs the concept of stable personal identity for something – maybe he wants to deposit his ill-gotten gains in the bank with certainty that the banker will give it back to him next time he shows up to withdraw it, or maybe he wants to bribe the sheriff to ignore his activities for the next while – all of a sudden Heraclitus is willing to tolerate the watered-down vulgar sense of identity like everyone else.<\/p><p>(actually, I can think of something even worse than that, which is a TV western based on this premise, where a roving band of pre-Socratic desperadoes terrorizes Texas. The climax is no doubt when the hero strides onto Main Street, revolver in hand, saying “There’s a new sheriff in town.” And Parmenides gruffly responds “No, I’m pretty sure that’s impossible.”)<\/p><p>At its best, philosophy is a revolutionary pursuit that dissolves our common-sense intuitions and exposes the possibility of much deeper structures behind them. One can respond by becoming a saint or madman, or by becoming a pragmatist who is willing to continue to participate in human society while also und<\/p><\/div><\/div><\/div><\/div>... ","plaintextDescription":"I.\n\nFrom Identity, Personal Identity, and the Self by John Perry:\n\n> \"There is something about practical things that knocks us off our philosophical high horses. Perhaps Heraclitus really thought he couldn’t step in the same river twice. Perhaps he even received tenure for that contribution to philosophy. But suppose some other ancient had claimed to have as much right as Heraclitus did to an ox Heraclitus had bought, on the grounds that since the animal had changed, it wasn’t the same one he had bought and so was up for grabs. Heraclitus would have quickly come up with some ersatz, watered-down version of identity of practical value for dealing with property rights, oxen, lyres, vineyards, and the like. And then he might have wondered if that watered-down vulgar sense of identity might be a considerably more valuable concept than a pure and philosophical sort of identity that nothing has.\n\nOkay, but I can think of something worse than that.\n\nImagine Heraclitus as a cattle rustler in the Old West. Every time a rancher catches him at his nefarious business, he patiently explains to them that identity doesn’t exist, and therefore the same argument against private property as made above. Flummoxed, they’re unable to think of a response before he rides off into the sunset.\n\nBut then when Heraclitus himself needs the concept of stable personal identity for something – maybe he wants to deposit his ill-gotten gains in the bank with certainty that the banker will give it back to him next time he shows up to withdraw it, or maybe he wants to bribe the sheriff to ignore his activities for the next while – all of a sudden Heraclitus is willing to tolerate the watered-down vulgar sense of identity like everyone else.\n\n(actually, I can think of something even worse than that, which is a TV western based on this premise, where a roving band of pre-Socratic desperadoes terrorizes Texas. The climax is no doubt when the hero strides onto Main Street, revolver in hand, saying “There","wordCount":2539,"version":"1.0.0"},"Revision:LDTSbmXtokYAsEq8e_description":{"_id":"LDTSbmXtokYAsEq8e_description","__typename":"Revision","htmlHighlight":"<p><strong>Motivated Reasoning<\/strong> is a label for various mental processes that lead to desired conclusions regardless of the veracity of those conclusions.<\/p><p><i>Related<\/i>: <a href=\"https://www.lesswrong.com/tag/confirmation-bias\">Confirmation Bias<\/a>, <a href=\"https://www.lesswrong.com/tag/rationalization\">Rationalization<\/a>, <a href=\"https://www.lesswrong.com/tag/self-deception\">Self-deception<\/a>&nbsp;<\/p><h2>Notable Posts<\/h2><ul><li><a href=\"https://lessestwrong.com/lw/it/semantic_stopsigns/\">Semantic Stopsigns<\/a><\/li><li><a href=\"https://lessestwrong.com/lw/j2/explainworshipignore/\">Explain/Worship/Ignore?<\/a><\/li><li><a href=\"https://lessestwrong.com/lw/jy/avoiding_your_beliefs_real_weak_points/\">Avoiding Your Belief's Real Weak Points<\/a><\/li><li><a href=\"https://lessestwrong.com/lw/km/motivated_stopping_and_motivated_continuation/\">Motivated Stopping and Motivated Continuation<\/a><\/li><li><a href=\"https://lesswrong.com/lw/js/the_bottom_line/\">The Bottom Line<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://lessestwrong.com/tag/rationalization\">Rationalization<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/motivated-skepticism\">Motivated skepticism<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/filtered-evidence\">Filtered evidence<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/confirmation-bias\">Positive bias<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/aversion-ugh-fields\">Ugh field<\/a><\/li><\/ul>"},"Tag:LDTSbmXtokYAsEq8e":{"_id":"LDTSbmXtokYAsEq8e","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:LDTSbmXtokYAsEq8e_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Motivated Reasoning","shortName":null,"slug":"motivated-reasoning","core":false,"postCount":69,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-24T07:47:20.152Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:vcvfjGJwRmFbMMS3d_description":{"_id":"vcvfjGJwRmFbMMS3d_description","__typename":"Revision","htmlHighlight":"<p><i>“<strong>Principles <\/strong>are fundamental truths that serve as the foundations for behavior that gets you what you want out of life. They can be applied again and again in similar situations to help you achieve your goals.”<\/i> ― Ray Dalio, Principles: Life and Work.<br><br>Principles, Heuristics, and rules of thumb are generalizations that aim to produce an optimal outcome relative to their cheapness as decision rules.&nbsp;<br><br>Not using generalizations, Rules of thumb and Heuristics isn't possible. precise decision rules such as <a href=\"https://www.lesswrong.com/tag/bayes-theorem-bayesianism\">Bayes Theorem <\/a>are <a href=\"https://en.wikipedia.org/wiki/Combinatorial_explosion\">computationally intractable <\/a>even to computers, and surely aren't feasible for humans. the question become whether you have good and effective principles to guide you.<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/chesterton-s-fence\">Chesterton's Fence<\/a>, <a href=\"https://www.lesswrong.com/tag/conservation-of-expected-evidence\">Conservation of Expected Evidence<\/a>, <a href=\"https://www.lesswrong.com/tag/occam-s-razor\">Occam's razor<\/a>, <a href=\"https://www.lesswrong.com/tag/goodhart-s-law\">Goodhart's Law<\/a>, <a href=\"https://www.lesswrong.com/tag/more-dakka\">More Dakka<\/a><\/p>"},"Tag:vcvfjGJwRmFbMMS3d":{"_id":"vcvfjGJwRmFbMMS3d","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:vcvfjGJwRmFbMMS3d_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Principles","shortName":null,"slug":"principles","core":false,"postCount":22,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-05T09:44:25.740Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:fzeoYhKoYPR3tDYFT":{"_id":"fzeoYhKoYPR3tDYFT","__typename":"SocialPreviewType","imageUrl":""},"Post:fzeoYhKoYPR3tDYFT":{"_id":"fzeoYhKoYPR3tDYFT","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f1a"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":10,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:LDTSbmXtokYAsEq8e"},{"__ref":"Tag:vcvfjGJwRmFbMMS3d"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:fzeoYhKoYPR3tDYFT"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-09-02T19:50:00.365Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"LDTSbmXtokYAsEq8e":1,"Ng8Gice9KNkncxqcj":1,"vcvfjGJwRmFbMMS3d":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f1a","commentCount":6,"voteCount":106,"baseScore":119,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":106,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00036784636904485524,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2017-09-02T19:50:00.365Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":13,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2017-09-02T19:50:00.365Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"beware-isolated-demands-for-rigor","title":"Beware Isolated Demands For Rigor","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:nKkCGrfLoqofKXXQD":{"_id":"nKkCGrfLoqofKXXQD","__typename":"Chapter","createdAt":"2017-08-24T01:22:08.473Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:nKkCGrfLoqofKXXQD_contents"},"number":0,"sequenceId":"XsMTxdQ6fprAQMoKi","postIds":["gFMH3Cqw4XxwL69iy","Kbm6QnJv9dgWsPHQP","9kcTNWopvXFncXgPy","DSzpr8Y9299jdDLc9","PQ3nutgxfTgvq69Xt","2brqzQWfmNx5Agdrx","G5eMM3Wp3hbCuKKPE","fzeoYhKoYPR3tDYFT"],"posts":[{"__ref":"Post:gFMH3Cqw4XxwL69iy"},{"__ref":"Post:Kbm6QnJv9dgWsPHQP"},{"__ref":"Post:9kcTNWopvXFncXgPy"},{"__ref":"Post:DSzpr8Y9299jdDLc9"},{"__ref":"Post:PQ3nutgxfTgvq69Xt"},{"__ref":"Post:2brqzQWfmNx5Agdrx"},{"__ref":"Post:G5eMM3Wp3hbCuKKPE"},{"__ref":"Post:fzeoYhKoYPR3tDYFT"}]},"Revision:5c6392dcbcb4ac6367c16e42":{"_id":"5c6392dcbcb4ac6367c16e42","__typename":"Revision","htmlHighlight":"<p>Once upon a time there were three little pigs who went out into the world to build their houses. The first pig was very lazy and built his house out of straw. The second pig was a little harder-working and built his house out of sticks. The third pig was the hardest-working of all, and built his house out of bricks. Then came the Big Bad Wolf. When he saw the house of straw, he huffed and he puffed and he blew the house down, eating the first little pig. When he saw the house of sticks, he huffed and he puffed and he blew the house down, eating the second little pig. When he saw the house of bricks, he got out a bazooka and blew the house to pieces, eating the third little pig.<\/p><p><b>Moral:<\/b> Reality doesn&#8217;t grade on a curve.<\/p>\n<hr>\n<p>Once upon a time there was a big strong troll who lived under a bridge. A little goat went across the bridge, and the troll reached out to grab and eat the goat. &#8220;Wait, Mr. Troll!&#8221;, the goat cried. &#8220;Soon my brother is coming, and he is even bigger than I am!&#8221; The troll let the goat pass, and soon came another goat, twice as big as the first. The troll reached out to grab and eat him, but the brother likewise objected, saying <i>his<\/i> brother was even bigger. Sure enough, a third goat arrived at the bridge, twice as big as the second, and the troll, now ready for a very hearty dinner, reached out to grab and eat him. &#8220;Wait!&#8221; said the third goat. &#8220;My brother is the biggest of us all!&#8221;. So the troll let the third goat pass. Then came the fourth goat, who was hundreds of miles tall and blotted out the sun, whose very steps caused earthquakes and made the rivers change course. Without even noticing, he stepped on bridge and troll, pulverizing both to bits.<\/p><p><b>Moral:<\/b> Sometimes growth is superexponential.<\/p>\n<hr>\n<p>Once upon a time, Chicken Little ran to her friend Henny Penny. &#8220;The sky is falling!&#8221; she shouted. &#8220;We must tell the king!&#8221; Henny Penny joined her, and together they headed toward the capital. On their way they run into their friend Goosey Loosey. &#8220;The sky is falling!&#8221; they shouted. &#8220;We must tell the king!&#8221; Goosey Loosey joined them, and together they headed toward the capital. On their way, they ran into the cunning Foxy Loxy. &#8220;The sky is falling!&#8221; they shouted. &#8220;We must tell the king!&#8221; &#8220;Oh,&#8221; said Foxy Loxy. &#8220;I know... <\/p>","plaintextDescription":"Once upon a time there were three little pigs who went out into the world to build their houses. The first pig was very lazy and built his house out of straw. The second pig was a little harder-working and built his house out of sticks. The third pig was the hardest-working of all, and built his house out of bricks. Then came the Big Bad Wolf. When he saw the house of straw, he huffed and he puffed and he blew the house down, eating the first little pig. When he saw the house of sticks, he huffed and he puffed and he blew the house down, eating the second little pig. When he saw the house of bricks, he got out a bazooka and blew the house to pieces, eating the third little pig.\n\nMoral: Reality doesn’t grade on a curve.\n\n----------------------------------------\n\nOnce upon a time there was a big strong troll who lived under a bridge. A little goat went across the bridge, and the troll reached out to grab and eat the goat. “Wait, Mr. Troll!”, the goat cried. “Soon my brother is coming, and he is even bigger than I am!” The troll let the goat pass, and soon came another goat, twice as big as the first. The troll reached out to grab and eat him, but the brother likewise objected, saying his brother was even bigger. Sure enough, a third goat arrived at the bridge, twice as big as the second, and the troll, now ready for a very hearty dinner, reached out to grab and eat him. “Wait!” said the third goat. “My brother is the biggest of us all!”. So the troll let the third goat pass. Then came the fourth goat, who was hundreds of miles tall and blotted out the sun, whose very steps caused earthquakes and made the rivers change course. Without even noticing, he stepped on bridge and troll, pulverizing both to bits.\n\nMoral: Sometimes growth is superexponential.\n\n----------------------------------------\n\nOnce upon a time, Chicken Little ran to her friend Henny Penny. “The sky is falling!” she shouted. “We must tell the king!” Henny Penny joined her, and together they headed towar","wordCount":800,"version":"1.0.0"},"Revision:hNFdS3rRiYgqqD8aM_description":{"_id":"hNFdS3rRiYgqqD8aM_description","__typename":"Revision","htmlHighlight":"<html><head><\/head><body><p><strong>Humor<\/strong>. This tag is a joke.<\/p><\/body><\/html>"},"Tag:hNFdS3rRiYgqqD8aM":{"_id":"hNFdS3rRiYgqqD8aM","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:hNFdS3rRiYgqqD8aM_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Humor","shortName":null,"slug":"humor","core":false,"postCount":190,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-22T22:52:13.969Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:F2XfCTxXLQBGjbm8P_description":{"_id":"F2XfCTxXLQBGjbm8P_description","__typename":"Revision","htmlHighlight":"<p><strong>Parables &amp; Fables<\/strong><\/p><p><strong>External links:<\/strong><br><a href=\"https://nickbostrom.com/fable/dragon.html\">The Fable of the Dragon-Tyrant<\/a> by Nick Bostrom (<a href=\"https://www.youtube.com/watch?v=cZYNADOHhVY\">animated version <\/a>by CGP Grey)<br><a href=\"https://slatestarcodex.com/2017/11/09/ars-longa-vita-brevis/\">Ars Longa, Vita Brevis<\/a> by Scott Alexander<br><a href=\"https://slatestarcodex.com/2017/10/23/kolmogorov-complicity-and-the-parable-of-lightning/\">Kolmogorov Complicity and the Parable of Lightning<\/a> by Scott Alexander<br><a href=\"https://andersen.sdu.dk/vaerk/hersholt/TheEmperorsNewClothes_e.html\">The Emperor's New Clothes<\/a><\/p><p><strong>Related tags: <\/strong><a href=\"https://www.lesswrong.com/tag/fiction\">Fiction<\/a>, <a href=\"https://www.lesswrong.com/tag/writing\">Writing<\/a>, <a href=\"https://www.lesswrong.com/tag/narratives-stories\">Narratives (stories)<\/a><\/p>"},"Tag:F2XfCTxXLQBGjbm8P":{"_id":"F2XfCTxXLQBGjbm8P","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:F2XfCTxXLQBGjbm8P_description"},"canVoteOnRels":null,"userId":"Q7NW4XaWQmfPfdcFj","name":"Parables & Fables","shortName":null,"slug":"parables-and-fables","core":false,"postCount":56,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-10T03:32:42.232Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:jiuackr7B5JAetbF6_description":{"_id":"jiuackr7B5JAetbF6_description","__typename":"Revision","htmlHighlight":"<p><strong>Transhumanism<\/strong> is the belief or movement in favour of human enhancement, especially beyond current human limitations and with advanced technology such as AI, cognitive enhancement, and life extension.<\/p><h2>References<\/h2><ul><li><a href=\"http://yudkowsky.net/singularity/simplified\">Transhumanism as Simplified Humanism<\/a> by <a href=\"https://www.lesswrong.com/tag/eliezer-yudkowsky\">Eliezer Yudkowsky<\/a><\/li><li>A <a href=\"http://www.ted.com/talks/nick_bostrom_on_our_biggest_problems.html\">TED talk<\/a> by transhumanist <a href=\"https://www.lesswrong.com/tag/nick-bostrom\">Nick Bostrom<\/a> on humanity's biggest problems<\/li><li><a href=\"http://www.nickbostrom.com/views/transhumanist.pdf\">The Transhumanist FAQ<\/a> (PDF) by <a href=\"https://www.lesswrong.com/tag/nick-bostrom\">Nick Bostrom<\/a> (<a href=\"http://whatistranshumanism.org/\">HTML version<\/a>)<\/li><li><a href=\"http://www.nickbostrom.com/ethics/values.html\">Transhumanist Values<\/a> by <a href=\"https://www.lesswrong.com/tag/nick-bostrom\">Nick Bostrom<\/a><\/li><li><a href=\"http://www.nickbostrom.com/papers/history.pdf\">A History of Transhumanist Thought<\/a> (PDF) by <a href=\"https://www.lesswrong.com/tag/nick-bostrom\">Nick Bostrom<\/a><\/li><li><a href=\"https://web.archive.org/web/20130115205756/http://www.acceleratingfuture.com/michael/blog/2007/09/seven-definitions-of-transhumanism/\">Seven Definitions of Transhumanism<\/a> by <a href=\"https://www.lesswrong.com/tag/michael-anissimov\">Michael Anissimov<\/a><\/li><li><a href=\"https://www.youtube.com/watch?v=bTMS9y8OVuY\">PostHuman: An Introduction to Transhumanism<\/a> (video)<\/li><\/ul><h2>See Also<\/h2><ul><li><a href=\"https://wiki.lesswrong.com/wiki/H+Pedia\">H+Pedia<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/fun-theory\">Fun theory<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/metaethics-sequence\">Metaethics sequence<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/mind-uploading\">Mind uploading<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/cryonics\">Cryonics<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Friendly_AI\">Friendly AI<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/abolitionism\">Abolitionism<\/a><\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"https://hpluspedia.org/\">H+Pedia, the transhumanist wiki<\/a><\/li><\/ul>"},"Tag:jiuackr7B5JAetbF6":{"_id":"jiuackr7B5JAetbF6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:jiuackr7B5JAetbF6_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Transhumanism","shortName":null,"slug":"transhumanism","core":false,"postCount":84,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-29T10:45:48.959Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:AYbhqi65SWzHzy7Xx":{"_id":"AYbhqi65SWzHzy7Xx","__typename":"SocialPreviewType","imageUrl":""},"Post:AYbhqi65SWzHzy7Xx":{"_id":"AYbhqi65SWzHzy7Xx","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e42"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":3,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:hNFdS3rRiYgqqD8aM"},{"__ref":"Tag:F2XfCTxXLQBGjbm8P"},{"__ref":"Tag:jiuackr7B5JAetbF6"}],"socialPreviewData":{"__ref":"SocialPreviewType:AYbhqi65SWzHzy7Xx"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-05-28T01:55:20.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"F2XfCTxXLQBGjbm8P":2,"hNFdS3rRiYgqqD8aM":3,"jiuackr7B5JAetbF6":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e42","commentCount":7,"voteCount":114,"baseScore":122,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":114,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00021837571694049984,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-02-06T14:51:18.453Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":15,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"transhumanist-fables","title":"Transhumanist Fables","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16da6":{"_id":"5c6392dcbcb4ac6367c16da6","__typename":"Revision","htmlHighlight":"<p>.<\/p><p>Seen <A HREF=\"http://chroniclesofrettek.tumblr.com/post/118057128657/wrapscallion-mitoticcephalopod-britney\">on Tumblr<\/A>, along with associated discussion:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/pills2.jpg\"><\/center><\/p><p><b>Yellow:<\/b><\/p><p>People&#8217;s minds are heartbreaking. Not because people are so bad, but because they&#8217;re so good.<\/p><p>Nobody is the villain of their own life story. You must have read hundreds of minds by now, and it&#8217;s true. Everybody thinks of themselves as an honest guy or gal just trying to get by, constantly under assault by circumstances and The System and hundreds and hundreds of assholes. They don&#8217;t just sort of believe this. They really believe it. You almost believe it yourself, when you&#8217;re deep into a reading. You can very clearly see the structure of evidence they&#8217;ve built up to support their narrative, and even though it looks silly to you, you can see why they will never escape it from the inside. You can see how every insult, every failure, no matter how deserved, is a totally unexpected kick in the gut.<\/p><p>When you chose the yellow pill, you had high hopes of becoming a spy, or a gossip columnist, or just the world&#8217;s greatest saleswoman. The thought of doing any of those things sickens you now. There is too much anguish in the world already. You feel like any of those things would be a violation. You briefly try to become a therapist, but it turns out that actually knowing everything about your client&#8217;s mind is horrendously countertherapeutic. Freud can say whatever he wants against defense mechanisms, but without them, you&#8217;re defenseless. Your sessions are spent in incisive cutting into your clients&#8217; deepest insecurities alternating with desperate reassurance that they are good people anyway.<\/p><p>Also, men. You knew, in a vague way, that men thought about sex all the time. But you didn&#8217;t realize the, um, content of some of their sexual fantasies. Is it even <i>legal<\/i> to fantasize about that? You want to be disgusted with them. But you realize that if you were as horny as they were all the time, you&#8217;d do much the same.<\/p><p>You give up. You become a forest ranger. Not the type who helps people explore the forest. The other type. The type where you hang out in a small cabin in the middle of the mountains and never talk to anybody. The only living thing you encounter is the occasional bear. It always thinks that it is a good bear, a proper bear, that a bear-hating world has it out for them in particular. You do nothing to disabuse it of this notion.<\/p><p><b>Green<\/b><\/p><p>The firs... <\/p>","plaintextDescription":".\n\nSeen on Tumblr, along with associated discussion:\n\n\n\nYellow:\n\nPeople’s minds are heartbreaking. Not because people are so bad, but because they’re so good.\n\nNobody is the villain of their own life story. You must have read hundreds of minds by now, and it’s true. Everybody thinks of themselves as an honest guy or gal just trying to get by, constantly under assault by circumstances and The System and hundreds and hundreds of assholes. They don’t just sort of believe this. They really believe it. You almost believe it yourself, when you’re deep into a reading. You can very clearly see the structure of evidence they’ve built up to support their narrative, and even though it looks silly to you, you can see why they will never escape it from the inside. You can see how every insult, every failure, no matter how deserved, is a totally unexpected kick in the gut.\n\nWhen you chose the yellow pill, you had high hopes of becoming a spy, or a gossip columnist, or just the world’s greatest saleswoman. The thought of doing any of those things sickens you now. There is too much anguish in the world already. You feel like any of those things would be a violation. You briefly try to become a therapist, but it turns out that actually knowing everything about your client’s mind is horrendously countertherapeutic. Freud can say whatever he wants against defense mechanisms, but without them, you’re defenseless. Your sessions are spent in incisive cutting into your clients’ deepest insecurities alternating with desperate reassurance that they are good people anyway.\n\nAlso, men. You knew, in a vague way, that men thought about sex all the time. But you didn’t realize the, um, content of some of their sexual fantasies. Is it even legal to fantasize about that? You want to be disgusted with them. But you realize that if you were as horny as they were all the time, you’d do much the same.\n\nYou give up. You become a forest ranger. Not the type who helps people explore the forest. The other","wordCount":6421,"version":"1.0.0"},"Revision:etDohXtBrXd8WqCtR_description":{"_id":"etDohXtBrXd8WqCtR_description","__typename":"Revision","htmlHighlight":"<p><strong>Fiction<\/strong> isn't literal truth, but when done well it captures truths and intuitions that are difficult to explain directly. (It’s also damn fun to read.)<\/p><blockquote><p>“Nonfiction conveys <i>knowledge,<\/i> fiction conveys <i>experience.<\/i>” - Eliezer Yudkowsky&nbsp;<\/p><\/blockquote><p>Eliezer Yudkowsky helped kickstart the genre of <a href=\"https://www.lesswrong.com/posts/q79vYjHAE9KHcAjSs/rationalist-fiction\"><i>rationalist fiction<\/i><\/a>, which is about characters who solve the problems in their world by thinking, in a way where the reader <i>could figure it out too<\/i>. Not where the genius character explains it afterward like Sherlock Holmes or Artemis Fowl, but where the problem is fair and you could’ve figured it out first. Eliezer has written about this in his short online book <a href=\"https://yudkowsky.tumblr.com/writing\"><u>The Abridged Guide to Intelligent Characters<\/u><\/a>.<\/p><p>Other fiction on the site is in the spirit of hard science fiction, and often involves taking the laws of a universe or the rules of a system to their extreme conclusions, and munchkining your way to become god (or something similar). They also share much of the parts of sci-fi that engage with difficult moral quandaries.<\/p><p>Fiction on this site also tends to have puns. I’m so sorry.<\/p><p>Much more fiction can be found at <a href=\"https://www.reddit.com/r/rational\">r/Rational<\/a>, which is a subreddit devoted to rationalist fiction.<\/p><p>This is a tag for works of fiction, not for analysis or discussion of literature. For that see <a href=\"https://www.lesswrong.com/tag/fiction-topic\">Fiction (topic)<\/a>.<\/p><h2>Fiction Sequences<\/h2><ul><li><a href=\"https://www.lesswrong.com/hpmor\">HPMOR<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/qWoFR4ytMpQ5vw3FT\">Three Worlds Collide<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/LAop879LCQWrM5YnE\">The Bayesian Conspiracy<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/4C33PKt2cQdA7oyfJ\">Murphy's Quest<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/TF77XsD5PbucbJsG3\">Luna Lovegood and the Chamber of Secrets<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/TjdhvTSptCYakw3Lc\">Bayeswatch<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/qMtriMPLdriNkAfSJ\">Short stories<\/a> by lsusr<\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"https://www.reddit.com/r/rational/\">/r/rational/<\/a> on <a href=\"https://lessestwrong.com/tag/reddit\">Reddit<\/a><\/li><li><a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/RationalFic\">RationalFic<\/a> on TV Tropes<\/li><li><a href=\"http://yudkowsky.tumblr.com/writing\">Eliezer Yudkowsky's guide to writing intelligent characters<\/a><\/li><li><a href=\"http://rationalreads.com/\">rationalreads.com<\/a><\/li><\/ul>"},"Tag:etDohXtBrXd8WqCtR":{"_id":"etDohXtBrXd8WqCtR","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:etDohXtBrXd8WqCtR_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Fiction","shortName":null,"slug":"fiction","core":false,"postCount":616,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-13T16:01:23.724Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:wJnm5cBiZGmKn595f":{"_id":"wJnm5cBiZGmKn595f","__typename":"SocialPreviewType","imageUrl":""},"Post:wJnm5cBiZGmKn595f":{"_id":"wJnm5cBiZGmKn595f","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16da6"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":26,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:hNFdS3rRiYgqqD8aM"}],"socialPreviewData":{"__ref":"SocialPreviewType:wJnm5cBiZGmKn595f"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-06-03T01:47:01.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":23,"hNFdS3rRiYgqqD8aM":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16da6","commentCount":15,"voteCount":186,"baseScore":240,"extendedScore":{"reacts":{"laugh":[{"karma":0,"quotes":["any good at urban planning"],"userId":"ufEvGTvAThKuq3uHJ","reactType":"created","displayName":"Marcelo Carreira (Mcc)"}]},"agreement":0,"approvalVoteCount":185,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0005360000068321824,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-10-13T05:02:25.991Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":23,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":25,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"and-i-show-you-how-deep-the-rabbit-hole-goes","title":"…And I Show You How Deep The Rabbit Hole Goes","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:HAnxHJJREcCRKRBEk":{"_id":"HAnxHJJREcCRKRBEk","__typename":"Chapter","createdAt":"2017-09-02T07:58:35.886Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"XsMTxdQ6fprAQMoKi","postIds":["AYbhqi65SWzHzy7Xx","wJnm5cBiZGmKn595f"],"posts":[{"__ref":"Post:AYbhqi65SWzHzy7Xx"},{"__ref":"Post:wJnm5cBiZGmKn595f"}]},"Revision:XsMTxdQ6fprAQMoKi_contents":{"_id":"XsMTxdQ6fprAQMoKi_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-07-01T21:46:04.937Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","commitMessage":"","wordCount":20,"htmlHighlight":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","plaintextDescription":"A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them."},"Collection:2izXHCrmJ684AnZ5X":{"_id":"2izXHCrmJ684AnZ5X","__typename":"Collection","title":"The Codex","createdAt":"2017-08-22T21:28:44.333Z","slug":"codex","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:2izXHCrmJ684AnZ5X_contents"},"firstPageLink":"/codex/eight-short-studies-on-excuses","gridImageId":"ItFKgn4_rrr58y_zurh8d","books":[{"__ref":"Book:jF58hKP9ZLzgy22Jr"},{"__ref":"Book:YhQ39PPHNrRCgYXcs"},{"__ref":"Book:kcCvSNNZd8pfQvf9E"},{"__ref":"Book:2tPEd5Gdm3iewB53M"}],"hideStartReadingButton":null,"noindex":false},"Sequence:XsMTxdQ6fprAQMoKi":{"_id":"XsMTxdQ6fprAQMoKi","__typename":"Sequence","chapters":[{"__ref":"Chapter:nKkCGrfLoqofKXXQD"},{"__ref":"Chapter:HAnxHJJREcCRKRBEk"}],"createdAt":"2017-08-24T01:21:12.377Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:XsMTxdQ6fprAQMoKi_contents"},"gridImageId":"sequencesgrid/rfpef83ejiwbsi1pmroz","bannerImageId":"sequences/i345prxcdiiwgczlrsya","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":499,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":0,"title":"Argument and Analysis","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:MqKMEqNgPXyFsnqiP_contents":{"_id":"MqKMEqNgPXyFsnqiP_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:27:53.657Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Podcast:63335fe68105d39e05b2a83f":{"_id":"63335fe68105d39e05b2a83f","__typename":"Podcast","title":"LessWrong MoreAudible Podcast","applePodcastLink":null,"spotifyPodcastLink":null},"PodcastEpisode:aoL7oe5gMG6quKJHj":{"_id":"aoL7oe5gMG6quKJHj","__typename":"PodcastEpisode","title":"Diseased thinking: dissolving questions about disease","podcast":{"__ref":"Podcast:63335fe68105d39e05b2a83f"},"episodeLink":"https://www.buzzsprout.com/2057498/11428119-diseased-thinking-dissolving-questions-about-disease-by-scott-alexander.js?container_id=buzzsprout-player-11428119&player=small","externalEpisodeId":"11428119"},"Revision:5c639197bcb4ac6367c0fb3a":{"_id":"5c639197bcb4ac6367c0fb3a","__typename":"Revision","htmlHighlight":"<p><strong>Related to: <\/strong><a href=\"https://www.lesswrong.com/lw/nm/disguised_queries/\">Disguised Queries<\/a>, <a href=\"https://www.lesswrong.com/lw/ng/words_as_hidden_inferences/\">Words as Hidden Inferences<\/a>, <a href=\"https://www.lesswrong.com/lw/of/dissolving_the_question/\">Dissolving the Question<\/a>, <a href=\"https://www.lesswrong.com/lw/24o/eight_short_studies_on_excuses/\">Eight Short Studies on Excuses<\/a><\/p><blockquote><em>Today&#x27;s therapeutic ethos, which celebrates curing and disparages judging, expresses the liberal disposition to assume that crime and other problematic behaviors reflect social or biological causation. While this absolves the individual of responsibility, it also strips the individual of personhood, and moral dignity<\/em><\/blockquote><p><em>            -- George Will, <a href=\"http://townhall.com/Common/PrintPage.aspx?g=761ecc84-473b-4123-bf28-c4fc179a9d3f&t=c\">townhall.com<\/a><\/em><\/p><p>Sandy is a morbidly obese woman looking for advice. <\/p><p>Her husband has no sympathy for her, and tells her she obviously needs to stop eating like a pig, and would it kill her to go to the gym once in a while? <\/p><p>Her doctor tells her that obesity is primarily genetic, and recommends the diet pill orlistat and a consultation with a surgeon about gastric bypass. <\/p><p>Her sister tells her that obesity is a perfectly valid lifestyle choice, and that fat-ism, equivalent to racism, is society&#x27;s way of keeping her down.<\/p><p>When she tells each of her friends about the opinions of the others, things really start to heat up.<\/p><p>Her husband accuses her doctor and sister of absolving her of personal responsibility with feel-good platitudes that in the end will only prevent her from getting the willpower she needs to start a real diet.<\/p><p>Her doctor accuses her husband of ignorance of the real causes of obesity and of the most effective treatments, and accuses her sister of legitimizing a dangerous health risk that could end with Sandy in hospital or even dead.<\/p><p>Her sister accuses her husband of being a jerk, and her doctor of trying to medicalize her behavior in order to turn it into a &quot;condition&quot; that will keep her on pills for life and make lots of money for Big Pharma.<\/p><p>Sandy is fictional, but similar conversations happen every day, not only about obesity but about a host of other marginal conditions that some consider character flaws, others diseases, and still others normal variation in the human condition. Attention deficit disorder, internet addiction, social anxiety disorder (as one skeptic said, didn&#x27;t we used to call this &quot;shyness&quot;?), alcoholism, chronic fatigue, oppositional defiant disorder (&quot;didn&#x27;t we used to call this being a teenager?&quot;), compulsive gambling, homosexuality, Aspergers&#x27; syndrome, antisocial personality, even depression have all been placed in two or mo... <\/p>","plaintextDescription":"Related to: Disguised Queries, Words as Hidden Inferences, Dissolving the Question, Eight Short Studies on Excuses\n\n> Today's therapeutic ethos, which celebrates curing and disparages judging, expresses the liberal disposition to assume that crime and other problematic behaviors reflect social or biological causation. While this absolves the individual of responsibility, it also strips the individual of personhood, and moral dignity\n\n-- George Will, townhall.com\n\nSandy is a morbidly obese woman looking for advice.\n\nHer husband has no sympathy for her, and tells her she obviously needs to stop eating like a pig, and would it kill her to go to the gym once in a while?\n\nHer doctor tells her that obesity is primarily genetic, and recommends the diet pill orlistat and a consultation with a surgeon about gastric bypass.\n\nHer sister tells her that obesity is a perfectly valid lifestyle choice, and that fat-ism, equivalent to racism, is society's way of keeping her down.\n\nWhen she tells each of her friends about the opinions of the others, things really start to heat up.\n\nHer husband accuses her doctor and sister of absolving her of personal responsibility with feel-good platitudes that in the end will only prevent her from getting the willpower she needs to start a real diet.\n\nHer doctor accuses her husband of ignorance of the real causes of obesity and of the most effective treatments, and accuses her sister of legitimizing a dangerous health risk that could end with Sandy in hospital or even dead.\n\nHer sister accuses her husband of being a jerk, and her doctor of trying to medicalize her behavior in order to turn it into a \"condition\" that will keep her on pills for life and make lots of money for Big Pharma.\n\nSandy is fictional, but similar conversations happen every day, not only about obesity but about a host of other marginal conditions that some consider character flaws, others diseases, and still others normal variation in the human condition. Attention deficit dis","wordCount":2738,"version":"1.0.0"},"Revision:xHjy88N2uJvGdgzfw_description":{"_id":"xHjy88N2uJvGdgzfw_description","__typename":"Revision","htmlHighlight":"<p><strong>Health. <\/strong>Note that, for convenience, posts relating to the 2019 coronavirus outbreak are instead found in <a href=\"https://www.lesswrong.com/tag/coronavirus?showPostCount=true&amp;useTagName=true\">here<\/a>.<\/p>"},"Tag:xHjy88N2uJvGdgzfw":{"_id":"xHjy88N2uJvGdgzfw","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:xHjy88N2uJvGdgzfw_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Health / Medicine / Disease","shortName":null,"slug":"health-medicine-disease","core":false,"postCount":298,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-10T11:55:55.351Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:9DmA84e4ZvYoYu6q8_description":{"_id":"9DmA84e4ZvYoYu6q8_description","__typename":"Revision","htmlHighlight":"<p>Posts which (we theorize) are good to show to new users, to get them excited about rationality. Posts listed here should be high-quality classics, should be accessible without having previously read the Sequences or anything else on LessWrong, and should somehow convince a certain sort of reader that rationality is important, and they want to read more about it. A good motivational intro post might argue the value of rationality directly, or it might point out a reasoning flaw which people recognize strongly in themselves, or it might introduce a rationality concept which is particularly sticky.<\/p><p>This tag will be treated as a special case in recommendations, and is configured such that it isn't displayed on posts and doesn't appear in search results when adding tags from a post page (but you can still apply it from here). If you aren't sure whether a post meets the criteria, use the discussion page, or just add it (someone else can downvote the tag's relevance later).<\/p>"},"Tag:9DmA84e4ZvYoYu6q8":{"_id":"9DmA84e4ZvYoYu6q8","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:9DmA84e4ZvYoYu6q8_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Motivational Intro Posts","shortName":null,"slug":"motivational-intro-posts","core":false,"postCount":10,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-04-05T17:35:51.421Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Tag:FtT2T9bRbECCGYxrL":{"_id":"FtT2T9bRbECCGYxrL","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"mPipmBTniuABY5PQy","name":"Philosophy of Language","shortName":null,"slug":"philosophy-of-language","core":false,"postCount":197,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-25T21:25:11.758Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:DsdbQhWAnPqfzo4Yw_description":{"_id":"DsdbQhWAnPqfzo4Yw_description","__typename":"Revision","htmlHighlight":"<p>The <strong>reversal test<\/strong> is a technique for fighting <a href=\"https://wiki.lesswrong.com/wiki/Status_quo_bias\"><u>status quo bias<\/u><\/a> in judgments about the preferred value of a continuous parameter. If one deems the change of the parameter in one direction to be undesirable, the reversal test is to check that either the change of that parameter in the opposite direction (away from status quo) is deemed desirable, or that there are strong reasons to expect that the current value of the parameter is (at least locally) the optimal one.<\/p><p>For example, if it became possible to increase the human lifespan, some would argue that it would be undesirable for people to live longer because, say, overpopulation would be difficult to manage. The reversal test is then to check that the same people accept that <i>shorter<\/i> lifespan is desirable, or that there are really strong reasons to believe that the current lifespan happens to be optimal.<\/p><blockquote><p>The rationale of the Reversal Test is simple: if a continuous parameter admits of a wide range of possible values, only a tiny subset of which can be local optima, then it is prima facie implausible that the actual value of that parameter should just happen to be at one of these rare local optima [...] the burden of proof shifts to those who maintain that some actual parameter is at such a local optimum: they need to provide some good reason for supposing that it is so.<\/p><p>Obviously, the Reversal Test does not show that preferring the status quo is always unjustified. In many cases, it is possible to meet the challenge posed by the Reversal Test<\/p><p>—The reversal test: eliminating status quo bias in applied ethics<\/p><\/blockquote><h2>Main article<\/h2><ul><li>Nick Bostrom, Toby Ord (2006). \"The reversal test: eliminating status quo bias in applied ethics\". <i>Ethics<\/i> (University of Chicago Press) <strong>116<\/strong> (4): 656-679. (<a href=\"http://www.nickbostrom.com/ethics/statusquo.pdf\"><u>PDF<\/u><\/a>)<\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://wiki.lesswrong.com/wiki/Status_quo_bias\"><u>Status quo bias<\/u><\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Privileging_the_hypothesis\"><u>Privileging the hypothesis<\/u><\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Shut_up_and_multiply\"><u>Shut up and multiply<\/u><\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Absurdity_heuristic\"><u>Absurdity heuristic<\/u><\/a><\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"http://philosophicaldisquisitions.blogspot.com/2012/11/the-reversal-test-and-status-quo-bias.html\"><u>\"The Reversal Test and Status Quo Bias\"<\/u><\/a> (John Danaher)<\/li><\/ul>"},"Tag:DsdbQhWAnPqfzo4Yw":{"_id":"DsdbQhWAnPqfzo4Yw","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:DsdbQhWAnPqfzo4Yw_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Reversal Test","shortName":null,"slug":"reversal-test","core":false,"postCount":6,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-20T01:21:41.056Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Tag:P3Wd3f2cWqqvQxDQS":{"_id":"P3Wd3f2cWqqvQxDQS","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Carving / Clustering Reality","shortName":null,"slug":"carving-clustering-reality","core":false,"postCount":18,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-19T21:43:21.175Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:RMtdp6eGNjTZcmwJ6_description":{"_id":"RMtdp6eGNjTZcmwJ6_description","__typename":"Revision","htmlHighlight":"<p><strong>Dissolving the question<\/strong> is the act of making a question no longer necessary: satisfying all associated curiosity, resolving all related confusions, but without answering the question. The classic example is the question \"If a tree falls in a forest and no one hears it, does it make a sound?\". The apparent paradox of the question is, in this case, resolved by pointing out the ambiguity of the term \"sound\". The question can be dissolved by <a href=\"https://www.lesswrong.com/tag/distinctions\">distinguishing<\/a> between \"Sound\" as referring to auditory experience and \"Sound\" as referring to vibrations in the air.&nbsp;<\/p><blockquote><p>“Many philosophers—particularly amateur philosophers, and ancient philosophers—share a dangerous instinct: If you give them a question, they try to answer it.” - Eliezer Yudkowsky, <a href=\"https://www.lesswrong.com/posts/Mc6QcrsbH5NRXbCRX/dissolving-the-question\">Dissolving the Question<\/a><\/p><\/blockquote><p>Sometimes a question <i>does<\/i> have a strong answer as stated, but also needs to be dissolved. This is (<a href=\"https://www.lesswrong.com/posts/NEeW7eSXThPz7o4Ne/thou-art-physics\">arguably<\/a>) the case with <a href=\"https://www.lesswrong.com/tag/free-will\">Free Will<\/a>, for example:<\/p><ul><li>If we do have free will, there's still an additional question of why so many philosophers would conclude otherwise.<\/li><li>If we don't have free will, there's still the question of why so many philosophers think we do.<\/li><\/ul><p>This is (probably) not just a case of \"the other side is being silly\": there does indeed seem to be something weird about the question which deserves scrutiny.<\/p><p>In other words, answering the question doesn't fully address the confusion that the question represents!<\/p><p>A <a href=\"https://www.lesswrong.com/tag/failure-mode\">failure mode<\/a> in this step is giving justifications instead of explaining the process itself. Arguing that the reason we have an illusion of free will was that it was <a href=\"https://www.lesswrong.com/tag/evolutionary-psychology\">evolutionarily adaptive<\/a> falls into this failure mode, as it doesn't explain the cognitive algorithm which produces the feeling of free will, and so doesn't dissolve the question. This can also be thought of as answering the \"Why\" instead of the \"How\", or as failing to provide a <a href=\"https://www.lesswrong.com/tag/gears-level\">gears level model<\/a>.<\/p><p>Dissolving a question usually (always?) involves providing a <a href=\"https://www.lesswrong.com/tag/cognitive-reduction\"><strong>cognitive reduction<\/strong><\/a> of the question.<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/deconfusion\"><strong>deconfusion<\/strong><\/a>, <a href=\"https://www.lesswrong.com/tag/cognitive-reduction\"><strong>cognitive reduction<\/strong><\/a><\/p>"},"Tag:RMtdp6eGNjTZcmwJ6":{"_id":"RMtdp6eGNjTZcmwJ6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:RMtdp6eGNjTZcmwJ6_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Dissolving the Question","shortName":null,"slug":"dissolving-the-question","core":false,"postCount":26,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-03-15T21:09:13.454Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:895quRDaK6gR2rM82":{"_id":"895quRDaK6gR2rM82","__typename":"SocialPreviewType","imageUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/895quRDaK6gR2rM82/n2mplnazxtxb6jrecxw0"},"Post:895quRDaK6gR2rM82":{"_id":"895quRDaK6gR2rM82","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":{"__ref":"PodcastEpisode:aoL7oe5gMG6quKJHj"},"deletedDraft":false,"contents":{"__ref":"Revision:5c639197bcb4ac6367c0fb3a"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":11,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:xHjy88N2uJvGdgzfw"},{"__ref":"Tag:9DmA84e4ZvYoYu6q8"},{"__ref":"Tag:FtT2T9bRbECCGYxrL"},{"__ref":"Tag:DsdbQhWAnPqfzo4Yw"},{"__ref":"Tag:P3Wd3f2cWqqvQxDQS"},{"__ref":"Tag:RMtdp6eGNjTZcmwJ6"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:895quRDaK6gR2rM82"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2010-05-30T21:16:19.449Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"9DmA84e4ZvYoYu6q8":2,"DsdbQhWAnPqfzo4Yw":2,"FtT2T9bRbECCGYxrL":2,"Ng8Gice9KNkncxqcj":7,"P3Wd3f2cWqqvQxDQS":1,"RMtdp6eGNjTZcmwJ6":1,"xHjy88N2uJvGdgzfw":6},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c639197bcb4ac6367c0fb3a","commentCount":356,"voteCount":435,"baseScore":523,"extendedScore":{"reacts":{"hitsTheMark":[{"karma":0,"quotes":["if giving condemnation instead of sympathy decreases the incidence of the disease enough to be worth the hurt feelings, condemn; otherwise, sympathize"],"userId":"vRDXpr5Fpqq7GzRBk","reactType":"created","displayName":"CJ Archer"}]},"agreement":0,"approvalVoteCount":430,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0007284612511284649,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2010-05-30T21:16:19.449Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"highlights","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":32,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":58,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2010-05-30T21:16:19.449Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":"aoL7oe5gMG6quKJHj","forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"diseased-thinking-dissolving-questions-about-disease","title":"Diseased thinking: dissolving questions about disease","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16cfb":{"_id":"5c6392c7bcb4ac6367c16cfb","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>&#8220;Silliest internet atheist argument&#8221; is a hotly contested title, but I have a special place in my heart for the people who occasionally try to prove Biblical fallibility by pointing out whales are not a type of fish.<\/p><p>(this is going to end up being a metaphor for something, so bear with me)<\/p><p>The argument goes like this. Jonah got swallowed by a whale. But the Bible says Jonah got swallowed by a big fish. So the Bible seems to think whales are just big fish. Therefore the Bible is fallible. Therefore, the Bible was not written by God.<\/p><p>The first problem here is that &#8220;whale&#8221; is just our own modern interpretation of the Bible. For all we know, Jonah was swallowed by a really really really big herring.<\/p><p>The second problem is that if the ancient Hebrews want to call whales a kind of fish, let them call whales a kind of fish.<\/p><p>I&#8217;m not making the weak and boring claim that since they&#8217;d never discovered genetics they don&#8217;t know better. I am making the much stronger claim that, even if the ancient Hebrews had taken enough of a break from murdering Philistines and building tabernacles to sequence the genomes of all knownspecies of aquatic animals, there&#8217;s nothing whatsoever wrong, false, or incorrect with them calling a whale a fish.<\/p><p>Now, there&#8217;s something wrong with saying &#8220;whales are phylogenetically just as closely related to bass, herring, and salmon as these three are related to each other.&#8221; What&#8217;s wrong with the statement is that it&#8217;s false. But saying &#8220;whales are a kind of fish&#8221; isn&#8217;t.<\/p><p>Suppose you travel back in time to ancient Israel and try to explain to King Solomon that whales are a kind of mammal and not a kind of fish.<\/p><p>Your translator isn&#8217;t very good, so you pause to explain &#8220;fish&#8221; and &#8220;mammal&#8221; to Solomon. You tell him that fish is &#8220;the sort of thing herring, bass, and salmon are&#8221; and mammal is &#8220;the sort of thing cows, sheep, and pigs are&#8221;. Solomon tells you that your word &#8220;fish&#8221; is Hebrew <i>dag<\/i> and your word &#8220;mammal&#8221; is Hebrew <i>behemah<\/i>.<\/p><p>So you try again and say that a whale is a <i>behemah<\/i>, not a <i>dag<\/i>. Solomon laughs at you and says you&#8217;re an idiot.<\/p><p>You explain that you&#8217;re not an idiot, that in fact all kinds of animals have things called genes, and the genes of a whale are much closer to th... <\/p>","plaintextDescription":"I.\n\n“Silliest internet atheist argument” is a hotly contested title, but I have a special place in my heart for the people who occasionally try to prove Biblical fallibility by pointing out whales are not a type of fish.\n\n(this is going to end up being a metaphor for something, so bear with me)\n\nThe argument goes like this. Jonah got swallowed by a whale. But the Bible says Jonah got swallowed by a big fish. So the Bible seems to think whales are just big fish. Therefore the Bible is fallible. Therefore, the Bible was not written by God.\n\nThe first problem here is that “whale” is just our own modern interpretation of the Bible. For all we know, Jonah was swallowed by a really really really big herring.\n\nThe second problem is that if the ancient Hebrews want to call whales a kind of fish, let them call whales a kind of fish.\n\nI’m not making the weak and boring claim that since they’d never discovered genetics they don’t know better. I am making the much stronger claim that, even if the ancient Hebrews had taken enough of a break from murdering Philistines and building tabernacles to sequence the genomes of all knownspecies of aquatic animals, there’s nothing whatsoever wrong, false, or incorrect with them calling a whale a fish.\n\nNow, there’s something wrong with saying “whales are phylogenetically just as closely related to bass, herring, and salmon as these three are related to each other.” What’s wrong with the statement is that it’s false. But saying “whales are a kind of fish” isn’t.\n\nSuppose you travel back in time to ancient Israel and try to explain to King Solomon that whales are a kind of mammal and not a kind of fish.\n\nYour translator isn’t very good, so you pause to explain “fish” and “mammal” to Solomon. You tell him that fish is “the sort of thing herring, bass, and salmon are” and mammal is “the sort of thing cows, sheep, and pigs are”. Solomon tells you that your word “fish” is Hebrew dag and your word “mammal” is Hebrew behemah.\n\nSo you try again and","wordCount":5278,"version":"1.0.0"},"Revision:AHK82ypfxF45rqh9D_description":{"_id":"AHK82ypfxF45rqh9D_description","__typename":"Revision","htmlHighlight":"<p>A common <a href=\"https://www.lesswrong.com/tag/failiure-mode\">Failure mode<\/a> is failing to notice a <strong>Distinction<\/strong> between two or more things. on the other hand, noticing distinctions can lead to insight, dissolving confusion, and better results.<\/p><blockquote><p>“intelligence is the measure of the number and the quality of the distinctions you have in a given situation” - Tony Robbins<\/p><\/blockquote><p>Thus, making and noticing distinctions is a core skill.<\/p><p><strong>See also: <\/strong><a href=\"https://www.lesswrong.com/tag/decoupling-vs-contextualizing\">Decoupling vs Contextualizing<\/a>, <a href=\"https://www.lesswrong.com/tag/conflict-vs-mistake\">Conflict vs Mistake<\/a>, <a href=\"https://www.lesswrong.com/tag/compartmentalization\">Compartmentalization<\/a>, <a href=\"https://www.lesswrong.com/tag/bucket-errors\">Bucket Errors<\/a>, <a href=\"https://www.lesswrong.com/tag/map-and-territory\">Map and Territory<\/a>, <a href=\"https://www.lesswrong.com/tag/fallacy-of-gray\">Fallacy of Gray<\/a>, <a href=\"https://www.lesswrong.com/tag/wanting-and-liking\">Wanting and liking<\/a><\/p><p><strong>External Links:<\/strong><br><a href=\"https://en.wikipedia.org/wiki/Use%E2%80%93mention_distinction\">Use–mention distinction<\/a><\/p>"},"Tag:AHK82ypfxF45rqh9D":{"_id":"AHK82ypfxF45rqh9D","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:AHK82ypfxF45rqh9D_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Distinctions","shortName":null,"slug":"distinctions","core":false,"postCount":108,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-23T20:53:12.566Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:aMHq4mA2PHSM2TMoH":{"_id":"aMHq4mA2PHSM2TMoH","__typename":"SocialPreviewType","imageUrl":""},"Post:aMHq4mA2PHSM2TMoH":{"_id":"aMHq4mA2PHSM2TMoH","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16cfb"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":21,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:FtT2T9bRbECCGYxrL"},{"__ref":"Tag:AHK82ypfxF45rqh9D"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:aMHq4mA2PHSM2TMoH"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-11-21T14:34:26.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"AHK82ypfxF45rqh9D":1,"FtT2T9bRbECCGYxrL":6,"Ng8Gice9KNkncxqcj":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16cfb","commentCount":9,"voteCount":86,"baseScore":97,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":84,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00020500000391621143,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-07-29T00:36:45.104Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":14,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-categories-were-made-for-man-not-man-for-the-categories","title":"The Categories Were Made For Man, Not Man For The Categories","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392babcb4ac6367c167c9":{"_id":"5c6392babcb4ac6367c167c9","__typename":"Revision","htmlHighlight":"<p><strong>Related to: <\/strong><a href=\"/lw/lc/leaky_generalizations/\">Leaky Generalizations<\/a>, <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">Replace the Symbol With The Substance<\/a>, <a href=\"/lw/ny/sneaking_in_connotations/\">Sneaking In Connotations<\/a><\/p><p>David Stove once <a href=\"http://web.maths.unsw.edu.au/~jim/worst.html\">ran a contest<\/a> to find the Worst Argument In The World, but he awarded the prize to his own entry, and one that shored up his politics to boot. It hardly seems like an objective process.<br /><br />If he can unilaterally declare a Worst Argument, then so can I. I declare the Worst Argument In The World to be this: \"X is in a category whose archetypal member gives us a certain emotional reaction. Therefore, we should apply that emotional reaction to X, even though it is not a central category member.\"<br /><br />Call it the Noncentral Fallacy. It sounds dumb when you put it like that. Who even does that, anyway?<br /><br />It sounds dumb only because we are talking soberly of categories and features. As soon as the argument gets framed in terms of <em>words<\/em>, it becomes so powerful that somewhere between many and most of the bad arguments in politics, philosophy and culture take some form of the noncentral fallacy. Before we get to those, let's look at a simpler example.<br /><br />Suppose someone wants to build a statue honoring Martin Luther King Jr. for his nonviolent resistance to racism. An opponent of the statue objects: \"But Martin Luther King was a <em>criminal<\/em>!\"<br /><br />Any historian can confirm this is correct. A criminal is technically someone who breaks the law, and King knowingly broke a law against peaceful anti-segregation protest - hence his famous Letter from Birmingham Jail.<br /><br />But in this case calling Martin Luther King a criminal is the noncentral. The archetypal criminal is a mugger or bank robber. He is driven only by greed, preys on the innocent, and weakens the fabric of society. Since we don't like these things, calling someone a \"criminal\" naturally lowers our opinion of them. <br /><br />The opponent is saying \"Because you don't like criminals, and Martin Luther King is a criminal, you should stop liking Martin Luther King.\" But King doesn't share the important criminal features of being driven by greed, preying on the innocent, or weakening the fabric of society that made us dislike criminals in the first place. Therefore, even though he is a criminal, there is no reason to dislike King.<\/p><p>This all seems so nice and logical when it's presented in this format. Unfortunately, it's also one hundred percent contrary to instinct: the urge is to respond \"Martin Luther King? A criminal? No he wasn't! You take ... <\/p>","plaintextDescription":"Related to: Leaky Generalizations, Replace the Symbol With The Substance, Sneaking In Connotations\n\nDavid Stove once ran a contest to find the Worst Argument In The World, but he awarded the prize to his own entry, and one that shored up his politics to boot. It hardly seems like an objective process.\n\nIf he can unilaterally declare a Worst Argument, then so can I. I declare the Worst Argument In The World to be this: \"X is in a category whose archetypal member gives us a certain emotional reaction. Therefore, we should apply that emotional reaction to X, even though it is not a central category member.\"\n\nCall it the Noncentral Fallacy. It sounds dumb when you put it like that. Who even does that, anyway?\n\nIt sounds dumb only because we are talking soberly of categories and features. As soon as the argument gets framed in terms of words, it becomes so powerful that somewhere between many and most of the bad arguments in politics, philosophy and culture take some form of the noncentral fallacy. Before we get to those, let's look at a simpler example.\n\nSuppose someone wants to build a statue honoring Martin Luther King Jr. for his nonviolent resistance to racism. An opponent of the statue objects: \"But Martin Luther King was a criminal!\"\n\nAny historian can confirm this is correct. A criminal is technically someone who breaks the law, and King knowingly broke a law against peaceful anti-segregation protest - hence his famous Letter from Birmingham Jail.\n\nBut in this case calling Martin Luther King a criminal is the noncentral. The archetypal criminal is a mugger or bank robber. He is driven only by greed, preys on the innocent, and weakens the fabric of society. Since we don't like these things, calling someone a \"criminal\" naturally lowers our opinion of them.\n\nThe opponent is saying \"Because you don't like criminals, and Martin Luther King is a criminal, you should stop liking Martin Luther King.\" But King doesn't share the important criminal features of being driven","wordCount":2143,"version":"1.0.0"},"Revision:ZXFpyQWPB5ideFbEG_description":{"_id":"ZXFpyQWPB5ideFbEG_description","__typename":"Revision","htmlHighlight":"<p>A <strong>conversation <\/strong>is when two people talk or correspond. Most content here is about <i>how to have good conversations.<\/i>&nbsp;(<i>This wikitag needs work.)<\/i><br><br>For records of conversations, see Interviews, Debates,...<\/p><p>See also:<\/p><ul><li>Communication<\/li><li>Communication Cultures<\/li><li>Relationshops<\/li><li>Community<\/li><\/ul><h2><i>Conversation Halter<\/i><\/h2><p>This term was introduced on LessWrong by Eliezer in the <a href=\"https://www.lesswrong.com/posts/wqmmv6NraYv4Xoeyj/conversation-halters\">eponymous post<\/a>:<\/p><blockquote><p><i>While working on my book, I found in passing that I'd developed a list of what I started out calling \"stonewalls\", but have since decided to refer to as \"conversation halters\".&nbsp; These tactics of argument are distinguished by their being attempts to cut off the flow of debate - which is rarely the wisest way to think, and should certainly rate an alarm bell.<\/i><\/p><\/blockquote>"},"Tag:ZXFpyQWPB5ideFbEG":{"_id":"ZXFpyQWPB5ideFbEG","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZXFpyQWPB5ideFbEG_description"},"canVoteOnRels":null,"userId":"73yyrm8KF6GDK9sRy","name":"Conversation (topic)","shortName":null,"slug":"conversation-topic","core":false,"postCount":133,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-28T16:22:41.929Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:yCWPkLi8wJvewPbEp":{"_id":"yCWPkLi8wJvewPbEp","__typename":"SocialPreviewType","imageUrl":""},"Post:yCWPkLi8wJvewPbEp":{"_id":"yCWPkLi8wJvewPbEp","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392babcb4ac6367c167c9"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:dJ6eJxJrCEget7Wb6"},{"__ref":"Tag:9DmA84e4ZvYoYu6q8"},{"__ref":"Tag:ZXFpyQWPB5ideFbEG"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:yCWPkLi8wJvewPbEp"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2012-08-27T03:36:08.152Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"9DmA84e4ZvYoYu6q8":3,"Ng8Gice9KNkncxqcj":8,"ZXFpyQWPB5ideFbEG":1,"dJ6eJxJrCEget7Wb6":5},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392babcb4ac6367c167c9","commentCount":1768,"voteCount":374,"baseScore":416,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":371,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0007071097497828305,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-10-19T15:04:11.816Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":18,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":54,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-noncentral-fallacy-the-worst-argument-in-the-world","title":"The noncentral fallacy - the worst argument in the world?","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:xKzbY7Nfgy5hSH9Ee":{"_id":"xKzbY7Nfgy5hSH9Ee","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Part of what bothers me  &#8211; and apparently several others &#8211; about <A HREF=\"http://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/\">yesterday&#8217;s motte-and-bailey discussion<\/A> is that here&#8217;s a fallacy &#8211; a pretty successful fallacy &#8211; that depends entirely on people not being entirely clear on what they&#8217;re arguing about. Somebody says God doesn&#8217;t exist. Another person objects that God is just a name for the order and beauty in the universe. Then this somehow helps defend the position that God is a supernatural creator being. How does that even happen?<\/p><p>&#8220;Sir, you&#8217;ve been accused of murdering your wife. We have three witnesses who said you did it. What do you have to say for yourself?&#8221;<\/p><p>&#8220;Well, your honor, I think it&#8217;s quite clear I didn&#8217;t murder the President. For one thing, he&#8217;s surrounded by Secret Service agents. For another, check the news. The President&#8217;s still alive.&#8221;<\/p><p>&#8220;Huh. For some reason I vaguely remember thinking you didn&#8217;t have a case. Yet now that I hear you talk, everything you say is incredibly persuasive. You&#8217;re free to go.&#8221;<\/p><p>While motte-and-bailey is less subtle, it seems to require a similar sort of misdirection. I&#8217;m not saying it&#8217;s impossible. I&#8217;m just saying it&#8217;s a fact that needs to be explained.<\/p><p>When everything works the way it&#8217;s supposed to in philosophy textbooks, arguments are supposed to go one of a couple of ways:<\/p><p>1. Questions of empirical fact, like &#8220;Is the Earth getting warmer?&#8221; or &#8220;Did aliens build the pyramids?&#8221;. You debate these by presenting factual evidence, like &#8220;An average of global weather station measurements show 2014 is the hottest year on record&#8221; or &#8220;One of the bricks at Giza says &#8216;Made In Tau Ceti V&#8217; on the bottom.&#8221; Then people try to refute these facts or present facts of their own.<\/p><p>2. Questions of morality, like &#8220;Is it wrong to abort children?&#8221; or &#8220;Should you refrain from downloading music you have not paid for?&#8221; You can only debate these <i>well<\/i> if you&#8217;ve already agreed upon a moral framework, like a particular version of natural law or consequentialism. But you can <i>sort of<\/i> debate them by comparing to examples of agreed-upon moral questions and trying to maintain consistency. For exmaple, &#8220;You wouldn&#8217;t kill a one day old baby, so how is a nine mo... <\/p>","plaintextDescription":"I.\n\nPart of what bothers me – and apparently several others – about yesterday’s motte-and-bailey discussion is that here’s a fallacy – a pretty successful fallacy – that depends entirely on people not being entirely clear on what they’re arguing about. Somebody says God doesn’t exist. Another person objects that God is just a name for the order and beauty in the universe. Then this somehow helps defend the position that God is a supernatural creator being. How does that even happen?\n\n“Sir, you’ve been accused of murdering your wife. We have three witnesses who said you did it. What do you have to say for yourself?”\n\n“Well, your honor, I think it’s quite clear I didn’t murder the President. For one thing, he’s surrounded by Secret Service agents. For another, check the news. The President’s still alive.”\n\n“Huh. For some reason I vaguely remember thinking you didn’t have a case. Yet now that I hear you talk, everything you say is incredibly persuasive. You’re free to go.”\n\nWhile motte-and-bailey is less subtle, it seems to require a similar sort of misdirection. I’m not saying it’s impossible. I’m just saying it’s a fact that needs to be explained.\n\nWhen everything works the way it’s supposed to in philosophy textbooks, arguments are supposed to go one of a couple of ways:\n\n1. Questions of empirical fact, like “Is the Earth getting warmer?” or “Did aliens build the pyramids?”. You debate these by presenting factual evidence, like “An average of global weather station measurements show 2014 is the hottest year on record” or “One of the bricks at Giza says ‘Made In Tau Ceti V’ on the bottom.” Then people try to refute these facts or present facts of their own.\n\n2. Questions of morality, like “Is it wrong to abort children?” or “Should you refrain from downloading music you have not paid for?” You can only debate these well if you’ve already agreed upon a moral framework, like a particular version of natural law or consequentialism. But you can sort of debate them by com","wordCount":6640,"version":"1.1.0"},"Revision:DdgSyQoZXjj3KnF4N_description":{"_id":"DdgSyQoZXjj3KnF4N_description","__typename":"Revision","htmlHighlight":"<p><strong>Tribalism<\/strong> or <strong>Coalitional Instincts <\/strong>is closely connected to the concept of in/out-groups. Coalitional instincts drive humans to act in ways which cause them join, support, defend, and maintain their membership in various coalitions that are defined by sharing a common identity. An illustrative example can be found in <a href=\"https://www.lesswrong.com/posts/6hfGNLf4Hg5DXqJCF/a-fable-of-science-and-politics\">A Fable of Science and Politics<\/a>.<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/blues-and-greens\">Blues and Greens<\/a>, <a href=\"https://www.lesswrong.com/tag/groupthink\">Groupthink<\/a>, <a href=\"https://www.lesswrong.com/tag/motivated-reasoning\">Motivated Reasoning<\/a>, <a href=\"https://www.lesswrong.com/tag/social-and-cultural-dynamics\">Social and Cultural Dynamics<\/a>, <a href=\"https://www.lesswrong.com/tag/social-reality\">Social Reality<\/a>.<\/p><blockquote>The primary function that drove the evolution of coalitions is the amplification of the power of its members in conflicts with non-members. This function explains a number of otherwise puzzling phenomena. For example,  ancestrally, if you had no coalition you were nakedly at the mercy of everyone else, so the instinct to belong to a coalition has urgency, preexisting and superseding any policy-driven basis for membership. This is why group beliefs are free to be so weird. [...] <\/blockquote><blockquote>... to earn membership in a group you must send signals that clearly indicate that you differentially support it, compared to rival groups. Hence, optimal weighting of beliefs and communications in the individual mind will make it feel good to think and express content conforming to and flattering to one&#x2019;s group&#x2019;s shared beliefs and to attack and misrepresent rival groups. The more biased away from neutral truth, the better the communication functions to affirm coalitional identity, generating polarization in excess of actual policy disagreements. Communications of practical and functional truths are generally useless as differential signals, because any honest person might say them regardless of coalitional loyalty. In contrast, unusual, exaggerated beliefs [...] are unlikely to be said except as expressive of identity, because there is no external reality to motivate nonmembers to speak absurdities. <\/blockquote><blockquote>-- John Tooby, &quot;<a href=\"https://www.edge.org/conversation/john_tooby-coalitional-instincts\">Coalitional Instincts<\/a>&quot;<\/blockquote><br><blockquote>Humans interact in dense social networks, and this poses a problem for bystanders when conflicts arise: which side, if any, to support. Choosing sides is a difficult strategic problem because the outcome of a conflict critically depends on which side other bystanders support. One strategy is siding with the higher status disputant, which can allow bystanders to coordinate with one another to take the same side, reducing fighting costs. However, this strategy carries the cost of e<\/blockquote>... "},"Tag:DdgSyQoZXjj3KnF4N":{"_id":"DdgSyQoZXjj3KnF4N","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:DdgSyQoZXjj3KnF4N_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Tribalism","shortName":null,"slug":"tribalism","core":false,"postCount":60,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-13T15:43:11.661Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:SJFsFfFhE6m2ThAYJ_description":{"_id":"SJFsFfFhE6m2ThAYJ_description","__typename":"Revision","htmlHighlight":"<p>One principle of rationality is that &quot;<a href=\"https://www.lesswrong.com/s/7gRSERQZbqTuLX5re/p/a7n8GdKiAZRX86T5A\">beliefs should pay rent in <strong>anticipated experiences<\/strong><\/a>.&quot; If you believe in something, what do you expect to be different as a result? What does the belief say should happen, and what does it say should <em>not<\/em> happen? If you have a verbal disagreement with someone, how does your disagreement cash out in differing expectations?<\/p><p>If two people try to get specific about the anticipated experiences driving their disagreement, one method for doing so is the <a href=\"https://www.lesswrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-resolving-disagreement\">double crux<\/a> technique. The notion that beliefs are models of what we expect to experience is also one of the basic premises of <a href=\"https://www.lesswrong.com/tag/predictive-processing\">predictive processing<\/a> theories of how the brain works. Beliefs that do not pay rent may be related to <a href=\"https://www.lesswrong.com/posts/4xKeNKFXFB458f5N8/ethnic-tension-and-meaningless-arguments\">meaningless arguments<\/a> driven by <a href=\"https://www.lesswrong.com/tag/coalitional-instincts\">coalitional instincts<\/a>. <\/p><blockquote> <em>If a tree falls in a forest and no one hears it, does it make a sound? One says, &#x201C;Yes it does, for it makes vibrations in the air.&#x201D; Another says, &#x201C;No it does not, for there is no auditory processing in any brain.&#x201D;<\/em>  [...]<\/blockquote><blockquote>Suppose that, after a tree falls, the two arguers walk into the forest together. Will one expect to see the tree fallen to the right, and the other expect to see the tree fallen to the left? Suppose that before the tree falls, the two leave a sound recorder next to the tree. Would one, playing back the recorder, expect to hear something different from the other? Suppose they attach an electroencephalograph to any brain in the world; would one expect to see a different trace than the other?<\/blockquote><blockquote>Though the two argue, one saying &#x201C;No,&#x201D; and the other saying &#x201C;Yes,&#x201D; they do not anticipate any different experiences. The two think they have different models of the world, but they have no difference with respect to what they expect will <em>happen to<\/em> them; their maps of the world do not diverge in any sensory detail.<\/blockquote><blockquote>-- Eliezer Yudkowsky, <a href=\"https://www.lesswrong.com/s/7gRSERQZbqTuLX5re/p/a7n8GdKiAZRX86T5A\">Making Beliefs Pay Rent (In Anticipated Experiences)<\/a><\/blockquote>"},"Tag:SJFsFfFhE6m2ThAYJ":{"_id":"SJFsFfFhE6m2ThAYJ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:SJFsFfFhE6m2ThAYJ_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Anticipated Experiences","shortName":null,"slug":"anticipated-experiences","core":false,"postCount":48,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-13T16:19:09.687Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:hD87ntaKvNsyFbzTt_description":{"_id":"hD87ntaKvNsyFbzTt_description","__typename":"Revision","htmlHighlight":"<p>Emotivism is a meta-ethical model. It's central claim is that moral statements do not express propositions but emotional attitudes.<\/p>"},"Tag:hD87ntaKvNsyFbzTt":{"_id":"hD87ntaKvNsyFbzTt","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:hD87ntaKvNsyFbzTt_description"},"canVoteOnRels":null,"userId":"aPtPfP4Ym6HFu6rxd","name":"Emotivism","shortName":null,"slug":"emotivism","core":false,"postCount":2,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-11-12T10:20:01.671Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:4xKeNKFXFB458f5N8":{"_id":"4xKeNKFXFB458f5N8","__typename":"SocialPreviewType","imageUrl":""},"Post:4xKeNKFXFB458f5N8":{"_id":"4xKeNKFXFB458f5N8","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:xKzbY7Nfgy5hSH9Ee"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":27,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:DdgSyQoZXjj3KnF4N"},{"__ref":"Tag:SJFsFfFhE6m2ThAYJ"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:hD87ntaKvNsyFbzTt"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:4xKeNKFXFB458f5N8"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-11-05T03:38:42.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"DdgSyQoZXjj3KnF4N":3,"SJFsFfFhE6m2ThAYJ":2,"gHCNhqxuJq2bZ2akb":2,"hD87ntaKvNsyFbzTt":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"xKzbY7Nfgy5hSH9Ee","commentCount":8,"voteCount":67,"baseScore":85,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":66,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00017800000205170363,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-01-25T14:27:57.461Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":6,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"ethnic-tension-and-meaningless-arguments","title":"Ethnic Tension And Meaningless Arguments","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:MqKMEqNgPXyFsnqiP":{"_id":"MqKMEqNgPXyFsnqiP","__typename":"Chapter","createdAt":"2017-08-24T01:27:53.657Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:MqKMEqNgPXyFsnqiP_contents"},"number":0,"sequenceId":"NHXY86jBahi968uW4","postIds":["895quRDaK6gR2rM82","aMHq4mA2PHSM2TMoH","yCWPkLi8wJvewPbEp","4xKeNKFXFB458f5N8"],"posts":[{"__ref":"Post:895quRDaK6gR2rM82"},{"__ref":"Post:aMHq4mA2PHSM2TMoH"},{"__ref":"Post:yCWPkLi8wJvewPbEp"},{"__ref":"Post:4xKeNKFXFB458f5N8"}]},"Revision:bYXxHzJpprMAzncow":{"_id":"bYXxHzJpprMAzncow","__typename":"Revision","htmlHighlight":"<p><i>[content warning: puns. This is mostly self-plagiarism from my Tumblr and Twitter]<\/i><\/p><p>Once upon a time there was a small desert village with a single well outside town. One day a young woman went to the well to fetch water, and the well heard her crying, and asked “What’s wrong?”<\/p><p>She stopped her sobbing and asked the well “You can talk?”<\/p><p>“Yes,” said the well. “Long ago, the witch who lives in this town gave me life so I could serve as a guardian to the townspeople.”<\/p><p>“Alas,” said the young woman. “I am the daughter of that witch. She lived in peace with the townsfolk for many years. But the new mayor, who is a violent and hateful man, riled the people up against her, and they burned her at the stake. I am young and still do not know very much magic. I tried to curse them, but my curses fizzled. Now I worry I will never avenge my mother’s death.”<\/p><p>“Do not be afraid,” said the well. “I will take care of this.”<\/p><p>The next morning, when the Mayor came to fetch water from the well, he heard an odd noise coming from the bottom. He peered over as far as he could to see what was happening. Then an impossibly long arm shot up from the bottom of the well, grabbed the mayor, and pulled him into the well shaft. There was a horrible crunching sound, and nobody ever saw the Mayor again. The townsfolk apologized to the witch’s daughter, and they all lived happily ever after.<\/p><p>Moral of the story: Living well is the best revenge.<\/p><hr><p>Pixar’s movie <i>Up<\/i> won the Academy Award for “Best Picture” and was widely hailed as one of the best children’s films of the decade. In fact, some people argued it was <i>too<\/i> good, and that kids were ignoring school, chores, and other responsibilities to watch it again and again. They said that along with the cute plot, the short, catchy name gave it an almost drug-like addictive quality. This made a lot of people very angry, and Pixar agreed to give its addictive must-watch movies longer names in the future.<\/p><p>Moral of the story: Do not call <i>Up<\/i> what you cannot put down.<\/p><hr><p>There’s a new report out of CERN that a team of scientists has unraveled the structure of the photon. Apparently this started years ago when some equations showed that photons acted like tiny “hands” – structures with a “palm” and radiating “fingers” – which “crawl” across time/space and “grab” the solid particles they interact with. This explained most of the properties of light but wasn’t an exact match f... <\/p>","plaintextDescription":"[content warning: puns. This is mostly self-plagiarism from my Tumblr and Twitter]\n\nOnce upon a time there was a small desert village with a single well outside town. One day a young woman went to the well to fetch water, and the well heard her crying, and asked “What’s wrong?”\n\nShe stopped her sobbing and asked the well “You can talk?”\n\n“Yes,” said the well. “Long ago, the witch who lives in this town gave me life so I could serve as a guardian to the townspeople.”\n\n“Alas,” said the young woman. “I am the daughter of that witch. She lived in peace with the townsfolk for many years. But the new mayor, who is a violent and hateful man, riled the people up against her, and they burned her at the stake. I am young and still do not know very much magic. I tried to curse them, but my curses fizzled. Now I worry I will never avenge my mother’s death.”\n\n“Do not be afraid,” said the well. “I will take care of this.”\n\nThe next morning, when the Mayor came to fetch water from the well, he heard an odd noise coming from the bottom. He peered over as far as he could to see what was happening. Then an impossibly long arm shot up from the bottom of the well, grabbed the mayor, and pulled him into the well shaft. There was a horrible crunching sound, and nobody ever saw the Mayor again. The townsfolk apologized to the witch’s daughter, and they all lived happily ever after.\n\nMoral of the story: Living well is the best revenge.\n\n----------------------------------------\n\nPixar’s movie Up won the Academy Award for “Best Picture” and was widely hailed as one of the best children’s films of the decade. In fact, some people argued it was too good, and that kids were ignoring school, chores, and other responsibilities to watch it again and again. They said that along with the cute plot, the short, catchy name gave it an almost drug-like addictive quality. This made a lot of people very angry, and Pixar agreed to give its addictive must-watch movies longer names in the future.\n\nMoral of t","wordCount":1206,"version":"1.1.0"},"SocialPreviewType:BZMc9Xzqw5WcCMHrr":{"_id":"BZMc9Xzqw5WcCMHrr","__typename":"SocialPreviewType","imageUrl":""},"Post:BZMc9Xzqw5WcCMHrr":{"_id":"BZMc9Xzqw5WcCMHrr","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:bYXxHzJpprMAzncow"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":5,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:hNFdS3rRiYgqqD8aM"}],"socialPreviewData":{"__ref":"SocialPreviewType:BZMc9Xzqw5WcCMHrr"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-10-18T02:22:45.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":5,"hNFdS3rRiYgqqD8aM":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"bYXxHzJpprMAzncow","commentCount":1,"voteCount":35,"baseScore":48,"extendedScore":{"reacts":{"laugh":[{"karma":11,"quotes":["Moral of the story: If you want a vision of the future, imagine a human face booting on a stamp forever."],"userId":"RzJoMN4BCcJLRYzPa","reactType":"created","displayName":"Ligeia"}]},"agreement":0,"approvalVoteCount":35,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00013141850649844855,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2017-12-22T10:38:01.763Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2016-10-18T02:22:45.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-moral-of-the-story","title":"The Moral Of The Story","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:5LrNYjZLYMtLE2bLR":{"_id":"5LrNYjZLYMtLE2bLR","__typename":"Chapter","createdAt":"2017-09-05T02:38:57.686Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"NHXY86jBahi968uW4","postIds":["BZMc9Xzqw5WcCMHrr"],"posts":[{"__ref":"Post:BZMc9Xzqw5WcCMHrr"}]},"Revision:NHXY86jBahi968uW4_contents":{"_id":"NHXY86jBahi968uW4_contents","__typename":"Revision","version":"1.7.0","updateType":"minor","editedAt":"2022-06-23T23:13:55.207Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>\"The essay “How An Algorithm Feels From The Inside” is a gift that keeps on giving. You can get a reputation as a daring and original thinker just by copy-pasting it at different arguments with a couple of appropriate words substituted for one another, mad-libs like. It is the solution to something like 25% of extant philosophical problems.\"<\/p>","commitMessage":"","wordCount":58,"htmlHighlight":"<p>\"The essay “How An Algorithm Feels From The Inside” is a gift that keeps on giving. You can get a reputation as a daring and original thinker just by copy-pasting it at different arguments with a couple of appropriate words substituted for one another, mad-libs like. It is the solution to something like 25% of extant philosophical problems.\"<\/p>","plaintextDescription":"\"The essay “How An Algorithm Feels From The Inside” is a gift that keeps on giving. You can get a reputation as a daring and original thinker just by copy-pasting it at different arguments with a couple of appropriate words substituted for one another, mad-libs like. It is the solution to something like 25% of extant philosophical problems.\""},"Sequence:NHXY86jBahi968uW4":{"_id":"NHXY86jBahi968uW4","__typename":"Sequence","chapters":[{"__ref":"Chapter:MqKMEqNgPXyFsnqiP"},{"__ref":"Chapter:5LrNYjZLYMtLE2bLR"}],"createdAt":"2017-08-24T01:26:10.168Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:NHXY86jBahi968uW4_contents"},"gridImageId":"sequencesgrid/bgpjay2m1labmbqdtjmi","bannerImageId":"sequences/vbpmg1s6k2euyoxi6dcp","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":5,"readPostsCount":0,"title":"Categorisation and Concepts","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:RPGmHEWZ5bmKBGnGc_contents":{"_id":"RPGmHEWZ5bmKBGnGc_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-09-05T01:03:41.764Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:dxn9HiNqh76A3nCGi":{"_id":"dxn9HiNqh76A3nCGi","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>A recent breakthrough in pseudoscience: the location of the Great Pyramid of Giza encodes the speed of light to seven decimal places.<\/p><p>This is actually true. The speed of light in a vacuum <a href=\"https://en.wikipedia.org/wiki/Speed_of_light\">is<\/a> 299,792,458 meters per second. The coordinates of of the Great Pyramid are 29.9792458° N, 31.1342880° E (you can <a href=\"https://www.google.com/maps/place/29%C2%B058'45.3%22N+31%C2%B008'03.4%22E/@29.9792458,31.1337408,19z/data=!3m1!4b1!4m5!3m4!1s0x0:0x0!8m2!3d29.9792458!4d31.134288\">confirm with Google Maps<\/a> that this gets you right on top of the Pyramid). The speed of light and the latitude number there have all the same digits. That’s a pretty impressive coincidence.<\/p><p>You might think this is idiotic because the meter was invented by 1600s French people. If ancient aliens or Atlanteans built the pyramids, why would they encode their secret wisdom using a unit of measurement from 1600s France? But there’s a way around this objection: the 1600s French people <a href=\"https://en.wikipedia.org/wiki/Metre#History_of_definition\">defined their meter<\/a> as 1/10,000,000th the distance between the Equator and the North Pole. If the aliens also thought that was an interesting way to measure length, then they could have encoded their secret wisdom in it. So you wouldn’t need aliens who could predict the thoughts of 1600s Frenchmen. Just aliens who <i>thought exactly like<\/i> 1600s Frenchmen.<\/p><p>(actually, a different group of 1600s Frenchmen proposed a different version of the meter, defined as the length of a pendulum with a half-period of one second. This turned out to be 99.7% of the 1/10,000,000th-the-way-to-the-North-Pole definition, so either one works unless you want super-exactness. I think a much more interesting conspiracy theory would be that aliens designed the Earth to encode secret wisdom about the periods of pendulums.)<\/p><p>But realistically, aliens who think suspiciously like French people probably weren’t involved. So how do we explain the coincidence? <\/p><p><b>II.<\/b><\/p><p>The following is indebted to user mrfintoil’s <a href=\"https://www.metabunk.org/debunked-the-great-pyramid-of-giza-and-the-speed-of-light.t2154/\">great explanation on metabunk.org<\/a>.<\/p><p>First, it’s <i>not<\/i> a coincidence to seven decimal places. Yes, that particular nine-digit sequence lands you atop the Great Pyramid. But that gives you way more precision than you need – cutting off the last three digits actually gets you closer rather than further from the center of the Pyramid. The only numbers that are doing any work are the 29.9792° N. So you really only get four decimal places worth of coincidence.<\/p><p>On the other hand, matching six digits is still pretty good. That’s literally a one-in-a-million chance.<\/p><p>So here the explanation has to go to how hard the pseudoscientists worked... <\/p>","plaintextDescription":"I.\n\nA recent breakthrough in pseudoscience: the location of the Great Pyramid of Giza encodes the speed of light to seven decimal places.\n\nThis is actually true. The speed of light in a vacuum is 299,792,458 meters per second. The coordinates of of the Great Pyramid are 29.9792458° N, 31.1342880° E (you can confirm with Google Maps that this gets you right on top of the Pyramid). The speed of light and the latitude number there have all the same digits. That’s a pretty impressive coincidence.\n\nYou might think this is idiotic because the meter was invented by 1600s French people. If ancient aliens or Atlanteans built the pyramids, why would they encode their secret wisdom using a unit of measurement from 1600s France? But there’s a way around this objection: the 1600s French people defined their meter as 1/10,000,000th the distance between the Equator and the North Pole. If the aliens also thought that was an interesting way to measure length, then they could have encoded their secret wisdom in it. So you wouldn’t need aliens who could predict the thoughts of 1600s Frenchmen. Just aliens who thought exactly like 1600s Frenchmen.\n\n(actually, a different group of 1600s Frenchmen proposed a different version of the meter, defined as the length of a pendulum with a half-period of one second. This turned out to be 99.7% of the 1/10,000,000th-the-way-to-the-North-Pole definition, so either one works unless you want super-exactness. I think a much more interesting conspiracy theory would be that aliens designed the Earth to encode secret wisdom about the periods of pendulums.)\n\nBut realistically, aliens who think suspiciously like French people probably weren’t involved. So how do we explain the coincidence?\n\nII.\n\nThe following is indebted to user mrfintoil’s great explanation on metabunk.org.\n\nFirst, it’s not a coincidence to seven decimal places. Yes, that particular nine-digit sequence lands you atop the Great Pyramid. But that gives you way more precision than you need ","wordCount":2238,"version":"1.0.1"},"Revision:xgpBASEThXPuKRhbS_description":{"_id":"xgpBASEThXPuKRhbS_description","__typename":"Revision","htmlHighlight":"<p><strong>Epistemology<\/strong> is the study of how we know the world. It's both a topic in philosophy and a practical concern for how we come to believe things are true.<\/p><p><strong>Related Sequences:<\/strong> <a href=\"https://www.lesswrong.com/s/SqFbMbtxGybdS2gRs\">Highly Advanced Epistemology 101 for Beginners<\/a>, <a href=\"https://www.lesswrong.com/s/FYMiCeXEgMzsB5stm\">Concepts in formal epistemology<\/a>, <a href=\"https://www.lesswrong.com/s/GTEay24Lxm3xoE4hy\">Novum Organum<\/a><\/p><p>Projects to help people improve their epistemics and individuals to contact:<\/p><ul><li>Pastcasting - forecasting past results so you get instant feedback<ul><li><a href=\"https://www.quantifiedintuitions.org/pastcasting\">https://www.quantifiedintuitions.org/pastcasting<\/a><\/li><\/ul><\/li><li>Calibration - see how justified your own confidence is<ul><li>https://www.quantifiedintuitions.org/calibration<\/li><\/ul><\/li><li>Historical Base rates - much thinking requires knowing roughly how often things have happened in the past<ul><li>Seems like Our World In Data might do some work here<\/li><li>There is at least one other effort<\/li><\/ul><\/li><li>Increasing summarisation - making it easier to get a basic understanding on EA/LessWrong topics<ul><li><a href=\"https://www.super-linear.org/twitter-thread?recordId=rec08e5GTz7A8U4kG\">Nonlinear offer a range of prizes for summaries of such works<\/a><ul><li>Nathan Young<\/li><\/ul><\/li><\/ul><\/li><\/ul><p>&nbsp;<\/p><p>Potential projects:<\/p><ul><li>Displaying estimates<ul><li>The <a href=\"https://www.lesswrong.com/tag/squiggle\">Squiggle<\/a> team seem focused on the first step of this<ul><li>Ozzie Gooen<\/li><\/ul><\/li><li>Nathan Young is interested in it<\/li><\/ul><\/li><li>&nbsp;<\/li><\/ul><p>Note:<\/p><ul><li>It is hard to build epistemic infrastructure among rationalists, because anyone who is capable of doing it can work on AI safety and most do<\/li><\/ul>"},"Tag:xgpBASEThXPuKRhbS":{"_id":"xgpBASEThXPuKRhbS","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:xgpBASEThXPuKRhbS_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Epistemology","shortName":null,"slug":"epistemology","core":false,"postCount":349,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-08T18:14:19.353Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Tag:bh7uxTTqmsQ8jZJdB":{"_id":"bh7uxTTqmsQ8jZJdB","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Probability & Statistics","shortName":null,"slug":"probability-and-statistics","core":false,"postCount":303,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-08T04:32:58.906Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:vg4LDxjdwHLotCm8w_description":{"_id":"vg4LDxjdwHLotCm8w_description","__typename":"Revision","htmlHighlight":"<p>The <strong>Replication Crisis<\/strong> was the discovery that many fields of so-called science were producing experimental results that could not be replicated, because they were illusions resulting from bad statistical and experimental practices.<\/p><p>The replication crisis began in the early 2010s when several high-profile irreproducible results inspired mass replication attempts, revealing that the majority of papers checked in psychology and a number of other fields were not replicable. Some of the irreproducible results, like <a href=\"https://www.lesswrong.com/tag/priming\">Priming<\/a>, appeared to bear on rationality and were referenced in early LessWrong posts.<\/p><ul><li><strong>External Links:<\/strong><br><a href=\"https://retractionwatch.com/\">Retraction Watch<\/a><\/li><li><a href=\"https://www.gwern.net/Replication\">Replication<\/a> on gwern.net<\/li><li><a href=\"https://arbital.com/p/likelihood_vs_pvalue/\">Likelihood functions, p-values, and the replication crisis<\/a> by Eliezer Yudkowsky<\/li><li><a href=\"https://en.wikipedia.org/wiki/Replication_crisis\">Wikipedia<\/a><\/li><\/ul><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science\">Practice &amp; Philosophy of Science<\/a>, <a href=\"https://www.lesswrong.com/tag/psychology\">Psychology<\/a>, <a href=\"https://www.lesswrong.com/tag/information-cascades\">Information Cascades<\/a>, <a href=\"https://www.lesswrong.com/tag/falsifiability\">Falsifiability<\/a><\/p>"},"Tag:vg4LDxjdwHLotCm8w":{"_id":"vg4LDxjdwHLotCm8w","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:vg4LDxjdwHLotCm8w_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Replication Crisis","shortName":null,"slug":"replication-crisis","core":false,"postCount":62,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-02T20:55:24.286Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:9HSwh2mE3tX6xvZ2W":{"_id":"9HSwh2mE3tX6xvZ2W","__typename":"SocialPreviewType","imageUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/9HSwh2mE3tX6xvZ2W/bngrgw07rz42ohn1whpw"},"Post:9HSwh2mE3tX6xvZ2W":{"_id":"9HSwh2mE3tX6xvZ2W","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:dxn9HiNqh76A3nCGi"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:xgpBASEThXPuKRhbS"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"},{"__ref":"Tag:vg4LDxjdwHLotCm8w"}],"socialPreviewData":{"__ref":"SocialPreviewType:9HSwh2mE3tX6xvZ2W"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-11-05T06:03:06.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"bh7uxTTqmsQ8jZJdB":1,"vg4LDxjdwHLotCm8w":1,"xgpBASEThXPuKRhbS":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"dxn9HiNqh76A3nCGi","commentCount":12,"voteCount":50,"baseScore":53,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":50,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00014400000509340316,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2016-11-05T06:03:06.000Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2016-11-05T06:03:06.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-pyramid-and-the-garden","title":"The Pyramid And The Garden","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e15":{"_id":"5c6392dcbcb4ac6367c16e15","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Epistemic status: This is basic stuff to anyone who has read the Sequences, but since many readers here haven&#8217;t I hope it is not too annoying to regurgitate it. Also, ironically, I&#8217;m not actually that sure of my thesis, which I guess means I&#8217;m extra-sure of my thesis]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>A couple of days ago, the Global Priorities Project came out with <A HREF=\"http://globalprioritiesproject.org/2015/08/quantifyingaisafety/\">a calculator<\/A> that allowed you to fill in your own numbers to estimate how concerned you should be with AI risk. One question asked how likely you thought it was that there would be dangerous superintelligences within a century, offering a drop down menu with probabilities ranging from 90% to 0.01%. And so people objected: there should be options to put in only one a million chance of AI risk! One in a billion! One in a&#8230;<\/p><p>For example, a commenter <A HREF=\"http://slatestarcodex.com/2015/08/16/links-815-linkety-split/#comment-228673\">writes<\/A> that: &#8220;the best (worst) part: the probability of AI risk is selected from a drop down list where the lowest probability available is 0.01%!! Are you kidding me??&#8221; and then goes on to say his estimate of the probability of human-level (not superintelligent!) AI this century is &#8220;very very low, maybe 1 in a million or less&#8221;. Several people on Facebook and Tumblr say the same thing &#8211; 1/10,000 chance just doesn&#8217;t represent how sure they are that there&#8217;s no risk from AI, they want one in a million or more.<\/p><p>Last week, I mentioned that Dylan Matthews&#8217; suggestion that maybe there was only 10^-67 chance you could affect AI risk was stupendously overconfident. I mentioned that was thousands of lower than than the chance, <i>per second<\/i>, of getting simultaneously hit by a tornado, meteor, and al-Qaeda bomb, while <i>also<\/i> winning the lottery twice in a row. Unless you&#8217;re comfortable with that level of improbability, you should stop using numbers like 10^-67.<\/p><p>But maybe it sounds like &#8220;one in a million&#8221; is much safer. That&#8217;s only 10^-6, after all, way below the tornado-meteor-terrorist-double-lottery range&#8230;<\/p><p>So let&#8217;s talk about overconfidence.<\/p><p>Nearly everyone is very very very overconfident. We know this from <A HREF=\"http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf\">experiments<\/A> where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people&#8217;s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they&#8217;re wrong) would get the question wrong only 1% of th... <\/p>","plaintextDescription":"[Epistemic status: This is basic stuff to anyone who has read the Sequences, but since many readers here haven’t I hope it is not too annoying to regurgitate it. Also, ironically, I’m not actually that sure of my thesis, which I guess means I’m extra-sure of my thesis]\n\nI.\n\nA couple of days ago, the Global Priorities Project came out with a calculator that allowed you to fill in your own numbers to estimate how concerned you should be with AI risk. One question asked how likely you thought it was that there would be dangerous superintelligences within a century, offering a drop down menu with probabilities ranging from 90% to 0.01%. And so people objected: there should be options to put in only one a million chance of AI risk! One in a billion! One in a…\n\nFor example, a commenter writes that: “the best (worst) part: the probability of AI risk is selected from a drop down list where the lowest probability available is 0.01%!! Are you kidding me??” and then goes on to say his estimate of the probability of human-level (not superintelligent!) AI this century is “very very low, maybe 1 in a million or less”. Several people on Facebook and Tumblr say the same thing – 1/10,000 chance just doesn’t represent how sure they are that there’s no risk from AI, they want one in a million or more.\n\nLast week, I mentioned that Dylan Matthews’ suggestion that maybe there was only 10^-67 chance you could affect AI risk was stupendously overconfident. I mentioned that was thousands of lower than than the chance, per second, of getting simultaneously hit by a tornado, meteor, and al-Qaeda bomb, while also winning the lottery twice in a row. Unless you’re comfortable with that level of improbability, you should stop using numbers like 10^-67.\n\nBut maybe it sounds like “one in a million” is much safer. That’s only 10^-6, after all, way below the tornado-meteor-terrorist-double-lottery range…\n\nSo let’s talk about overconfidence.\n\nNearly everyone is very very very overconfident. We know th","wordCount":4316,"version":"1.0.0"},"Revision:8daMDi9NEShyLqxth_description":{"_id":"8daMDi9NEShyLqxth_description","__typename":"Revision","htmlHighlight":"<p><strong>Forecasting&nbsp;<\/strong>or&nbsp;<strong>Predicting<\/strong> is the act of making statements about what will happen in the future (and in some cases, the past) and then scoring the predictions. Posts marked with this tag are for discussion of the practice, skill, and methodology of forecasting. Posts exclusively containing object-level lists of forecasts and predictions are in&nbsp;<a href=\"https://www.lesswrong.com/tag/forecasts\"><u>Forecasts<\/u><\/a>.<\/p><blockquote><p><i>Above all, don’t ask what to believe—ask what to anticipate. Every question of belief should flow from a question of anticipation, and that question of anticipation should be the center of the inquiry.<\/i><\/p><p>—<a href=\"https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences\"><u>Making Beliefs Pay Rent<\/u><\/a><\/p><\/blockquote><p>Forecasting allows individuals and institutions to test their internal models of reality. &nbsp;A forecaster with a good track record can have more confidence in future predictions and hence actions in the same area as they have a good track record in. Organisations with decision-makers with good track records can likewise be more confident in their choices.<\/p><p>Crucially, forecasting is a tool to test decision making, rather than a tool for good decision making. If your decision makers are found to be poor forecasters, that is a bad sign, but if your decision making process doesn't involve forecasting, it's not a bad sign. It's not clear that it should.<\/p><h1>Where to start<\/h1><p>Some common recommendations for getting into forecasting are as follows:<\/p><ul><li>Track your personal forecasts. Get a notebook, spreadsheet or <a href=\"https://fatebook.io\">fatebook.io<\/a> and write what you think will happen and a % or odds chance. Follow up on it later.<\/li><li>Bet fake money on <a href=\"https://manifold.markets/\">manifold.markets<\/a>. It's still pretty addictive, so if you have a gambling problem, please avoid.<\/li><li>Take part in the monthly <a href=\"https://www.quantifiedintuitions.org/estimation-game\">estimation game<\/a>. Test your ability to estimate quantities. This is correlated with your ability to navigate the world well<\/li><li>Forecast on <a href=\"https://metaculus.com\">metaculus.com<\/a>. Questions are often pretty focused on geopolitics<\/li><li>Read <a href=\"https://www.amazon.co.uk/Superforecasting-Science-Prediction-Philip-Tetlock/dp/1847947158\">Superforecasting<\/a> by Philip Tetlock. This is if books are a way you learn well.&nbsp;<\/li><\/ul><h1>Forecasting Techniques<\/h1><p>Forecasting is hard but many top forecasters use common techniques. This suggests that forecasting is a skill that can be learnt and practised.<\/p><h2>Base rates<\/h2><p><a href=\"https://en.wikipedia.org/wiki/Reference_class_forecasting\"><i><u>Reference Class Forecasting on Wikipedia<\/u><\/i><\/a><\/p><p>Suppose we are trying to find the probability that an event will occur within the next 5 years. One good place to start is by asking \"of all similar time periods, what fraction of the time does this event occur?\". This is the base rate.<\/p><p>If we want to know the probab... <\/p>"},"Tag:8daMDi9NEShyLqxth":{"_id":"8daMDi9NEShyLqxth","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:8daMDi9NEShyLqxth_description"},"canVoteOnRels":null,"userId":"iBcH2a3HdWGS2JEZA","name":"Forecasting & Prediction","shortName":null,"slug":"forecasting-and-prediction","core":false,"postCount":421,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-10T05:54:39.783Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:CcyGR3pp3FCDuW6Pf":{"_id":"CcyGR3pp3FCDuW6Pf","__typename":"SocialPreviewType","imageUrl":""},"Post:CcyGR3pp3FCDuW6Pf":{"_id":"CcyGR3pp3FCDuW6Pf","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e15"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":17,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:8daMDi9NEShyLqxth"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:CcyGR3pp3FCDuW6Pf"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-08-21T02:21:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"8daMDi9NEShyLqxth":3,"Ng8Gice9KNkncxqcj":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e15","commentCount":6,"voteCount":48,"baseScore":63,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":47,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0001449999981559813,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-12-24T23:07:45.381Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2015-08-21T02:21:00.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"on-overconfidence","title":"On Overconfidence","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16f20":{"_id":"5c6392dcbcb4ac6367c16f20","__typename":"Revision","htmlHighlight":"<p>I do not believe that the utility weights I worked on last week &#8211; the ones that say living in North Korea is 37% as good as living in the First World &#8211; are objectively correct or correspond to any sort of natural category. So why do I find them so interesting?<\/p><p>A few weeks ago I got to go to a free CFAR tutorial (you can hear about these kinds of things by <A HREF=\"http://appliedrationality.org/newsletter-popup/\">signing up for their newsletter<\/A>). During this particular tutorial, Julia tried to explain Bayes&#8217; Theorem to some, er, rationality virgins. I record a heavily-edited-to-avoid-recognizable-details memory of the conversation below:<\/p><p><b>Julia:<\/b> So let&#8217;s try an example. Suppose there&#8217;s a five percent chance per month your computer breaks down. In that case&#8230;<br />\n<b>Student:<\/b> Whoa. Hold on here. That&#8217;s not the chance my computer will break down.<br />\n<b>Julia:<\/b> No? Well, what do you think the chance is?<br />\n<b>Student:<\/b> Who knows? It might happen, or it might not.<br />\n<b>Julia:<\/b> Right, but can you turn that into a number?<br />\n<b>Student:<\/b> No. I have no idea whether my computer will break. I&#8217;d be making the number up.<br />\n<b>Julia:<\/b> Well, in a sense, yes. But you&#8217;d be communicating some information. A 1% chance your computer will break down is very different from a 99% chance.<br />\n<b>Student:<\/b> I don&#8217;t know the future. Why do you want to me to pretend I do?<br />\n<b>Julia:<\/b> <i>(who is heroically nice and patient)<\/i> Okay, let&#8217;s back up. Suppose you buy a sandwich. Is the sandwich probably poisoned, or probably not poisoned?<br />\n<b>Student:<\/b> Exactly which sandwich are we talking about here?<\/p><p>In the context of a lesson on probability, this is a problem I think most people would be able to avoid. But the student&#8217;s attitude, the one that rejects hokey quantification of things we don&#8217;t actually know how to quantify, is a pretty common one. And it informs a lot of the objections to utilitarianism &#8211; the problem of quantifying exactly how bad North Korea shares some of the pitfalls of quantifying exactly how likely your computer is to break (for example, &#8220;we are kind of making this number up&#8221; is a pitfall).<\/p><p>The explanation that Julia and I tried to give the other student was that imperfect information still beats zero information. Even if the number &#8220;five percent&#8221; was made up (suppose that this is a new kind of computer being used in a new way that cannot be easily compared to longevity data for previous co... <\/p>","plaintextDescription":"I do not believe that the utility weights I worked on last week – the ones that say living in North Korea is 37% as good as living in the First World – are objectively correct or correspond to any sort of natural category. So why do I find them so interesting?\n\nA few weeks ago I got to go to a free CFAR tutorial (you can hear about these kinds of things by signing up for their newsletter). During this particular tutorial, Julia tried to explain Bayes’ Theorem to some, er, rationality virgins. I record a heavily-edited-to-avoid-recognizable-details memory of the conversation below:\n\nJulia: So let’s try an example. Suppose there’s a five percent chance per month your computer breaks down. In that case…\nStudent: Whoa. Hold on here. That’s not the chance my computer will break down.\nJulia: No? Well, what do you think the chance is?\nStudent: Who knows? It might happen, or it might not.\nJulia: Right, but can you turn that into a number?\nStudent: No. I have no idea whether my computer will break. I’d be making the number up.\nJulia: Well, in a sense, yes. But you’d be communicating some information. A 1% chance your computer will break down is very different from a 99% chance.\nStudent: I don’t know the future. Why do you want to me to pretend I do?\nJulia: (who is heroically nice and patient) Okay, let’s back up. Suppose you buy a sandwich. Is the sandwich probably poisoned, or probably not poisoned?\nStudent: Exactly which sandwich are we talking about here?\n\nIn the context of a lesson on probability, this is a problem I think most people would be able to avoid. But the student’s attitude, the one that rejects hokey quantification of things we don’t actually know how to quantify, is a pretty common one. And it informs a lot of the objections to utilitarianism – the problem of quantifying exactly how bad North Korea shares some of the pitfalls of quantifying exactly how likely your computer is to break (for example, “we are kind of making this number up” is a pitfall).\n\nThe e","wordCount":1464,"version":"1.0.0"},"Tag:KoXbd2HmbdRfqLngk":{"_id":"KoXbd2HmbdRfqLngk","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Planning & Decision-Making","shortName":null,"slug":"planning-and-decision-making","core":false,"postCount":128,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-17T21:17:27.266Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:LhX3F2SvGDarZCuh6_description":{"_id":"LhX3F2SvGDarZCuh6_description","__typename":"Revision","htmlHighlight":"<p><strong>Bayes' Theorem<\/strong> (also known as Bayes' Law) is a law of probability that describes the proper way to incorporate new evidence into prior probabilities to form an updated probability estimate. It is commonly regarded as the foundation of consistent rational reasoning under uncertainty. Bayes Theorem is named after Reverend Thomas Bayes who proved the theorem in 1763.&nbsp;<\/p><p>Bayes' theorem commonly takes the form:<\/p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"{\\displaystyle P(A|B)={\\frac {P(B|A)\\,P(A)}{P(B)}}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 5.962em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 5.962em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 5.962em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 5.962em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><p>where A is the proposition of interest, B is the observed evidence, P(A) and P(B) are prior probabilities, and P(A|B) is the posterior probability of A.<\/p><p>With the posterior odds, the prior odds and the <a href=\"https://wiki.lesswrong.com/wiki/Likelihood_ratio\"><u>likelihood ratio<\/u><\/a> written explicitly, the theorem reads:<\/p><span><span class=\"mjpage mjpage__block\"><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"{\\displaystyle {\\frac {P(A|B)}{P(\\neg A|B)}}={\\frac {P(A)}{P(\\neg A)}}\\cdot {\\frac {P(B|A)}{P(B|\\neg A)}}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mstyle\"><span class=\"mjx-mrow\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.183em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.183em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 4.183em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">¬<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.183em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.146em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 3.146em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 3.146em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">¬<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 3.146em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><\/span><\/span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">⋅<\/span><\/span><span class=\"mjx-texatom MJXc-space2\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.183em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.183em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 4.183em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">¬<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.183em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><p>&nbsp;<\/p><h2>Visualisation of Bayes' Rule<\/h2><figure class=\"image image_resized\" style=\"width:100%\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/LhX3F2SvGDarZCuh6/hmsnhsz2ei6beeylrwv2\" alt=\"Bayes.png\"><\/figure>"},"Tag:LhX3F2SvGDarZCuh6":{"_id":"LhX3F2SvGDarZCuh6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:LhX3F2SvGDarZCuh6_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Bayes' Theorem","shortName":null,"slug":"bayes-theorem","core":false,"postCount":173,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-29T02:02:50.973Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:9Tw5RqnEzqEtaoEkq":{"_id":"9Tw5RqnEzqEtaoEkq","__typename":"SocialPreviewType","imageUrl":""},"Post:9Tw5RqnEzqEtaoEkq":{"_id":"9Tw5RqnEzqEtaoEkq","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f20"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:KoXbd2HmbdRfqLngk"},{"__ref":"Tag:LhX3F2SvGDarZCuh6"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:9Tw5RqnEzqEtaoEkq"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-09-03T20:56:25.373Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"KoXbd2HmbdRfqLngk":3,"LhX3F2SvGDarZCuh6":2,"Ng8Gice9KNkncxqcj":2,"bh7uxTTqmsQ8jZJdB":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f20","commentCount":0,"voteCount":46,"baseScore":74,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":46,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0002288516698172316,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"if-it-s-worth-doing-it-s-worth-doing-with-made-up-statistics","title":"If It’s Worth Doing, It’s Worth Doing With Made-Up Statistics","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c639286bcb4ac6367c1534d":{"_id":"5c639286bcb4ac6367c1534d","__typename":"Revision","htmlHighlight":"<p>Utility maximization often requires determining a probability of a particular statement being true. But humans are not utility maximizers and often refuse to give precise numerical probabilities. Nevertheless, their actions reflect a \"hidden\" probability. For example, even someone who refused to give a precise probability for Barack Obama's re-election would probably jump at the chance to take a bet in which ey lost $5 if Obama wasn't re-elected but won $5 million if he was; such decisions demand that the decider covertly be working off of at least a vague probability.<br /><br />When untrained people try to translate vague feelings like \"It seems Obama will probably be re-elected\" into a precise numerical probability, they commonly fall into certain traps and pitfalls that make their probability estimates inaccurate. Calling a probability estimate \"inaccurate\" causes philosophical problems, but these problems can be resolved by remembering that <a href=\"/lw/s6/probability_is_subjectively_objective\">probability is \"subjectively objective\"<\/a> - that although a mind \"hosts\" a probability estimate, that mind does not arbitrarily determine the estimate, but rather calculates it according to mathematical laws from available evidence. These calculations require too much computational power to use outside the simplest hypothetical examples, but they provide a standard by which to judge real probability estimates. They also suggest tests by which one can judge probabilities as well-calibrated or poorly-calibrated: for example, a person who constantly assigns 90% confidence to eir guesses but only guesses the right answer half the time is poorly calibrated. So calling a probability estimate \"accurate\" or \"inaccurate\" has a real philosophical grounding.<br /><br />There exist several techniques that help people translate vague feelings of probability into more accurate numerical estimates. Most of them translate probabilities from forms <a href=\"http://wiki.lesswrong.com/wiki/Near/far_thinking\">without immediate consequences<\/a> (which the brain supposedly processes for signaling purposes) to forms with immediate consequences (which the brain supposedly processes while focusing on those consequences).<\/p><p><a id=\"more\"><\/a><br /><br /><strong>Prepare for Revelation<\/strong><\/p><p>What would you expect if you believed the answer to your question were about to be revealed to you?<br /><br />In <a href=\"/lw/i4/belief_in_belief/\">Belief in Belief<\/a>, a man acts as if there is a dragon in his garage, but every time his neighbor comes up with an idea to test it, he has a reason why the test wouldn't work. If he imagined Om... <\/p>","plaintextDescription":"Utility maximization often requires determining a probability of a particular statement being true. But humans are not utility maximizers and often refuse to give precise numerical probabilities. Nevertheless, their actions reflect a \"hidden\" probability. For example, even someone who refused to give a precise probability for Barack Obama's re-election would probably jump at the chance to take a bet in which ey lost $5 if Obama wasn't re-elected but won $5 million if he was; such decisions demand that the decider covertly be working off of at least a vague probability.\n\nWhen untrained people try to translate vague feelings like \"It seems Obama will probably be re-elected\" into a precise numerical probability, they commonly fall into certain traps and pitfalls that make their probability estimates inaccurate. Calling a probability estimate \"inaccurate\" causes philosophical problems, but these problems can be resolved by remembering that probability is \"subjectively objective\" - that although a mind \"hosts\" a probability estimate, that mind does not arbitrarily determine the estimate, but rather calculates it according to mathematical laws from available evidence. These calculations require too much computational power to use outside the simplest hypothetical examples, but they provide a standard by which to judge real probability estimates. They also suggest tests by which one can judge probabilities as well-calibrated or poorly-calibrated: for example, a person who constantly assigns 90% confidence to eir guesses but only guesses the right answer half the time is poorly calibrated. So calling a probability estimate \"accurate\" or \"inaccurate\" has a real philosophical grounding.\n\nThere exist several techniques that help people translate vague feelings of probability into more accurate numerical estimates. Most of them translate probabilities from forms without immediate consequences (which the brain supposedly processes for signaling purposes) to forms with immediate ","wordCount":1969,"version":"1.0.0"},"Revision:E8PHMuf7tsr8teXAe_description":{"_id":"E8PHMuf7tsr8teXAe_description","__typename":"Revision","htmlHighlight":"<p><strong>Betting<\/strong> is staking money (or some other form of value) on one's beliefs. It is considered rationally virtuous to bet on one's beliefs, as the real stakes force one to actually consider precisely what they <a href=\"https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences\">anticipate<\/a> will really happen. LessWrong has a culture of betting.<\/p><p><i>See also:<\/i> <a href=\"https://www.lesswrong.com/tag/prediction-markets\">Prediction Markets, <\/a><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction\">Forecasting &amp; Prediction, <\/a><a href=\"https://www.lesswrong.com/tag/forecasts\">Forecasts (Specific Predictions)<\/a><\/p><h2>Why is betting important?<\/h2><p>The argument in favor of betting is that one should generally either accept a proposed bet, in order to make money in expectation, or update their beliefs so the bet becomes unprofitable. There are exceptions to this rule, some theoretical, such as the example of <a href=\"https://www.lesswrong.com/posts/G7HgP9KTWAMSv6oEJ/bets-and-updating\">Omega and Omicron<\/a>, and some practical, such as uncertainty about whether the bet will be fulfilled. Offering a bet forces someone to think more carefully and share their beliefs more precisely. Losing a bet, even small, can make it more emotionally visceral in a way that might lead to sharpening belief <a href=\"https://www.lesswrong.com/tag/calibration\">calibration<\/a> more. Bets can be made about beliefs that can be immediately verified or about beliefs that will only be verifiable in the future.<\/p><p>In popular culture, this idea is often referred to as \"putting one's money where one's mouth is\".<\/p><p><a href=\"https://marginalrevolution.com/marginalrevolution/2012/11/a-bet-is-a-tax-on-bullshit.html\">A Bet is a Tax on Bullshit<\/a> mentions that:<\/p><blockquote><p>In fact, the NYTimes should require that Silver, and other pundits, bet their beliefs. Furthermore, to remove any possibility of manipulation, the NYTimes should escrow a portion of Silver’s salary in a blind trust bet. In other words, the NYTimes should bet a portion of Silver’s salary, at the odds implied by Silver’s model, randomly choosing which side of the bet to take, only revealing to Silver the bet and its outcome after the election is over. A blind trust bet creates incentives for Silver to be disinterested in the outcome but very interested in the accuracy of the forecast.<\/p><\/blockquote><p>In <a href=\"https://www.econlib.org/archives/2009/03/what_does_the_b.html\">What Does the Betting Norm Tax?<\/a>, Bryan Caplan says that such a norm should also be present among scholars.<\/p><h2>Operationalization for Bets<\/h2><p><i>Operationalizing a belief<\/i> is the practice of transforming a belief into a bet with a clear, unambiguous resolution criteria. Sometimes this can be difficult, but there can be ways around some difficulties as explained in <a href=\"https://www.lesswrong.com/posts/LzyN9wzEdfS3j5SmT/tricky-bets-and-truth-tracking-fields\">Tricky Bets and Truth-Tracking Fields<\/a>. The same challenges are present for prediction markets.<\/p><h2>Prediction Markets<\/h2><p>A<a href=\"https://www.lesswrong.com/tag/prediction-markets\"> prediction market<\/a> is a way for everyone to participate in betting on a particular question. A positive e... <\/p>"},"Tag:E8PHMuf7tsr8teXAe":{"_id":"E8PHMuf7tsr8teXAe","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:E8PHMuf7tsr8teXAe_description"},"canVoteOnRels":null,"userId":"dRGmZYGDzf5LFNjtz","name":"Betting","shortName":null,"slug":"betting","core":false,"postCount":85,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-25T21:27:40.796Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Tag:Zwv9eHi7KGg5KA9oM":{"_id":"Zwv9eHi7KGg5KA9oM","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Introspection","shortName":null,"slug":"introspection","core":false,"postCount":72,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-27T20:43:34.869Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:r8aAqSBeeeMNRtiYK":{"_id":"r8aAqSBeeeMNRtiYK","__typename":"SocialPreviewType","imageUrl":""},"Post:r8aAqSBeeeMNRtiYK":{"_id":"r8aAqSBeeeMNRtiYK","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c639286bcb4ac6367c1534d"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:E8PHMuf7tsr8teXAe"},{"__ref":"Tag:Zwv9eHi7KGg5KA9oM"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"}],"socialPreviewData":{"__ref":"SocialPreviewType:r8aAqSBeeeMNRtiYK"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2011-01-04T23:38:27.801Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"E8PHMuf7tsr8teXAe":1,"Zwv9eHi7KGg5KA9oM":1,"bh7uxTTqmsQ8jZJdB":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c639286bcb4ac6367c1534d","commentCount":60,"voteCount":94,"baseScore":110,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":94,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00017235259292647243,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-12-16T19:46:16.569Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":20,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"techniques-for-probability-estimates","title":"Techniques for probability estimates","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6391c6bcb4ac6367c10f4b":{"_id":"5c6391c6bcb4ac6367c10f4b","__typename":"Revision","htmlHighlight":"<p><strong>Related to: <\/strong><a href=\"/lw/mo/infinite_certainty/\">Infinite Certainty<\/a><\/p><p>Suppose the people at <a href=\"http://fivethirtyeight.blogs.nytimes.com/\">FiveThirtyEight<\/a> have created a model to predict the results of an important election. After crunching poll data, area demographics, and all the usual things one crunches in such a situation, their model returns a greater than 999,999,999 in a billion chance that the incumbent wins the election. Suppose further that the results of this model are your only data and you know nothing else about the election. What is your confidence level that the incumbent wins the election?<br /><br />Mine would be significantly less than 999,999,999 in a billion.<\/p><p>When an argument gives a probability of 999,999,999 in a billion for an event, then probably the majority of the probability of the event is no longer in \"But that still leaves a one in a billion chance, right?\". The majority of the probability is in \"That argument is flawed\". Even if you have no particular reason to believe the argument is flawed, the background chance of an argument being flawed is still greater than one in a billion.<\/p><p><br />More than one in a billion times a political scientist writes a model, ey will get completely confused and write something with no relation to reality. More than one in a billion times a programmer writes a program to crunch political statistics, there will be a bug that completely invalidates the results. More than one in a billion times a staffer at a website publishes the results of a political calculation online, ey will accidentally switch which candidate goes with which chance of winning.<br /><br />So one must distinguish between levels of confidence internal and external to a specific model or argument. Here the model's internal level of confidence is 999,999,999/billion. But my external level of confidence should be lower, even if the model is my only evidence, by an amount proportional to my trust in the model.<\/p><p><a id=\"more\"><\/a><br /><br /><strong>Is That Really True?<\/strong><\/p><p>One might be tempted to respond \"But there's an equal chance that the false model is too high, versus that it is too low.\" Maybe there was a bug in the computer program, but it prevented it from giving the incumbent's real chances of 999,999,999,999 out of a <em>trillion<\/em>.<br /><br />The prior probability of a candidate winning an election is 50%<sup>1<\/sup>. We need information to push us away from this probability in either direction. To push significantly away from this probability, we need strong information. Any weakness in the information weakens... <\/p>","plaintextDescription":"Related to: Infinite Certainty\n\nSuppose the people at FiveThirtyEight have created a model to predict the results of an important election. After crunching poll data, area demographics, and all the usual things one crunches in such a situation, their model returns a greater than 999,999,999 in a billion chance that the incumbent wins the election. Suppose further that the results of this model are your only data and you know nothing else about the election. What is your confidence level that the incumbent wins the election?\n\nMine would be significantly less than 999,999,999 in a billion.\n\nWhen an argument gives a probability of 999,999,999 in a billion for an event, then probably the majority of the probability of the event is no longer in \"But that still leaves a one in a billion chance, right?\". The majority of the probability is in \"That argument is flawed\". Even if you have no particular reason to believe the argument is flawed, the background chance of an argument being flawed is still greater than one in a billion.\n\n\nMore than one in a billion times a political scientist writes a model, ey will get completely confused and write something with no relation to reality. More than one in a billion times a programmer writes a program to crunch political statistics, there will be a bug that completely invalidates the results. More than one in a billion times a staffer at a website publishes the results of a political calculation online, ey will accidentally switch which candidate goes with which chance of winning.\n\nSo one must distinguish between levels of confidence internal and external to a specific model or argument. Here the model's internal level of confidence is 999,999,999/billion. But my external level of confidence should be lower, even if the model is my only evidence, by an amount proportional to my trust in the model.\n\n\n\nIs That Really True?\n\nOne might be tempted to respond \"But there's an equal chance that the false model is too high, versus that it is ","wordCount":1879,"version":"1.0.0"},"Revision:rWzGNdjuep56W5u2d_description":{"_id":"rWzGNdjuep56W5u2d_description","__typename":"Revision","htmlHighlight":"<p>An <strong>Inside View <\/strong>on a topic involves making predictions based on your understanding of the details of the process. An <strong>Outside View <\/strong>involves ignoring these details and using an estimate based on a class of roughly similar previous cases (alternatively, this is called <a href=\"http://en.wikipedia.org/wiki/Reference_class_forecasting\">reference class forecasting<\/a>), though it has been <a href=\"https://www.lesswrong.com/posts/BcYfsi7vmhDvzQGiF/taboo-outside-view\">pointed out<\/a> that the possible meaning has expanded beyond that.<\/p><p>For example, someone working on a project may estimate that they can reasonably get 20% of it done per day, so they will get it done in five days (inside view). Or they might consider that all of their previous projects were completed just before the deadline, so since the deadline for this project is in 30 days, that's when it will get done (outside view).<\/p><p>The terms were originally developed by Daniel Kahneman and Amos Tversky. An early use is in <a href=\"http://doi.org/10.1287/mnsc.39.1.17\">Timid Choices and Bold Forecasts: A Cognitive Perspective on Risk Taking (Kahneman &amp; Lovallo, 1993)<\/a> and the terms were popularised in <i>Thinking, Fast and Slow<\/i> (Kahneman, 2011; <a href=\"https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/daniel-kahneman-beware-the-inside-view\">relevant excerpt<\/a>). The planning example is discussed in <a href=\"https://www.lesswrong.com/posts/CPm5LTwHrvBJCa9h5/planning-fallacy\">The Planning Fallacy<\/a>.&nbsp;<\/p><h3>Examples of outside view<\/h3><p><strong>1.<\/strong> From <a href=\"https://www.overcomingbias.com/2007/07/beware-the-insi.html\">Beware the Inside View<\/a>, by Robin Hanson:<\/p><blockquote><p>I did 1500 piece jigsaw puzzle of fireworks, my first jigsaw in at least ten years.&nbsp; Several times I had the strong impression that I had carefully eliminated every possible place a piece could go, or every possible piece that could go in a place.&nbsp; I was very tempted to conclude that many pieces were missing, or that the box had extra pieces from another puzzle.&nbsp; This wasn’t impossible – the puzzle was an open box a relative had done before.&nbsp; And the alternative seemed humiliating.&nbsp;<\/p><\/blockquote><blockquote><p>But I allowed a very different part of my mind, using different considerations, to overrule this judgment; so many extra or missing pieces seemed unlikely.&nbsp; And in the end there was only one missing and no extra pieces.&nbsp; I recall a similar experience when I was learning to program. I would carefully check my program and find no errors, and then when my program wouldn’t run I was tempted to suspect compiler or hardware errors.&nbsp; Of course the problem was almost always my fault.&nbsp; &nbsp;<\/p><\/blockquote><p><strong>2.<\/strong> Japanese students expected to finish their essays an average of 10 days before deadline. The average completion time was actually 1 day before deadline. When asked when they'd completed similar, previous tasks, the ... <\/p>"},"Tag:rWzGNdjuep56W5u2d":{"_id":"rWzGNdjuep56W5u2d","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:rWzGNdjuep56W5u2d_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Inside/Outside View","shortName":null,"slug":"inside-outside-view","core":false,"postCount":58,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-29T10:04:10.220Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:QT87jxkk6DXuS8hGA_description":{"_id":"QT87jxkk6DXuS8hGA_description","__typename":"Revision","htmlHighlight":"<p>In the simple case, <strong>explicit reasoning <\/strong>is reasoning which:<\/p><ul><li>Can be explained in language.<\/li><li>Uses well-defined terms.<\/li><li>Relies on well-understood reasoning steps.<\/li><li>Has clear assumptions and conclusions.<\/li><li>You are aware of doing when you do it.<\/li><\/ul><blockquote><p>\"What do I mean by <i><strong>explicit reason<\/strong>?<\/i> I don’t refer merely to “<a href=\"https://www.lesswrong.com/tag/dual-process-theory-system-1-and-system-2\">System 2<\/a>”, the brain’s slow, sequential, analytical, fully conscious, and effortful mode of cognition. I refer to the <i>informed<\/i> application of this type of thinking. Gathering data with real effort to find out, crunching the numbers with a grasp of the math, modeling the world with testable predictions, reflection on your thinking with an awareness of biases. Reason requires good inputs and a lot of effort.\" - <a href=\"https://www.lesswrong.com/users/jacob-falkovich\">Jacob Falkovich<\/a>, <a href=\"https://www.lesswrong.com/posts/YcdArE79SDxwWAuyF/the-treacherous-path-to-rationality\">The Treacherous Path to Rationality<\/a><\/p><\/blockquote><p>However, the exact definition may vary based on context. For example, explicit reasoning might be operationalized as imaginary verbal reasoning taking place in a person's inner monologue (ie, in auditory working memory). In other cases, we might have a much higher standard, eg actual symbolic logic written on an external medium such as paper. So, reasoning can be more and less explicit, along several dimensions.<\/p><p>Explicit reasoning is one of many modes of reasoning by which humans may reach conclusions. While it is not always the best mode of reasoning, it has the advantage of being <i>scrutable<\/i>, ie, open to inspection. This makes it easier to correct, in particular through imaginary verbal reasoning modelled after dialogue (ie, mentally responding to yourself as if you were another person, with critiques and corrections). Since it can easily be recorded, it can also be subject to feedback from many other people, which can further improve the quality of this type of reasoning. Also, explicit reasoning can easily be chained together to reach less obvious conclusions.<\/p><p>Other types of reasoning include <a href=\"https://www.lesswrong.com/tag/inner-simulator-suprise-o-meter\">inner sim<\/a>, gestalt pattern recognition, mental imagery, and <a href=\"https://www.lesswrong.com/tag/focusing\">Gendlin's Focusing<\/a>. Important questions include when to trust different modes of reasoning, how to combine the results of different reasoning modes, and how to best facilitate communication between different modes of reasoning.<\/p><p>Related to: <a href=\"https://www.lesswrong.com/tag/dual-process-theory-system-1-and-system-2\">Dual Process Theory<\/a><\/p>"},"Tag:QT87jxkk6DXuS8hGA":{"_id":"QT87jxkk6DXuS8hGA","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:QT87jxkk6DXuS8hGA_description"},"canVoteOnRels":null,"userId":"Q7NW4XaWQmfPfdcFj","name":"Explicit Reasoning","shortName":null,"slug":"explicit-reasoning","core":false,"postCount":12,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-11-15T18:14:02.542Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:GrtbTAPfkJa4D6jjH":{"_id":"GrtbTAPfkJa4D6jjH","__typename":"SocialPreviewType","imageUrl":""},"Post:GrtbTAPfkJa4D6jjH":{"_id":"GrtbTAPfkJa4D6jjH","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6391c6bcb4ac6367c10f4b"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:AHK82ypfxF45rqh9D"},{"__ref":"Tag:rWzGNdjuep56W5u2d"},{"__ref":"Tag:QT87jxkk6DXuS8hGA"},{"__ref":"Tag:8daMDi9NEShyLqxth"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:GrtbTAPfkJa4D6jjH"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2010-12-16T03:06:07.660Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"postCategory":"post","tagRelevance":{"8daMDi9NEShyLqxth":2,"AHK82ypfxF45rqh9D":6,"Ng8Gice9KNkncxqcj":2,"QT87jxkk6DXuS8hGA":2,"bh7uxTTqmsQ8jZJdB":2,"rWzGNdjuep56W5u2d":6},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6391c6bcb4ac6367c10f4b","commentCount":192,"voteCount":185,"baseScore":234,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":185,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0003487823996692896,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-03-11T03:03:13.878Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":18,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":31,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"confidence-levels-inside-and-outside-an-argument","title":"Confidence levels inside and outside an argument","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:RPGmHEWZ5bmKBGnGc":{"_id":"RPGmHEWZ5bmKBGnGc","__typename":"Chapter","createdAt":"2017-09-05T01:03:41.764Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:RPGmHEWZ5bmKBGnGc_contents"},"number":0,"sequenceId":"TQW9brvXJ5Fajorr4","postIds":["9HSwh2mE3tX6xvZ2W","CcyGR3pp3FCDuW6Pf","9Tw5RqnEzqEtaoEkq","r8aAqSBeeeMNRtiYK","GrtbTAPfkJa4D6jjH"],"posts":[{"__ref":"Post:9HSwh2mE3tX6xvZ2W"},{"__ref":"Post:CcyGR3pp3FCDuW6Pf"},{"__ref":"Post:9Tw5RqnEzqEtaoEkq"},{"__ref":"Post:r8aAqSBeeeMNRtiYK"},{"__ref":"Post:GrtbTAPfkJa4D6jjH"}]},"Revision:5c6392c7bcb4ac6367c16cbe":{"_id":"5c6392c7bcb4ac6367c16cbe","__typename":"Revision","htmlHighlight":"<p>Once upon a time a logician accomplished a great deed, and the God-Emperor offered him a choice of rewards. &#8220;You may,&#8221; said the God-Emperor &#8220;have the hand of my eldest daughter, who is the heir to the throne, yet plain to look upon. Or you may take my youngest daughter, who is beautiful beyond words, but without inheritance.&#8221;<\/p>\n<p>The next day, the God-Emperor caught the logician in bed with <i>both<\/i> his daughters. Enraged, he hurled threats and abuse at the scholar, who responded with a grin: &#8220;Guess someone never learned the difference between &#8216;or&#8217; and &#8216;xor&#8217;.&#8221;<\/p>\n<p>The God-Emperor ordered the logician brought to the throne room in chains, and told him &#8220;You have offended me and betrayed my generosity, so you will be subjected to trial by ordeal. I have placed in front of you seven chests. Six of the chests contain skulls. One of the chests contains the key to your chains. I have asked the most devious minds in my kingdom to prepare a logic puzzle giving hints as to which chest is which. You may open a single chest. If you do not find the chest with the key on your first try, you will be slathered in barbecue sauce and thrown to the wolves.&#8221;<\/p>\n<p>The logician approached the chests, and upon each was written a clue in complicated logical notation. He examined all seven, and then stood a while, deep in thought. Finally, he opened the third chest. Inside was a golden key.<\/p>\n<p>&#8220;Very impressive!&#8221; said the God-Emperor. Then he yelled &#8220;Guards! Slather this man in barbecue sauce and throw him to the wolves!&#8221;<\/p>\n<p>&#8220;But&#8230;but!&#8221; babbled the terrified logician &#8220;&#8230;but you said&#8230;!&#8221;<\/p>\n<p>The God-Emperor grinned. &#8220;Guess someone never learned the difference between &#8216;if&#8217; and &#8216;iff&#8217;.&#8221;<\/p>","plaintextDescription":"Once upon a time a logician accomplished a great deed, and the God-Emperor offered him a choice of rewards. “You may,” said the God-Emperor “have the hand of my eldest daughter, who is the heir to the throne, yet plain to look upon. Or you may take my youngest daughter, who is beautiful beyond words, but without inheritance.”\n\nThe next day, the God-Emperor caught the logician in bed with both his daughters. Enraged, he hurled threats and abuse at the scholar, who responded with a grin: “Guess someone never learned the difference between ‘or’ and ‘xor’.”\n\nThe God-Emperor ordered the logician brought to the throne room in chains, and told him “You have offended me and betrayed my generosity, so you will be subjected to trial by ordeal. I have placed in front of you seven chests. Six of the chests contain skulls. One of the chests contains the key to your chains. I have asked the most devious minds in my kingdom to prepare a logic puzzle giving hints as to which chest is which. You may open a single chest. If you do not find the chest with the key on your first try, you will be slathered in barbecue sauce and thrown to the wolves.”\n\nThe logician approached the chests, and upon each was written a clue in complicated logical notation. He examined all seven, and then stood a while, deep in thought. Finally, he opened the third chest. Inside was a golden key.\n\n“Very impressive!” said the God-Emperor. Then he yelled “Guards! Slather this man in barbecue sauce and throw him to the wolves!”\n\n“But…but!” babbled the terrified logician “…but you said…!”\n\nThe God-Emperor grinned. “Guess someone never learned the difference between ‘if’ and ‘iff’.”","wordCount":283,"version":"1.0.0"},"SocialPreviewType:2gWs8SScqeDFidqyv":{"_id":"2gWs8SScqeDFidqyv","__typename":"SocialPreviewType","imageUrl":""},"Post:2gWs8SScqeDFidqyv":{"_id":"2gWs8SScqeDFidqyv","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16cbe"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:F2XfCTxXLQBGjbm8P"}],"socialPreviewData":{"__ref":"SocialPreviewType:2gWs8SScqeDFidqyv"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-12-05T01:54:07.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"F2XfCTxXLQBGjbm8P":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16cbe","commentCount":0,"voteCount":35,"baseScore":46,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":34,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00008800000068731606,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-logician-and-the-god-emperor","title":"The Logician And The God-Emperor","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16cf3":{"_id":"5c6392c7bcb4ac6367c16cf3","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Content warning: suicide]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>It all started when I made that phone call.<\/p><p>I was really bad. All the tenure-track positions I&#8217;d applied to had politely declined, and I saw my future in academia gradually slipping away from me. Then the night before, my boyfriend had said he thought maybe we should start seeing other people. I didn&#8217;t even know if we were broken up or not, and at that point I couldn&#8217;t bring myself to care. I sat on my bed, thinking about things for a while, and finally I called the suicide hotline.<\/p><p>&#8220;Hello?&#8221; a woman&#8217;s voice answered on the other side. Somehow, just hearing someone else made me feel about five times better.<\/p><p>&#8220;Hello,&#8221; I said, a little more confidently. &#8220;I&#8217;ve been thinking of committing suicide. I need help.&#8221;<\/p><p>&#8220;Okay,&#8221; she said. &#8220;Is there a gun in your house?&#8221;<\/p><p>&#8220;No.&#8221;<\/p><p>&#8220;All right. The first thing you need to do is get one. Overdosing on pills is common, but it almost never works. You can get a firearm at almost any large sporting goods store, but if there aren&#8217;t any near you, we can start talking about maybe jumping from a high&#8230;&#8221;<\/p><p>&#8220;What the HELL?&#8221; I interrupted, suddenly way more angry than depressed. &#8220;You&#8217;re supposed to @#!$ing tell me not to do it!&#8221;<\/p><p>&#8220;This is the suicide hotline,&#8221; the woman said, now sounding confused. Then, &#8220;Are you sure you weren&#8217;t thinking of the suicide <i>prevention<\/i> hotline?&#8221;<\/p><p>&#8220;Give me a break! I took a psychology class in undergrad, I know what a suicide hotline is!&#8221;<\/p><p>&#8220;I&#8217;m sorry you seem to be upset. But this is the suicide hotline. It&#8217;s like how there&#8217;s the Walk For Breast Cancer, but also the Walk Against Breast Cancer.&#8221;<\/p><p>&#8220;There&#8217;s the what? But&#8230;I was <i>in<\/i> the Walk For Breast Cancer! I thought&#8230;&#8221;<\/p><p>&#8220;It sounds like you have some issues,&#8221; said the woman, politely.<\/p><p>&#8220;Ugh,&#8221; I said. &#8220;Yeah.&#8221;<\/p><p>&#8220;Do you feel like you need professional help?&#8221;<\/p><p>&#8220;Yeah.&#8221;<\/p><p>&#8220;I do have a free clinic with an opening available tomorrow at three PM, would you like me to slot you in for an appointment?&#8221;<\/p><p>So you&#8217;re probably wondering why in the world I would take an appointment arranged by the suicide hotline that wasn&#8217;t a suicide prevention hotline.... <\/p>","plaintextDescription":"[Content warning: suicide]\n\nI.\n\nIt all started when I made that phone call.\n\nI was really bad. All the tenure-track positions I’d applied to had politely declined, and I saw my future in academia gradually slipping away from me. Then the night before, my boyfriend had said he thought maybe we should start seeing other people. I didn’t even know if we were broken up or not, and at that point I couldn’t bring myself to care. I sat on my bed, thinking about things for a while, and finally I called the suicide hotline.\n\n“Hello?” a woman’s voice answered on the other side. Somehow, just hearing someone else made me feel about five times better.\n\n“Hello,” I said, a little more confidently. “I’ve been thinking of committing suicide. I need help.”\n\n“Okay,” she said. “Is there a gun in your house?”\n\n“No.”\n\n“All right. The first thing you need to do is get one. Overdosing on pills is common, but it almost never works. You can get a firearm at almost any large sporting goods store, but if there aren’t any near you, we can start talking about maybe jumping from a high…”\n\n“What the HELL?” I interrupted, suddenly way more angry than depressed. “You’re supposed to @#!$ing tell me not to do it!”\n\n“This is the suicide hotline,” the woman said, now sounding confused. Then, “Are you sure you weren’t thinking of the suicide prevention hotline?”\n\n“Give me a break! I took a psychology class in undergrad, I know what a suicide hotline is!”\n\n“I’m sorry you seem to be upset. But this is the suicide hotline. It’s like how there’s the Walk For Breast Cancer, but also the Walk Against Breast Cancer.”\n\n“There’s the what? But…I was in the Walk For Breast Cancer! I thought…”\n\n“It sounds like you have some issues,” said the woman, politely.\n\n“Ugh,” I said. “Yeah.”\n\n“Do you feel like you need professional help?”\n\n“Yeah.”\n\n“I do have a free clinic with an opening available tomorrow at three PM, would you like me to slot you in for an appointment?”\n\nSo you’re probably wondering why in the world I wou","wordCount":2112,"version":"1.0.0"},"Revision:gsv9XWbZDcnZmKuqM_description":{"_id":"gsv9XWbZDcnZmKuqM_description","__typename":"Revision","htmlHighlight":"<p><strong>Psychiatry <\/strong>is the medical specialty devoted to the diagnosis, prevention, and treatment of mental disorders. These include various maladaptations related to mood, behavior, cognition, and perceptions.<\/p>"},"Tag:gsv9XWbZDcnZmKuqM":{"_id":"gsv9XWbZDcnZmKuqM","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:gsv9XWbZDcnZmKuqM_description"},"canVoteOnRels":null,"userId":"me9AorpaKpuWPmz6m","name":"Psychiatry","shortName":null,"slug":"psychiatry","core":false,"postCount":35,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-02T08:08:19.942Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:FLnDFnXyWrKr6eiT6":{"_id":"FLnDFnXyWrKr6eiT6","__typename":"SocialPreviewType","imageUrl":""},"Post:FLnDFnXyWrKr6eiT6":{"_id":"FLnDFnXyWrKr6eiT6","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16cf3"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:gsv9XWbZDcnZmKuqM"}],"socialPreviewData":{"__ref":"SocialPreviewType:FLnDFnXyWrKr6eiT6"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-07-18T04:25:14.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":1,"gsv9XWbZDcnZmKuqM":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16cf3","commentCount":1,"voteCount":38,"baseScore":45,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":38,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00010399999882793054,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-10-13T19:23:59.586Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"reverse-psychology","title":"Reverse Psychology","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:C4ckCwk7fMj9hWYNq":{"_id":"C4ckCwk7fMj9hWYNq","__typename":"Chapter","createdAt":"2017-09-05T02:39:53.507Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"TQW9brvXJ5Fajorr4","postIds":["2gWs8SScqeDFidqyv","FLnDFnXyWrKr6eiT6"],"posts":[{"__ref":"Post:2gWs8SScqeDFidqyv"},{"__ref":"Post:FLnDFnXyWrKr6eiT6"}]},"Revision:TQW9brvXJ5Fajorr4_contents":{"_id":"TQW9brvXJ5Fajorr4_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-06-23T22:40:56.142Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Nearly everyone is very very very overconfident. We know this from <a href=\"http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf\">experiments<\/a> where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.<\/p><p>It gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are <i>fifty thousand times<\/i> as confident as they should be.<\/p>","commitMessage":"","wordCount":119,"htmlHighlight":"<p>Nearly everyone is very very very overconfident. We know this from <a href=\"http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf\">experiments<\/a> where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.<\/p><p>It gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are <i>fifty thousand times<\/i> as confident as they should be.<\/p>","plaintextDescription":"Nearly everyone is very very very overconfident. We know this from experiments where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.\n\nIt gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are fifty thousand times as confident as they should be."},"Sequence:TQW9brvXJ5Fajorr4":{"_id":"TQW9brvXJ5Fajorr4","__typename":"Sequence","chapters":[{"__ref":"Chapter:RPGmHEWZ5bmKBGnGc"},{"__ref":"Chapter:C4ckCwk7fMj9hWYNq"}],"createdAt":"2017-09-05T01:01:05.221Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:TQW9brvXJ5Fajorr4_contents"},"gridImageId":"sequencesgrid/dyq1iu03mw0qo54n6byk","bannerImageId":"sequences/s7io2gbfmdhk7lyn0flk","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Probability and Predictions","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Book:jF58hKP9ZLzgy22Jr":{"_id":"jF58hKP9ZLzgy22Jr","__typename":"Book","createdAt":"2017-09-02T07:28:06.986Z","title":"Good and Bad Reasoning","number":1,"subtitle":null,"tocTitle":null,"contents":null,"sequenceIds":["XsMTxdQ6fprAQMoKi","NHXY86jBahi968uW4","TQW9brvXJ5Fajorr4"],"sequences":[{"__ref":"Sequence:XsMTxdQ6fprAQMoKi"},{"__ref":"Sequence:NHXY86jBahi968uW4"},{"__ref":"Sequence:TQW9brvXJ5Fajorr4"}],"postIds":[],"posts":[],"collectionId":"2izXHCrmJ684AnZ5X","displaySequencesAsGrid":null,"hideProgressBar":null,"showChapters":null},"Revision:Aq8eTBkLZARRzqe5h_contents":{"_id":"Aq8eTBkLZARRzqe5h_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:29:52.393Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:5c6392dcbcb4ac6367c16e4c":{"_id":"5c6392dcbcb4ac6367c16e4c","__typename":"Revision","htmlHighlight":"<p>Aquinas famously <A HREF=\"http://en.wikipedia.org/wiki/Homo_unius_libri\">said<\/A>: beware the man of one book. I would add: beware the man of one study.<\/p><p>For example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result &#8211; that it&#8217;s weakly effective.<\/p><p>But there will also be random noise caused by inevitable variation and by some of the experiments being better quality than others. In the end, we might expect something looking kind of like a bell curve. The peak will be at &#8220;weakly effective&#8221;, but there will be a few studies to either side. Something like this:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/onestudy.png\"><\/center><\/p><p>We see that the peak of the curve is somewhere to the right of neutral &#8211; ie weakly effective &#8211; and that there are about 15 studies that find this correct result.<\/p><p>But there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There&#8217;s even 1 study finding that the drug is very bad, maybe seriously dangerous.<\/p><p>This is before we get into fraud or statistical malpractice. I&#8217;m saying this is what&#8217;s going to happen just by normal variation in experimental design. As we increase experimental rigor, the bell curve might get squashed horizontally, but there will still be a bell curve.<\/p><p>In practice it&#8217;s worse than this, because this is assuming everyone is investigating exactly the same question.<\/p><p>Suppose that the graph is titled &#8220;Effectiveness Of This Drug In Treating Bipolar Disorder&#8221;. <\/p><p>But maybe the drug is more effective in bipolar i than in bipolar ii (Depakote, for example)<\/p><p>Or maybe the drug is very effective against bipolar mania, but much less effective against bipolar depression (Depakote again).<\/p><p>Or maybe the drug is a good acute antimanic agent, but very poor at maintenance treatment (let&#8217;s stick with Depakote).<\/p><p>If you have a graph titled &#8220;Effectiveness Of Depakote In Treating Bipolar Disorder&#8221; plotting studies from &#8220;Very Bad&#8221; to &#8220;Very Good&#8221; &#8211; and you stick all the studies &#8211; maintenence, manic, depressive, bipolar i, bipolar ii &#8211; on the graph, then you&#8217;re going to end running the gamut from &#8220;very bad&#8221; to &#82... <\/p>","plaintextDescription":"Aquinas famously said: beware the man of one book. I would add: beware the man of one study.\n\nFor example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result – that it’s weakly effective.\n\nBut there will also be random noise caused by inevitable variation and by some of the experiments being better quality than others. In the end, we might expect something looking kind of like a bell curve. The peak will be at “weakly effective”, but there will be a few studies to either side. Something like this:\n\n\n\nWe see that the peak of the curve is somewhere to the right of neutral – ie weakly effective – and that there are about 15 studies that find this correct result.\n\nBut there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There’s even 1 study finding that the drug is very bad, maybe seriously dangerous.\n\nThis is before we get into fraud or statistical malpractice. I’m saying this is what’s going to happen just by normal variation in experimental design. As we increase experimental rigor, the bell curve might get squashed horizontally, but there will still be a bell curve.\n\nIn practice it’s worse than this, because this is assuming everyone is investigating exactly the same question.\n\nSuppose that the graph is titled “Effectiveness Of This Drug In Treating Bipolar Disorder”.\n\nBut maybe the drug is more effective in bipolar i than in bipolar ii (Depakote, for example)\n\nOr maybe the drug is very effective against bipolar mania, but much less effective against bipolar depression (Depakote again).\n\nOr maybe the drug is a good acute antimanic agent, but very poor at maintenance treatment (let’s stick with Depakote).\n\nIf you have a graph titled “E","wordCount":2504,"version":"1.0.0"},"Revision:ZpG9rheyAkgCoEQea_description":{"_id":"ZpG9rheyAkgCoEQea_description","__typename":"Revision","htmlHighlight":"<p><strong>Practice and Philosophy of Science<\/strong> is for posts that discuss how science is done or should be done; examples include <a href=\"https://www.lesswrong.com/posts/tSemJckYr29Gnxod2/building-intuitions-on-non-empirical-arguments-in-science\">Building Intuitions on Non-Empirical Arguments in Science<\/a> and the <a href=\"https://www.lesswrong.com/s/fxynfGCSHpY4FmBZy\">Science and Rationality sequence<\/a>. (It is not for posts that simply report on a new scientific result.)<\/p>"},"Tag:ZpG9rheyAkgCoEQea":{"_id":"ZpG9rheyAkgCoEQea","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZpG9rheyAkgCoEQea_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Practice & Philosophy of Science","shortName":null,"slug":"practice-and-philosophy-of-science","core":false,"postCount":240,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-10T11:53:33.735Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:ythFNoiAotjvuEGkg":{"_id":"ythFNoiAotjvuEGkg","__typename":"SocialPreviewType","imageUrl":""},"Post:ythFNoiAotjvuEGkg":{"_id":"ythFNoiAotjvuEGkg","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e4c"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":10,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ZpG9rheyAkgCoEQea"},{"__ref":"Tag:vcvfjGJwRmFbMMS3d"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:ythFNoiAotjvuEGkg"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-12-12T09:04:56.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":2,"ZpG9rheyAkgCoEQea":3,"vcvfjGJwRmFbMMS3d":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e4c","commentCount":1,"voteCount":57,"baseScore":62,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":57,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0001308673236053437,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2019-06-07T18:00:26.750Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":8,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"beware-the-man-of-one-study","title":"Beware The Man Of One Study","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e18":{"_id":"5c6392dcbcb4ac6367c16e18","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>As usual, I was insufficiently pessimistic.<\/p><p>I infer this from <i>The Federalist<\/i>&#8216;s <A HREF=\"http://thefederalist.com/2014/12/11/new-doj-data-on-sexual-assaults-college-students-are-actually-less-likely-to-be-victimized/\">article on campus rape<\/A>:<\/p>\n<blockquote><p>A new report on sexual assault released today by the U.S. Department of Justice (DOJ) officially puts to bed the bogus statistic that one in five women on college campuses are victims of sexual assault. In fact, non-students are 25 percent more likely to be victims of sexual assault than students, according to the data. And the real number of assault victims is several orders of magnitude lower than one-in-five.<\/p><\/blockquote>\n<p>The article compares the older Campus Sexual Assault Survey (which found 14-20% of women were raped since entering college) to the just-released National Crime Victmization Survey (which found that 0.6% of female college students are raped per year). They write &#8220;Instead of 1 in 5, the real number is 0.03 in 5.&#8221;<\/p><p>So the first thing I will mock <i>The Federalist<\/i> for doing is directly comparing per year sexual assault rates to per college career sexual assault rates, whereas obviously these are very different things. You can&#8217;t <i>quite<\/i> just divide the latter by four to get the former, but that&#8217;s going to work a heck of a lot better than <i>not<\/i> doing it, so let&#8217;s estimate the real discrepancy as more like 0.5% per year versus 5% per year. <\/p><p>But I can&#8217;t get too mad at them yet, because that&#8217;s still a pretty big discrepancy.<\/p><p><i>However,<\/i> faced with this discrepancy a reasonable person might say &#8220;Hmm, we have two different studies that say two different things. I wonder what&#8217;s going on here and which study we should believe?&#8221;<\/p><p><i>The Federalist<\/i> staff said &#8220;Ha! There&#8217;s an old study with findings we didn&#8217;t like, but now there&#8217;s a new study with different findings we <i>do<\/i> like. So the old study is debunked!&#8221;<\/p><p><b>II.<\/b><\/p><p>My last essay, <A HREF=\"http://slatestarcodex.com/2014/12/12/beware-the-man-of-one-study/\">Beware The Man Of One Study<\/A>, noted that one thing partisans do to justify their bias is selectively acknowledge studies from only one side of a complicated literature.<\/p><p>The reason it was insufficiently pessimistic is that there are also people like the Federalist staff, who acknowledge the existence of opposing studies, but only with the adjective &#8220;debunked&#8221; in front of them. By &#8220;debunked&#8221; they usually mean one of two things:<\/p><p>1. Someone on my side published a study later that found something else<br />\n2. Someone on my side accused it of having methodol... <\/p>","plaintextDescription":"I.\n\nAs usual, I was insufficiently pessimistic.\n\nI infer this from The Federalist‘s article on campus rape:\n\n> A new report on sexual assault released today by the U.S. Department of Justice (DOJ) officially puts to bed the bogus statistic that one in five women on college campuses are victims of sexual assault. In fact, non-students are 25 percent more likely to be victims of sexual assault than students, according to the data. And the real number of assault victims is several orders of magnitude lower than one-in-five.\n\nThe article compares the older Campus Sexual Assault Survey (which found 14-20% of women were raped since entering college) to the just-released National Crime Victmization Survey (which found that 0.6% of female college students are raped per year). They write “Instead of 1 in 5, the real number is 0.03 in 5.”\n\nSo the first thing I will mock The Federalist for doing is directly comparing per year sexual assault rates to per college career sexual assault rates, whereas obviously these are very different things. You can’t quite just divide the latter by four to get the former, but that’s going to work a heck of a lot better than not doing it, so let’s estimate the real discrepancy as more like 0.5% per year versus 5% per year.\n\nBut I can’t get too mad at them yet, because that’s still a pretty big discrepancy.\n\nHowever, faced with this discrepancy a reasonable person might say “Hmm, we have two different studies that say two different things. I wonder what’s going on here and which study we should believe?”\n\nThe Federalist staff said “Ha! There’s an old study with findings we didn’t like, but now there’s a new study with different findings we do like. So the old study is debunked!”\n\nII.\n\nMy last essay, Beware The Man Of One Study, noted that one thing partisans do to justify their bias is selectively acknowledge studies from only one side of a complicated literature.\n\nThe reason it was insufficiently pessimistic is that there are also people like th","wordCount":1878,"version":"1.0.0"},"SocialPreviewType:kdmCm5NQTpqhJmGm6":{"_id":"kdmCm5NQTpqhJmGm6","__typename":"SocialPreviewType","imageUrl":""},"Post:kdmCm5NQTpqhJmGm6":{"_id":"kdmCm5NQTpqhJmGm6","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e18"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:AHK82ypfxF45rqh9D"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"}],"socialPreviewData":{"__ref":"SocialPreviewType:kdmCm5NQTpqhJmGm6"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-12-13T12:08:44.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"AHK82ypfxF45rqh9D":5,"bh7uxTTqmsQ8jZJdB":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e18","commentCount":4,"voteCount":36,"baseScore":46,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":36,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00009899999713525176,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-06-17T01:56:27.656Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":5,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"debunked-and-well-refuted","title":"Debunked And Well-Refuted","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16cee":{"_id":"5c6392c7bcb4ac6367c16cee","__typename":"Revision","htmlHighlight":"<p><b>Beware of Phantom Lizardmen<\/b><\/p><p>I have only done a little bit of social science research, but it was enough to make me hate people. One study I helped with analyzed whether people from different countries had different answers on a certain psychological test. So we put up a website where people answered some questions about themselves (like &#8220;what country are you from?&#8221;) and then took the psychological test.<\/p><p>And so of course people screwed it up in every conceivable way. There were the merely dumb, like the guy who put &#8220;male&#8221; as his nationality and &#8220;American&#8221; as his gender. But there were also the actively malicious or at least annoying, like the people (yes, more than one) who wrote in &#8220;Martian&#8221;.<\/p><p>I think we all probably know someone like this, maybe a couple people like this.<\/p><p>I also think most of us <i>don&#8217;t<\/i> know someone who believes reptilian aliens in human form control all the major nations of Earth.<\/p><p>Public Policy Polling&#8217;s recent <a href=\"http://www.publicpolicypolling.com/main/2013/04/conspiracy-theory-poll-results-.html\">poll on conspiracy theories<\/a> mostly showed up on my Facebook feed as &#8220;Four percent of Americans believe lizardmen are running the Earth&#8221;.<\/p><p>(of note, an additional 7% of Americans are &#8220;not sure&#8221; whether lizardmen are running the Earth or not.)<\/p><p>Imagine the situation. You&#8217;re at home, eating dinner. You get a call from someone who says &#8220;Hello, this is Public Policy Polling. Would you mind answering some questions for us?&#8221; You say &#8220;Sure&#8221;. An extremely dignified sounding voice says &#8211; and this is the exact wording of the question &#8211; &#8220;Do you believe that shape-shifting reptilian people control our world by taking on human form and gaining political power to manipulate our society, or not?&#8221; Then it urges you to press 1 if yes, press 2 if no, press 3 if not sure.<\/p><p>So first we get the people who think &#8220;Wait, was 1 the one for if I did believe in lizardmen, or if I didn&#8217;t? I&#8217;ll just press 1 and move on to the next question.&#8221;<\/p><p>Then we get the people who are like &#8220;I never heard it before, but if this nice pollster thinks it&#8217;s true, I might as well go along with them.&#8221;<\/p><p>Then we get the people who are all &#8220;F#&amp;k you, polling company, I don&#8217;t want people calling me when I&#8217;m at dinner. You screw with me, I tell you what I&#8217;m going to do. I&#8217;m going to tell you I... <\/p>","plaintextDescription":"Beware of Phantom Lizardmen\n\nI have only done a little bit of social science research, but it was enough to make me hate people. One study I helped with analyzed whether people from different countries had different answers on a certain psychological test. So we put up a website where people answered some questions about themselves (like “what country are you from?”) and then took the psychological test.\n\nAnd so of course people screwed it up in every conceivable way. There were the merely dumb, like the guy who put “male” as his nationality and “American” as his gender. But there were also the actively malicious or at least annoying, like the people (yes, more than one) who wrote in “Martian”.\n\nI think we all probably know someone like this, maybe a couple people like this.\n\nI also think most of us don’t know someone who believes reptilian aliens in human form control all the major nations of Earth.\n\nPublic Policy Polling’s recent poll on conspiracy theories mostly showed up on my Facebook feed as “Four percent of Americans believe lizardmen are running the Earth”.\n\n(of note, an additional 7% of Americans are “not sure” whether lizardmen are running the Earth or not.)\n\nImagine the situation. You’re at home, eating dinner. You get a call from someone who says “Hello, this is Public Policy Polling. Would you mind answering some questions for us?” You say “Sure”. An extremely dignified sounding voice says – and this is the exact wording of the question – “Do you believe that shape-shifting reptilian people control our world by taking on human form and gaining political power to manipulate our society, or not?” Then it urges you to press 1 if yes, press 2 if no, press 3 if not sure.\n\nSo first we get the people who think “Wait, was 1 the one for if I did believe in lizardmen, or if I didn’t? I’ll just press 1 and move on to the next question.”\n\nThen we get the people who are like “I never heard it before, but if this nice pollster thinks it’s true, I might as well go al","wordCount":1590,"version":"1.0.0"},"SocialPreviewType:CsKrQdQJJCFPjfKjF":{"_id":"CsKrQdQJJCFPjfKjF","__typename":"SocialPreviewType","imageUrl":""},"Post:CsKrQdQJJCFPjfKjF":{"_id":"CsKrQdQJJCFPjfKjF","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16cee"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:CsKrQdQJJCFPjfKjF"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-04-12T10:49:25.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":1,"bh7uxTTqmsQ8jZJdB":1,"gHCNhqxuJq2bZ2akb":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16cee","commentCount":1,"voteCount":36,"baseScore":42,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":35,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00007400000322377309,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2019-01-10T19:52:25.792Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":5,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"noisy-poll-results-and-reptilian-muslim-climatologists-from","title":"Noisy Poll Results And Reptilian Muslim Climatologists from Mars","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16ccd":{"_id":"5c6392c7bcb4ac6367c16ccd","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>First we have <A HREF=\"http://www.socio.mta.hu/dynamic/simmons_et_al_2011.pdf\">False Positive Psychology: Undisclosed Flexibility In Data Collection And Analysis Allows Presenting Anything As Significant<\/A> (h/t Jonas Vollmer).<\/p><p>The message is hardly unique: there are lots of tricks unscrupulous or desperate scientists can use to artificially nudge results to the 5% significance level. The clarity of the presentation <i>is<\/i> unique. They start by discussing four particular tricks:<\/p><p>1. Measure multiple dependent variables, then report the ones that are significant. For example, if you&#8217;re measuring whether treatment for a certain psychiatric disorder improves life outcomes, you can collect five different measures of life outcomes &#8211; let&#8217;s say educational attainment, income, self-reported happiness, whether or not ever arrested, whether or not in romantic relationship &#8211; and have a 25%-ish probability one of them will come out at significance by chance. Then you can publish a paper called &#8220;Psychiatric Treatment Found To Increase Educational Attainment&#8221; without ever mentioning the four negative tests.<\/p><p>2. Artificially choose when to end your experiment. Suppose you want to prove that yelling at a coin makes it more likely to come up tails. You yell at a coin and flip it. It comes up heads. You try again. It comes up tails. You try again. It comes up heads. You try again. It comes up tails. You try again. It comes up tails again. You try again. It comes up tails again. You note that it came up tails four out of six times &#8211; a 66% success rate compared to expected 50% &#8211; and declare victory. Of course, this result wouldn&#8217;t be significant, and it seems as if this should be a general rule &#8211; that almost by the definition of significance, you shouldn&#8217;t be able to obtain it just be stopping the experiment at the right point. But the authors of the study perform several simulations to prove that this trick is more successful than you&#8217;d think:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/darkstats0.png\"><\/center><\/p><p>3. Control for &#8220;confounders&#8221; (in practice, most often gender). I sometimes call this the &#8220;Elderly Hispanic Woman Effect&#8221; after drug trials that find that their drug doesn&#8217;t have significant effects in the general population, but it <i>does<\/i> significantly help elderly Hispanic women.  The trick is you split the population into twenty subgroups (young white men, young white women, elderly white men, elderly white wome... <\/p>","plaintextDescription":"I.\n\nFirst we have False Positive Psychology: Undisclosed Flexibility In Data Collection And Analysis Allows Presenting Anything As Significant (h/t Jonas Vollmer).\n\nThe message is hardly unique: there are lots of tricks unscrupulous or desperate scientists can use to artificially nudge results to the 5% significance level. The clarity of the presentation is unique. They start by discussing four particular tricks:\n\n1. Measure multiple dependent variables, then report the ones that are significant. For example, if you’re measuring whether treatment for a certain psychiatric disorder improves life outcomes, you can collect five different measures of life outcomes – let’s say educational attainment, income, self-reported happiness, whether or not ever arrested, whether or not in romantic relationship – and have a 25%-ish probability one of them will come out at significance by chance. Then you can publish a paper called “Psychiatric Treatment Found To Increase Educational Attainment” without ever mentioning the four negative tests.\n\n2. Artificially choose when to end your experiment. Suppose you want to prove that yelling at a coin makes it more likely to come up tails. You yell at a coin and flip it. It comes up heads. You try again. It comes up tails. You try again. It comes up heads. You try again. It comes up tails. You try again. It comes up tails again. You try again. It comes up tails again. You note that it came up tails four out of six times – a 66% success rate compared to expected 50% – and declare victory. Of course, this result wouldn’t be significant, and it seems as if this should be a general rule – that almost by the definition of significance, you shouldn’t be able to obtain it just be stopping the experiment at the right point. But the authors of the study perform several simulations to prove that this trick is more successful than you’d think:\n\n\n\n3. Control for “confounders” (in practice, most often gender). I sometimes call this the “Elderly Hispani","wordCount":1974,"version":"1.0.0"},"Revision:XYHzLjwYiqpeqaf4c_description":{"_id":"XYHzLjwYiqpeqaf4c_description","__typename":"Revision","htmlHighlight":"<p><strong>Dark Arts <\/strong>is a colloquial term for techniques or methods which involve deception and/or manipulation of others or oneself into believing things for non-truth-seeking reasons. These techniques may prey on human cognitive biases.<\/p><p>Some use the term to refer more narrowly to techniques that work equally well to compel both true and false beliefs, i.e., they are <a href=\"https://www.lesswrong.com/posts/qajfiXo5qRThZQG7s/guided-by-the-beauty-of-our-weapons\">symmetric weapons<\/a>. Some focus more on the Dark Arts as applied to oneself (self-deception) vs applied to manipulating others.<\/p><p>An example from the <a href=\"https://www.lesswrong.com/posts/4DBBQkEQvNEWafkek/dark-arts-of-rationality\">Dark Arts of Rationality<\/a>:<\/p><blockquote><p>Today, we're going to talk about Dark rationalist techniques: productivity tools which seem incoherent, mad, and downright irrational. These techniques include:<\/p><ol><li>Willful Inconsistency<\/li><li>Intentional Compartmentalization<\/li><li>Modifying Terminal Goals<\/li><\/ol><\/blockquote><h2>Art vs. Technology<\/h2><p>Sometimes these arts are further augmented by the use of <strong>persuasion technology<\/strong>, such as broadcast advertising or PowerPoint slides. Persuasion technology may prevent the person who is being targeted from carefully deliberating on the intended message, or thinking up an effective response to it in real time.<\/p><p>Such effects can be caused by something as benign as the use of a specialist vocabulary which the target is unfamiliar with, or an institutional vocabulary with high-status connotations: this is one reason why many specialist professions employ ethical codes to regulate their unbalanced power relationship with customers.<\/p><p>The use of such techniques as whiteboards or PowerPoint slides brings additional concerns, since these tend to connote a single party as the one \"in charge\" of the presentation: this makes it even more difficult for the intended audience to raise any effective objection, and encourages them to focus their attention on the content of the whiteboard or slides. Said content is often presented as a list of abrupt \"bullet points\", further connoting it as factual, objective and neutral. One outspoken critic of PowerPoint, management professor David R. Beatty, states: \"It is like a disease. It's the AIDS of management.\" Beatty further states that Powerpoint \"removes subtlety and thinking\".<\/p><p>Many futurists expect that a technological singularity of even a very mild character will lead to an explosion in the use of radically effective persuasive technology, or \"cognotechnology\"--a term coined by American military researchers at the Lawrence Livermore Laboratories. The collection and... <\/p>"},"Tag:XYHzLjwYiqpeqaf4c":{"_id":"XYHzLjwYiqpeqaf4c","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:XYHzLjwYiqpeqaf4c_description"},"canVoteOnRels":null,"userId":"73yyrm8KF6GDK9sRy","name":"Dark Arts","shortName":null,"slug":"dark-arts","core":false,"postCount":61,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-01T14:13:34.342Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:SQAfPKZBAAKYMjx25":{"_id":"SQAfPKZBAAKYMjx25","__typename":"SocialPreviewType","imageUrl":""},"Post:SQAfPKZBAAKYMjx25":{"_id":"SQAfPKZBAAKYMjx25","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16ccd"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:XYHzLjwYiqpeqaf4c"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"}],"socialPreviewData":{"__ref":"SocialPreviewType:SQAfPKZBAAKYMjx25"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-01-02T05:51:30.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"XYHzLjwYiqpeqaf4c":2,"bh7uxTTqmsQ8jZJdB":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16ccd","commentCount":4,"voteCount":35,"baseScore":36,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":35,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00006900000153109431,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-09-16T16:28:06.306Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"two-dark-side-statistics-papers","title":"Two Dark Side Statistics Papers","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16c47":{"_id":"5c6392c7bcb4ac6367c16c47","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Allan Crossman calls parapsychology <A HREF=\"http://lesswrong.com/lw/1ib/parapsychology_the_control_group_for_science/\">the control group for science<\/A>.<\/p><p>That is, in let&#8217;s say a drug testing experiment, you give some people the drug and they recover. That doesn&#8217;t tell you much until you give some other people a placebo drug you <i>know<\/i> doesn&#8217;t work &#8211; but which they themselves believe in &#8211; and see how many of <i>them<\/i> recover. That number tells you how many people will recover whether the drug works or not. Unless people on your real drug do significantly better than people on the placebo drug, you haven&#8217;t found anything.<\/p><p>On the meta-level, you&#8217;re studying some phenomenon and you get some positive findings. That doesn&#8217;t tell you much until you take some other researchers who are studying a phenomenon you <i>know<\/i> doesn&#8217;t exist &#8211; but which they themselves believe in &#8211; and see how many of <i>them<\/i> get positive findings. That number tells you how many studies will discover positive results whether the phenomenon is real or not. Unless studies of the real phenomenon do significantly better than studies of the placebo phenomenon, you haven&#8217;t found anything.<\/p><p>Trying to set up placebo science would be a logistical nightmare. You&#8217;d have to find a phenomenon that definitely doesn&#8217;t exist, somehow convince a whole community of scientists across the world that it does, and fund them to study it for a couple of decades without them figuring it out.<\/p><p>Luckily we have a natural experiment in terms of parapsychology &#8211; the study of psychic phenomena &#8211; which most reasonable people believe don&#8217;t exist, but which a community of practicing scientists believes in and publishes papers on all the time.<\/p><p>The results are pretty dismal. Parapsychologists are able to produce experimental evidence for psychic phenomena about as easily as normal scientists are able to produce such evidence for normal, non-psychic phenomena. This suggests the existence of a very large &#8220;placebo effect&#8221; in science &#8211; ie with enough energy focused on a subject, you can <i>always<\/i> produce &#8220;experimental evidence&#8221; for it that meets the usual scientific standards. As Eliezer Yudkowsky puts it:<\/p>\n<blockquote><p>Parapsychologists are constantly protesting that they are playing by all the standard scientific rules, and yet their results are being ignored &#8211; that they are unfairly being held to higher standard<\/p><\/blockquote>... ","plaintextDescription":"I.\n\nAllan Crossman calls parapsychology the control group for science.\n\nThat is, in let’s say a drug testing experiment, you give some people the drug and they recover. That doesn’t tell you much until you give some other people a placebo drug you know doesn’t work – but which they themselves believe in – and see how many of them recover. That number tells you how many people will recover whether the drug works or not. Unless people on your real drug do significantly better than people on the placebo drug, you haven’t found anything.\n\nOn the meta-level, you’re studying some phenomenon and you get some positive findings. That doesn’t tell you much until you take some other researchers who are studying a phenomenon you know doesn’t exist – but which they themselves believe in – and see how many of them get positive findings. That number tells you how many studies will discover positive results whether the phenomenon is real or not. Unless studies of the real phenomenon do significantly better than studies of the placebo phenomenon, you haven’t found anything.\n\nTrying to set up placebo science would be a logistical nightmare. You’d have to find a phenomenon that definitely doesn’t exist, somehow convince a whole community of scientists across the world that it does, and fund them to study it for a couple of decades without them figuring it out.\n\nLuckily we have a natural experiment in terms of parapsychology – the study of psychic phenomena – which most reasonable people believe don’t exist, but which a community of practicing scientists believes in and publishes papers on all the time.\n\nThe results are pretty dismal. Parapsychologists are able to produce experimental evidence for psychic phenomena about as easily as normal scientists are able to produce such evidence for normal, non-psychic phenomena. This suggests the existence of a very large “placebo effect” in science – ie with enough energy focused on a subject, you can always produce “experimental evidence” for ","wordCount":4617,"version":"1.0.0"},"SocialPreviewType:bXuAXCbzw9hsJSuEN":{"_id":"bXuAXCbzw9hsJSuEN","__typename":"SocialPreviewType","imageUrl":""},"Post:bXuAXCbzw9hsJSuEN":{"_id":"bXuAXCbzw9hsJSuEN","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16c47"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":18,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:vg4LDxjdwHLotCm8w"}],"socialPreviewData":{"__ref":"SocialPreviewType:bXuAXCbzw9hsJSuEN"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-04-29T00:46:27.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"vg4LDxjdwHLotCm8w":22},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16c47","commentCount":5,"voteCount":32,"baseScore":43,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":32,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00008499999967170879,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-06-23T16:39:00.339Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":6,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-control-group-is-out-of-control","title":"The Control Group Is Out Of Control","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e44":{"_id":"5c6392dcbcb4ac6367c16e44","__typename":"Revision","htmlHighlight":"<p>I remember hearing someone I know try to explain rationality to his friends.<\/p><p>He started with &#8220;It&#8217;s important to have correct beliefs. You might think this is obvious, but think about creationists and homeopaths and people who think the moon landing was a hoax.&#8221; And then further on in this vein.<\/p><p>And I thought: &#8220;NO NO NO NO NO NO NO!&#8221;<\/p><p>I will make a confession. Every time someone talks about the stupidity of creationists, moon-hoaxers, and homeopaths, I cringe.<\/p><p>It&#8217;s not that moon-hoaxers, homeopaths et al aren&#8217;t dumb. They are. It&#8217;s not even that these people don&#8217;t do real harm. They do.<\/p><p>(although probably less than people think; people rarely stop conventional treatment in favor of homeopathy, and both <A HREF=\"http://whatstheharm.net/homeopathy.html\">a popular website<\/A> and <A HREF=\"http://onlinelibrary.wiley.com/doi/10.1111/ijcp.12026/full\">a review article<\/A> have a really hard time finding more than a handful of people genuinely harmed by it. Moon hoaxes seem even less dangerous, <A HREF=\"http://news.bbc.co.uk/2/hi/americas/2272321.stm\">unless of course you are standing near Buzz Aldrin when you talk about them<\/A>.)<\/p><p>What annoys me about the people who harp on moon-hoaxing and homeopathy &#8211; without any interest in the rest of medicine or space history &#8211;  is that it seems like an attempt to Other irrationality.<\/p><p>(yes, I did just use &#8220;other&#8221; as a verb. Maybe I&#8217;ve been hanging around Continental types too much lately.)<\/p><p>It&#8217;s saying &#8220;Look, over here! It&#8217;s irrational people, believing things that we can instantly dismiss as dumb. Things we feel no temptation, not one bit, to believe. It must be that they are defective and we are rational.&#8221;<\/p><p>But to me, the rationality movement is about Self-ing irrationality.<\/p><p>(yes, I did just use &#8220;self&#8221; as a verb. I don&#8217;t even have the excuse of it being part of a philosophical tradition)<\/p><p>It is about realizing that you, yes you, might be wrong about the things that you&#8217;re most certain of, and nothing can save you except maybe extreme epistemic paranoia.<\/p><p>Talking about moon-hoaxers and homeopaths too much, at least the way we do it, is <i>counterproductive<\/i> to this goal. Throw examples of obviously stupid false beliefs at someone, and they start thinking all false beliefs are obvious. Give too many examples of false beliefs that aren&#8217;t tempting to them, and they start believing they&#8217;re immune to temptation.<\/p><p>And it raises sloppiness to a virtue.<\/p><p>Take homeopathy. I can&#8217;t even count the num... <\/p>","plaintextDescription":"I remember hearing someone I know try to explain rationality to his friends.\n\nHe started with “It’s important to have correct beliefs. You might think this is obvious, but think about creationists and homeopaths and people who think the moon landing was a hoax.” And then further on in this vein.\n\nAnd I thought: “NO NO NO NO NO NO NO!”\n\nI will make a confession. Every time someone talks about the stupidity of creationists, moon-hoaxers, and homeopaths, I cringe.\n\nIt’s not that moon-hoaxers, homeopaths et al aren’t dumb. They are. It’s not even that these people don’t do real harm. They do.\n\n(although probably less than people think; people rarely stop conventional treatment in favor of homeopathy, and both a popular website and a review article have a really hard time finding more than a handful of people genuinely harmed by it. Moon hoaxes seem even less dangerous, unless of course you are standing near Buzz Aldrin when you talk about them.)\n\nWhat annoys me about the people who harp on moon-hoaxing and homeopathy – without any interest in the rest of medicine or space history – is that it seems like an attempt to Other irrationality.\n\n(yes, I did just use “other” as a verb. Maybe I’ve been hanging around Continental types too much lately.)\n\nIt’s saying “Look, over here! It’s irrational people, believing things that we can instantly dismiss as dumb. Things we feel no temptation, not one bit, to believe. It must be that they are defective and we are rational.”\n\nBut to me, the rationality movement is about Self-ing irrationality.\n\n(yes, I did just use “self” as a verb. I don’t even have the excuse of it being part of a philosophical tradition)\n\nIt is about realizing that you, yes you, might be wrong about the things that you’re most certain of, and nothing can save you except maybe extreme epistemic paranoia.\n\nTalking about moon-hoaxers and homeopaths too much, at least the way we do it, is counterproductive to this goal. Throw examples of obviously stupid false belief","wordCount":1394,"version":"1.0.0"},"Revision:9YFoDPFwMoWthzgkY_description":{"_id":"9YFoDPFwMoWthzgkY_description","__typename":"Revision","htmlHighlight":"<p><strong>Pitfalls of Rationality<\/strong> are frequent <a href=\"https://www.lesswrong.com/tag/failure-mode\">error modes<\/a>, obstacles or problems that arise when people try to practice rationality, or engage with rationality-related materials. Related concepts include the \"valley of bad rationality\".<br><br>There are two threads touched in posts under this tag:<\/p><ol><li>Things that go wrong when people try to be more rational and they unintentionally end up making things worse.<\/li><li>Arguably, why haven't rationalists visible succeeded at their bold and ambitious goals yet?<\/li><\/ol><p>Regarding the first point, from <a href=\"https://www.lesswrong.com/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley\">Incremental Progress and the Valley<\/a>:<\/p><blockquote><p>Ah.&nbsp; Well, here's the the thing:&nbsp; An <i>incremental<\/i> step in the direction of rationality, if the result is still irrational in other ways, does not have to yield <i>incrementally <\/i>more winning.<\/p><p>The optimality theorems that we have for probability theory and decision theory, are for <i>perfect<\/i> probability theory and decision theory.&nbsp; There is no companion theorem which says that, starting from some flawed initial form, every <i>incremental<\/i> modification of the algorithm that takes the structure closer to the ideal, must yield an <i>incremental<\/i> improvement in performance.&nbsp; This has not yet been proven, because it is not, in fact, true.<\/p><\/blockquote><p>See also: <a href=\"https://www.lesswrong.com/tag/criticisms-of-the-rationalist-movement\">Criticisms of the Rationalist Movement<\/a>, <a href=\"https://www.lesswrong.com/tag/value-of-rationality\">Value of Rationality<\/a><\/p>"},"Tag:9YFoDPFwMoWthzgkY":{"_id":"9YFoDPFwMoWthzgkY","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:9YFoDPFwMoWthzgkY_description"},"canVoteOnRels":null,"userId":"x5S2Kuj6TfQTGuo63","name":"Pitfalls of Rationality","shortName":null,"slug":"pitfalls-of-rationality","core":false,"postCount":76,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-11T19:31:37.154Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:izp6eeJJEg9v5zcur_description":{"_id":"izp6eeJJEg9v5zcur_description","__typename":"Revision","htmlHighlight":"<p>The <strong>LessWrong<\/strong> <strong>Community<\/strong> consists of the people who write on LessWrong and who contribute to its mission of refining the art of human rationality. This tag includes community events, analysis of the health, norms and direction of the community, and space to understand communities in general.<\/p><p>LessWrong also has many brothers and sisters like the Berkeley Rationality Community, <a href=\"https://www.reddit.com/r/slatestarcodex/\">SlateStarCodex<\/a>, <a href=\"https://www.reddit.com/r/rational/\">Rational Fiction<\/a>, <a href=\"https://forum.effectivealtruism.org/\">Effective Altruism<\/a>, <a href=\"https://www.alignmentforum.org/\">AI Alignment<\/a>, and more, who participate here. To see upcoming LessWrong events, go to the <a href=\"https://www.lesswrong.com/community\">community section<\/a>.<\/p><hr><h2><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Community Sub-Topics<\/strong><\/h2><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:50%\"><p><strong>All<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/bounties-active?showPostCount=true&amp;useTagName=true\">Bounties (active)<\/a><br><a href=\"https://www.lesswrong.com/tag/grants-and-fundraising-opportunities?showPostCount=true\">Grants &amp; Fundraising<\/a><br><a href=\"http://www.lesswrong.com/tag/growth-stories?showPostCount=true&amp;useTagName=true\">Growth Stories<\/a><br><a href=\"https://www.lesswrong.com/tag/online-socialization?showPostCount=true&amp;useTagName=true\">Online Socialization<\/a><br><a href=\"https://www.lesswrong.com/tag/petrov-day?showPostCount=true&amp;useTagName=true\">Petrov Day<\/a><br><a href=\"https://www.lesswrong.com/tag/public-discourse?showPostCount=true&amp;useTagName=true\">Public Discourse<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/ritual?showPostCount=true&amp;useTagName=true\">Ritual<\/a><br><a href=\"https://www.lesswrong.com/tag/solstice-celebration?showPostCount=true&amp;useTagName=true\">Solstice Celebration<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:50%\"><p><strong>LessWrong<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/events-community?showPostCount=true&amp;useTagName=true\">Events (Community)<\/a><br><a href=\"https://www.lesswrong.com/tag/site-meta?showPostCount=true&amp;useTagName=true\">Site Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/greaterwrong-meta?showPostCount=true&amp;useTagName=true\">GreaterWrong Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/lesswrong-events?showPostCount=true&amp;useTagName=true\">LessWrong Events<\/a><br><a href=\"http://www.lesswrong.com/tag/lw-moderation?showPostCount=true&amp;useTagName=true\">LW Moderation<\/a><br><a href=\"http://www.lesswrong.com/tag/meetups-topic?showPostCount=true&amp;useTagName=true\">Meetups (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/moderation-topic?showPostCount=true&amp;useTagName=true\">Moderation (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/the-sf-bay-area?showPostCount=true&amp;useTagName=true\">The SF Bay Area<\/a><br><a href=\"http://www.lesswrong.com/tag/tagging?showPostCount=true\">Tagging<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure><p><i>Not all Community posts are tagged with subtopics.<\/i><\/p><hr><p>This tag applies to any post about:<\/p><ul><li>Specific projects, orgs, and prizes [e.g. <a href=\"http://www.lesswrong.com/posts/xFGQdgJndLcthgWoE\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/cSzaxcmeYW6z7cgtc\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/nDHbgjdddG5EN6ocg\"><u>5<\/u><\/a>]<\/li><li>Requests and offers for help [<a href=\"http://www.lesswrong.com/posts/bSWavBThj6ebB62gD\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/LuL7LLqcdmM7TTYvW\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/x72ta8C3dKu2QRfPv\"><u>3<\/u><\/a>]<\/li><li>Announcements, retrospectives, funding requests, and AMAs from orgs [<a href=\"http://www.lesswrong.com/posts/XJiNtvxoiLCpBn6FH\"><u>1<\/u><\/a> <a href=\"https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama\"><u>2<\/u><\/a> <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/tCHsm5ZyAca8HfJSG\"><u>5<\/u><\/a>]<\/li><li>Discussions of the orgs in the LessWrong, Rationalist cluster [<a href=\"http://www.lesswrong.com/posts/KpnyCT7CZy4Qe6kx6\"><u>1<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/6SGqkCgHuNr7d4yJm/thoughts-on-the-singularity-institute-si\"><u>2<\/u><\/a>]<\/li><li>Discussions about the LessWrong, Rationalist, and related communities [<a href=\"http://www.lesswrong.com/posts/2Ee5DPBxowTTXZ6zf\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/yGycR8tFA3JJbvApp\"><u>2<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/zAqoj79A7QuhJKKvi\"><u>3<\/u><\/a>]<\/li><\/ul><p>While the <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a><i> <\/i>core tag is for posts discussing how to do good in general, the Community tag is for the specific, concrete efforts of our community to execute plans.<\/p>"},"Tag:izp6eeJJEg9v5zcur":{"_id":"izp6eeJJEg9v5zcur","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:izp6eeJJEg9v5zcur_description"},"canVoteOnRels":null,"userId":"XtphY3uYHwruKqDyG","name":"Community","shortName":null,"slug":"community","core":true,"postCount":2260,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":15,"createdAt":"2020-06-14T03:38:34.631Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:ckuuDa8DmJ4pdFeD8":{"_id":"ckuuDa8DmJ4pdFeD8","__typename":"SocialPreviewType","imageUrl":""},"Post:ckuuDa8DmJ4pdFeD8":{"_id":"ckuuDa8DmJ4pdFeD8","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e44"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:9YFoDPFwMoWthzgkY"},{"__ref":"Tag:izp6eeJJEg9v5zcur"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:ckuuDa8DmJ4pdFeD8"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-04-16T01:04:58.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"9YFoDPFwMoWthzgkY":1,"Ng8Gice9KNkncxqcj":2,"izp6eeJJEg9v5zcur":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e44","commentCount":1,"voteCount":42,"baseScore":59,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":42,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00011700000322889537,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-09-20T21:43:18.431Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":12,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":9,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-cowpox-of-doubt","title":"The Cowpox of Doubt","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e8b":{"_id":"5c6392dcbcb4ac6367c16e8b","__typename":"Revision","htmlHighlight":"<p>After a brief spurt of debate over the claim that &#8220;97% of relevant published papers support anthropogenic climate change&#8221;, I think the picture has mostly settled to an agreement that &#8211; although we can contest the methodology of that particular study &#8211; there are multiple lines of evidence that the number is somewhere in the nineties.<\/p><p>So if any doubt at all is to remain about climate change, it has to come from the worry that sometimes entire scientific fields can get things near-unanimously wrong, especially for political or conformity-related reasons.<\/p><p>In fact, I&#8217;d go so far as to say that if we are not climatologists ourselves, our prior on climate change should be <i>based upon<\/i> how frequently entire scientific fields get things terribly wrong for political or conformity-related reasons.<\/p><p>Skeptics mock the claim that <A HREF=\"http://skeptico.blogs.com/skeptico/2005/11/science_wrong.html\">science was wrong before<\/A>, but skeptics mock <i>everything<\/i>. A better plan might be to try to quantify the frequency of scientific failures so we can see how good (or bad) the chances are for any given field.<\/p><p>Before we investigate, we should define our reference class properly. I think a scientific mistake only counts as a reason for doubting climate change (or any other commonly-accepted scientific paradigm) if:<\/p><p>1. It was made sometime in the recent past. Aristotle was wrong about all sorts of things, and so were those doctors who thought everything had to do with black bile, but the scientific community back then was a lot less rigorous than our own. Let&#8217;s say it counts if it&#8217;s after 1900.<\/p><p>2. It was part of a really important theory, one of the fundamental paradigms of an entire field. I&#8217;m sure some tiny group of biologists have been wrong about how many chromosomes a shrew has, but that&#8217;s probably an easier mistake to wander into than all of climatology screwing up simultaneously.<\/p><p>3. It was a stubborn resistance to the truth, rather than just a failure to have come up with the correct theory immediately. People were geocentrists before they were heliocentrists, but this wasn&#8217;t because the field of astronomy became overly politicized and self-assured, it was because (aside from <A HREF=\"http://en.wikipedia.org/wiki/Aristarchus_of_Samos\">one ancient Greek guy<\/A> nobody really read) heliocentrism wasn&#8217;t invented until the 1500s, and after that it took people a couple of generations to catch on. In the same way, Newton&#8217;s theory of gravity wasn&#8217;t q... <\/p>","plaintextDescription":"After a brief spurt of debate over the claim that “97% of relevant published papers support anthropogenic climate change”, I think the picture has mostly settled to an agreement that – although we can contest the methodology of that particular study – there are multiple lines of evidence that the number is somewhere in the nineties.\n\nSo if any doubt at all is to remain about climate change, it has to come from the worry that sometimes entire scientific fields can get things near-unanimously wrong, especially for political or conformity-related reasons.\n\nIn fact, I’d go so far as to say that if we are not climatologists ourselves, our prior on climate change should be based upon how frequently entire scientific fields get things terribly wrong for political or conformity-related reasons.\n\nSkeptics mock the claim that science was wrong before, but skeptics mock everything. A better plan might be to try to quantify the frequency of scientific failures so we can see how good (or bad) the chances are for any given field.\n\nBefore we investigate, we should define our reference class properly. I think a scientific mistake only counts as a reason for doubting climate change (or any other commonly-accepted scientific paradigm) if:\n\n1. It was made sometime in the recent past. Aristotle was wrong about all sorts of things, and so were those doctors who thought everything had to do with black bile, but the scientific community back then was a lot less rigorous than our own. Let’s say it counts if it’s after 1900.\n\n2. It was part of a really important theory, one of the fundamental paradigms of an entire field. I’m sure some tiny group of biologists have been wrong about how many chromosomes a shrew has, but that’s probably an easier mistake to wander into than all of climatology screwing up simultaneously.\n\n3. It was a stubborn resistance to the truth, rather than just a failure to have come up with the correct theory immediately. People were geocentrists before they were helioc","wordCount":1612,"version":"1.0.0"},"Revision:EvPPocx6FHcoDfygQ_description":{"_id":"EvPPocx6FHcoDfygQ_description","__typename":"Revision","htmlHighlight":"<p>A <strong>Consensus <\/strong>is a general or full agreement between members of a group. A consensus can be useful in deciding what's true (e.g, a scientific consensus), or as a criteria in decision making. A <strong>False Consensus<\/strong> can happen when someone thinks a position is in consensus when it isn't. one can also claim a consensus falsely to advance their position and make it difficult for others to oppose it. a <strong>False Controversy<\/strong> can happen when one mistakes something to not be in consensus when in fact it is. Claiming false controversies is a common way of creating uncertainty and doubt.<\/p><p>There are many things that are considered a consensus on LessWrong, even though they're are not considered a consensus in the scientific community, such as: <a href=\"https://www.lesswrong.com/tag/one-boxing\">One-Boxing<\/a>, cooperating on the <a href=\"https://www.lesswrong.com/tag/prisoner-s-dilemma\">Prisoner's Dilemma<\/a>, &nbsp;<a href=\"https://www.lesswrong.com/tag/bayesianism\">Bayesianism<\/a> over <a href=\"https://en.wikipedia.org/wiki/Frequentist_probability\">frequentist<\/a> probability (and more to be added)<\/p><p>Notable things that <i>aren't<\/i> in consensus on LessWrong include <a href=\"https://www.lesswrong.com/tag/blackmail-extortion\">Blackmail / Extortion<\/a>, <a href=\"https://www.lesswrong.com/tag/is-rationality-any-good\">the benefits of rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/ai-timelines\">AI Timelines<\/a> and <a href=\"https://www.lesswrong.com/tag/ai-takeoff\">AI Takeoff<\/a>, as well as <a href=\"Friendly Artificial Intelligence\">AI alignment strategies<\/a>,&nbsp;<\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/common-knowledge\">Common Knowledge<\/a>, <a href=\"https://www.lesswrong.com/tag/disagreement\">Disagreement<\/a>, <a href=\"https://www.lesswrong.com/tag/modesty\">Modesty<\/a>, <a href=\"https://www.lesswrong.com/tag/modesty-argument\">Modesty argument<\/a>, <a href=\"https://www.lesswrong.com/tag/aumann-agreement\">Aumann agreement<\/a>, <a href=\"https://www.lesswrong.com/tag/government\">Government<\/a> (in the context of democracies), <a href=\"https://www.lesswrong.com/tag/contrarianism\">Contrarianism<\/a><\/p><p><strong>See also:<\/strong> <a href=\"https://en.wikipedia.org/wiki/Consensus_(disambiguation)\">consensus on wikipedia<\/a><\/p>"},"Tag:EvPPocx6FHcoDfygQ":{"_id":"EvPPocx6FHcoDfygQ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:EvPPocx6FHcoDfygQ_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Consensus","shortName":null,"slug":"consensus","core":false,"postCount":23,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-01-26T12:04:18.098Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:5f5c37ee1b5cdee568cfb1a2_description":{"_id":"5f5c37ee1b5cdee568cfb1a2_description","__typename":"Revision","htmlHighlight":"<p><strong>Science<\/strong> is a method for developing true beliefs about the world. It works by developing hypotheses about the world, creating experiments that would allow the hypotheses to be tested, and running the experiments. By having people publish their falsifiable predictions and their experimental results, science protects itself from individuals deceiving themselves or others.<\/p><h2>Blog posts<\/h2><ul><li><a href=\"http://lesswrong.com/lw/in/scientific_evidence_legal_evidence_rational/\">Scientific Evidence, Legal Evidence, Rational Evidence<\/a><\/li><li><a href=\"http://lesswrong.com/lw/io/is_molecular_nanotechnology_scientific/\">Is Molecular Nanotechnology \"Scientific\"?<\/a><\/li><li><a href=\"http://lesswrong.com/lw/kj/no_one_knows_what_science_doesnt_know/\">No One Knows What Science Doesn't Know<\/a><\/li><li><a href=\"http://lesswrong.com/lw/ow/the_beauty_of_settled_science/\">The Beauty of Settled Science<\/a><\/li><li><a href=\"http://lesswrong.com/lw/qa/the_dilemma_science_or_bayes/\">The Dilemma: Science or Bayes?<\/a> and <a href=\"http://lesswrong.com/lw/qb/science_doesnt_trust_your_rationality/\">Science Doesn't Trust Your Rationality<\/a><\/li><li><a href=\"http://lesswrong.com/lw/qc/when_science_cant_help/\">When Science Can't Help<\/a>, <a href=\"http://lesswrong.com/lw/qd/science_isnt_strict_enough/\">Science Isn't Strict Enough<\/a>, <a href=\"http://lesswrong.com/lw/qe/do_scientists_already_know_this_stuff/\">Do Scientists Already Know This Stuff?<\/a> and <a href=\"http://lesswrong.com/lw/qf/no_safe_defense_not_even_science/\">No Safe Defense, Not Even Science<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/rational-evidence\">Rational evidence<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/general-knowledge\">General knowledge<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning\">Scholarship<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/traditional-rationality\">Traditional rationality<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/No_one_knows_what_science_doesn't_know\">No one knows what science doesn't know<\/a><\/li><\/ul>"},"Tag:5f5c37ee1b5cdee568cfb1a2":{"_id":"5f5c37ee1b5cdee568cfb1a2","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb1a2_description"},"canVoteOnRels":null,"userId":"XzXbiS2zWYNdZdLW8","name":"Science","shortName":null,"slug":"science","core":false,"postCount":13,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.140Z","wikiOnly":true,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:Sd2r7H8bCmd9ChGbX":{"_id":"Sd2r7H8bCmd9ChGbX","__typename":"SocialPreviewType","imageUrl":""},"Post:Sd2r7H8bCmd9ChGbX":{"_id":"Sd2r7H8bCmd9ChGbX","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e8b"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:EvPPocx6FHcoDfygQ"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb1a2"}],"socialPreviewData":{"__ref":"SocialPreviewType:Sd2r7H8bCmd9ChGbX"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-07-03T01:36:31.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"EvPPocx6FHcoDfygQ":1,"5f5c37ee1b5cdee568cfb1a2":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e8b","commentCount":8,"voteCount":22,"baseScore":23,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":22,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0000470000013592653,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-08-17T06:56:07.769Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":2,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"how-common-are-science-failures","title":"How Common Are Science Failures?","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392babcb4ac6367c1659b":{"_id":"5c6392babcb4ac6367c1659b","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[<b>Related to:<\/b> <A HREF=\"http://slatestarcodex.com/2015/08/09/contrarians-crackpots-and-consensus/\">Contrarians, Crackpots, and Consensus<\/A>, <A HREF=\"http://slatestarcodex.com/2014/07/02/how-common-are-science-failures/\">How Common Are Science Failures?<\/A>. Epistemic status is &#8220;subtle and likely to be misinterpreted&#8221;.]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>There&#8217;s a <A HREF=\"http://amasci.com/weird/vindac.html#j42\">list of scientific mavericks who were ridiculed by hidebound reactionaries but later vindicated<\/A> that&#8217;s been going viral. I examined the first ten mavericks on the list to see if its claims held up. Overall I wasn&#8217;t too impressed. Let me go over them in more detail.<\/p><p>SVANTE ARRHENIUS:<\/p>\n<blockquote><p>His idea that electrolytes are full of charged atoms was considered crazy. The atomic theory was new at the time, and everyone &#8220;knew&#8221; that atoms were indivisible (and hence they could not lose or gain any electric charge.) Because of his heretical idea, he only received his university degree by a very narrow margin.<\/p><\/blockquote>\n<p>Sure, the professors who were judging his PhD thesis weren&#8217;t too convinced. So Arrhenius sent his proposal to the world&#8217;s top chemists at the time, and they were super-interested and started fighting among themselves to work with Arrhenius on it. Top chemist Wilhelm Ostwald received the paper the same day his daughter was born, and suggested that the paper was the more exciting of the two events. He journeyed to Arrhenius&#8217; hometown of Uppsala, Sweden to try to convince Arrhenius to work with him; Arrhenius refused for personal reasons but later got a scholarship and worked with the top physicists in Europe. Arrhenius became a professor in a prestigious university about ten years after presenting his &#8220;ridiculed&#8221; paper, and won the Nobel Prize ten years after that.<\/p><p>HANS ALFVEN:<\/p>\n<blockquote><p>Astronomers thought that gravity alone is important in solar systems, in galaxies, etc. Alfven&#8217;s idea that plasma physics is of equal or greater importance to gravity was derided for decades.<\/p><\/blockquote>\n<p>This isn&#8217;t a great description of Alfven&#8217;s conflict with the establishment, but the list seems basically right insofar as Alfven&#8217;s ideas were ignored for thirty years before being proven mostly correct. I will give them this one.<\/p><p>JOHN BAIRD:<\/p>\n<blockquote><p>When the first television system was demonstrated to the Royal Society (British scientists,) they scoffed and ridiculed, calling Baird a swindler.<\/p><\/blockquote>\n<p>I can&#8217;t find any reference to this in various Baird articles and biographies. The closest I can come is <A HREF=\"http://www.bbc.com/news/uk-england-oxfordshire-38080275\">this article<\/A> by someone who was there at the demonstration, who sai... <\/p>","plaintextDescription":"[Related to: Contrarians, Crackpots, and Consensus, How Common Are Science Failures?. Epistemic status is “subtle and likely to be misinterpreted”.]\n\nI.\n\nThere’s a list of scientific mavericks who were ridiculed by hidebound reactionaries but later vindicated that’s been going viral. I examined the first ten mavericks on the list to see if its claims held up. Overall I wasn’t too impressed. Let me go over them in more detail.\n\nSVANTE ARRHENIUS:\n\n> His idea that electrolytes are full of charged atoms was considered crazy. The atomic theory was new at the time, and everyone “knew” that atoms were indivisible (and hence they could not lose or gain any electric charge.) Because of his heretical idea, he only received his university degree by a very narrow margin.\n\nSure, the professors who were judging his PhD thesis weren’t too convinced. So Arrhenius sent his proposal to the world’s top chemists at the time, and they were super-interested and started fighting among themselves to work with Arrhenius on it. Top chemist Wilhelm Ostwald received the paper the same day his daughter was born, and suggested that the paper was the more exciting of the two events. He journeyed to Arrhenius’ hometown of Uppsala, Sweden to try to convince Arrhenius to work with him; Arrhenius refused for personal reasons but later got a scholarship and worked with the top physicists in Europe. Arrhenius became a professor in a prestigious university about ten years after presenting his “ridiculed” paper, and won the Nobel Prize ten years after that.\n\nHANS ALFVEN:\n\n> Astronomers thought that gravity alone is important in solar systems, in galaxies, etc. Alfven’s idea that plasma physics is of equal or greater importance to gravity was derided for decades.\n\nThis isn’t a great description of Alfven’s conflict with the establishment, but the list seems basically right insofar as Alfven’s ideas were ignored for thirty years before being proven mostly correct. I will give them this one.\n\nJOHN BAIRD:\n\n>","wordCount":5566,"version":"1.0.0"},"Tag:Xno6pRXizN9AmFFTa":{"_id":"Xno6pRXizN9AmFFTa","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Implicit Association Test (IAT)","shortName":null,"slug":"implicit-association-test-iat","core":false,"postCount":3,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-19T23:21:58.148Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:aHjTRDkGypPqbXWpN_description":{"_id":"aHjTRDkGypPqbXWpN_description","__typename":"Revision","htmlHighlight":"<p><strong>Intellectual Progress <\/strong>is the progressive accumulation of knowledge. Questions include <i>How is intellectual progress made? <\/i>and <i>How do we make more?<\/i> <a href=\"https://www.lesswrong.com/tag/intellectual-progress-individual-level\">Intellectual Progress (Individual-Level)<\/a> and the <a href=\"https://www.lesswrong.com/tag/scholarship-and-learning\">Scholarship &amp; Learning<\/a> tag is focused on the learning and research of individuals. In contrast, Intellectual Progress (Society-Level) is about how we, humanity, collectively make progress on important questions. What broader conditions, institutions, and technologies enable progress?<\/p><p>Also related to: <a href=\"https://www.lesswrong.com/tag/progress-studies\">Progress Studies<\/a>, <a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science\">Practice &amp; Philosophy of Science<\/a><br>&nbsp;<\/p><p>[TO-DO: link Science tag(s)]<\/p>"},"Tag:aHjTRDkGypPqbXWpN":{"_id":"aHjTRDkGypPqbXWpN","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:aHjTRDkGypPqbXWpN_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Intellectual Progress (Society-Level)","shortName":null,"slug":"intellectual-progress-society-level","core":false,"postCount":115,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-19T20:22:19.435Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:fF9GEdWXKJ3z73TmB_description":{"_id":"fF9GEdWXKJ3z73TmB_description","__typename":"Revision","htmlHighlight":"<p><strong>Scholarship &amp; Learning. <\/strong>Here be posts on how to study, research, and learn.<\/p><p>Topics include, but are not limited to: how to research, how to understand material deeply, note-taking, and useful scholarship resources.<\/p><blockquote><p><i>The eleventh virtue is scholarship. Study many sciences and absorb their power as your own. Each field that you consume makes you larger. If you swallow enough sciences the gaps between them will diminish and your knowledge will become a unified whole. If you are gluttonous you will become vaster than mountains. – <\/i><a href=\"https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/twelve-virtues-of-rationality\"><i>Twelve Virtues of Rationality<\/i><\/a><\/p><\/blockquote><h2>See Also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/spaced-repetition\">Spaced Repetition<\/a> is a technique for long-term retention of learned material.<\/li><li><a href=\"https://www.lesswrong.com/tag/fact-posts?showPostCount=true&amp;useTagName=true\">Fact Posts<\/a> are pieces of writing that attempt to build an understanding of the world, starting bottom up with empirical facts rather than \"opinions\".<\/li><li>The other <a href=\"https://www.lesswrong.com/tag/virtues?showPostCount=true&amp;useTagName=true\">Virtues<\/a> of Rationality.<\/li><\/ul><h2>Top Resources<\/h2><ul><li><a href=\"https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently\">Scholarship: How to Do It Efficiently<\/a> is a guide to quickly researching topics and understanding what is known within a field.<\/li><li><a href=\"https://www.lesswrong.com/posts/RKz7pc6snBttndxXz/literature-review-for-academic-outsiders-what-how-and-why-1\">Literature Review For Academic Outsiders: What, How, and Why<\/a> similar to the first resource, contains many links to further resources.<\/li><li><a href=\"https://www.lesswrong.com/posts/gxbGKa2AnQsrn3Gni/how-do-you-assess-the-quality-reliability-of-a-scientific\">[Question] How do you assess the quality / reliability of a scientific study?<\/a> A question post with many highly excellent lengthy responses, several which received bounty payouts.<\/li><li><a href=\"https://www.lesswrong.com/posts/w5F4w8tNZc6LcBKRP/on-learning-difficult-things\">On learning difficult things<\/a> covers techniques and methods for studying difficult topics.<\/li><li><a href=\"https://www.lesswrong.com/posts/TPjbTXntR54XSZ3F2/paper-reading-for-gears\">Paper-Reading for Gears<\/a> is a guide studying to actually build up a mechanistic, gears-level understanding of a topic.<\/li><li><a href=\"https://www.lesswrong.com/posts/oPEWyxJjRo4oKHzMu/the-3-books-technique-for-learning-a-new-skilll\">The 3 Books Technique for Learning a New Skilll<\/a> is a short post suggests finding a What, How, and Why book for any skill or topic you wish to learn.<\/li><li><a href=\"https://www.lesswrong.com/posts/xg3hXCYQPJkwHyik2/the-best-textbooks-on-every-subject\">The Best Textbooks on Every Subject<\/a> crowd-sourced list where every recommendation requires that the recommender have read three books on the topic and can explain why one textbook is better than others.<\/li><li><a href=\"https://www.lesswrong.com/posts/rBkZvbGDQZhEymReM/forum-participation-as-a-research-strategy\">Forum participation as a research strategy<\/a> argues that participation on discussion forums on a research topic is actually a great way for researchers to make progress.<\/li><li><a href=\"https://www.lesswrong.com/posts/Sdx6A6yLByRRs8iLY/fact-posts-how-and-why\">Fact Posts: How and Why<\/a> is guide on exploring empirical question by starting with raw facts rather than expert opinion and prior analysis. Compared more typical research, the Fact Post method helps you ground your understanding in facts and see the topic freshly.<\/li><li><a href=\"https://www.lesswrong.com/posts/tRQek3Xb9cKZ2o6iA/how-to-not-do-a-literature-review\">How to (not) do a literature review<\/a> which contains a very concrete list of steps for literature reviews, including mistakes to avoid.<\/li><\/ul><p><strong>Ex<\/strong>... <\/p>"},"Tag:fF9GEdWXKJ3z73TmB":{"_id":"fF9GEdWXKJ3z73TmB","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:fF9GEdWXKJ3z73TmB_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Scholarship & Learning","shortName":null,"slug":"scholarship-and-learning","core":false,"postCount":329,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-09T16:57:01.474Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:ERPL3v2Y976W7XG3j":{"_id":"ERPL3v2Y976W7XG3j","__typename":"SocialPreviewType","imageUrl":""},"Post:ERPL3v2Y976W7XG3j":{"_id":"ERPL3v2Y976W7XG3j","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392babcb4ac6367c1659b"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":22,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:EvPPocx6FHcoDfygQ"},{"__ref":"Tag:Xno6pRXizN9AmFFTa"},{"__ref":"Tag:aHjTRDkGypPqbXWpN"},{"__ref":"Tag:vg4LDxjdwHLotCm8w"},{"__ref":"Tag:fF9GEdWXKJ3z73TmB"}],"socialPreviewData":{"__ref":"SocialPreviewType:ERPL3v2Y976W7XG3j"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-09-02T08:44:12.184Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"EvPPocx6FHcoDfygQ":5,"Xno6pRXizN9AmFFTa":2,"aHjTRDkGypPqbXWpN":2,"fF9GEdWXKJ3z73TmB":2,"vg4LDxjdwHLotCm8w":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392babcb4ac6367c1659b","commentCount":1,"voteCount":27,"baseScore":30,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":27,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0000940000027185306,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-01-06T17:36:23.528Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"learning-to-love-scientific-consensus","title":"Learning To Love Scientific Consensus","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:Aq8eTBkLZARRzqe5h":{"_id":"Aq8eTBkLZARRzqe5h","__typename":"Chapter","createdAt":"2017-08-24T01:29:52.393Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:Aq8eTBkLZARRzqe5h_contents"},"number":0,"sequenceId":"BQBqPowfxjvoee8jw","postIds":["ythFNoiAotjvuEGkg","kdmCm5NQTpqhJmGm6","CsKrQdQJJCFPjfKjF","SQAfPKZBAAKYMjx25","bXuAXCbzw9hsJSuEN","ckuuDa8DmJ4pdFeD8","Sd2r7H8bCmd9ChGbX","ERPL3v2Y976W7XG3j"],"posts":[{"__ref":"Post:ythFNoiAotjvuEGkg"},{"__ref":"Post:kdmCm5NQTpqhJmGm6"},{"__ref":"Post:CsKrQdQJJCFPjfKjF"},{"__ref":"Post:SQAfPKZBAAKYMjx25"},{"__ref":"Post:bXuAXCbzw9hsJSuEN"},{"__ref":"Post:ckuuDa8DmJ4pdFeD8"},{"__ref":"Post:Sd2r7H8bCmd9ChGbX"},{"__ref":"Post:ERPL3v2Y976W7XG3j"}]},"Revision:5c6392dcbcb4ac6367c16f34":{"_id":"5c6392dcbcb4ac6367c16f34","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Epistemic status: Pieced together from memory years after the event. I may have mis-remembered some things or gotten them in the wrong order. Aside from that &#8211; and the obvious jokes &#8211; this is all true. I&#8217;m being deliberately vague in places because I don&#8217;t want to condemn anything specific without being able to prove anything.]<\/i><\/font><\/p><p><b>September 2014<\/b><\/p><p>There&#8217;s a screening test for bipolar disorder. You ask patients a bunch of things like &#8220;Do you ever feel really happy, then really sad?&#8221;. If they say &#8216;yes&#8217; to enough of these questions, you start to worry.<\/p><p>Some psychiatrists love this test. I hate it. Patients will say &#8220;Yes, that absolutely describes me!&#8221; and someone will diagnose them with bipolar disorder. Then if you ask what they meant, they&#8217;d say something like &#8220;Once my local football team made it to the Super Bowl and I was really happy, but then they lost and I was really sad.&#8221; I don&#8217;t even want to tell you how many people get diagnosed bipolar because of stuff like this.<\/p><p>There was a study that supposedly proved this test worked. But parts of it confused me, and it was done on a totally different population that didn&#8217;t generalize to hospital inpatients. Also, it said in big letters THIS IS JUST A SCREENING TEST IT IS NOT INTENDED FOR DIAGNOSIS, and everyone was using it for diagnosis.<\/p><p>So I complained to some sympathetic doctors and professors, and they asked &#8220;Why not do a study?&#8221;<\/p><p>Why <i>not<\/i> do a study? Why not join the great tradition of scientists, going back to Galileo and Newton, and make my mark on the world? Why not replace my griping about bipolar screening with an experiment about bipolar screening, an experiment done to the highest standards of the empirical tradition, one that would throw the entire weight of the scientific establishment behind my complaint? I&#8217;d been writing about science for so long, even doing my own informal experiments, why not move on to join the big leagues?<\/p><p>For (it would turn out) a whole host of excellent reasons that I was about to learn.<\/p><p>A spring in my step, I journeyed to my hospital&#8217;s Research Department, hidden in a corner office just outside the orthopaedic ward. It was locked, as always. After enough knocking, a lady finally opened the door and motioned for me to sit down at a paperwork-filled desk.<\/p><p>&#8220;I want to... <\/p>","plaintextDescription":"[Epistemic status: Pieced together from memory years after the event. I may have mis-remembered some things or gotten them in the wrong order. Aside from that – and the obvious jokes – this is all true. I’m being deliberately vague in places because I don’t want to condemn anything specific without being able to prove anything.]\n\nSeptember 2014\n\nThere’s a screening test for bipolar disorder. You ask patients a bunch of things like “Do you ever feel really happy, then really sad?”. If they say ‘yes’ to enough of these questions, you start to worry.\n\nSome psychiatrists love this test. I hate it. Patients will say “Yes, that absolutely describes me!” and someone will diagnose them with bipolar disorder. Then if you ask what they meant, they’d say something like “Once my local football team made it to the Super Bowl and I was really happy, but then they lost and I was really sad.” I don’t even want to tell you how many people get diagnosed bipolar because of stuff like this.\n\nThere was a study that supposedly proved this test worked. But parts of it confused me, and it was done on a totally different population that didn’t generalize to hospital inpatients. Also, it said in big letters THIS IS JUST A SCREENING TEST IT IS NOT INTENDED FOR DIAGNOSIS, and everyone was using it for diagnosis.\n\nSo I complained to some sympathetic doctors and professors, and they asked “Why not do a study?”\n\nWhy not do a study? Why not join the great tradition of scientists, going back to Galileo and Newton, and make my mark on the world? Why not replace my griping about bipolar screening with an experiment about bipolar screening, an experiment done to the highest standards of the empirical tradition, one that would throw the entire weight of the scientific establishment behind my complaint? I’d been writing about science for so long, even doing my own informal experiments, why not move on to join the big leagues?\n\nFor (it would turn out) a whole host of excellent reasons that I was about to","wordCount":5741,"version":"1.0.0"},"Revision:BcnLB8PkrkqPhZ6XY_description":{"_id":"BcnLB8PkrkqPhZ6XY_description","__typename":"Revision","htmlHighlight":"<p><strong>Bureaucracy<\/strong><\/p><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/moral-mazes\">Moral Mazes<\/a>, <a href=\"https://www.lesswrong.com/tag/politics\">Politics<\/a>, <a href=\"https://www.lesswrong.com/tag/mechanism-design\">Mechanism Design<\/a>, <a href=\"https://www.lesswrong.com/tag/stagnation\">Stagnation<\/a><\/p>"},"Tag:BcnLB8PkrkqPhZ6XY":{"_id":"BcnLB8PkrkqPhZ6XY","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:BcnLB8PkrkqPhZ6XY_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Bureaucracy","shortName":null,"slug":"bureaucracy-1","core":false,"postCount":17,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-11-10T19:32:38.353Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:zcvsZQWJBFK6SxK4K_description":{"_id":"zcvsZQWJBFK6SxK4K_description","__typename":"Revision","htmlHighlight":"<p>A <strong>Postmortem <\/strong>or <strong>Retrospective <\/strong>is a reflection on past actions with an eye to what went well, what didn't, and the cause of any failures. Retrospectives are crucial for improving one's rationality: they are the opportunity to the grade both one's direct decisions as well as the decision-procedure and epistemic algorithms that one was employing. Sharing such accounts publicly is prosocial and allows others to learn from one's experience too.<\/p><p>One can ask \"could I have done better had I reasoned better with the information available?\" Often the answer is \"yes\", and one can apply lessons learnt going forward. It can feel painful to reflect on one's mistakes, but doing so is how one grows.&nbsp;<\/p><p>This tag is specifically reporting actions and outcomes together with an evaluation of the choices/thinking patterns used. If a post focuses on changes in general beliefs about the world, without reflecting on specific actions, then it is a good fit for&nbsp;the <a href=\"https://www.lesswrong.com/tag/updated-beliefs-examples-of\">Updated Beliefs<\/a> tag. A central example of a Postmortems &amp; Retrospectives post is “<a href=\"https://www.lesswrong.com/posts/kAgJJa3HLSZxsuSrf/arbital-postmortem\">Arbital Postmortem<\/a>”; in contrast, central examples of Updated Beliefs posts are “<a href=\"https://www.lesswrong.com/posts/4QemtxDFaGXyGSrGD/other-people-are-wrong-vs-i-am-right\">'Other people are wrong' vs 'I am right'<\/a>” and “<a href=\"https://www.lesswrong.com/posts/MgFDzAfCku9MSDLuw/six-economics-misconceptions-of-mine-which-i-ve-resolved\">Six Economics Misconceptions<\/a>”.<\/p><p><strong>Related pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/updated-beliefs-examples-of\">Updated Beliefs (examples of)<\/a>, <a href=\"https://www.lesswrong.com/tag/growth-stories\">Growth Stories<\/a>, <a href=\"https://www.lesswrong.com/tag/progress-studies\">Progress Studies<\/a><\/p><p><strong>See also:<\/strong> <a href=\"https://en.wikipedia.org/wiki/Pre-mortem\">Premortem<\/a><\/p>"},"Tag:zcvsZQWJBFK6SxK4K":{"_id":"zcvsZQWJBFK6SxK4K","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:zcvsZQWJBFK6SxK4K_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Postmortems & Retrospectives","shortName":null,"slug":"postmortems-and-retrospectives","core":false,"postCount":186,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-23T06:09:17.291Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:gBChm3THPGFcrq5eH":{"_id":"gBChm3THPGFcrq5eH","__typename":"SocialPreviewType","imageUrl":""},"Post:gBChm3THPGFcrq5eH":{"_id":"gBChm3THPGFcrq5eH","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f34"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":23,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:xHjy88N2uJvGdgzfw"},{"__ref":"Tag:BcnLB8PkrkqPhZ6XY"},{"__ref":"Tag:zcvsZQWJBFK6SxK4K"},{"__ref":"Tag:ZpG9rheyAkgCoEQea"}],"socialPreviewData":{"__ref":"SocialPreviewType:gBChm3THPGFcrq5eH"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-09-28T16:47:54.661Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"BcnLB8PkrkqPhZ6XY":2,"ZpG9rheyAkgCoEQea":1,"xHjy88N2uJvGdgzfw":3,"zcvsZQWJBFK6SxK4K":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f34","commentCount":1,"voteCount":45,"baseScore":55,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":45,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0001720000000204891,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2017-12-29T23:24:29.262Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":9,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"my-irb-nightmare","title":"My IRB Nightmare","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e34":{"_id":"5c6392dcbcb4ac6367c16e34","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Dear Dr. McCord:<\/p><p>Seven years ago, our research staff read with interest your work on Berkeleyan idealism. We were particularly fascinated by your seemingly outrageous claim that it might be possible for individuals to imagine mental worlds so strongly that they would take on a reality of their own.<\/p><p>At the time, as our laboratory had an interest in novel solutions to the overpopulation problem, we embarked upon a test project to see whether a parallel world could be imaged and then colonized by citizens from our own dimension. Using advanced science you could not possibly comprehend, we came up with a practical implementation of your idea. Dr. Michael Adwell, whom I believe you met during your time in Oxford, volunteered to enter the device we had constructed as our first research subject. We very briefly imaged an alternate world based on the contents of Dr. Adwell&#8217;s mind before the good doctor unfortunately had a grand mal seizure. He was disconnected from the device and rushed to the hospital, where he passed away several hours later.<\/p><p>Two years ago we revisited some of our calculations on the project and determined, to our surprise, that the world Dr. Adwell had created might still exist in some sense; that it had somehow managed to sustain itself separate from the doctor&#8217;s mental activity. We worked feverishly to construct a device that might let us interact with his imaged world. Six months ago we succeeded. The computational demands of the machine were immense, but after throwing the remainder of our budget for the year at the Kyoto Supercomputing Laboratory, we were able to rent enough processing power to translate myself and Dr. Lachlan Fairchild into the imaged world, which we dubbed &#8220;Adwellia&#8221; after our late colleague. Our superiors informed us that when the next fiscal year rolled around in four months, there would be enough money in the budget to translate us back home.<\/p><p><b>II.<\/b><\/p><p>On first arrival, Adwellia seemed much like home. We landed on the shores of a small lake in what seemed to be a wooded area. Since it was getting dark, we soon set to pitching camp for the night. Our first unpleasant surprise was that the kerosene heater we had brought with us wouldn&#8217;t work, leaving us cold and disheartened. Lachlan collected some logs to build a fire, but our matches didn&#8217;t seem to work either. I remembered the seventh page of... <\/p>","plaintextDescription":"I.\n\nDear Dr. McCord:\n\nSeven years ago, our research staff read with interest your work on Berkeleyan idealism. We were particularly fascinated by your seemingly outrageous claim that it might be possible for individuals to imagine mental worlds so strongly that they would take on a reality of their own.\n\nAt the time, as our laboratory had an interest in novel solutions to the overpopulation problem, we embarked upon a test project to see whether a parallel world could be imaged and then colonized by citizens from our own dimension. Using advanced science you could not possibly comprehend, we came up with a practical implementation of your idea. Dr. Michael Adwell, whom I believe you met during your time in Oxford, volunteered to enter the device we had constructed as our first research subject. We very briefly imaged an alternate world based on the contents of Dr. Adwell’s mind before the good doctor unfortunately had a grand mal seizure. He was disconnected from the device and rushed to the hospital, where he passed away several hours later.\n\nTwo years ago we revisited some of our calculations on the project and determined, to our surprise, that the world Dr. Adwell had created might still exist in some sense; that it had somehow managed to sustain itself separate from the doctor’s mental activity. We worked feverishly to construct a device that might let us interact with his imaged world. Six months ago we succeeded. The computational demands of the machine were immense, but after throwing the remainder of our budget for the year at the Kyoto Supercomputing Laboratory, we were able to rent enough processing power to translate myself and Dr. Lachlan Fairchild into the imaged world, which we dubbed “Adwellia” after our late colleague. Our superiors informed us that when the next fiscal year rolled around in four months, there would be enough money in the budget to translate us back home.\n\nII.\n\nOn first arrival, Adwellia seemed much like home. We landed on the shores","wordCount":8311,"version":"1.0.0"},"SocialPreviewType:hMQPyLDbg3bA7P6aN":{"_id":"hMQPyLDbg3bA7P6aN","__typename":"SocialPreviewType","imageUrl":""},"Post:hMQPyLDbg3bA7P6aN":{"_id":"hMQPyLDbg3bA7P6aN","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e34"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":33,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:hMQPyLDbg3bA7P6aN"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-04-03T17:36:55.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e34","commentCount":1,"voteCount":31,"baseScore":36,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":31,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00007100000220816582,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2019-06-04T04:59:29.143Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":2,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-study-of-anglophysics","title":"The Study of Anglophysics","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:okm8e8LYrgWmYPphj":{"_id":"okm8e8LYrgWmYPphj","__typename":"Chapter","createdAt":"2017-09-02T08:36:42.323Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"BQBqPowfxjvoee8jw","postIds":["gBChm3THPGFcrq5eH","hMQPyLDbg3bA7P6aN"],"posts":[{"__ref":"Post:gBChm3THPGFcrq5eH"},{"__ref":"Post:hMQPyLDbg3bA7P6aN"}]},"Revision:BQBqPowfxjvoee8jw_contents":{"_id":"BQBqPowfxjvoee8jw_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-06-23T22:52:14.492Z","userId":"r38pkCm7wF4M44MDQ","html":"<p><br>Aquinas famously <a href=\"http://en.wikipedia.org/wiki/Homo_unius_libri\">said<\/a>: beware the man of one book. I would add: beware the man of one study.<\/p><p>For example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result – that it’s weakly effective.<\/p><p>But there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There’s even 1 study finding that the drug is very bad, maybe seriously dangerous.<\/p>","commitMessage":"","wordCount":119,"htmlHighlight":"<p><br>Aquinas famously <a href=\"http://en.wikipedia.org/wiki/Homo_unius_libri\">said<\/a>: beware the man of one book. I would add: beware the man of one study.<\/p><p>For example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result – that it’s weakly effective.<\/p><p>But there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There’s even 1 study finding that the drug is very bad, maybe seriously dangerous.<\/p>","plaintextDescription":"\nAquinas famously said: beware the man of one book. I would add: beware the man of one study.\n\nFor example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result – that it’s weakly effective.\n\nBut there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. There’s even 1 study finding that the drug is very bad, maybe seriously dangerous."},"Sequence:BQBqPowfxjvoee8jw":{"_id":"BQBqPowfxjvoee8jw","__typename":"Sequence","chapters":[{"__ref":"Chapter:Aq8eTBkLZARRzqe5h"},{"__ref":"Chapter:okm8e8LYrgWmYPphj"}],"createdAt":"2017-08-24T01:28:54.686Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:BQBqPowfxjvoee8jw_contents"},"gridImageId":"sequencesgrid/zukiyrvljrwfe5bql7ek","bannerImageId":"sequences/ggacjkojjuxq4egurzln","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":0,"title":"Studies and Statistics","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:5c6392c7bcb4ac6367c16cc0":{"_id":"5c6392c7bcb4ac6367c16cc0","__typename":"Revision","htmlHighlight":"<p>This month I work on my hospital&#8217;s Substance Abuse Team, which means we treat people who have been hospitalized for alcohol or drug-related problems and then gingerly suggest that maybe they should use drugs a little less.<\/p><p>The two doctors leading the team are both very experienced and have kind of seen it all, so it&#8217;s interesting to get a perspective on drug issues from people on the front line. In particular, one of my attendings is an Obama-loving long-haired hippie who nevertheless vehemently opposes medical marijuana or any relaxation on marijuana&#8217;s status at all. He says that &#8220;just because I&#8217;m a Democrat doesn&#8217;t mean I have to support stupid policies I know are wrong&#8221; and he&#8217;s able to back up his opinion with an impressive variety of studies.<\/p><p>To be honest, I had kind of forgotten that the Universe was allowed to contain negative consequences for legalizing drugs. What with all the mental energy it took protesting the the Drug War and getting outraged at police brutality and celebrating Colorado&#8217;s recently permitting recreational cannabis use and so on, it had completely slipped my mind that the legalization of marijuana might have negative consequences and that I couldn&#8217;t reject it out of hand until I had done some research.<\/p><p>So I&#8217;ve been doing the research. Not to try to convince my attending of anything &#8211; as the old saying goes, do not meddle in the affairs of attendings, <A HREF=\"http://www.youtube.com/watch?v=TyT8uc6ath4\">because you are crunchy and taste good with ketchup<\/A> &#8211; but just to figure out where exactly things stand.<\/p><p><b>I. Would Relaxation Of Penalties On Marijuana Increase Marijuana Use?<\/b><\/p><p>Starting in the 1970s, several states decriminalized possession of marijuana &#8211; that is, possession could not be penalized by jail time. It could still be penalized by fines and other smaller penalties, and manufacture and sale could still be punished by jail time.<\/p><p>Starting in the 1990s, several states legalized medical marijuana. People with medical marijuana cards, which in many cases were laughably easy to get with or without good evidence of disease, were allowed to grow and use marijuana, despite concerns that some of this would end up on the illegal market.<\/p><p>Starting last week, Colorado legalized recreational use of marijuana, as well as cultivation and sale (subject to heavy regulations). Washington will follow later this year, and ... <\/p>","plaintextDescription":"This month I work on my hospital’s Substance Abuse Team, which means we treat people who have been hospitalized for alcohol or drug-related problems and then gingerly suggest that maybe they should use drugs a little less.\n\nThe two doctors leading the team are both very experienced and have kind of seen it all, so it’s interesting to get a perspective on drug issues from people on the front line. In particular, one of my attendings is an Obama-loving long-haired hippie who nevertheless vehemently opposes medical marijuana or any relaxation on marijuana’s status at all. He says that “just because I’m a Democrat doesn’t mean I have to support stupid policies I know are wrong” and he’s able to back up his opinion with an impressive variety of studies.\n\nTo be honest, I had kind of forgotten that the Universe was allowed to contain negative consequences for legalizing drugs. What with all the mental energy it took protesting the the Drug War and getting outraged at police brutality and celebrating Colorado’s recently permitting recreational cannabis use and so on, it had completely slipped my mind that the legalization of marijuana might have negative consequences and that I couldn’t reject it out of hand until I had done some research.\n\nSo I’ve been doing the research. Not to try to convince my attending of anything – as the old saying goes, do not meddle in the affairs of attendings, because you are crunchy and taste good with ketchup – but just to figure out where exactly things stand.\n\nI. Would Relaxation Of Penalties On Marijuana Increase Marijuana Use?\n\nStarting in the 1970s, several states decriminalized possession of marijuana – that is, possession could not be penalized by jail time. It could still be penalized by fines and other smaller penalties, and manufacture and sale could still be punished by jail time.\n\nStarting in the 1990s, several states legalized medical marijuana. People with medical marijuana cards, which in many cases were laughably easy to get wi","wordCount":5662,"version":"1.0.0"},"Revision:PXuimenPYFKRdSor5_description":{"_id":"PXuimenPYFKRdSor5_description","__typename":"Revision","htmlHighlight":"<p>A cost-benefit analysis is a method for quantitatively assigning values to different actions.<\/p>\n<p>For each action, it weighs up the costs of taking that action against the benefit of that action, usually in expectation if uncertainty is involved.<\/p>\n<p>Cost-benefit analyses can be done at varying levels of precision, starting with <a href=\"https://www.lesswrong.com/posts/PsEppdvgRisz5xAHG/fermi-estimates\">fermi estimates<\/a> and going up to <a href=\"https://en.wikipedia.org/wiki/Monte_Carlo_method\">Monte-Carlo analyses<\/a> with research into the distributions underlying the relevant factors.<\/p>\n<p>See Also:<\/p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Cost%E2%80%93benefit_analysis\">Cost-benefit analysis on Wikipedia<\/a><\/li>\n<li><a href=\"https://www.lesswrong.com/tag/do-the-math-then-burn-the-math-and-go-with-your-gut\">Do The Math, Then Burn The Math and Go With Your Gut<\/a><\/li>\n<li><a href=\"https://www.lesswrong.com/tag/fermi-estimation\">Fermi Estimation<\/a><\/li>\n<li><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction\">Forecasting and Prediction<\/a><\/li>\n<\/ul>"},"Tag:PXuimenPYFKRdSor5":{"_id":"PXuimenPYFKRdSor5","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:PXuimenPYFKRdSor5_description"},"canVoteOnRels":null,"userId":"ezbRa3dntKWQ5995r","name":"Cost-Benefit Analysis","shortName":null,"slug":"cost-benefit-analysis","core":false,"postCount":6,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2024-03-30T22:13:29.504Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:TLrqSmzoGoA3v5tNP_description":{"_id":"TLrqSmzoGoA3v5tNP_description","__typename":"Revision","htmlHighlight":"<p>A <strong>Fact post <\/strong>is a piece of writing that attempts to build an understanding of the world, starting bottom up with empirical facts rather than \"opinions\". &nbsp;Under this tag, one can find posts that present lots of basic facts about topics.<\/p><p>Fact posts were introduced in <a href=\"https://www.lesswrong.com/posts/Sdx6A6yLByRRs8iLY/fact-posts-how-and-why\"><strong>Fact Posts: How and Why<\/strong><\/a> by sarahconstantin:<\/p><blockquote><p>The most useful thinking skill I've taught myself, which I think should be more widely practiced, is writing what I call \"fact posts.\" &nbsp;I write a bunch of these on my <a href=\"https://srconstantin.wordpress.com/\">blog<\/a>. (I write fact posts about pregnancy and childbirth <a href=\"https://parentingwithevidence.wordpress.com/\">here.<\/a>)<\/p><p>To write a fact post, you start with an empirical question, or a general topic. &nbsp;Something like \"How common are hate crimes?\" or \"Are epidurals really dangerous?\" or \"What causes manufacturing job loss?\" &nbsp;<\/p><p>It's okay if this is a topic you know very little about. This is an exercise in original seeing and showing your reasoning, not finding the official last word on a topic or doing the best analysis in the world.<\/p><p>Then you open up a Google doc and start taking notes.<\/p><p>You look for <i>quantitative&nbsp;data from conventionally reliable sources<\/i>. &nbsp;CDC data for incidences of diseases and other health risks in the US; WHO data for global health issues; Bureau of Labor Statistics data for US employment; and so on. Published scientific journal articles, especially from reputable journals and large randomized studies.<\/p><p>You explicitly do <i>not <\/i>look for opinion, even expert opinion. You avoid news, and you're wary of think-tank white papers. You're looking for raw information. You are taking a <i>sola scriptura <\/i>approach, for better and for worse.<\/p><p>And then you start letting the data show you things.&nbsp;<\/p><p>You see things that are surprising or odd, and you note that.<\/p><\/blockquote><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/distillation-and-pedagogy\">Distillation and Pedagogy<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/epistemic-review\">Epistemic Review<\/a><\/li><\/ul>"},"Tag:TLrqSmzoGoA3v5tNP":{"_id":"TLrqSmzoGoA3v5tNP","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:TLrqSmzoGoA3v5tNP_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Fact posts","shortName":null,"slug":"fact-posts","core":false,"postCount":39,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-29T16:18:58.710Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:c8khnHoRTSGjmHLLf":{"_id":"c8khnHoRTSGjmHLLf","__typename":"SocialPreviewType","imageUrl":""},"Post:c8khnHoRTSGjmHLLf":{"_id":"c8khnHoRTSGjmHLLf","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16cc0"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":23,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:PXuimenPYFKRdSor5"},{"__ref":"Tag:TLrqSmzoGoA3v5tNP"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:c8khnHoRTSGjmHLLf"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-01-05T20:41:27.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":3,"PXuimenPYFKRdSor5":2,"TLrqSmzoGoA3v5tNP":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16cc0","commentCount":4,"voteCount":29,"baseScore":32,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":29,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00006199999916134402,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-05-27T22:18:50.235Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"marijuana-much-more-than-you-wanted-to-know","title":"Marijuana: Much More Than You Wanted To Know","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e91":{"_id":"5c6392dcbcb4ac6367c16e91","__typename":"Revision","htmlHighlight":"<p>After hearing conflicting advice from diet books and the medical community, I decided to look into wheat.<\/p><p>There are two sets of arguments against including wheat in the diet. First, wheat is a carbohydrate, and some people support low carbohydrate diets. Second, something might be especially dangerous about wheat itself.<\/p><p>It was much easier to figure out the state of the evidence on low-carbohydrate diets. They seem to be <A HREF=\"http://www.annualreviews.org/doi/full/10.1146/annurev-publhealth-032013-182351\">at least as good and maybe a little better<\/A> for weight loss than traditional diets, but this might just be because there are lots of carbohydrates that taste very good and when forced to avoid them, people eat less stuff. They may or may not positively affect metabolic parameters and quality of life. (<A HREF=\"http://link.springer.com/article/10.1007%2Fs11883-009-0069-8\">1<\/A>, <A HREF=\"http://press.endocrine.org/doi/abs/10.1210/jc.2002-021480\">2<\/A>, <A HREF=\"http://jama.jamanetwork.com/article.aspx?articleid=200094\">3<\/A>, <A HREF=\"http://link.springer.com/article/10.1007%2Fs11136-009-9444-8\">4<\/A>). They don&#8217;t seem to cause either major health benefits or major health risks in the medium term, which is the longest term for which there is good data available &#8211; for example, they have <A HREF=\"http://www.nutritionj.com/content/12/1/58\">no effect on cancer rates<\/A>. Overall they seem solid but unspectacular. But there&#8217;s a long way between &#8220;low carbohydrate diet&#8221; and &#8220;stop eating wheat&#8221;.<\/p><p>So I was more interested in figuring out what was going on with wheat in particular.<\/p><p>Wheat contains chemicals [citation needed]. The ones that keep cropping up (no pun intended) in these kinds of discussions are phytates, lectins, gluten, gliadin, and agglutinin, the last three of which for your convenience have been given names that all sound alike.<\/p><p>Various claims have been made about these chemicals&#8217; effects on health. These have some prima facie plausibility. Plants don&#8217;t want to be eaten [citation needed] and they sometimes fill their grains with toxins to discourage animals from eating them. Ricin, a lectin in the seeds of the castor oil plant so toxic it gets used in chemical warfare, is a pretty good example. Most toxins are less dramatic, and most animals have enzymes that break down the toxins in their preferred food sources effectively. But if humans are insufficiently good at this, maybe because they didn&#8217;t evolve to eat wheat, some of these chemicals could be toxic to humans.<\/p><p>On the other hand, this same argument covers every pretty much every grain and vegetable and a lot of legumes &#8211; pretty much every plant-based food source except edible fruits. So we need a lot more evidence to start worrying about wheat.<\/p><p>I found the following cl... <\/p>","plaintextDescription":"After hearing conflicting advice from diet books and the medical community, I decided to look into wheat.\n\nThere are two sets of arguments against including wheat in the diet. First, wheat is a carbohydrate, and some people support low carbohydrate diets. Second, something might be especially dangerous about wheat itself.\n\nIt was much easier to figure out the state of the evidence on low-carbohydrate diets. They seem to be at least as good and maybe a little better for weight loss than traditional diets, but this might just be because there are lots of carbohydrates that taste very good and when forced to avoid them, people eat less stuff. They may or may not positively affect metabolic parameters and quality of life. (1, 2, 3, 4). They don’t seem to cause either major health benefits or major health risks in the medium term, which is the longest term for which there is good data available – for example, they have no effect on cancer rates. Overall they seem solid but unspectacular. But there’s a long way between “low carbohydrate diet” and “stop eating wheat”.\n\nSo I was more interested in figuring out what was going on with wheat in particular.\n\nWheat contains chemicals [citation needed]. The ones that keep cropping up (no pun intended) in these kinds of discussions are phytates, lectins, gluten, gliadin, and agglutinin, the last three of which for your convenience have been given names that all sound alike.\n\nVarious claims have been made about these chemicals’ effects on health. These have some prima facie plausibility. Plants don’t want to be eaten [citation needed] and they sometimes fill their grains with toxins to discourage animals from eating them. Ricin, a lectin in the seeds of the castor oil plant so toxic it gets used in chemical warfare, is a pretty good example. Most toxins are less dramatic, and most animals have enzymes that break down the toxins in their preferred food sources effectively. But if humans are insufficiently good at this, maybe because","wordCount":5154,"version":"1.0.0"},"SocialPreviewType:g4pi2jfQHFF6mPdjw":{"_id":"g4pi2jfQHFF6mPdjw","__typename":"SocialPreviewType","imageUrl":""},"Post:g4pi2jfQHFF6mPdjw":{"_id":"g4pi2jfQHFF6mPdjw","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e91"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":21,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:TLrqSmzoGoA3v5tNP"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:g4pi2jfQHFF6mPdjw"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-03-31T00:26:51.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"TLrqSmzoGoA3v5tNP":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e91","commentCount":2,"voteCount":21,"baseScore":21,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0000414910027757287,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-10-29T13:16:54.898Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"wheat-much-more-than-you-wanted-to-know","title":"Wheat: Much More Than You Wanted To Know","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:TmDEvbtFCfQD43Jw8":{"_id":"TmDEvbtFCfQD43Jw8","__typename":"Revision","htmlHighlight":"<p>The claim that &#8220;SSRIs don&#8217;t work&#8221; or &#8220;SSRIs are mostly just placebo&#8221; is most commonly associated with Irving Kirsch, a man with the awesome job title of &#8220;Associate Director Of The Program For Placebo Studies at Harvard&#8221;.<\/p><p>(fun fact: there&#8217;s actually no such thing as &#8220;Placebo Studies&#8221;, but Professor Kirsch&#8217;s <i>belief<\/i> that he directs a Harvard department inspires him to create much higher-quality research.)<\/p><p>In 1998, he published <A HREF=\"http://web.archive.org/web/19980715085305/http://journals.apa.org/prevention/volume1/pre0010002a.html\">a meta-analysis<\/A> of 19 placebo-controlled drug trials that suggested that almost all of the benefits of antidepressants were due to the placebo effect. Psychiatrists denounced him, saying that you can choose pretty much whatever studies you want for a meta-analysis.<\/p><p>After biding his time for a decade, in 2008 he struck back with <A HREF=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2253608/\">another meta-analysis<\/A>, this being one of the first papers in all of medical science to take the audacious step of demanding all the FDA&#8217;s data through the Freedom of Information Act. Since drug companies are required to report all their studies to the FDA, this theoretically provides a rare and wonderful publication-bias-free data set. Using this set, he found that, although antidepressants did seem to outperform placebo, the effect was not &#8220;clinically significant&#8221; except &#8220;at the upper end of very severe depression&#8221;.<\/p><p>This launched a minor war between supporters and detractors. Probably the strongest support he received was <A HREF=\"http://jama.jamanetwork.com/article.aspx?articleid=185157\">a big 2010 meta-analysis<\/A> by Fournier et al, which found that<\/p>\n<blockquote><p>The magnitude of benefit of antidepressant medication compared with placebo increases with severity of depression symptoms and may be minimal or nonexistent, on average, in patients with mild or moderate symptoms. For patients with very severe depression, the benefit of medications over placebo is substantial.<\/p><\/blockquote>\n<p>Of course, a very large number of antidepressants are given to people with mild or moderate depression. So what now?<\/p><p>Let me sort the debate about antidepressants into a series of complaints:<\/p><p>1. Antidepressants were oversold and painted as having more biochemical backing than was really justified<br />\n2. Modern SSRI antidepressants are no better than older tricyclic and MAOI antidepressants, but are prescribed much more because of said overselling<br />\n3. There is large publication bias in the antidepressant literature<br />\n4. The effect size of antidepressa... <\/p>","plaintextDescription":"The claim that “SSRIs don’t work” or “SSRIs are mostly just placebo” is most commonly associated with Irving Kirsch, a man with the awesome job title of “Associate Director Of The Program For Placebo Studies at Harvard”.\n\n(fun fact: there’s actually no such thing as “Placebo Studies”, but Professor Kirsch’s belief that he directs a Harvard department inspires him to create much higher-quality research.)\n\nIn 1998, he published a meta-analysis of 19 placebo-controlled drug trials that suggested that almost all of the benefits of antidepressants were due to the placebo effect. Psychiatrists denounced him, saying that you can choose pretty much whatever studies you want for a meta-analysis.\n\nAfter biding his time for a decade, in 2008 he struck back with another meta-analysis, this being one of the first papers in all of medical science to take the audacious step of demanding all the FDA’s data through the Freedom of Information Act. Since drug companies are required to report all their studies to the FDA, this theoretically provides a rare and wonderful publication-bias-free data set. Using this set, he found that, although antidepressants did seem to outperform placebo, the effect was not “clinically significant” except “at the upper end of very severe depression”.\n\nThis launched a minor war between supporters and detractors. Probably the strongest support he received was a big 2010 meta-analysis by Fournier et al, which found that\n\n> The magnitude of benefit of antidepressant medication compared with placebo increases with severity of depression symptoms and may be minimal or nonexistent, on average, in patients with mild or moderate symptoms. For patients with very severe depression, the benefit of medications over placebo is substantial.\n\nOf course, a very large number of antidepressants are given to people with mild or moderate depression. So what now?\n\nLet me sort the debate about antidepressants into a series of complaints:\n\n1. Antidepressants were oversold and ","wordCount":8049,"version":"1.1.0"},"SocialPreviewType:znEhB9hJtwXica5s3":{"_id":"znEhB9hJtwXica5s3","__typename":"SocialPreviewType","imageUrl":""},"Post:znEhB9hJtwXica5s3":{"_id":"znEhB9hJtwXica5s3","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:TmDEvbtFCfQD43Jw8"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":32,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:TLrqSmzoGoA3v5tNP"},{"__ref":"Tag:xHjy88N2uJvGdgzfw"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:znEhB9hJtwXica5s3"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-07-08T02:06:48.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"TLrqSmzoGoA3v5tNP":2,"xHjy88N2uJvGdgzfw":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"TmDEvbtFCfQD43Jw8","commentCount":2,"voteCount":22,"baseScore":28,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":22,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00005792534284410067,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-01-02T00:49:45.553Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":3,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"ssris-much-more-than-you-wanted-to-know","title":"SSRIs: Much More Than You Wanted To Know","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:qxgmF9zg7G9fagqeX":{"_id":"qxgmF9zg7G9fagqeX","__typename":"Revision","htmlHighlight":"<p><i>[EDIT 10/27: Slight changes in response to feedback; correcting some definitions. I am not an expert in this field and will continue to make changes as I learn about them. There is a critique of this post <\/i><a href=\"http://www.reddit.com/r/psychology/comments/2kdy7p/alcoholics_anonymous_much_more_than_you_wanted_to/clkp7wn\"><i>here<\/i><\/a><i> and other worse critiques elsewhere. My only excuse for doing this is that I am failing less spectacularly than other online sources writing about the same topic.]<\/i><\/p><p>I’ve worked with doctors who think Alcoholics Anonymous is so important for the treatment of alcoholism that anyone who refuses to go at least three times a week is in denial about their problem and can’t benefit from further treatment.<\/p><p>I’ve also worked with doctors who are so against the organization that they describe it as a “cult” and say that a physician who recommends it is no better than one who recommends crystal healing or dianetics.<\/p><p>I finally got so exasperated that I put on my Research Cap and started looking through the evidence base.<\/p><p>My conclusion, after several hours of study, is that now I understand why most people don’t do this.<\/p><p>The studies surrounding Alcoholics Anonymous are some of the most convoluted, hilariously screwed-up research I have ever seen. They go wrong in ways I didn’t even realize research <i>could<\/i> go wrong before. Just to give some examples:<\/p><p>– In several studies, subjects in the “not attending Alcoholics Anonymous” condition attended Alcoholics Anonymous more than subjects in the “attending Alcoholics Anonymous” condition.<\/p><p>– Almost everyone’s belief about AA’s retention rate is off by a factor of five because one person long ago misread a really confusing graph and everyone else copied them without double-checking.<\/p><p>– The largest study ever in the field, a $30 million effort over 8 years following thousands of patients, had no untreated control group.<\/p><p>Not only are the studies poor, but the people interpreting them are heavily politicized. The entire field of addiction medicine has gotten stuck in the middle of some of the most divisive issues in our culture, like whether addiction is a biological disease or a failure of willpower, whether problems should be solved by community and peer groups or by highly trained professionals, and whether there’s a role for appealing to a higher power in any public organization. AA’s supporters see it as a scruffy grassroots organization of real people willing to get their hands dirty, who can cure addicts failed time and time again by... <\/p>","plaintextDescription":"[EDIT 10/27: Slight changes in response to feedback; correcting some definitions. I am not an expert in this field and will continue to make changes as I learn about them. There is a critique of this post here and other worse critiques elsewhere. My only excuse for doing this is that I am failing less spectacularly than other online sources writing about the same topic.]\n\nI’ve worked with doctors who think Alcoholics Anonymous is so important for the treatment of alcoholism that anyone who refuses to go at least three times a week is in denial about their problem and can’t benefit from further treatment.\n\nI’ve also worked with doctors who are so against the organization that they describe it as a “cult” and say that a physician who recommends it is no better than one who recommends crystal healing or dianetics.\n\nI finally got so exasperated that I put on my Research Cap and started looking through the evidence base.\n\nMy conclusion, after several hours of study, is that now I understand why most people don’t do this.\n\nThe studies surrounding Alcoholics Anonymous are some of the most convoluted, hilariously screwed-up research I have ever seen. They go wrong in ways I didn’t even realize research could go wrong before. Just to give some examples:\n\n– In several studies, subjects in the “not attending Alcoholics Anonymous” condition attended Alcoholics Anonymous more than subjects in the “attending Alcoholics Anonymous” condition.\n\n– Almost everyone’s belief about AA’s retention rate is off by a factor of five because one person long ago misread a really confusing graph and everyone else copied them without double-checking.\n\n– The largest study ever in the field, a $30 million effort over 8 years following thousands of patients, had no untreated control group.\n\nNot only are the studies poor, but the people interpreting them are heavily politicized. The entire field of addiction medicine has gotten stuck in the middle of some of the most divisive issues in our culture, l","wordCount":5320,"version":"1.1.0"},"Revision:CfX6pGepdjQYELSpK_customHighlight":{"_id":"CfX6pGepdjQYELSpK_customHighlight","__typename":"Revision","html":"<p>I’ve worked with doctors who think Alcoholics Anonymous is so important for the treatment of alcoholism that anyone who refuses to go at least three times a week is in denial about their problem and can’t benefit from further treatment.<\/p><p>I’ve also worked with doctors who are so against the organization that they describe it as a “cult” and say that a physician who recommends it is no better than one who recommends crystal healing or dianetics.<\/p><p>I finally got so exasperated that I put on my Research Cap and started looking through the evidence base.<\/p><p>My conclusion, after several hours of study, is that now I understand why most people don’t do this.<\/p>","plaintextDescription":"I’ve worked with doctors who think Alcoholics Anonymous is so important for the treatment of alcoholism that anyone who refuses to go at least three times a week is in denial about their problem and can’t benefit from further treatment.\n\nI’ve also worked with doctors who are so against the organization that they describe it as a “cult” and say that a physician who recommends it is no better than one who recommends crystal healing or dianetics.\n\nI finally got so exasperated that I put on my Research Cap and started looking through the evidence base.\n\nMy conclusion, after several hours of study, is that now I understand why most people don’t do this."},"SocialPreviewType:CfX6pGepdjQYELSpK":{"_id":"CfX6pGepdjQYELSpK","__typename":"SocialPreviewType","imageUrl":"http://slatestarcodex.com/blog_images/darkstats2.png"},"Post:CfX6pGepdjQYELSpK":{"_id":"CfX6pGepdjQYELSpK","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:qxgmF9zg7G9fagqeX"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":21,"rejectedReason":null,"customHighlight":{"__ref":"Revision:CfX6pGepdjQYELSpK_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:CfX6pGepdjQYELSpK"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-10-26T06:15:44.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"qxgmF9zg7G9fagqeX","commentCount":0,"voteCount":15,"baseScore":18,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0000390923123632092,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2014-10-26T06:15:44.000Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"alcoholics-anonymous-much-more-than-you-wanted-to-know","title":"Alcoholics Anonymous: Much More Than You Wanted To Know","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e80":{"_id":"5c6392dcbcb4ac6367c16e80","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[WARNING: I am not a pharmacologist. I am not a researcher. I am not a statistician. This is not medical advice. This is really weird and you should not take it too seriously until it has been confirmed]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>I&#8217;ve been playing around with data from Internet databases that aggregate patient reviews of medications.<\/p><p>Are these any good? I looked at four of the largest such databases &#8211; <A HREF=\"http://www.drugs.com/drug_information.html\">Drugs.com<\/A>, <A HREF=\"http://www.webmd.com/drugs/index-drugs.aspx?show=drugs\">WebMD<\/A>, <A HREF=\"http://www.askapatient.com/\">AskAPatient<\/A>, and <A HREF=\"http://www.druglib.com/\">DrugLib<\/A> &#8211; as well as psychiatry-specific site <A HREF=\"http://www.crazymeds.us/pmwiki/pmwiki.php/Main/HomePage\">CrazyMeds<\/A> &#8211; and took their data on twenty-three major antidepressants. Then I correlated them with one another to see if the five sites mostly agreed.<\/p><p>Correlations between Drugs.com, AskAPatient, and WebMD were generally large and positive (around 0.7). Correlations between CrazyMeds and DrugLib were generally small or negative. In retrospect this makes sense, because these two sites didn&#8217;t allow separation of ratings by condition, so for example Seroquel-for-depression was being mixed with Seroquel-for-schizophrenia. <\/p><p>So I threw out the two offending sites and kept Drugs.com, AskAPatient, and WebMD. I normalized all the data, then took the weighted average of all three sites. From this huge sample (the least-reviewed drug had 35 ratings, the most-reviewed drug 4,797) I obtained a unified opinion of patients&#8217; favorite and least favorite antidepressants.<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/prescription_table.png\"><\/center><\/p><p>This doesn&#8217;t surprise me at all. Everyone secretly knows Nardil and Parnate (the two commonly-used drugs in the MAOI class) are excellent antidepressants<sup>1<\/sup>. Oh, <A HREF=\"http://psychiatrist-blog.blogspot.com/2008/03/why-this-shrink-doesnt-prescribe-maois.html\">nobody<\/A> will prescribe them, because of the dynamic discussed <A HREF=\"http://slatestarcodex.com/2015/04/25/nefarious-nefazodone-and-flashy-rare-side-effects/\">here<\/A>, but in their hearts they know it&#8217;s true.<\/p><p>Likewise, I feel pretty good to see that Serzone, which I recently defended, is number five. I&#8217;ve had terrible luck with Viibryd, and it just seems to make people taking it more annoying, which is not a listed side effect but which I swear has happened.<\/p><p>The table also <A HREF=\"http://slatestarcodex.com/2015/04/30/prescriptions-paradoxes-and-perversities/#comment-201233\">matches<\/A> the evidence from chemistry &#8211; drugs with similar molecular structure get similar ratings, as do drugs with similar function. This is, I think, a good list.<\/p><p>Which is too bad, because it makes the next part that much more terrifying.<\/p><p><b>II.<\/b><\/p><p>There is a sixth major Internet database of drug ratings. It is called <A HREF=\"https://www.healthtap.com/raterx\">RateRx<\/A>, and it differs from the other five in an important way: it solicits ratings from doctors, not patients. It&#8217;s a great idea &#8211; if you trust your doctor t... <\/p>","plaintextDescription":"[WARNING: I am not a pharmacologist. I am not a researcher. I am not a statistician. This is not medical advice. This is really weird and you should not take it too seriously until it has been confirmed]\n\nI.\n\nI’ve been playing around with data from Internet databases that aggregate patient reviews of medications.\n\nAre these any good? I looked at four of the largest such databases – Drugs.com, WebMD, AskAPatient, and DrugLib – as well as psychiatry-specific site CrazyMeds – and took their data on twenty-three major antidepressants. Then I correlated them with one another to see if the five sites mostly agreed.\n\nCorrelations between Drugs.com, AskAPatient, and WebMD were generally large and positive (around 0.7). Correlations between CrazyMeds and DrugLib were generally small or negative. In retrospect this makes sense, because these two sites didn’t allow separation of ratings by condition, so for example Seroquel-for-depression was being mixed with Seroquel-for-schizophrenia.\n\nSo I threw out the two offending sites and kept Drugs.com, AskAPatient, and WebMD. I normalized all the data, then took the weighted average of all three sites. From this huge sample (the least-reviewed drug had 35 ratings, the most-reviewed drug 4,797) I obtained a unified opinion of patients’ favorite and least favorite antidepressants.\n\n\n\nThis doesn’t surprise me at all. Everyone secretly knows Nardil and Parnate (the two commonly-used drugs in the MAOI class) are excellent antidepressants1. Oh, nobody will prescribe them, because of the dynamic discussed here, but in their hearts they know it’s true.\n\nLikewise, I feel pretty good to see that Serzone, which I recently defended, is number five. I’ve had terrible luck with Viibryd, and it just seems to make people taking it more annoying, which is not a listed side effect but which I swear has happened.\n\nThe table also matches the evidence from chemistry – drugs with similar molecular structure get similar ratings, as do drugs with similar fu","wordCount":3095,"version":"1.0.0"},"SocialPreviewType:ALEYMFAuFSCz8v5YE":{"_id":"ALEYMFAuFSCz8v5YE","__typename":"SocialPreviewType","imageUrl":""},"Post:ALEYMFAuFSCz8v5YE":{"_id":"ALEYMFAuFSCz8v5YE","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e80"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":12,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:gsv9XWbZDcnZmKuqM"}],"socialPreviewData":{"__ref":"SocialPreviewType:ALEYMFAuFSCz8v5YE"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-04-30T04:52:19.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"gsv9XWbZDcnZmKuqM":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e80","commentCount":4,"voteCount":17,"baseScore":19,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":17,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00004274796447134577,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-04-19T16:01:55.487Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"prescriptions-paradoxes-and-perversities","title":"Prescriptions, Paradoxes, and Perversities","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16c4c":{"_id":"5c6392c7bcb4ac6367c16c4c","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Epistemic status: I think I probably wrung the right conclusions out of this evidence, but this isn&#8217;t the only line of evidence bearing on the broader gun control issue and all I can say is what it&#8217;s <i>consistent<\/i> with. Content warning for discussion of suicide, murder, and race]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>From a Vox article on <A HREF=\"http://www.vox.com/2015/10/3/9444417/gun-violence-united-states-america\">America&#8217;s Gun Problem, Explained<\/A>: &#8220;On Wednesday, it happened again: There was a mass shooting — this time, in San Bernardino, California. And once again on Sunday, President Barack Obama called for measures that make it harder for would-be shooters to buy deadly firearms.&#8221;<\/p><p>Then it goes on to say that &#8220;more guns mean more gun deaths, period. The research on this is overwhelmingly clear. No matter how you look at the data, more guns mean more gun deaths.&#8221; It cites the following chart:<\/p><p><IMG SRC=\"http://slatestarcodex.com/blog_images/gun_deaths1.png\"><\/p><p>&#8230;then uses the graph as a lead in to talk about active shooter situations, gun-homicide relationships, and outrage over gun massacres.<\/p><p>Did you notice that the axis of this graph says &#8220;gun deaths&#8221;, and that this is a totally different thing from gun murders?<\/p><p>(this isn&#8217;t an isolated incident: Vox does the same thing <A HREF=\"http://www.vox.com/2015/8/24/9183525/gun-violence-statistics\">here<\/A> and <A HREF=\"http://www.vox.com/2015/8/27/9217163/america-guns-europe\">here<\/A>)<\/p><p>Gun deaths are a combined measure of gun homicides and gun suicides. Here is a graph of guns vs. gun homicides:<\/p><p><IMG SRC=\"http://slatestarcodex.com/blog_images/gun_deaths3.png\"><\/p><p>And here is a graph of guns vs. gun suicides:<\/p><p><IMG SRC=\"http://slatestarcodex.com/blog_images/gun_deaths4.png\"><\/p><p>The relationship between gun ownership and homicide is weak (and appears negative), the relationship between gun ownership and suicide is strong and positive. The entire effect Vox highlights in their graph is due to gun suicides, but they are using it to imply conclusions about gun homicides. This is why you shouldn&#8217;t make a category combining two unlike things.<\/p><p><b>II.<\/b><\/p><p>I am not the first person to notice this. <A HREF=\"http://www.washingtonexaminer.com/no-states-with-higher-gun-ownership-dont-have-more-gun-murders/article/2573353\">The Washington Examiner<\/A> makes the same criticism of Vox&#8217;s statistics that I do. And Robert VerBruggen of National Review does <A HREF=\"http://www.nationalreview.com/article/427967/san-bernardino-shooting-guns-homicide-statistics?target=author&#038;tid=1043\">the same analysis<\/A> decomposing gun deaths into suicides and homicides, and like me finds no correlation with homicides.<\/p><p>German Lopez of Vox responds <A HREF=\"http://www.vox.com/policy-and-politics/2015/12/8/9870240/gun-ownership-deaths-homicides\">here<\/A>. He argues that VerBruggen can&#8217;t just do a raw uncontrolled correlation of state gun ownership with state murder rates without adjusting for confounders. This is true, although given that Vox has done this time and time again for months on end and all VerBruggen is doing is correctly pointing out a flaw in their methods, it feels kind of like an <A HREF=\"http://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/\">isolated<\/a>... <\/p>","plaintextDescription":"[Epistemic status: I think I probably wrung the right conclusions out of this evidence, but this isn’t the only line of evidence bearing on the broader gun control issue and all I can say is what it’s consistent with. Content warning for discussion of suicide, murder, and race]\n\nI.\n\nFrom a Vox article on America’s Gun Problem, Explained: “On Wednesday, it happened again: There was a mass shooting — this time, in San Bernardino, California. And once again on Sunday, President Barack Obama called for measures that make it harder for would-be shooters to buy deadly firearms.”\n\nThen it goes on to say that “more guns mean more gun deaths, period. The research on this is overwhelmingly clear. No matter how you look at the data, more guns mean more gun deaths.” It cites the following chart:\n\n\n\n…then uses the graph as a lead in to talk about active shooter situations, gun-homicide relationships, and outrage over gun massacres.\n\nDid you notice that the axis of this graph says “gun deaths”, and that this is a totally different thing from gun murders?\n\n(this isn’t an isolated incident: Vox does the same thing here and here)\n\nGun deaths are a combined measure of gun homicides and gun suicides. Here is a graph of guns vs. gun homicides:\n\n\n\nAnd here is a graph of guns vs. gun suicides:\n\n\n\nThe relationship between gun ownership and homicide is weak (and appears negative), the relationship between gun ownership and suicide is strong and positive. The entire effect Vox highlights in their graph is due to gun suicides, but they are using it to imply conclusions about gun homicides. This is why you shouldn’t make a category combining two unlike things.\n\nII.\n\nI am not the first person to notice this. The Washington Examiner makes the same criticism of Vox’s statistics that I do. And Robert VerBruggen of National Review does the same analysis decomposing gun deaths into suicides and homicides, and like me finds no correlation with homicides.\n\nGerman Lopez of Vox responds here. He argues","wordCount":4365,"version":"1.0.0"},"SocialPreviewType:FW3DEYbKPZJh5A8Bj":{"_id":"FW3DEYbKPZJh5A8Bj","__typename":"SocialPreviewType","imageUrl":""},"Post:FW3DEYbKPZJh5A8Bj":{"_id":"FW3DEYbKPZJh5A8Bj","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16c4c"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":17,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:FW3DEYbKPZJh5A8Bj"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-01-07T02:29:05.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16c4c","commentCount":1,"voteCount":20,"baseScore":23,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00005629639053950086,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-01-13T18:21:59.559Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"guns-and-states","title":"Guns And States","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16df7":{"_id":"5c6392dcbcb4ac6367c16df7","__typename":"Revision","htmlHighlight":"<p><i><font size=\"1\">[Epistemic status: This is really complicated, this is not my field, people who have spent their entire lives studying this subject have different opinions, and I don&#8217;t claim to have done more than a very superficial survey. I welcome corrections on the many inevitable errors.]<\/font><\/i><\/p><p><b>I.<\/b><\/p><p><A HREF=\"http://www.bloomberg.com/news/articles/2014-06-12/to-strip-teacher-tenure-judge-cites-the-economic-cost-of-bad-teaching\">Newspapers report<\/A> that having a better teacher for even a single grade (for example, a better fourth-grade teacher) can improve a child&#8217;s lifetime earning prospects by $80,000. Meanwhile, <A HREF=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3592970/\">behavioral genetics studies<\/A> suggest that <A HREF=\"http://amzn.to/1OAT1of\">a child&#8217;s parents have minimal (non-genetic) impact<\/A> on their future earnings. So one year with your fourth-grade teacher making you learn fractions has vast effects on your prospects, but twenty-odd years with your parents shaping you at every moment doesn&#8217;t? <i>Huh?<\/i> I decided to try to figure this out by looking into the research on teacher effectiveness more closely.<\/p><p>First, how much do teachers matter compared to other things? To find out, researchers take a district full of kids with varying standardized test scores and try to figure out how much of the variance can be predicted by what school the kids are in, what teacher&#8217;s class the kids are in, and other demographic factors about the kids. So for example if the test scores of two kids in the same teacher&#8217;s class were on average no more similar than the test scores of two kids in two different teachers&#8217; classes, then teachers can&#8217;t matter very much. But if we were consistently seeing things like everybody in Teacher A&#8217;s class getting A+s and everyone in Teacher B&#8217;s class getting Ds, that would suggest that good teachers are very important.<\/p><p>Here are the results from three teams that tried this (<A HREF=\"http://ies.ed.gov/director/speeches2002/03_05/2002_03_05a.asp\">source<\/A>, <A HREF=\"https://www.ets.org/s/pdf/23497_Angoff%20Report-web.pdf\">source<\/A>, <A HREF=\"http://www.cedr.us/papers/working/CEDR%20WP%202010-6_Teacher%20Effectiveness%20in%20WA%20%2812-7-10%29.pdf\">source<\/A>):<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/teacher1.png\"><\/center><\/p><p>These differ a little in that the first one assumes away all noise (&#8220;unexplained variance&#8221;) and the latter two keep it in. But they all agree pretty well that individual factors are most important, followed by school and teacher factors of roughly equal size. Teacher factors explain somewhere between 5% and 20% of the variance. Other studies seem to agree, usually a little to the lower end. For example, <A HREF=\"https://roundtheinkwell.files.wordpress.com/2011/10/three-way-error-analysis.pdf\">Goldhaber, Brewer, and Anderson (1999)<\/A> find teachers explain 9% of variance; <A HREF=\"http://epa.sagepub.com/content/26/3/237.short?rss=1&#038;ssource=mfc\">Nye, Konstantopoulos, and Hedges (2004)<\/A> find they explain 13% of variance for math and 7% for reading. The <A HREF=\"http://www.amstat.org/policy/pdfs/ASA_VAM_Statement.pdf\">American Statistical Association<\/A> summarize... <\/p>","plaintextDescription":"[Epistemic status: This is really complicated, this is not my field, people who have spent their entire lives studying this subject have different opinions, and I don’t claim to have done more than a very superficial survey. I welcome corrections on the many inevitable errors.]\n\nI.\n\nNewspapers report that having a better teacher for even a single grade (for example, a better fourth-grade teacher) can improve a child’s lifetime earning prospects by $80,000. Meanwhile, behavioral genetics studies suggest that a child’s parents have minimal (non-genetic) impact on their future earnings. So one year with your fourth-grade teacher making you learn fractions has vast effects on your prospects, but twenty-odd years with your parents shaping you at every moment doesn’t? Huh? I decided to try to figure this out by looking into the research on teacher effectiveness more closely.\n\nFirst, how much do teachers matter compared to other things? To find out, researchers take a district full of kids with varying standardized test scores and try to figure out how much of the variance can be predicted by what school the kids are in, what teacher’s class the kids are in, and other demographic factors about the kids. So for example if the test scores of two kids in the same teacher’s class were on average no more similar than the test scores of two kids in two different teachers’ classes, then teachers can’t matter very much. But if we were consistently seeing things like everybody in Teacher A’s class getting A+s and everyone in Teacher B’s class getting Ds, that would suggest that good teachers are very important.\n\nHere are the results from three teams that tried this (source, source, source):\n\n\n\nThese differ a little in that the first one assumes away all noise (“unexplained variance”) and the latter two keep it in. But they all agree pretty well that individual factors are most important, followed by school and teacher factors of roughly equal size. Teacher factors explain somewhere","wordCount":6728,"version":"1.0.0"},"SocialPreviewType:K9aLcuxAPyf5jGyFX":{"_id":"K9aLcuxAPyf5jGyFX","__typename":"SocialPreviewType","imageUrl":""},"Post:K9aLcuxAPyf5jGyFX":{"_id":"K9aLcuxAPyf5jGyFX","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16df7"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":27,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:TLrqSmzoGoA3v5tNP"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:K9aLcuxAPyf5jGyFX"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-05-19T06:13:32.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"TLrqSmzoGoA3v5tNP":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16df7","commentCount":3,"voteCount":15,"baseScore":16,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00004249203630024567,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-02-02T19:06:37.087Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"teachers-much-more-than-you-wanted-to-know","title":"Teachers: Much More Than You Wanted To Know","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16d40":{"_id":"5c6392c7bcb4ac6367c16d40","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Epistemic status: very uncertain. Not to be taken as medical advice. Talk to your doctor before deciding whether or not to get any tests.]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>There are many antidepressants in common use. With a few exceptions, none are globally better than any others. The conventional wisdom says patients should keep trying antidepressants until they find one that works for them. If we knew beforehand which antidepressants would work for which patients, it would save everyone a lot of time, money, and misery. This is the allure of pharmacogenomics, the new field of genetically-guided medication prescription.<\/p><p>Everybody has various different types of cytochrome enzymes which metabolize medication. Some of them play major roles in metabolizing antidepressants; usually it&#8217;s really complicated and several different enzymes can affect the same antidepressant at different stages. But sometimes one or another dominates; for example, Prozac is mostly metabolized by one enzyme called CYP2D6, and Zoloft is mostly metabolized by a different enzyme called CYP2C19.<\/p><p>Suppose (say the pharmacogenomicists) that my individual genetics code for a normal CYP2D6, but a hyperactive CYP2C19 that works ten times faster than usual. Then maybe Prozac would work normally for me, but every drop of Zoloft would get shredded by my enzymes before it can even get to my brain. A genetic test could tell my psychiatrist this, and then she would know to give me Prozac and not Zoloft. Some tests like this are already commercially available. Preliminary results look encouraging.  As always, the key words are &#8220;preliminary&#8221; and &#8220;look&#8221;, and did I mention that these results were mostly produced by pharma companies pushing their products?<\/p><p>But let me dream for a just a second. There&#8217;s been this uneasy tension in psychopharmacology. Clinical psychiatrists give their patients antidepressants and see them get better. Then research psychiatrists do studies and show that antidepressant effect sizes are so small as to be practically unnoticeable. The clinicians say &#8220;Something must be wrong with your studies, we see our patients on antidepressants get much better all the time&#8221;. The researchers counter with &#8220;The plural of anecdote isn&#8217;t &#8216;data&#8217;, your intuitions deceive you, antidepressant effects are almost imperceptibly weak.&#8221; At this point we prescribe... <\/p>","plaintextDescription":"[Epistemic status: very uncertain. Not to be taken as medical advice. Talk to your doctor before deciding whether or not to get any tests.]\n\nI.\n\nThere are many antidepressants in common use. With a few exceptions, none are globally better than any others. The conventional wisdom says patients should keep trying antidepressants until they find one that works for them. If we knew beforehand which antidepressants would work for which patients, it would save everyone a lot of time, money, and misery. This is the allure of pharmacogenomics, the new field of genetically-guided medication prescription.\n\nEverybody has various different types of cytochrome enzymes which metabolize medication. Some of them play major roles in metabolizing antidepressants; usually it’s really complicated and several different enzymes can affect the same antidepressant at different stages. But sometimes one or another dominates; for example, Prozac is mostly metabolized by one enzyme called CYP2D6, and Zoloft is mostly metabolized by a different enzyme called CYP2C19.\n\nSuppose (say the pharmacogenomicists) that my individual genetics code for a normal CYP2D6, but a hyperactive CYP2C19 that works ten times faster than usual. Then maybe Prozac would work normally for me, but every drop of Zoloft would get shredded by my enzymes before it can even get to my brain. A genetic test could tell my psychiatrist this, and then she would know to give me Prozac and not Zoloft. Some tests like this are already commercially available. Preliminary results look encouraging. As always, the key words are “preliminary” and “look”, and did I mention that these results were mostly produced by pharma companies pushing their products?\n\nBut let me dream for a just a second. There’s been this uneasy tension in psychopharmacology. Clinical psychiatrists give their patients antidepressants and see them get better. Then research psychiatrists do studies and show that antidepressant effect sizes are so small as to be pract","wordCount":5930,"version":"1.0.0"},"SocialPreviewType:oHsMeXehPy4jHcmwy":{"_id":"oHsMeXehPy4jHcmwy","__typename":"SocialPreviewType","imageUrl":""},"Post:oHsMeXehPy4jHcmwy":{"_id":"oHsMeXehPy4jHcmwy","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16d40"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":24,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:oHsMeXehPy4jHcmwy"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-03-06T05:38:42.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16d40","commentCount":0,"voteCount":9,"baseScore":9,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.000027530202714842744,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"antidepressant-pharmacogenomics-much-more-than-you-wanted-to","title":"Antidepressant Pharmacogenomics: Much More Than You Wanted To Know","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:Ap653obbCyZnhKoeZ":{"_id":"Ap653obbCyZnhKoeZ","__typename":"Chapter","createdAt":"2017-08-24T01:33:50.217Z","title":"Much More Than You Wanted to Know","subtitle":null,"contents":null,"number":0,"sequenceId":"B384FrQNrxSq4hZoS","postIds":["c8khnHoRTSGjmHLLf","g4pi2jfQHFF6mPdjw","znEhB9hJtwXica5s3","CfX6pGepdjQYELSpK","ALEYMFAuFSCz8v5YE","FW3DEYbKPZJh5A8Bj","K9aLcuxAPyf5jGyFX","oHsMeXehPy4jHcmwy"],"posts":[{"__ref":"Post:c8khnHoRTSGjmHLLf"},{"__ref":"Post:g4pi2jfQHFF6mPdjw"},{"__ref":"Post:znEhB9hJtwXica5s3"},{"__ref":"Post:CfX6pGepdjQYELSpK"},{"__ref":"Post:ALEYMFAuFSCz8v5YE"},{"__ref":"Post:FW3DEYbKPZJh5A8Bj"},{"__ref":"Post:K9aLcuxAPyf5jGyFX"},{"__ref":"Post:oHsMeXehPy4jHcmwy"}]},"Revision:5c6392dcbcb4ac6367c16ea6":{"_id":"5c6392dcbcb4ac6367c16ea6","__typename":"Revision","htmlHighlight":"<p><i>(inspired by <A HREF=\"http://www.chriswooding.com/zombies-seriously-enough/\">Zombies: Seriously, Enough<\/A>, <A HREF=\"http://thewritersadvice.com/2012/07/26/zombies-are-sooooooooo-overdone/\">Zombies Are So Overdone<\/A>, and <A HREF=\"http://io9.com/10-science-fiction-and-fantasy-stories-that-editors-are-1566121756\">Scifi/Fantasy Stories Editors Are Tired Of Seeing: Zombies<\/A>)<\/i><\/p><p>He walked into my office and threw the manuscript on my desk with a thud.<\/p><p>&#8220;It&#8217;s called <i>Thankful For Zombies<\/i>. A zombie story where&#8230;&#8221;<\/p><p>&#8220;Nope,&#8221; I said.<\/p><p>His face deflated like a balloon. &#8220;But I didn&#8217;t even&#8230;&#8221;<\/p><p>&#8220;Zombies are overdone,&#8221; I said.<\/p><p>&#8220;But this is a zombie story with a twist!&#8221;<\/p><p>&#8220;Zombie stories with twists are <i>super<\/i> overdone.&#8221;<\/p><p>&#8220;But this is a story about an extended family who get together for Thanksgiving dinner, only to be interrupted by a zombie apocalypse. It&#8217;s a Thanksgiving story about zombies. You have to admit that the combination of zombies and Thanksgiving has never&#8230;&#8221;<\/p><p>&#8220;Done,&#8221; I said.<\/p><p>&#8220;Wait, really? The family starts out estranged and suspicious of each other, but then when they all have to work together to&#8230;&#8221;<\/p><p>&#8220;Done,&#8221; I said.<\/p><p>&#8220;How could that have been done?&#8221;<\/p><p>&#8220;Listen. I know you won&#8217;t believe me, but for the past ten years or so, the best literary minds of our generation have been working on creating zombie stories <i>just<\/i> different enough from every other zombie story around to get published. First the clever and interesting twists got explored. Then the mediocre and boring twists. Then the absurd and idiotic twists. Finally the genre got <i>entirely mined out<\/i>. There is now a New York Times bestselling book about zombies invading Jane Austen&#8217;s <i>Pride and Prejudice<\/i>. If your idea isn&#8217;t weirder than that, <i>it&#8217;s been done<\/i>. And that&#8217;s the logical &#8216;if&#8217;. If your idea <i>is<\/i> weirder than that, <i>it has also been done<\/i>.&#8221;<\/p><p>&#8220;I <i>will<\/i> get <i>Thankful for Zombies<\/i> published,&#8221; he said.<\/p><p>&#8220;You won&#8217;t,&#8221; I advised him.<\/p><p>&#8220;I just have to think of an original angle.&#8221;<\/p><p>&#8220;You really won&#8217;t,&#8221; I told him.<\/p><p>&#8220;The zombies are the good guys,&#8221; he proposed.<\/p><p>&#8220;Done.&#8221;<\/p><p>&#8220;The zombies are smarter than humans.&#8221;<\/p><p>&#8220;Done.&#8221;<\/p><p>&#8220;In the end, we ourselves are the zombies.&#8221;<\/p><p>&#8220;Done.&#8221;<\/p><p>&#8220;A human girl falls in love with a zombie.&#8221;<\/p><p>&#8220;<A HREF=\"http://www.emeraldrain.com/cd/cd_yzil.html\">Done.<\/A>&#8221;<\/p><p>&#8220;Okay, fine. Toss the Thanksgiving angle. There&#8217;s got to be some zombie plot that will be fresh and new.&#8221... <\/p>","plaintextDescription":"(inspired by Zombies: Seriously, Enough, Zombies Are So Overdone, and Scifi/Fantasy Stories Editors Are Tired Of Seeing: Zombies)\n\nHe walked into my office and threw the manuscript on my desk with a thud.\n\n“It’s called Thankful For Zombies. A zombie story where…”\n\n“Nope,” I said.\n\nHis face deflated like a balloon. “But I didn’t even…”\n\n“Zombies are overdone,” I said.\n\n“But this is a zombie story with a twist!”\n\n“Zombie stories with twists are super overdone.”\n\n“But this is a story about an extended family who get together for Thanksgiving dinner, only to be interrupted by a zombie apocalypse. It’s a Thanksgiving story about zombies. You have to admit that the combination of zombies and Thanksgiving has never…”\n\n“Done,” I said.\n\n“Wait, really? The family starts out estranged and suspicious of each other, but then when they all have to work together to…”\n\n“Done,” I said.\n\n“How could that have been done?”\n\n“Listen. I know you won’t believe me, but for the past ten years or so, the best literary minds of our generation have been working on creating zombie stories just different enough from every other zombie story around to get published. First the clever and interesting twists got explored. Then the mediocre and boring twists. Then the absurd and idiotic twists. Finally the genre got entirely mined out. There is now a New York Times bestselling book about zombies invading Jane Austen’s Pride and Prejudice. If your idea isn’t weirder than that, it’s been done. And that’s the logical ‘if’. If your idea is weirder than that, it has also been done.”\n\n“I will get Thankful for Zombies published,” he said.\n\n“You won’t,” I advised him.\n\n“I just have to think of an original angle.”\n\n“You really won’t,” I told him.\n\n“The zombies are the good guys,” he proposed.\n\n“Done.”\n\n“The zombies are smarter than humans.”\n\n“Done.”\n\n“In the end, we ourselves are the zombies.”\n\n“Done.”\n\n“A human girl falls in love with a zombie.”\n\n“Done.”\n\n“Okay, fine. Toss the Thanksgiving angle. There’s got ","wordCount":1020,"version":"1.0.0"},"SocialPreviewType:jFzovY2CERF5bd2EW":{"_id":"jFzovY2CERF5bd2EW","__typename":"SocialPreviewType","imageUrl":""},"Post:jFzovY2CERF5bd2EW":{"_id":"jFzovY2CERF5bd2EW","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ea6"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":4,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:hNFdS3rRiYgqqD8aM"}],"socialPreviewData":{"__ref":"SocialPreviewType:jFzovY2CERF5bd2EW"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-12-07T20:11:47.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":13,"hNFdS3rRiYgqqD8aM":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ea6","commentCount":0,"voteCount":25,"baseScore":30,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":25,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00006365852459566668,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2018-03-06T04:37:07.370Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"a-story-with-zombies","title":"A Story With Zombies","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e9b":{"_id":"5c6392dcbcb4ac6367c16e9b","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Content note: fictional story contains gaslighting-type elements. May induce Cartesian skepticism]<\/i><\/font><\/p><p>You wake up in one of those pod things like in <i>The Matrix<\/i>. There&#8217;s a woman standing in front of you, wearing a lab coat, holding a clipboard.<\/p><p>&#8220;Hi,&#8221; she says. &#8220;This is the real world. You used to live here. We erased your memories and stuck you in a simulated world for a while, like in <i>The Matrix<\/i>. It was part of a great experiment.&#8221;<\/p><p>&#8220;What?&#8221; you shout. &#8220;My whole life, a lie? How dare you deceive me as part of some grand &#8216;experiment&#8217; I never consented to?&#8221;<\/p><p>&#8220;Oh,&#8221; said the woman, &#8220;actually, you did consent, in exchange for extra credit in your undergraduate psychology course.&#8221; She hands you the clipboard. There is a consent form with your name on it, in your handwriting.<\/p><p>You give her a sheepish look. &#8220;What was the experiment?&#8221;<\/p><p>&#8220;You know families?&#8221; asks the woman.<\/p><p>&#8220;Of course,&#8221; you say.<\/p><p>&#8220;Yeah,&#8221; says the woman. &#8220;Not really a thing. Like, if you think about it, it doesn&#8217;t make any sense. Why would you care more for your genetic siblings and cousins and whoever than for your friends and people who are genuinely close to you? That&#8217;s like racism &#8211; but even worse, at least racists identify with a group of millions of people instead of a group of half a dozen. Why should parents have to raise children whom they might not even like, who might have been a total accident? Why should people, motivated by guilt, make herculean efforts to &#8220;keep in touch&#8221; with some nephew or cousin whom they clearly would be perfectly happy to ignore entirely?&#8221;<\/p><p>&#8220;Uh,&#8221; you say, &#8220;not really in the mood for philosophy. Families have been around forever and they aren&#8217;t going anywhere, who cares?&#8221;<\/p><p>&#8220;Actually,&#8221; says the woman, &#8220;in the real world, no one believes in family. There&#8217;s no such thing. Children are taken at birth from their parents and given to people who contract to raise them in exchange for a fixed percent of their future earnings.&#8221;<\/p><p>&#8220;That&#8217;s monstrous!&#8221; you say. &#8220;When did this happen? Weren&#8217;t there protests?&#8221;<\/p><p>&#8220;It&#8217;s always been this way,&#8221; says the woman. &#8220;There&#8217;s <i>never<\/i> been such a thing as the family. List... <\/p>","plaintextDescription":"[Content note: fictional story contains gaslighting-type elements. May induce Cartesian skepticism]\n\nYou wake up in one of those pod things like in The Matrix. There’s a woman standing in front of you, wearing a lab coat, holding a clipboard.\n\n“Hi,” she says. “This is the real world. You used to live here. We erased your memories and stuck you in a simulated world for a while, like in The Matrix. It was part of a great experiment.”\n\n“What?” you shout. “My whole life, a lie? How dare you deceive me as part of some grand ‘experiment’ I never consented to?”\n\n“Oh,” said the woman, “actually, you did consent, in exchange for extra credit in your undergraduate psychology course.” She hands you the clipboard. There is a consent form with your name on it, in your handwriting.\n\nYou give her a sheepish look. “What was the experiment?”\n\n“You know families?” asks the woman.\n\n“Of course,” you say.\n\n“Yeah,” says the woman. “Not really a thing. Like, if you think about it, it doesn’t make any sense. Why would you care more for your genetic siblings and cousins and whoever than for your friends and people who are genuinely close to you? That’s like racism – but even worse, at least racists identify with a group of millions of people instead of a group of half a dozen. Why should parents have to raise children whom they might not even like, who might have been a total accident? Why should people, motivated by guilt, make herculean efforts to “keep in touch” with some nephew or cousin whom they clearly would be perfectly happy to ignore entirely?”\n\n“Uh,” you say, “not really in the mood for philosophy. Families have been around forever and they aren’t going anywhere, who cares?”\n\n“Actually,” says the woman, “in the real world, no one believes in family. There’s no such thing. Children are taken at birth from their parents and given to people who contract to raise them in exchange for a fixed percent of their future earnings.”\n\n“That’s monstrous!” you say. “When did this happen? Weren","wordCount":2623,"version":"1.0.0"},"Revision:5f5c37ee1b5cdee568cfb124_description":{"_id":"5f5c37ee1b5cdee568cfb124_description","__typename":"Revision","htmlHighlight":"<p><strong>Conformity bias<\/strong> is a tendency to behave similarly to the others in a group, even if doing so goes against your own judgment.<\/p><h2>Blog posts<\/h2><ul><li><a href=\"http://lesswrong.com/lw/m9/aschs_conformity_experiment/\">Asch's Conformity Experiment<\/a><\/li><li><a href=\"http://lesswrong.com/lw/mb/lonely_dissent/\">Lonely Dissent<\/a><\/li><li><a href=\"http://lesswrong.com/lw/ma/on_expressing_your_concerns/\">On Expressing Your Concerns<\/a><\/li><li><a href=\"http://lesswrong.com/lw/1ww/undiscriminating_skepticism/\">Undiscriminating Skepticism<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/affective-death-spiral\">Affective death spiral<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/groupthink\">Groupthink<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/in-group-bias\">In-group bias<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/improper-belief\">Improper belief<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/akrasia\">Akrasia<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/death-spirals-and-the-cult-attractor\">Death Spirals and the Cult Attractor<\/a><\/li><\/ul>"},"Tag:5f5c37ee1b5cdee568cfb124":{"_id":"5f5c37ee1b5cdee568cfb124","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb124_description"},"canVoteOnRels":null,"userId":"qf77EiaoMw7tH3GSr","name":"Conformity Bias","shortName":null,"slug":"conformity-bias","core":false,"postCount":17,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:51.914Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:pfmZ5cYQCahABGZzi":{"_id":"pfmZ5cYQCahABGZzi","__typename":"SocialPreviewType","imageUrl":""},"Post:pfmZ5cYQCahABGZzi":{"_id":"pfmZ5cYQCahABGZzi","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e9b"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":10,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb124"}],"socialPreviewData":{"__ref":"SocialPreviewType:pfmZ5cYQCahABGZzi"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-06-04T02:16:21.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":3,"5f5c37ee1b5cdee568cfb124":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e9b","commentCount":0,"voteCount":50,"baseScore":58,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":50,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00011599919525906444,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"asches-to-asches","title":"Asches to Asches","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:h98gtQYj7rkbPxebN":{"_id":"h98gtQYj7rkbPxebN","__typename":"Chapter","createdAt":"2017-09-02T08:42:28.360Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"B384FrQNrxSq4hZoS","postIds":["jFzovY2CERF5bd2EW","pfmZ5cYQCahABGZzi"],"posts":[{"__ref":"Post:jFzovY2CERF5bd2EW"},{"__ref":"Post:pfmZ5cYQCahABGZzi"}]},"Revision:B384FrQNrxSq4hZoS_contents":{"_id":"B384FrQNrxSq4hZoS_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:32:25.576Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>Synthesising scientific knowledge to answer a policy question is difficult. This sequence is a series of attempts to do just that, with intricate and winding literature reviews.<\/p>","commitMessage":null,"wordCount":27,"htmlHighlight":"<p>Synthesising scientific knowledge to answer a policy question is difficult. This sequence is a series of attempts to do just that, with intricate and winding literature reviews.<\/p>","plaintextDescription":"Synthesising scientific knowledge to answer a policy question is difficult. This sequence is a series of attempts to do just that, with intricate and winding literature reviews."},"Sequence:B384FrQNrxSq4hZoS":{"_id":"B384FrQNrxSq4hZoS","__typename":"Sequence","chapters":[{"__ref":"Chapter:Ap653obbCyZnhKoeZ"},{"__ref":"Chapter:h98gtQYj7rkbPxebN"}],"createdAt":"2017-08-24T01:32:25.576Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:B384FrQNrxSq4hZoS_contents"},"gridImageId":"sequencesgrid/ggdn92agzidnk0voif2z","bannerImageId":"sequences/p6oizab58tj8y9gulhz6","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":0,"title":"Research and Reviews","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:dRTatDhSy6kToJ2gs_contents":{"_id":"dRTatDhSy6kToJ2gs_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-09-05T02:20:10.614Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:5c6392c7bcb4ac6367c16c66":{"_id":"5c6392c7bcb4ac6367c16c66","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>A group of Manhattan Project physicists <A HREF=\"https://en.wikipedia.org/wiki/The_Martians_(scientists)\">created<\/A> a tongue-in-cheek mythology where superintelligent Martian scouts landed in Budapest in the late 19th century and stayed for about a generation, after which they decided the planet was unsuitable for their needs and disappeared. The only clue to their existence were the children they had with local women.<\/p><p>The joke was that this explained why the Manhattan Project was led by a group of Hungarian supergeniuses, all born in Budapest between 1890 and 1920. These included Manhattan Project founder <A HREF=\"https://en.wikipedia.org/wiki/Leo_Szilard\">Leo Szilard<\/A>, H-bomb creator <A HREF=\"https://en.wikipedia.org/wiki/Edward_Teller\">Edward Teller<\/A>, Nobel-Prize-winning quantum physicist <A HREF=\"https://en.wikipedia.org/wiki/Eugene_Wigner\">Eugene Wigner<\/A>, and legendary polymath <A HREF=\"https://en.wikipedia.org/wiki/John_von_Neumann\">John von Neumann<\/A>, namesake of <A HREF=\"https://en.wikipedia.org/wiki/List_of_things_named_after_John_von_Neumann\">the List Of Things Named After John Von Neumann<\/A>.<\/p><p>The coincidences actually pile up beyond this. Von Neumann, Wigner, and possibly Teller all went to the same central Budapest high school at about the same time, leading a friend to joke about the atomic bomb being <i>basically<\/i> a Hungarian high school science fair project.<\/p><p>But maybe we shouldn&#8217;t be joking about this so much. Suppose we learned that Beethoven, Mozart, and Bach all had the same childhood piano tutor. It sounds less like &#8220;ha ha, what a funny coincidence&#8221; and more like &#8220;wait, who was this guy, and how quickly can we make everyone else start doing what he did?&#8221;<\/p><p>In this case, the guy was <A HREF=\"https://en.wikipedia.org/wiki/L%C3%A1szl%C3%B3_R%C3%A1tz\">Laszlo Ratz<\/A>, legendary Budapest high school math teacher. I didn&#8217;t even know people <i>told<\/i> legends about high school math teachers, but apparently they do, and this guy features in a lot of them. There is apparently a Laszlo Ratz Memorial Congress for high school math teachers each year, and a Laszlo Ratz medal for services to the profession. There are plaques and statues to this guy. It&#8217;s pretty impressive.<\/p><p>A while ago I looked into the literature on teachers <A HREF=\"http://slatestarcodex.com/2016/05/19/teachers-much-more-than-you-wanted-to-know/\">and concluded<\/A> that they didn&#8217;t have much effect overall. Similarly, Freddie deBoer writes that most claims that certain schools or programs have transformative effects on their students <A HREF=\"https://fredrikdeboer.com/2017/03/29/why-selection-bias-is-the-most-powerful-force-in-education/\">are the result of selection bias<\/A>.<\/p><p>On the other hand, we have a Hungarian academy producing like half the brainpower behind 20th century physics, and Nobel laureates who literally <A HREF=\"https://en.wikipedia.org/wiki/L%C3%A1szl%C3%B3_R%C3%A1tz#Eugene_Wigner_about_his_teacher_L.C3.A1szl.C3.B3_R.C3.A1tz\">keep a picture<\/A> of their high school math teacher on the wall of their office to inspire them. Perhaps even if teachers don&#8217;t explain much of the <i>existing<\/i> variability, there ar... <\/p>","plaintextDescription":"I.\n\nA group of Manhattan Project physicists created a tongue-in-cheek mythology where superintelligent Martian scouts landed in Budapest in the late 19th century and stayed for about a generation, after which they decided the planet was unsuitable for their needs and disappeared. The only clue to their existence were the children they had with local women.\n\nThe joke was that this explained why the Manhattan Project was led by a group of Hungarian supergeniuses, all born in Budapest between 1890 and 1920. These included Manhattan Project founder Leo Szilard, H-bomb creator Edward Teller, Nobel-Prize-winning quantum physicist Eugene Wigner, and legendary polymath John von Neumann, namesake of the List Of Things Named After John Von Neumann.\n\nThe coincidences actually pile up beyond this. Von Neumann, Wigner, and possibly Teller all went to the same central Budapest high school at about the same time, leading a friend to joke about the atomic bomb being basically a Hungarian high school science fair project.\n\nBut maybe we shouldn’t be joking about this so much. Suppose we learned that Beethoven, Mozart, and Bach all had the same childhood piano tutor. It sounds less like “ha ha, what a funny coincidence” and more like “wait, who was this guy, and how quickly can we make everyone else start doing what he did?”\n\nIn this case, the guy was Laszlo Ratz, legendary Budapest high school math teacher. I didn’t even know people told legends about high school math teachers, but apparently they do, and this guy features in a lot of them. There is apparently a Laszlo Ratz Memorial Congress for high school math teachers each year, and a Laszlo Ratz medal for services to the profession. There are plaques and statues to this guy. It’s pretty impressive.\n\nA while ago I looked into the literature on teachers and concluded that they didn’t have much effect overall. Similarly, Freddie deBoer writes that most claims that certain schools or programs have transformative effects on their stud","wordCount":4087,"version":"1.0.0"},"Tag:e9wHzopbGCAFwp9Rw":{"_id":"e9wHzopbGCAFwp9Rw","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"mPipmBTniuABY5PQy","name":"Human Genetics","shortName":null,"slug":"human-genetics","core":false,"postCount":49,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-09T08:09:32.094Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:4cKQgA4S7xfNeeWXg_description":{"_id":"4cKQgA4S7xfNeeWXg_description","__typename":"Revision","htmlHighlight":"<p><strong>IQ <\/strong>is a score derived from a set of standardized tests designed to assess human intelligence. The <strong>g-factor <\/strong>(general intelligence factor) is the underlying psychometric construct that the IQ tests are trying to measure.<\/p><p>This tag is specifically for discussions about these formal constructs. For discussions about artificial intelligence, see <a href=\"https://www.lesswrong.com/tag/ai\">AI<\/a>. For discussions about human-level intelligence in a broader sense, see <a href=\"https://www.lesswrong.com/tag/general-intelligence\">General Intelligence<\/a>.<\/p>"},"Tag:4cKQgA4S7xfNeeWXg":{"_id":"4cKQgA4S7xfNeeWXg","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:4cKQgA4S7xfNeeWXg_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"IQ and g-factor","shortName":null,"slug":"iq-and-g-factor","core":false,"postCount":68,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-12T09:28:46.598Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:xPJKZyPCvap4Fven8":{"_id":"xPJKZyPCvap4Fven8","__typename":"SocialPreviewType","imageUrl":""},"Post:xPJKZyPCvap4Fven8":{"_id":"xPJKZyPCvap4Fven8","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16c66"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":16,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:e9wHzopbGCAFwp9Rw"},{"__ref":"Tag:4cKQgA4S7xfNeeWXg"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:xPJKZyPCvap4Fven8"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-05-26T09:45:22.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"4cKQgA4S7xfNeeWXg":2,"e9wHzopbGCAFwp9Rw":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16c66","commentCount":10,"voteCount":41,"baseScore":54,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":41,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00016098501509986818,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-09-05T13:46:31.748Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":13,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":13,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-atomic-bomb-considered-as-hungarian-high-school-science","title":"The Atomic Bomb Considered As Hungarian High School Science Fair Project","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16dec":{"_id":"5c6392dcbcb4ac6367c16dec","__typename":"Revision","htmlHighlight":"<p><em>[Epistemic status: Very speculative. I am not a neuroscientist and apologize for any misinterpretation of the papers involved. Thanks to the people who posted these papers in <a href=\"http://slatestarcodex.reddit.com/\">r/slatestarcodex<\/a>. See also <a href=\"http://slatestarcodex.com/2015/08/28/mysticism-and-pattern-matching/\">Mysticism and Pattern-Matching<\/a> and <a href=\"http://lesswrong.com/lw/e25/bayes_for_schizophrenics_reasoning_in_delusional/\">Bayes For Schizophrenics<\/a>]<\/em><\/p><p>Bayes’ Theorem is an equation for calculating certain kinds of conditional probabilities. For something so obscure, it’s attracted a surprisingly wide fanbase, including <a href=\"https://www.bu.edu/cghd/files/2010/10/Gill-Sabin-2005-Why-Clinicians-are-Natural-Bayesians.pdf\">doctors<\/a>, <a href=\"ftp://ftp-sop.inria.fr/modemic/campillo/micr/bib/clark2005b.pdf\">environmental scientists<\/a>, <a href=\"http://econlog.econlib.org/archives/2009/11/why_arent_acade.html\">economists<\/a>, <a href=\"http://bayesianbodybuilding.com/\">bodybuilders<\/a>, <a href=\"http://delong.typepad.com/sdj/2013/01/cosma-shalizi-vs-the-fen-dwelling-bayesians.html\">fen-dwellers<\/a>, and <a href=\"http://sci-hub.cc/10.1177/1745691611406928\">international smugglers<\/a>. Eventually the hype reached the point where there was both a <a href=\"https://www.youtube.com/watch?v=t6jFFlz9o-E\">Bayesian cabaret<\/a> <em>and<\/em> a <a href=\"https://www.youtube.com/watch?v=lntEPbMCWAs\">Bayesian choir<\/a>, popular books using Bayes’ Theorem to prove both the <a href=\"https://www.amazon.com/The-Probability-God-Calculation-Ultimate/dp/1400054788/ref=as_li_ss_tl?s=books&ie=UTF8&qid=1332516104&sr=1-1&linkCode=ll1&tag=slastacod-20&linkId=4caa5e695aaa2faf31e963a911690137\">existence<\/a> and the <a href=\"https://www.amazon.com/Proving-History-Bayess-Theorem-Historical/dp/1616145595/ref=as_li_ss_tl?s=books&ie=UTF8&qid=1473562460&sr=1-1&keywords=bayes+theorem+christianity&linkCode=ll1&tag=slastacod-20&linkId=a835ae3d1185022fabc200fd94dac9f3\">nonexistence<\/a> of God, and even <a href=\"http://www.businessinsider.com/dating-for-bayesians-heres-how-to-use-statistics-to-improve-your-love-life-2013-11\">Bayesian dating advice<\/a>. Eventually everyone agreed to dial down their exuberance a little, and accept that Bayes’ Theorem might not literally explain <em>absolutely<\/em> everything.<\/p><p>So – did you know that the neurotransmitters in the brain might represent different terms in Bayes’ Theorem?<\/p><p>First things first: Bayes’ Theorem is a mathematical framework for integrating new evidence with prior beliefs. For example, suppose you’re sitting in your quiet suburban home and you hear something that sounds like a lion roaring. You have some prior beliefs that lions are unlikely to be near your house, so you figure that it’s probably not a lion. Probably it’s some weird machine of your neighbor’s that just happens to sound like a lion, or some kids pranking you by playing lion noises, or something. You end up believing that there’s probably no lion nearby, but you do have a slightly higher probability of there being a lion nearby than you had before you heard the roaring noise. Bayes’ Theorem is just this kind of reasoning converted to math. You can find the long version <a href=\"https://arbital.com/p/bayes_rule_guide/\">here<\/a>.<\/p><p>This is what the brain does too: integrate new evidence with prior beliefs. Here are some examples I’ve used on this blog before:<\/p><p><\/p><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1538421748/sequences/It's%20Bayes%20All%20the%20Way%20Up/topdown1.png\" class=\"draft-image \" style=\"\" /><\/figure><\/span><p><\/p><p><\/p><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1538421738/sequences/It's%20Bayes%20All%20the%20Way%20Up/topdown2.gif\" class=\"draft-image \" style=\"\" /><\/figure><\/span><p><\/p><p><\/p><span><figure><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1538421732/sequences/It's%20Bayes%20All%20the%20Way%20Up/topdown3.jpg\" class=\"draft-image \" style=\"\" /><\/figure><\/span><p><\/p><p>All three of these are examples of top-down processing. Bottom-up processing is when you build perceptions into a model of the the world. Top-down processing is when you let your models of the world influence your perceptions. In the first image, you view the center letter of the the first word as an H and the second as an A, even though they’re the the same character; your model of the world tells you that THE CAT is more likely than TAE CHT. In the second i... <\/p>","plaintextDescription":"[Epistemic status: Very speculative. I am not a neuroscientist and apologize for any misinterpretation of the papers involved. Thanks to the people who posted these papers in r/slatestarcodex. See also Mysticism and Pattern-Matching and Bayes For Schizophrenics]\n\nBayes’ Theorem is an equation for calculating certain kinds of conditional probabilities. For something so obscure, it’s attracted a surprisingly wide fanbase, including doctors, environmental scientists, economists, bodybuilders, fen-dwellers, and international smugglers. Eventually the hype reached the point where there was both a Bayesian cabaret and a Bayesian choir, popular books using Bayes’ Theorem to prove both the existence and the nonexistence of God, and even Bayesian dating advice. Eventually everyone agreed to dial down their exuberance a little, and accept that Bayes’ Theorem might not literally explain absolutely everything.\n\nSo – did you know that the neurotransmitters in the brain might represent different terms in Bayes’ Theorem?\n\nFirst things first: Bayes’ Theorem is a mathematical framework for integrating new evidence with prior beliefs. For example, suppose you’re sitting in your quiet suburban home and you hear something that sounds like a lion roaring. You have some prior beliefs that lions are unlikely to be near your house, so you figure that it’s probably not a lion. Probably it’s some weird machine of your neighbor’s that just happens to sound like a lion, or some kids pranking you by playing lion noises, or something. You end up believing that there’s probably no lion nearby, but you do have a slightly higher probability of there being a lion nearby than you had before you heard the roaring noise. Bayes’ Theorem is just this kind of reasoning converted to math. You can find the long version here.\n\nThis is what the brain does too: integrate new evidence with prior beliefs. Here are some examples I’ve used on this blog before:\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll three of these are examples of top-do","wordCount":3503,"version":"1.0.0"},"Revision:YAotJ9Le3S2rCJgf8_description":{"_id":"YAotJ9Le3S2rCJgf8_description","__typename":"Revision","htmlHighlight":"<p>(From <a href=\"https://en.wikipedia.org/wiki/Predictive_coding\">Wikipedia<\/a>) <strong>predictive processing<\/strong> (a.k.a. predictive coding, the Bayesian Brain hypothesis) is a theory of brain function in which the brain is constantly generating and updating a mental model of the environment. The model is used to generate predictions of sensory input that are compared to actual sensory input. This comparison results in prediction errors that are then used to update and revise the mental model.<\/p><p><a href=\"https://www.lesswrong.com/tag/free-energy-principle\">Active Inference<\/a> can be seen as a generalisation of predictive processing. While predictive processing only explains the agent's perception, Active Inference models both perception and action as inference under the same unifying objective: optimisation of the informational quantity called variational free energy.<\/p><p><strong>External Links:<\/strong><br><a href=\"https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/\">Book Review: Surfing Uncertainty<\/a> - Introduction to predictive processing by Scott Alexander<br><a href=\"https://slatestarcodex.com/2017/09/06/predictive-processing-and-perceptual-control/\">Predictive Processing And Perceptual Control<\/a> by Scott Alexander<\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/perceptual-control-theory\">Perceptual Control Theory<\/a>, <a href=\"https://www.lesswrong.com/tag/neuroscience\">Neuroscience<\/a><\/p>"},"Tag:YAotJ9Le3S2rCJgf8":{"_id":"YAotJ9Le3S2rCJgf8","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YAotJ9Le3S2rCJgf8_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Predictive Processing","shortName":null,"slug":"predictive-processing","core":false,"postCount":47,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-09T09:52:22.567Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:Wi3EopKJ2aNdtxSWg_description":{"_id":"Wi3EopKJ2aNdtxSWg_description","__typename":"Revision","htmlHighlight":"<p><strong>Neuroscience<\/strong> is a field of study dealing with the structure or function of the brain. It is of particular interest to LessWrong both because it can shed light on <a href=\"https://www.lesswrong.com/tag/ai?showPostCount=true\">AI<\/a>, and because it is often helpful for <a href=\"https://www.lesswrong.com/tag/rationality?showPostCount=true\">rationality<\/a>. For example, understanding how <a href=\"https://www.lesswrong.com/posts/rD57ysqawarsbry6v?lw_source=posts_sheet\">attentional control<\/a> works can inform possible solutions.<\/p><p>Some specific theories of neuroscience:<\/p><ul><li><a href=\"https://www.lesswrong.com/tag/predictive-processing\">Predictive processing<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/free-energy-principle\">FEP/Active Inference<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/ixZLTmFfnKRbaStA5/book-review-a-thousand-brains-by-jeff-hawkins\">A Thousand Brains theory<\/a><\/li><\/ul><p>See also:<\/p><ul><li><a href=\"https://www.lesswrong.com/tag/neuromorphic-ai\">Neuromorphic AI<\/a><\/li><\/ul>"},"Tag:Wi3EopKJ2aNdtxSWg":{"_id":"Wi3EopKJ2aNdtxSWg","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Wi3EopKJ2aNdtxSWg_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Neuroscience","shortName":null,"slug":"neuroscience","core":false,"postCount":205,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-09T09:57:06.243Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:KrEwDMN4YXp5YWD45":{"_id":"KrEwDMN4YXp5YWD45","__typename":"SocialPreviewType","imageUrl":""},"Post:KrEwDMN4YXp5YWD45":{"_id":"KrEwDMN4YXp5YWD45","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16dec"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":14,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:LhX3F2SvGDarZCuh6"},{"__ref":"Tag:YAotJ9Le3S2rCJgf8"},{"__ref":"Tag:Wi3EopKJ2aNdtxSWg"}],"socialPreviewData":{"__ref":"SocialPreviewType:KrEwDMN4YXp5YWD45"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-09-12T13:35:46.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"LhX3F2SvGDarZCuh6":4,"Wi3EopKJ2aNdtxSWg":2,"YAotJ9Le3S2rCJgf8":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16dec","commentCount":0,"voteCount":24,"baseScore":32,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":24,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00008552943472750485,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":2,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"it-s-bayes-all-the-way-up","title":"It’s Bayes All The Way Up","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16f09":{"_id":"5c6392dcbcb4ac6367c16f09","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Epistemic status: So, so speculative. Don&#8217;t take any of this seriously until it&#8217;s replicated and endorsed by other people.]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>If you&#8217;ve ever wanted to see a glitch in the Matrix, watch this spinning mask:<\/p><p><center><font size=\"1\"><IMG SRC=\"http://slatestarcodex.com/blog_images/spinning_mask.gif\"><\/p><p><i>Source: <A HREF=\"http://hearingthevoice.org/2013/11/14/predictive-coding-masterclass/\">http://hearingthevoice.org/2013/11/14/predictive-coding-masterclass/<\/A><\/i><\/font><\/center><\/p><p>Did you see it? As the face started to turn away from you, your brain did&#8230;<i>something<\/i>, and then you were seeing a normal frontwards-facing mask again. It turns out your visual system has really strong views about whether faces should be inside-out or not, and it&#8217;s willing to execute a hard override on perception if it doesn&#8217;t like what it sees.<\/p><p>But not always. Some people get glitchier glitches than others; a few seem almost immune. Studies find schizophrenics and autistic people to be consistently less glitchy than the rest of us. The correlation&#8217;s not perfect. But it&#8217;s definitely there. Something about these people&#8217;s different cognitive processing styles lets them see through the illusion.<\/p><p>I wanted to replicate this result myself. So a few months ago, when I surveyed readers of my blog, I included some questions about perceptual illusions (including a <A HREF=\"http://blog.brainfacts.org/wp-content/uploads/albert6.jpg\">static version<\/A> of the hollow mask). I got five thousand responses, including a few from schizophrenic and autistic readers. Sure enough, the effect was there.<\/p><p>Schizophrenic readers were about twice as likely to report a weak reaction to the mask illusion as non-schizophrenics (28% vs. 14%, p = 0.04). They were also more likely to have a weak reaction to a similar illusion, the <A HREF=\"https://en.wikipedia.org/wiki/Spinning_Dancer\">Spinning Dancer<\/A> (58% vs. 81%, p = 0.01). Readers with a family history of schizophrenia landed in between schizophrenics and healthy controls (16% for mask, 63% for dancer, ns).<\/p><p>Autistic readers were only slightly more likely to report a weak reaction to the mask illusion than neurotypicals (17% vs. 14%), but thanks to our big sample size we could be pretty confident that this was a meaningful difference (p = 0.004). There was no different between autists and neurotypicals on the Spinning Dancer, not even a weak trend (58% vs. 60%, p = 0.4).<\/p><p>Looking deeper, I found a few other anomalies on illusion perception. Most were small and inconsistent. But one stood out: transgender people had an altered response pattern on both illusions, stronger than the alteration for autism and almost as strong as the one for schizophre... <\/p>","plaintextDescription":"[Epistemic status: So, so speculative. Don’t take any of this seriously until it’s replicated and endorsed by other people.]\n\nI.\n\nIf you’ve ever wanted to see a glitch in the Matrix, watch this spinning mask:\n\n\n\nSource: http://hearingthevoice.org/2013/11/14/predictive-coding-masterclass/\n\nDid you see it? As the face started to turn away from you, your brain did…something, and then you were seeing a normal frontwards-facing mask again. It turns out your visual system has really strong views about whether faces should be inside-out or not, and it’s willing to execute a hard override on perception if it doesn’t like what it sees.\n\nBut not always. Some people get glitchier glitches than others; a few seem almost immune. Studies find schizophrenics and autistic people to be consistently less glitchy than the rest of us. The correlation’s not perfect. But it’s definitely there. Something about these people’s different cognitive processing styles lets them see through the illusion.\n\nI wanted to replicate this result myself. So a few months ago, when I surveyed readers of my blog, I included some questions about perceptual illusions (including a static version of the hollow mask). I got five thousand responses, including a few from schizophrenic and autistic readers. Sure enough, the effect was there.\n\nSchizophrenic readers were about twice as likely to report a weak reaction to the mask illusion as non-schizophrenics (28% vs. 14%, p = 0.04). They were also more likely to have a weak reaction to a similar illusion, the Spinning Dancer (58% vs. 81%, p = 0.01). Readers with a family history of schizophrenia landed in between schizophrenics and healthy controls (16% for mask, 63% for dancer, ns).\n\nAutistic readers were only slightly more likely to report a weak reaction to the mask illusion than neurotypicals (17% vs. 14%), but thanks to our big sample size we could be pretty confident that this was a meaningful difference (p = 0.004). There was no different between autists an","wordCount":2589,"version":"1.0.0"},"Tag:W9aNkPwtPhMrcfgj7":{"_id":"W9aNkPwtPhMrcfgj7","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"mPipmBTniuABY5PQy","name":"Sex & Gender","shortName":null,"slug":"sex-and-gender","core":false,"postCount":90,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-09T05:46:26.441Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:P2nYKqwmHdYKARTG8":{"_id":"P2nYKqwmHdYKARTG8","__typename":"SocialPreviewType","imageUrl":""},"Post:P2nYKqwmHdYKARTG8":{"_id":"P2nYKqwmHdYKARTG8","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f09"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":10,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:W9aNkPwtPhMrcfgj7"}],"socialPreviewData":{"__ref":"SocialPreviewType:P2nYKqwmHdYKARTG8"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-06-28T19:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"W9aNkPwtPhMrcfgj7":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f09","commentCount":4,"voteCount":18,"baseScore":23,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":18,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00006900000153109431,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2019-04-06T23:07:16.203Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"why-are-transgender-people-immune-to-optical-illusions","title":"Why Are Transgender People Immune To Optical Illusions?","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:dRTatDhSy6kToJ2gs":{"_id":"dRTatDhSy6kToJ2gs","__typename":"Chapter","createdAt":"2017-09-05T02:20:10.614Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:dRTatDhSy6kToJ2gs_contents"},"number":0,"sequenceId":"k5MPpr72eiGknaS7F","postIds":["xPJKZyPCvap4Fven8","KrEwDMN4YXp5YWD45","P2nYKqwmHdYKARTG8"],"posts":[{"__ref":"Post:xPJKZyPCvap4Fven8"},{"__ref":"Post:KrEwDMN4YXp5YWD45"},{"__ref":"Post:P2nYKqwmHdYKARTG8"}]},"Revision:5c6392babcb4ac6367c165a1":{"_id":"5c6392babcb4ac6367c165a1","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Content warning: panic, suffocation]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>I recently presented this case at a conference and I figured you guys might want to hear it too. Various details have been obfuscated or changed around to protect confidentiality of the people involved.<\/p><p>A 20-something year old woman comes into the emergency room complaining that she can&#8217;t breathe. The emergency doctors note that she&#8217;s breathing perfectly normally. She says okay, fine, she&#8217;s breathing normally <i>now<\/i>, but she&#8217;s certain she&#8217;s about to suffocate. She&#8217;s having constant panic attacks, gasping for breath, feels like she can&#8217;t get any air into her lungs, been awake 96 hours straight because she&#8217;s afraid she&#8217;ll stop breathing in her sleep. She accepts voluntary admission to the psychiatric unit with a diagnosis of panic disorder.<\/p><p>We take a full history in the psych ward and there&#8217;s not much of interest. She&#8217;s never had any psychiatric conditions in the past. She&#8217;s never used any psychiatric medication. She&#8217;s never had any serious diseases. One month ago, she gave birth to a healthy baby girl, and she&#8217;s been very busy with all the new baby-related issues, but she doesn&#8217;t think it&#8217;s stressed her out unreasonably much.<\/p><p>We start her on an SSRI with (as usual) little immediate effect. On the ward, she continues to have panic attacks, which look like her gasping for breath and being utterly convinced that she is about to die; these last from a few minutes to a few hours. In between these she&#8217;s reasonable and cooperative but still very worried about her breathing. There are no other psychiatric symptoms. She isn&#8217;t delusional &#8211; when we tell her that our tests show her breathing is fine, she&#8217;s willing to admit we&#8217;re probably right &#8211; she just <i>feels<\/i> on a gut level like she can&#8217;t breathe. I&#8217;m still not really sure what&#8217;s going on.<\/p><p>So at this point, I do what any good psychiatrist would: I Google &#8220;how do you treat a patient who thinks she&#8217;s suffocating?&#8221; And I stumble onto one of the first convincing explanations I&#8217;ve ever seen of the pathophysiology of a psychiatric disorder.<\/p><p><b>II.<\/b><\/p><p>Panic disorder is a DSM-approved psychiatric condition affecting about 3% of the population. It&#8217;s marked by &#8220;panic attacks&#8221;, short (minutes to hours) episodes where p... <\/p>","plaintextDescription":"[Content warning: panic, suffocation]\n\nI.\n\nI recently presented this case at a conference and I figured you guys might want to hear it too. Various details have been obfuscated or changed around to protect confidentiality of the people involved.\n\nA 20-something year old woman comes into the emergency room complaining that she can’t breathe. The emergency doctors note that she’s breathing perfectly normally. She says okay, fine, she’s breathing normally now, but she’s certain she’s about to suffocate. She’s having constant panic attacks, gasping for breath, feels like she can’t get any air into her lungs, been awake 96 hours straight because she’s afraid she’ll stop breathing in her sleep. She accepts voluntary admission to the psychiatric unit with a diagnosis of panic disorder.\n\nWe take a full history in the psych ward and there’s not much of interest. She’s never had any psychiatric conditions in the past. She’s never used any psychiatric medication. She’s never had any serious diseases. One month ago, she gave birth to a healthy baby girl, and she’s been very busy with all the new baby-related issues, but she doesn’t think it’s stressed her out unreasonably much.\n\nWe start her on an SSRI with (as usual) little immediate effect. On the ward, she continues to have panic attacks, which look like her gasping for breath and being utterly convinced that she is about to die; these last from a few minutes to a few hours. In between these she’s reasonable and cooperative but still very worried about her breathing. There are no other psychiatric symptoms. She isn’t delusional – when we tell her that our tests show her breathing is fine, she’s willing to admit we’re probably right – she just feels on a gut level like she can’t breathe. I’m still not really sure what’s going on.\n\nSo at this point, I do what any good psychiatrist would: I Google “how do you treat a patient who thinks she’s suffocating?” And I stumble onto one of the first convincing explanations I’ve ever see","wordCount":3116,"version":"1.0.0"},"SocialPreviewType:HTGCGASf9xfB6edAh":{"_id":"HTGCGASf9xfB6edAh","__typename":"SocialPreviewType","imageUrl":""},"Post:HTGCGASf9xfB6edAh":{"_id":"HTGCGASf9xfB6edAh","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392babcb4ac6367c165a1"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":12,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:HTGCGASf9xfB6edAh"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-09-02T19:42:31.833Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392babcb4ac6367c165a1","commentCount":1,"voteCount":17,"baseScore":17,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":17,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.000052999999752501026,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-05T16:42:36.600Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":3,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-case-of-the-suffocating-woman","title":"The Case Of The Suffocating Woman","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:P8fxtnmE67LnaJry5":{"_id":"P8fxtnmE67LnaJry5","__typename":"Chapter","createdAt":"2017-09-05T03:04:48.542Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"k5MPpr72eiGknaS7F","postIds":["HTGCGASf9xfB6edAh"],"posts":[{"__ref":"Post:HTGCGASf9xfB6edAh"}]},"Revision:k5MPpr72eiGknaS7F_contents":{"_id":"k5MPpr72eiGknaS7F_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-09-05T02:19:15.940Z","userId":"XgYW5s8njaYrtyP7q","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Sequence:k5MPpr72eiGknaS7F":{"_id":"k5MPpr72eiGknaS7F","__typename":"Sequence","chapters":[{"__ref":"Chapter:dRTatDhSy6kToJ2gs"},{"__ref":"Chapter:P8fxtnmE67LnaJry5"}],"createdAt":"2017-09-05T02:19:15.940Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:k5MPpr72eiGknaS7F_contents"},"gridImageId":"sequencesgrid/byzxi4zdrlvodk0ph46r","bannerImageId":"sequences/ysr4l3sqb6vfszn49p1u","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Hypotheses and Hunches","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Book:YhQ39PPHNrRCgYXcs":{"_id":"YhQ39PPHNrRCgYXcs","__typename":"Book","createdAt":"2017-09-02T07:29:47.314Z","title":"The Institution of Science","number":2,"subtitle":null,"tocTitle":null,"contents":null,"sequenceIds":["BQBqPowfxjvoee8jw","B384FrQNrxSq4hZoS","k5MPpr72eiGknaS7F"],"sequences":[{"__ref":"Sequence:BQBqPowfxjvoee8jw"},{"__ref":"Sequence:B384FrQNrxSq4hZoS"},{"__ref":"Sequence:k5MPpr72eiGknaS7F"}],"postIds":[],"posts":[],"collectionId":"2izXHCrmJ684AnZ5X","displaySequencesAsGrid":null,"hideProgressBar":null,"showChapters":null},"Revision:fE48ZoheQmewNHeWi_contents":{"_id":"fE48ZoheQmewNHeWi_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-22T21:15:37.601Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:sQbbJKpq9tnKmKe4n":{"_id":"sQbbJKpq9tnKmKe4n","__typename":"Revision","htmlHighlight":"<p><i>[Content warning: Politics, religion, social justice, spoilers for “The Secret of Father Brown”. This isn’t especially original to me and I don’t claim anything more than to be explaining and rewording things I have heard from a bunch of other people. Unapologetically America-centric because I’m not informed enough to make it otherwise. Try to keep this off Reddit and other similar sorts of things.]<\/i><\/p><p><strong>I.<\/strong><\/p><p>In Chesterton’s <a href=\"https://www.amazon.com/Secret-Father-Brown-ebook/dp/B003XYE7YU/ref=as_li_ss_tl?_encoding=UTF8&amp;redirect=true&amp;ref_=as_li_tl&amp;linkCode=ll1&amp;tag=slatestarcode-20&amp;linkId=80cee7fc381622e3e77edf8f12fdb13d\"><i>The Secret of Father Brown<\/i><\/a><\/p><figure class=\"image\"><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&amp;l=as2&amp;o=1&amp;a=B003XYE7YU\"><\/figure><p>, a beloved nobleman who murdered his good-for-nothing brother in a duel thirty years ago returns to his hometown wracked by guilt. All the townspeople want to forgive him immediately, and they mock the titular priest for only being willing to give a measured forgiveness conditional on penance and self-reflection. They lecture the priest on the virtues of charity and compassion.<\/p><p>Later, it comes out that the beloved nobleman did <i>not<\/i> in fact kill his good-for-nothing brother. The good-for-nothing brother killed the beloved nobleman (and stole his identity). <i>Now<\/i> the townspeople want to see him lynched or burned alive, and it is only the priest who – consistently – offers a measured forgiveness conditional on penance and self-reflection.<\/p><p>The priest tells them:<\/p><blockquote><p>It seems to me that you only pardon the sins that you don’t really think sinful. You only forgive criminals when they commit what you don’t regard as crimes, but rather as conventions. You forgive a conventional duel just as you forgive a conventional divorce. You forgive because there isn’t anything to be forgiven.<\/p><\/blockquote><p>He further notes that this is why the townspeople can self-righteously consider themselves more compassionate and forgiving than he is. Actual forgiveness, the kind the priest needs to cultivate to forgive evildoers, is really really hard. The fake forgiveness the townspeople use to forgive the people they like is really easy, so they get to boast not only of their forgiving nature, but of how much nicer they are than those mean old priests who find forgiveness difficult and want penance along with it.<\/p><p>After some thought I agree with Chesterton’s point. There are a lot of people who say “I forgive you” when they mean “No harm done”, and a lot of people who say “That was unforgiveable” when they mean “That was genuinely really bad”. Whether or not forgiveness is <i>right<\/i> is a complicated topic I do not want to get in here. But since forgiveness is generally consider... <\/p>","plaintextDescription":"[Content warning: Politics, religion, social justice, spoilers for “The Secret of Father Brown”. This isn’t especially original to me and I don’t claim anything more than to be explaining and rewording things I have heard from a bunch of other people. Unapologetically America-centric because I’m not informed enough to make it otherwise. Try to keep this off Reddit and other similar sorts of things.]\n\nI.\n\nIn Chesterton’s The Secret of Father Brown\n\n, a beloved nobleman who murdered his good-for-nothing brother in a duel thirty years ago returns to his hometown wracked by guilt. All the townspeople want to forgive him immediately, and they mock the titular priest for only being willing to give a measured forgiveness conditional on penance and self-reflection. They lecture the priest on the virtues of charity and compassion.\n\nLater, it comes out that the beloved nobleman did not in fact kill his good-for-nothing brother. The good-for-nothing brother killed the beloved nobleman (and stole his identity). Now the townspeople want to see him lynched or burned alive, and it is only the priest who – consistently – offers a measured forgiveness conditional on penance and self-reflection.\n\nThe priest tells them:\n\n> It seems to me that you only pardon the sins that you don’t really think sinful. You only forgive criminals when they commit what you don’t regard as crimes, but rather as conventions. You forgive a conventional duel just as you forgive a conventional divorce. You forgive because there isn’t anything to be forgiven.\n\nHe further notes that this is why the townspeople can self-righteously consider themselves more compassionate and forgiving than he is. Actual forgiveness, the kind the priest needs to cultivate to forgive evildoers, is really really hard. The fake forgiveness the townspeople use to forgive the people they like is really easy, so they get to boast not only of their forgiving nature, but of how much nicer they are than those mean old priests who find for","wordCount":8451,"version":"1.2.0"},"Revision:GLMFmFvXGyAcG25ni_customHighlight":{"_id":"GLMFmFvXGyAcG25ni_customHighlight","__typename":"Revision","html":"<p>In Chesterton’s <a href=\"https://www.amazon.com/Secret-Father-Brown-ebook/dp/B003XYE7YU/ref=as_li_ss_tl?_encoding=UTF8&amp;redirect=true&amp;ref_=as_li_tl&amp;linkCode=ll1&amp;tag=slatestarcode-20&amp;linkId=80cee7fc381622e3e77edf8f12fdb13d\"><i>The Secret of Father Brown<\/i><\/a>, a beloved nobleman who murdered his good-for-nothing brother in a duel thirty years ago returns to his hometown wracked by guilt. All the townspeople want to forgive him immediately, and they mock the titular priest for only being willing to give a measured forgiveness conditional on penance and self-reflection. They lecture the priest on the virtues of charity and compassion.<\/p><p>Later, it comes out that the beloved nobleman did <i>not<\/i> in fact kill his good-for-nothing brother. The good-for-nothing brother killed the beloved nobleman (and stole his identity). <i>Now<\/i> the townspeople want to see him lynched or burned alive, and it is only the priest who – consistently – offers a measured forgiveness conditional on penance and self-reflection.<\/p>","plaintextDescription":"In Chesterton’s The Secret of Father Brown, a beloved nobleman who murdered his good-for-nothing brother in a duel thirty years ago returns to his hometown wracked by guilt. All the townspeople want to forgive him immediately, and they mock the titular priest for only being willing to give a measured forgiveness conditional on penance and self-reflection. They lecture the priest on the virtues of charity and compassion.\n\nLater, it comes out that the beloved nobleman did not in fact kill his good-for-nothing brother. The good-for-nothing brother killed the beloved nobleman (and stole his identity). Now the townspeople want to see him lynched or burned alive, and it is only the priest who – consistently – offers a measured forgiveness conditional on penance and self-reflection."},"Tag:FkzScn5byCs9PxGsA":{"_id":"FkzScn5byCs9PxGsA","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"6cdBbjJCA9L49Ekoh","name":"Politics","shortName":null,"slug":"politics","core":false,"postCount":499,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-25T23:51:55.084Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:GLMFmFvXGyAcG25ni":{"_id":"GLMFmFvXGyAcG25ni","__typename":"SocialPreviewType","imageUrl":"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&l=as2&o=1&a=B003XYE7YU"},"Post:GLMFmFvXGyAcG25ni":{"_id":"GLMFmFvXGyAcG25ni","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:sQbbJKpq9tnKmKe4n"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":34,"rejectedReason":null,"customHighlight":{"__ref":"Revision:GLMFmFvXGyAcG25ni_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:FkzScn5byCs9PxGsA"},{"__ref":"Tag:DdgSyQoZXjj3KnF4N"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:GLMFmFvXGyAcG25ni"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-09-02T08:22:19.612Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2022-12-12T18:53:37.320Z","meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"DdgSyQoZXjj3KnF4N":4,"FkzScn5byCs9PxGsA":10,"gHCNhqxuJq2bZ2akb":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"sQbbJKpq9tnKmKe4n","commentCount":4,"voteCount":72,"baseScore":96,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":72,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0003254122275393456,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-02-15T09:53:23.465Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":8,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":10,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"i-can-tolerate-anything-except-the-outgroup","title":"I Can Tolerate Anything Except The Outgroup","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16c3b":{"_id":"5c6392c7bcb4ac6367c16c3b","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p><A HREF=\"https://www.amazon.com/Albions-Seed-British-Folkways-cultural/dp/0195069056/ref=as_li_ss_tl?s=books&#038;ie=UTF8&#038;qid=1487533337&#038;sr=1-1&#038;keywords=albion's+seed&#038;linkCode=ll1&#038;tag=slatestarcode-20&#038;linkId=9cb7e7ccd8e93a105159e71c2c6522a8\"><i>Albion&#8217;s Seed<\/i><\/A> by David Fischer is a history professor&#8217;s nine-hundred-page treatise on patterns of early immigration to the Eastern United States. It&#8217;s not light reading and not the sort of thing I would normally pick up. I read it anyway on the advice of people who kept telling me it explains everything about America. And it sort of does.<\/p><p>In school, we tend to think of the original American colonists as &#8220;Englishmen&#8221;, a maximally non-diverse group who form the background for all of the diversity and ethnic conflict to come later. Fischer&#8217;s thesis is the opposite. Different parts of the country were settled by very different groups of Englishmen with different regional backgrounds, religions, social classes, and philosophies. The colonization process essentially extracted a single stratum of English society, isolated it from all the others, and then plunked it down on its own somewhere in the Eastern US.<\/p><p>I used to play <i>Alpha Centauri<\/i>, a computer game about the colonization of its namesake star system. One of the dynamics that made it so interesting was its backstory, where a Puerto Rican survivalist, an African plutocrat, and other colorful characters organized their own colonial expeditions and competed to seize territory and resources. You got to explore not only the settlement of a new world, but the settlement of a new world by societies dominated by extreme founder effects. What kind of weird pathologies and wonderful innovations do you get when a group of overly romantic Scottish environmentalists is allowed to develop on its own trajectory free of all non-overly-romantic-Scottish-environmentalist influences? <i>Albion&#8217;s Seed<\/i> argues that this is basically the process that formed several early US states.<\/p><p>Fischer describes four of these migrations: the Puritans to New England in the 1620s, the Cavaliers to Virginia in the 1640s, the Quakers to Pennsylvania in the 1670s, and the Borderers to Appalachia in the 1700s.<\/p><p><b>II.<\/b><\/p><p><b>A<A HREF=\"http://civilization.wikia.com/wiki/Human_Hive_%28SMAC%29\">:<\/A> The Puritans<\/b><\/p><p>I hear about these people every Thanksgiving, then never think about them again for the next 364 days. They were a Calvinist sect that dissented against the Church of England and followed their own brand of dour, industrious, fun-hating Christianity. Most of them were from East Anglia, the part of England just northeast of London. They came to America partly because they felt persecuted, but... <\/p>","plaintextDescription":"I.\n\nAlbion’s Seed by David Fischer is a history professor’s nine-hundred-page treatise on patterns of early immigration to the Eastern United States. It’s not light reading and not the sort of thing I would normally pick up. I read it anyway on the advice of people who kept telling me it explains everything about America. And it sort of does.\n\nIn school, we tend to think of the original American colonists as “Englishmen”, a maximally non-diverse group who form the background for all of the diversity and ethnic conflict to come later. Fischer’s thesis is the opposite. Different parts of the country were settled by very different groups of Englishmen with different regional backgrounds, religions, social classes, and philosophies. The colonization process essentially extracted a single stratum of English society, isolated it from all the others, and then plunked it down on its own somewhere in the Eastern US.\n\nI used to play Alpha Centauri, a computer game about the colonization of its namesake star system. One of the dynamics that made it so interesting was its backstory, where a Puerto Rican survivalist, an African plutocrat, and other colorful characters organized their own colonial expeditions and competed to seize territory and resources. You got to explore not only the settlement of a new world, but the settlement of a new world by societies dominated by extreme founder effects. What kind of weird pathologies and wonderful innovations do you get when a group of overly romantic Scottish environmentalists is allowed to develop on its own trajectory free of all non-overly-romantic-Scottish-environmentalist influences? Albion’s Seed argues that this is basically the process that formed several early US states.\n\nFischer describes four of these migrations: the Puritans to New England in the 1620s, the Cavaliers to Virginia in the 1640s, the Quakers to Pennsylvania in the 1670s, and the Borderers to Appalachia in the 1700s.\n\nII.\n\nA: The Puritans\n\nI hear about these peo","wordCount":9593,"version":"1.0.0"},"Revision:4Kcm4etxAJjmeDkHP_description":{"_id":"4Kcm4etxAJjmeDkHP_description","__typename":"Revision","htmlHighlight":"<p><strong>Book Reviews <\/strong>(or media reviews) on LessWrong are different from normal book reviews; they summarize and respond to a book's core ideas first, and judge whether you should read it second. A good book review sometimes distills the book's ideas so well that you no longer need to read the book.<\/p><p>Reviews engage with the perspective of the author, someone who has put in the effort to record their understanding of the world. Some of the best essays on LessWrong are reviews that teach us about <a href=\"https://www.lesswrong.com/tag/history\">history<\/a>, <a href=\"https://www.lesswrong.com/tag/replication-crisis\">psychology<\/a>, <a href=\"https://www.lesswrong.com/tag/biology\">biology<\/a>, or some other area where the author has developed a detailed understanding of a phenomena that few others have ever reached, and the essay writer engages with that perspective from our rationalist perspective.<\/p><p>Good book reviews embody the virtues of <a href=\"https://www.lesswrong.com/tag/scholarship-and-learning\"><u>scholarship<\/u><\/a>, <a href=\"https://www.lesswrong.com/tag/curiosity\">curiosity<\/a> and perspective-taking.<\/p><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/epistemic-review\">Epistemic Review<\/a>, <a href=\"https://www.lesswrong.com/tag/summaries\">Summaries<\/a>, <a href=\"https://www.lesswrong.com/tag/literature-reviews\">Literature Reviews<\/a>, <a href=\"https://www.lesswrong.com/tag/lesswrong-review\">LessWrong Review<\/a><\/p>"},"Tag:4Kcm4etxAJjmeDkHP":{"_id":"4Kcm4etxAJjmeDkHP","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:4Kcm4etxAJjmeDkHP_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Book Reviews / Media Reviews","shortName":null,"slug":"book-reviews-media-reviews","core":false,"postCount":385,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-13T04:57:42.173Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:bY5MaF2EATwDkomvu_description":{"_id":"bY5MaF2EATwDkomvu_description","__typename":"Revision","htmlHighlight":"<p><strong>History<\/strong>: \"Why should I remember the Wright Brothers’ first flight? I was not there. But as a rationalist, could I dare to not remember, when the event actually happened? Is there so much difference between seeing an event through your eyes—which is actually a causal chain involving reflected photons, not a direct connection—and seeing an event through a history book? Photons and history books both descend by causal chains from the event itself.\" - Eliezer Yudkowsky, <a href=\"https://www.lesswrong.com/posts/TLKPj4GDXetZuPDH5/making-history-available\"><i>Making History Available<\/i><\/a>.<\/p><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/history-of-rationality\">History of Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/history-of-less-wrong\">History of Less Wrong<\/a><\/p>"},"Tag:bY5MaF2EATwDkomvu":{"_id":"bY5MaF2EATwDkomvu","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:bY5MaF2EATwDkomvu_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"History","shortName":null,"slug":"history","core":false,"postCount":245,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-26T00:42:17.591Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:Y345zuBetHqGnotwm":{"_id":"Y345zuBetHqGnotwm","__typename":"SocialPreviewType","imageUrl":""},"Post:Y345zuBetHqGnotwm":{"_id":"Y345zuBetHqGnotwm","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16c3b"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":38,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:4Kcm4etxAJjmeDkHP"},{"__ref":"Tag:bY5MaF2EATwDkomvu"}],"socialPreviewData":{"__ref":"SocialPreviewType:Y345zuBetHqGnotwm"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-04-27T08:40:44.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"4Kcm4etxAJjmeDkHP":7,"bY5MaF2EATwDkomvu":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16c3b","commentCount":1,"voteCount":24,"baseScore":34,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00008695725409779698,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2019-02-07T01:01:53.689Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"book-review-albion-s-seed","title":"Book Review: Albion’s Seed","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e0d":{"_id":"5c6392dcbcb4ac6367c16e0d","__typename":"Revision","htmlHighlight":"<p>Last year <A HREF=\"http://slatestarcodex.com/2016/04/27/book-review-albions-seed/\">I reviewed <i>Albion&#8217;s Seed<\/i><\/A>, historian David Fischer&#8217;s work on the four great English migrations to America (and JayMan continues the story in his series on <A HREF=\"https://jaymans.wordpress.com/american-nations-series/\">American Nations<\/A>). These early migrations help explain modern regional patterns like why Massachusetts is so liberal or why Appalachia seems so backwards. As always, there&#8217;s the lingering question of how much of these patterns are cultural versus genetic versus gene-cultural interaction.<\/p><p>Now Han et al take this field high-tech with the publication of <A HREF=\"http://www.nature.com/articles/ncomms14238/\">Clustering Of 770,000 Genomes Reveals Post-Colonial Population Structure Of North America<\/A> (h/t gwern, werttrew)<\/p><p>The team looked at 770,000 genomes analyzed by the AncestryDNA company and used a technique called identity-by-descent to find recent common ancestors. Then they used some other techniques to divide them into natural clusters. This is what they got:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/albion_gene.jpg\"><\/p><p><i>This is the European-settler-focused map &#8211; there&#8217;s another one focusing on immigrant groups lower down <A HREF=\"http://www.nature.com/articles/ncomms14238/figures/3\">here<\/A><\/i><\/center><\/p><p>This is kind of beautiful. While not exactly matching <i>Albion&#8217;s Seed<\/i>, it at least clearly shows its New Englander and Pennsylvania Quaker migrations (more realistically the Germans who came along with the Quakers), with less distinct signals for Borderers and Virginians. It shows how they spread directly west from their place of origin in almost exactly the way <i>American Nations<\/i> predicted. It even confirms my own conjecture that the belt of Democrat voters along southern Michigan corresponds to an area of New Englander settlement there (see part III <A HREF=\"http://slatestarcodex.com/2016/04/27/book-review-albions-seed/\">here<\/A>, or search &#8220;linear distribution of blue&#8221;). And it confirms Razib Khan&#8217;s observation that <A HREF=\"http://www.unz.com/gnxp/mormons-among-the-gentiles/\">the Mormons are just displaced New Englanders<\/A> and that their various unusual demographic features make sense in that context.<\/p><p>My biggest confusion is in the Southern/Appalachian region. I think Fischer would have predicted two distinct strains: a Tidewater/Virginian population along the coasts, and a Borderer/Appalachian population centered in West Virginia and Kentucky. Instead there are three populations, all of which start along the Atlantic Coast and continue inland in about the same way. Assuming red/&#8221;Appalachian&#8221; is the Borderers, I don&#8217;t know if Fischer has a good explanation for the purple/&#8221;upland south&#8221; vs. gold/&#8221;lower south&#8221; distinction. Nor I do get under... <\/p>","plaintextDescription":"Last year I reviewed Albion’s Seed, historian David Fischer’s work on the four great English migrations to America (and JayMan continues the story in his series on American Nations). These early migrations help explain modern regional patterns like why Massachusetts is so liberal or why Appalachia seems so backwards. As always, there’s the lingering question of how much of these patterns are cultural versus genetic versus gene-cultural interaction.\n\nNow Han et al take this field high-tech with the publication of Clustering Of 770,000 Genomes Reveals Post-Colonial Population Structure Of North America (h/t gwern, werttrew)\n\nThe team looked at 770,000 genomes analyzed by the AncestryDNA company and used a technique called identity-by-descent to find recent common ancestors. Then they used some other techniques to divide them into natural clusters. This is what they got:\n\n\n\nThis is the European-settler-focused map – there’s another one focusing on immigrant groups lower down here\n\nThis is kind of beautiful. While not exactly matching Albion’s Seed, it at least clearly shows its New Englander and Pennsylvania Quaker migrations (more realistically the Germans who came along with the Quakers), with less distinct signals for Borderers and Virginians. It shows how they spread directly west from their place of origin in almost exactly the way American Nations predicted. It even confirms my own conjecture that the belt of Democrat voters along southern Michigan corresponds to an area of New Englander settlement there (see part III here, or search “linear distribution of blue”). And it confirms Razib Khan’s observation that the Mormons are just displaced New Englanders and that their various unusual demographic features make sense in that context.\n\nMy biggest confusion is in the Southern/Appalachian region. I think Fischer would have predicted two distinct strains: a Tidewater/Virginian population along the coasts, and a Borderer/Appalachian population centered in West Virgini","wordCount":543,"version":"1.0.0"},"SocialPreviewType:BpYDqQNZ2NZNCqPp6":{"_id":"BpYDqQNZ2NZNCqPp6","__typename":"SocialPreviewType","imageUrl":""},"Post:BpYDqQNZ2NZNCqPp6":{"_id":"BpYDqQNZ2NZNCqPp6","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e0d"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":2,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:e9wHzopbGCAFwp9Rw"}],"socialPreviewData":{"__ref":"SocialPreviewType:BpYDqQNZ2NZNCqPp6"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-02-09T02:15:03.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"e9wHzopbGCAFwp9Rw":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e0d","commentCount":0,"voteCount":11,"baseScore":17,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.000049874674004968256,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"albion-s-seed-genotyped","title":"Albion’s Seed, Genotyped","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16eab":{"_id":"5c6392dcbcb4ac6367c16eab","__typename":"Revision","htmlHighlight":"<p>Today during an otherwise terrible lecture on ADHD I realized something important we get sort of backwards.<\/p><p>There&#8217;s this stereotype that the Left believes that human characteristics are socially determined, and therefore mutable. And social problems are easy to fix, through things like education and social services and <A HREF=\"http://slatestarcodex.com/2013/12/22/public-awareness-campaigns/\">public awareness campaigns<\/A> and &#8220;calling people out&#8221;, and so we have a responsiblity to fix them, thus radically improving society and making life better for everyone.<\/p><p>But the Right (by now I guess the far right) believes human characteristics are <i>biologically<\/i> determined, and biology is fixed. Therefore we shouldn&#8217;t bother trying to improve things, and any attempt is just utopianism or &#8220;immanentizing the eschaton&#8221; or a shady justification for tyranny and busybodyness.<\/p><p>And I think I reject this whole premise.<\/p><p>See, my terrible lecture on ADHD suggested several reasons for the increasing prevalence of the disease. Of these I remember two: the spiritual desert of modern adolescence, and insufficient iron in the diet. And I remember thinking &#8220;Man, I hope it&#8217;s the iron one, because that seems a <i>lot<\/i> easier to fix.&#8221;<\/p><p>Society is <i>really hard to change<\/i>. We figured drug use was &#8220;just&#8221; a social problem, and it&#8217;s <i>obvious<\/i> how to solve social problems, so we gave kids nice little lessons in school about how you should Just Say No. There were advertisements in sports and video games about how Winners Don&#8217;t Do Drugs. And just in case that didn&#8217;t work, the cherry on the social engineering sundae was putting all the drug users in jail, where they would have a lot of time to think about what they&#8217;d done and be so moved by the prospect of further punishment that they would come clean.<\/p><p>And that is why, even to this day, nobody uses drugs.<\/p><p>On the other hand, biology is gratifyingly easy to change. Sometimes it&#8217;s just giving people more iron supplements. But the best example is lead. Banning lead was probably kind of controversial at the time, but in the end some refineries probably had to change their refining process and some gas stations had to put up &#8220;UNLEADED&#8221; signs and then we were done. And crime <A HREF=\"http://www3.amherst.edu/~jwreyes/papers/LeadCrimeNBERWP13097.pdf\">dropped<\/A> like fifty percent in a couple of decades &#8211; including many forms of drug abuse.<\/p><p>Saying &#8220;Tendency toward drug abuse is primarily determined by fixed bra... <\/p>","plaintextDescription":"Today during an otherwise terrible lecture on ADHD I realized something important we get sort of backwards.\n\nThere’s this stereotype that the Left believes that human characteristics are socially determined, and therefore mutable. And social problems are easy to fix, through things like education and social services and public awareness campaigns and “calling people out”, and so we have a responsiblity to fix them, thus radically improving society and making life better for everyone.\n\nBut the Right (by now I guess the far right) believes human characteristics are biologically determined, and biology is fixed. Therefore we shouldn’t bother trying to improve things, and any attempt is just utopianism or “immanentizing the eschaton” or a shady justification for tyranny and busybodyness.\n\nAnd I think I reject this whole premise.\n\nSee, my terrible lecture on ADHD suggested several reasons for the increasing prevalence of the disease. Of these I remember two: the spiritual desert of modern adolescence, and insufficient iron in the diet. And I remember thinking “Man, I hope it’s the iron one, because that seems a lot easier to fix.”\n\nSociety is really hard to change. We figured drug use was “just” a social problem, and it’s obvious how to solve social problems, so we gave kids nice little lessons in school about how you should Just Say No. There were advertisements in sports and video games about how Winners Don’t Do Drugs. And just in case that didn’t work, the cherry on the social engineering sundae was putting all the drug users in jail, where they would have a lot of time to think about what they’d done and be so moved by the prospect of further punishment that they would come clean.\n\nAnd that is why, even to this day, nobody uses drugs.\n\nOn the other hand, biology is gratifyingly easy to change. Sometimes it’s just giving people more iron supplements. But the best example is lead. Banning lead was probably kind of controversial at the time, but in the end some refiner","wordCount":849,"version":"1.0.0"},"Tag:jaf5zfcGgCB2REXGw":{"_id":"jaf5zfcGgCB2REXGw","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Biology","shortName":null,"slug":"biology","core":false,"postCount":211,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-11T02:08:39.903Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:2HafkDSNdtMzptzcN":{"_id":"2HafkDSNdtMzptzcN","__typename":"SocialPreviewType","imageUrl":""},"Post:2HafkDSNdtMzptzcN":{"_id":"2HafkDSNdtMzptzcN","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16eab"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":3,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:jaf5zfcGgCB2REXGw"},{"__ref":"Tag:AHK82ypfxF45rqh9D"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"}],"socialPreviewData":{"__ref":"SocialPreviewType:2HafkDSNdtMzptzcN"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-09-11T00:27:06.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"AHK82ypfxF45rqh9D":2,"gHCNhqxuJq2bZ2akb":2,"jaf5zfcGgCB2REXGw":7},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16eab","commentCount":1,"voteCount":34,"baseScore":45,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00009309227607445791,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2018-11-12T15:15:58.671Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"society-is-fixed-biology-is-mutable","title":"Society Is Fixed, Biology Is Mutable","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:fE48ZoheQmewNHeWi":{"_id":"fE48ZoheQmewNHeWi","__typename":"Chapter","createdAt":"2017-08-22T21:15:37.601Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:fE48ZoheQmewNHeWi_contents"},"number":0,"sequenceId":"rNuPrZvabXe2MaZv8","postIds":["GLMFmFvXGyAcG25ni","Y345zuBetHqGnotwm","BpYDqQNZ2NZNCqPp6","2HafkDSNdtMzptzcN"],"posts":[{"__ref":"Post:GLMFmFvXGyAcG25ni"},{"__ref":"Post:Y345zuBetHqGnotwm"},{"__ref":"Post:BpYDqQNZ2NZNCqPp6"},{"__ref":"Post:2HafkDSNdtMzptzcN"}]},"Revision:5c6392c7bcb4ac6367c16bfe":{"_id":"5c6392c7bcb4ac6367c16bfe","__typename":"Revision","htmlHighlight":"<p><i>I have been really enjoying <A HREF=\"http://literarystarbucks.com\">literarystarbucks.tumblr.com<\/A>, which publishes complicated jokes about what famous authors and fictional characters order at Starbucks. I like it so much I wish I knew more great literature, so I could get more of the jokes.<\/p><p>Since the creators seem to be restricting themselves to the literary world, I hope they won&#8217;t mind if I fail to resist the temptation to steal their technique for my own field of interest. Disclaimer: two of these are widely-known philosophy jokes and not original to me.<\/i><\/p><p><center> * * * <\/center><\/p><p>Parmenides goes up to the counter. “Same as always?” asks the barista. Parmenides nods.<\/p><p><center> * * * <\/center><\/p><p>Pythagoras goes up to the counter and orders a caffe Americano. “Mmmmm,” he says, tasting it. “How do you guys make such good coffee?” “It’s made from the freshest beans,” the barista answers. Pythagoras screams and runs out of the store.<\/p><p><center> * * * <\/center><\/p><p>Thales goes up to the counter, says he’s trying to break his caffeine habit, and orders a decaf. The barista hands it to him. He takes a sip and spits it out. “Yuck!” he says. “What is this, water?”<\/p><p><center> * * * <\/center><\/p><p>Gottfried Leibniz goes up to the counter and orders a muffin. The barista says he’s lucky since there is only one muffin left. Isaac Newton shoves his way up to the counter, saying Leibniz cut in line and he was first. Leibniz insists that he was first. The two of them come to blows.<\/p><p><center> * * * <\/center><\/p><p>Georg Wilhelm Friedrich Hegel goes up to the counter and gives a tremendously long custom order in German, specifying exactly how much of each sort of syrup he wants, various espresso shots, cream in exactly the right pattern, and a bunch of toppings, all added in a specific order at a specific temperature. The barista can’t follow him, so just gives up and hands him a small plain coffee. He walks away. The people behind him in line are very impressed with his apparent expertise, and they all order the same thing Hegel got. The barista gives each of them a small plain coffee, and they all remark on how delicious it tastes and what a remarkable coffee connoisseur that Hegel is. “The Hegel” becomes a new Starbucks special and is wildly popular for the next seventy years.<\/p><p><center> * * * <\/center><\/p><p>Socrates goes up to the counter. “What would you like?” asks the barista. “What would you recommend?” asks Socrates. “I would go with the pumpkin spice latte,” says the barista. “Why?” asks Socrates. “It’s seasonal,” she answers. “But why exact... <\/p>","plaintextDescription":"I have been really enjoying literarystarbucks.tumblr.com, which publishes complicated jokes about what famous authors and fictional characters order at Starbucks. I like it so much I wish I knew more great literature, so I could get more of the jokes.\n\nSince the creators seem to be restricting themselves to the literary world, I hope they won’t mind if I fail to resist the temptation to steal their technique for my own field of interest. Disclaimer: two of these are widely-known philosophy jokes and not original to me.\n\n* * *\n\nParmenides goes up to the counter. “Same as always?” asks the barista. Parmenides nods.\n\n* * *\n\nPythagoras goes up to the counter and orders a caffe Americano. “Mmmmm,” he says, tasting it. “How do you guys make such good coffee?” “It’s made from the freshest beans,” the barista answers. Pythagoras screams and runs out of the store.\n\n* * *\n\nThales goes up to the counter, says he’s trying to break his caffeine habit, and orders a decaf. The barista hands it to him. He takes a sip and spits it out. “Yuck!” he says. “What is this, water?”\n\n* * *\n\nGottfried Leibniz goes up to the counter and orders a muffin. The barista says he’s lucky since there is only one muffin left. Isaac Newton shoves his way up to the counter, saying Leibniz cut in line and he was first. Leibniz insists that he was first. The two of them come to blows.\n\n* * *\n\nGeorg Wilhelm Friedrich Hegel goes up to the counter and gives a tremendously long custom order in German, specifying exactly how much of each sort of syrup he wants, various espresso shots, cream in exactly the right pattern, and a bunch of toppings, all added in a specific order at a specific temperature. The barista can’t follow him, so just gives up and hands him a small plain coffee. He walks away. The people behind him in line are very impressed with his apparent expertise, and they all order the same thing Hegel got. The barista gives each of them a small plain coffee, and they all remark on how delicious it t","wordCount":1510,"version":"1.0.0"},"Revision:GLykb6NukBeBQtDvQ_description":{"_id":"GLykb6NukBeBQtDvQ_description","__typename":"Revision","htmlHighlight":"<p>(From Wikipedia,) <em>Philosophy<\/em> is the study of general and fundamental questions about existence, knowledge, values, reason, mind, and language.<\/p><p>This tag probably implies non-Less Wrong philosophy in particular. This could be mainstream or academic philosophy, Eastern philosophy, or something else<\/p>"},"Tag:GLykb6NukBeBQtDvQ":{"_id":"GLykb6NukBeBQtDvQ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:GLykb6NukBeBQtDvQ_description"},"canVoteOnRels":null,"userId":"SsduPgHwY2zeZpmKT","name":"Philosophy","shortName":null,"slug":"philosophy","core":false,"postCount":317,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-14T00:48:32.880Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:BPKvZuLRyiJBjfNbg":{"_id":"BPKvZuLRyiJBjfNbg","__typename":"SocialPreviewType","imageUrl":""},"Post:BPKvZuLRyiJBjfNbg":{"_id":"BPKvZuLRyiJBjfNbg","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16bfe"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:hNFdS3rRiYgqqD8aM"},{"__ref":"Tag:GLykb6NukBeBQtDvQ"}],"socialPreviewData":{"__ref":"SocialPreviewType:BPKvZuLRyiJBjfNbg"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-01-25T20:42:24.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"GLykb6NukBeBQtDvQ":1,"hNFdS3rRiYgqqD8aM":9},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16bfe","commentCount":4,"voteCount":50,"baseScore":56,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":50,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00012037844862788916,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-24T08:35:48.788Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"a-philosopher-walks-into-a-coffee-shop","title":"A Philosopher Walks Into A Coffee Shop","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16caf":{"_id":"5c6392c7bcb4ac6367c16caf","__typename":"Revision","htmlHighlight":"<p>On an ordinary evening, Tal Aivon was lively and pleasant. The collection of longhouses and yurts within its tall brick walls shone bright with kerosene &#8211; not just torches, real kerosene &#8211; and its communal meeting area was noisy with conversation and song. The children would be playing their games, and on the eves of holy days the Lorekeepers would chant their stories of the Lost World, accompanied by lyres and the town&#8217;s one decaying gyitar.<\/p><p>Tonight, though, a pall lay on Tal Aivon. The six gates of its tall brick walls were barred and shut, and foreboding warriors dressed in odd combinations of Kevlar and steel armor stood just within them, brandishing their swords. Families locked themselves in their yurts and longhouses, huddled around little kerosene lanterns. In the temple, the priests knelt before the stone idols of St. Christ and St. Mahomet, chanting plaintive prayers for protection.<\/p><p>&#8220;I still don&#8217;t understand,&#8221; Meical Dorn complained, from inside the longest longhouse &#8220;what this is all about. &#8220;None of the wildlings are anywhere nearby &#8211; I should know, I&#8217;ve came through two hundred miles of forest to get here &#8211; and the only three towns in this area are at peace with you. In Great Rabda, even an impending attack couldn&#8217;t make us cower inside like this. I have half a mind to think there&#8217;s something you&#8217;re not telling me, Fin. Something that might&#8230;threaten our deal.&#8221;<\/p><p>Fin Lerisas, Chief Lorekeeper for Tal Aivon, sighed. &#8220;Nothing that would threaten our deal, Meical. Great Rabda has gold. We have sunblessings. Just stay here long enough for our bankers to figure out the price, and you&#8217;ll have timers and mathers and lighters of your very own.&#8221;<\/p><p>Meical glanced longingly at the Chief Lorekeeper&#8217;s own sunblessing, a timer that stood on the shelf of his private room. 1:52 AM gleamed on its face, with an maddeningly smooth red glow unlike sunlight or moonlight or firelight. Yet Meical knew it was sunlight, or something like. He was the Lorekeeper of Great Rabda. The Lorekeepers of Tal Aivon were far wiser than he &#8211; how could they not be with the town&#8217;s close proximity to ruined Diteroi and its trove of artifacts from the Lost World &#8211; but even he knew how sunblessings worked. You took them outside and the blue tiles on their surfac... <\/p>","plaintextDescription":"On an ordinary evening, Tal Aivon was lively and pleasant. The collection of longhouses and yurts within its tall brick walls shone bright with kerosene – not just torches, real kerosene – and its communal meeting area was noisy with conversation and song. The children would be playing their games, and on the eves of holy days the Lorekeepers would chant their stories of the Lost World, accompanied by lyres and the town’s one decaying gyitar.\n\nTonight, though, a pall lay on Tal Aivon. The six gates of its tall brick walls were barred and shut, and foreboding warriors dressed in odd combinations of Kevlar and steel armor stood just within them, brandishing their swords. Families locked themselves in their yurts and longhouses, huddled around little kerosene lanterns. In the temple, the priests knelt before the stone idols of St. Christ and St. Mahomet, chanting plaintive prayers for protection.\n\n“I still don’t understand,” Meical Dorn complained, from inside the longest longhouse “what this is all about. “None of the wildlings are anywhere nearby – I should know, I’ve came through two hundred miles of forest to get here – and the only three towns in this area are at peace with you. In Great Rabda, even an impending attack couldn’t make us cower inside like this. I have half a mind to think there’s something you’re not telling me, Fin. Something that might…threaten our deal.”\n\nFin Lerisas, Chief Lorekeeper for Tal Aivon, sighed. “Nothing that would threaten our deal, Meical. Great Rabda has gold. We have sunblessings. Just stay here long enough for our bankers to figure out the price, and you’ll have timers and mathers and lighters of your very own.”\n\nMeical glanced longingly at the Chief Lorekeeper’s own sunblessing, a timer that stood on the shelf of his private room. 1:52 AM gleamed on its face, with an maddeningly smooth red glow unlike sunlight or moonlight or firelight. Yet Meical knew it was sunlight, or something like. He was the Lorekeeper of Great Rabda. The","wordCount":1896,"version":"1.0.0"},"SocialPreviewType:8KHR3tfa4SJjMSkXd":{"_id":"8KHR3tfa4SJjMSkXd","__typename":"SocialPreviewType","imageUrl":""},"Post:8KHR3tfa4SJjMSkXd":{"_id":"8KHR3tfa4SJjMSkXd","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16caf"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:8KHR3tfa4SJjMSkXd"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2013-11-03T07:07:34.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16caf","commentCount":0,"voteCount":21,"baseScore":21,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00004086346598342061,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-witching-hour","title":"The Witching Hour","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:GdcuzLpXnafNpYm6b":{"_id":"GdcuzLpXnafNpYm6b","__typename":"Chapter","createdAt":"2017-09-02T19:32:40.852Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"rNuPrZvabXe2MaZv8","postIds":["BPKvZuLRyiJBjfNbg","8KHR3tfa4SJjMSkXd"],"posts":[{"__ref":"Post:BPKvZuLRyiJBjfNbg"},{"__ref":"Post:8KHR3tfa4SJjMSkXd"}]},"Revision:rNuPrZvabXe2MaZv8_contents":{"_id":"rNuPrZvabXe2MaZv8_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-22T21:15:37.325Z","userId":"XgYW5s8njaYrtyP7q","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Sequence:rNuPrZvabXe2MaZv8":{"_id":"rNuPrZvabXe2MaZv8","__typename":"Sequence","chapters":[{"__ref":"Chapter:fE48ZoheQmewNHeWi"},{"__ref":"Chapter:GdcuzLpXnafNpYm6b"}],"createdAt":"2017-08-22T21:15:37.325Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:rNuPrZvabXe2MaZv8_contents"},"gridImageId":"sequencesgrid/acfvxltz0mnyd7jqdq76","bannerImageId":"sequences/bhe8eug3szquha8hfbca","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":6,"readPostsCount":0,"title":"Politics and Pragmatics","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:5c6392c7bcb4ac6367c16c56":{"_id":"5c6392c7bcb4ac6367c16c56","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Imagine a little kingdom with a quaint custom: when a man likes a woman, he offers her a tulip; if she accepts, they are married shortly thereafter. A couple who marries sans tulip is considered to be living in sin; no other form of proposal is appropriate or accepted.<\/p><p>One day, a Dutch trader comes to the little kingdom. He explains that his homeland <i>also<\/i> has a quaint custom involving tulips: they <A HREF=\"http://en.wikipedia.org/wiki/Tulip_mania\">speculate on them, bidding the price up to stratospheric levels.<\/A> Why, in the Netherlands, a tulip can go for ten times more than the average worker earns in a year! The trader is pleased to find a new source of bulbs, and offers the people of the kingdom a few guilders per tulip, which they happily accept.<\/p><p>Soon other Dutch traders show up and start a bidding war. The price of tulips goes up, and up, and up; first dozens of guilders, then hundreds. Tulip-growers make a fortune, but everyone else is less pleased. Suitors wishing to give a token of their love find themselves having to invest their entire life savings &#8211; with no guarantee that the woman will even say yes! Soon, some of the poorest people are locked out of marriage and family-raising entirely.<\/p><p>Some of the members of Parliament are outraged. Marriage is, they say, a human right, and to see it forcibly denied the poor by foreign speculators is nothing less than an abomination. They demand that the King provide every man enough money to guarantee he can buy a tulip. Some objections are raised: won&#8217;t it deplete the Treasury? Are we obligated to buy everyone a beautiful flawless bulb, or just the sickliest, grungiest plant that will technically satisfy the requirements of the ritual? If some man continuously proposes to women who reject him, are we obligated to pay for a new bulb each time, subsidizing his stupidity?<\/p><p>The pro-subsidy faction declares that the people asking these question are well-off, and can probably afford tulips of their own, and so from their place of privilege they are trying to raise pointless objections to other people being able to obtain the connubial happiness they themselves enjoy. After the doubters are tarred and feathered and thrown in the river, Parliament votes that the public purse pay for as many tulips as the poor need, whatever the price.<\/p><p>A few years later, another Dutch trader comes to the little kingdom. Everyone asks if he is there to buy tulips, and he says no,... <\/p>","plaintextDescription":"I.\n\nImagine a little kingdom with a quaint custom: when a man likes a woman, he offers her a tulip; if she accepts, they are married shortly thereafter. A couple who marries sans tulip is considered to be living in sin; no other form of proposal is appropriate or accepted.\n\nOne day, a Dutch trader comes to the little kingdom. He explains that his homeland also has a quaint custom involving tulips: they speculate on them, bidding the price up to stratospheric levels. Why, in the Netherlands, a tulip can go for ten times more than the average worker earns in a year! The trader is pleased to find a new source of bulbs, and offers the people of the kingdom a few guilders per tulip, which they happily accept.\n\nSoon other Dutch traders show up and start a bidding war. The price of tulips goes up, and up, and up; first dozens of guilders, then hundreds. Tulip-growers make a fortune, but everyone else is less pleased. Suitors wishing to give a token of their love find themselves having to invest their entire life savings – with no guarantee that the woman will even say yes! Soon, some of the poorest people are locked out of marriage and family-raising entirely.\n\nSome of the members of Parliament are outraged. Marriage is, they say, a human right, and to see it forcibly denied the poor by foreign speculators is nothing less than an abomination. They demand that the King provide every man enough money to guarantee he can buy a tulip. Some objections are raised: won’t it deplete the Treasury? Are we obligated to buy everyone a beautiful flawless bulb, or just the sickliest, grungiest plant that will technically satisfy the requirements of the ritual? If some man continuously proposes to women who reject him, are we obligated to pay for a new bulb each time, subsidizing his stupidity?\n\nThe pro-subsidy faction declares that the people asking these question are well-off, and can probably afford tulips of their own, and so from their place of privilege they are trying to raise poi","wordCount":2325,"version":"1.0.0"},"Revision:PDJ6KqJBRzvKPfuS3_description":{"_id":"PDJ6KqJBRzvKPfuS3_description","__typename":"Revision","htmlHighlight":"<p><strong>Economics<\/strong> is the social science that studies how humans and other agents interact in a universe with scarce resources. It deals with topics such as trade, specialization of labor, accumulation of capital, technology, and resource consumption. Agents in economics are generally assumed to have utility functions, which they try to maximize under various constraints.<\/p><p>Economics is usually separated into microeconomics and macroeconomics. Microeconomics concerns the behavior of agents as they interact in a market. More narrowly, it studies the price mechanism, a decentralized system of allocating goods and services based on an evolving system of prices and trade, which all actors in a market economy contribute towards. The price mechanism is closely related to the concept of the <a href=\"https://en.wikipedia.org/wiki/Invisible_hand\">invisible hand<\/a>, first introduced by <a href=\"https://en.wikipedia.org/wiki/Adam_Smith\">Adam Smith<\/a>. <a href=\"https://www.lesswrong.com/tag/game-theory\">Game theory<\/a> is the mathematical study of rational agency, which formalizes many standard results in microeconomics.<\/p><p>Macroeconomics concerns the aggregate behavior of entire economies. For example, it studies economic growth, inflation, international trade and unemployment. An ongoing debate concerns to what extent the <a href=\"https://www.lesswrong.com/tag/economic-consequences-of-agi\">impacts of artificial intelligence<\/a> should be viewed through the lens of economics.<\/p>"},"Tag:PDJ6KqJBRzvKPfuS3":{"_id":"PDJ6KqJBRzvKPfuS3","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:PDJ6KqJBRzvKPfuS3_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Economics","shortName":null,"slug":"economics","core":false,"postCount":462,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T22:24:48.135Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:Fafzj3wMvoCW4WjeF":{"_id":"Fafzj3wMvoCW4WjeF","__typename":"SocialPreviewType","imageUrl":""},"Post:Fafzj3wMvoCW4WjeF":{"_id":"Fafzj3wMvoCW4WjeF","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16c56"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"}],"socialPreviewData":{"__ref":"SocialPreviewType:Fafzj3wMvoCW4WjeF"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-06-06T04:19:14.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"PDJ6KqJBRzvKPfuS3":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16c56","commentCount":5,"voteCount":51,"baseScore":56,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":51,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00012642104411497712,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-07-30T01:37:16.572Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2015-06-06T04:19:14.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"against-tulip-subsidies","title":"Against Tulip Subsidies","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:2JdMvMyuyjTj9hTqh":{"_id":"2JdMvMyuyjTj9hTqh","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Tyler Cowen <a href=\"https://www.bloomberg.com/view/articles/2017-01-18/this-economic-phenomenon-is-making-government-sick\">writes about cost disease<\/a>. I’d previously heard the term used to refer only to a specific theory of why costs are increasing, involving labor becoming more efficient in some areas than others. Cowen seems to use it indiscriminately to refer to increasing costs in general – which I guess is fine, goodness knows we need a word for that.<\/p><p>Cowen assumes his readers already understand that cost disease exists. I don’t know if this is true. My impression is that most people still don’t know about cost disease, or don’t realize the extent of it. So I thought I would make the case for the cost disease in the sectors Tyler mentions – health care and education – plus a couple more.<\/p><p><u>First<\/u> let’s look at primary education:<\/p><p><\/p><center><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/BBQ5HEnL3ShefQxEj/h2k39xtyggdidq2mfxll\"><\/center><p><\/p><p>There was some argument about the style of this graph, but <a href=\"http://www.politifact.com/virginia/statements/2015/mar/02/dave-brat/brat-us-school-spending-375-percent-over-30-years-/\">as per Politifact<\/a> the basic claim is true. Per student spending has increased about 2.5x in the past forty years even after adjusting for inflation.<\/p><p>At the same time, test scores have stayed relatively stagnant. You can see <a href=\"http://nationsreportcard.gov/ltt_2012/summary.aspx\">the full numbers here<\/a>, but in short, high school students’ reading scores went from 285 in 1971 to 287 today – a difference of 0.7%. <\/p><p>There is some heterogenity across races – white students’ test scores increased 1.4% and minority students’ scores by about 20%. But it is hard to credit school spending for the minority students’ improvement, which occurred almost entirely during the period from 1975-1985. School spending has been on exactly the same trajectory before and after that time, and in white and minority areas, suggesting that there was something specific about that decade which improved minority (but not white) scores. Most likely this was the general improvement in minorities’ conditions around that time, giving them better nutrition and a more stable family life. It’s hard to construct a narrative where it was school spending that did it – and even if it did, note that the majority of the increase in school spending happened from 1985 on, and demonstrably helped neither whites <i>nor<\/i> minorities.<\/p><p>I discuss this phenomenon more <a href=\"http://slatestarcodex.com/2016/12/02/contra-robinson-on-schooling/\">here<\/a> and <a href=\"http://slatestarcodex.com/2016/12/04/highlights-from-the-comment-thread-on-school-choice/\">here<\/a>, but the summary is: no, it’s not just because of special ed; no, it’s not just a factor of how you measure test scores; no, there’s not a “ceiling effect”. Costs really did more-or-less double without any concomitant increase in measurable quality.<\/p><p>So, imagine you’re a poor person. White, minority, whatever. Which would you... <\/p>","plaintextDescription":"I.\n\nTyler Cowen writes about cost disease. I’d previously heard the term used to refer only to a specific theory of why costs are increasing, involving labor becoming more efficient in some areas than others. Cowen seems to use it indiscriminately to refer to increasing costs in general – which I guess is fine, goodness knows we need a word for that.\n\nCowen assumes his readers already understand that cost disease exists. I don’t know if this is true. My impression is that most people still don’t know about cost disease, or don’t realize the extent of it. So I thought I would make the case for the cost disease in the sectors Tyler mentions – health care and education – plus a couple more.\n\nFirst let’s look at primary education:\n\n\n\n\n\nThere was some argument about the style of this graph, but as per Politifact the basic claim is true. Per student spending has increased about 2.5x in the past forty years even after adjusting for inflation.\n\nAt the same time, test scores have stayed relatively stagnant. You can see the full numbers here, but in short, high school students’ reading scores went from 285 in 1971 to 287 today – a difference of 0.7%.\n\nThere is some heterogenity across races – white students’ test scores increased 1.4% and minority students’ scores by about 20%. But it is hard to credit school spending for the minority students’ improvement, which occurred almost entirely during the period from 1975-1985. School spending has been on exactly the same trajectory before and after that time, and in white and minority areas, suggesting that there was something specific about that decade which improved minority (but not white) scores. Most likely this was the general improvement in minorities’ conditions around that time, giving them better nutrition and a more stable family life. It’s hard to construct a narrative where it was school spending that did it – and even if it did, note that the majority of the increase in school spending happened from 1985 on, and demon","wordCount":6496,"version":"1.0.1"},"Revision:8XiMxJaWbjNtWLsEj_description":{"_id":"8XiMxJaWbjNtWLsEj_description","__typename":"Revision","htmlHighlight":"<p><strong>Cost Disease<\/strong> or <strong>Baumol's cost disease <\/strong>is a name for the rise of salaries in jobs that have experienced no or low increase of labor productivity [<a href=\"https://en.wikipedia.org/wiki/Baumol%27s_cost_disease\">1<\/a>]. Some use the term generally to refer to rising costs in general [<a href=\"https://www.lesswrong.com/posts/BBQ5HEnL3ShefQxEj/considerations-on-cost-disease\">2<\/a>].<\/p><p>Often the questions being asked in Cost Disease discussion are why the cost healthcare and education have increased many, many times over.<\/p><p><strong>External Posts:<\/strong><br><a href=\"https://slatestarcodex.com/2019/06/10/book-review-the-prices-are-too-dmn-high/\">Book Review: Why Are The Prices So D*mn High? <\/a>- Scott Alexander<br>&nbsp;<\/p>"},"Tag:8XiMxJaWbjNtWLsEj":{"_id":"8XiMxJaWbjNtWLsEj","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:8XiMxJaWbjNtWLsEj_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Cost Disease","shortName":null,"slug":"cost-disease","core":false,"postCount":9,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-17T01:31:13.419Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:BBQ5HEnL3ShefQxEj":{"_id":"BBQ5HEnL3ShefQxEj","__typename":"SocialPreviewType","imageUrl":"http://slatestarcodex.com/blog_images/primary_scost.gif"},"Post:BBQ5HEnL3ShefQxEj":{"_id":"BBQ5HEnL3ShefQxEj","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:2JdMvMyuyjTj9hTqh"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":26,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:8XiMxJaWbjNtWLsEj"},{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:BBQ5HEnL3ShefQxEj"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-02-10T04:33:36.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":4,"8XiMxJaWbjNtWLsEj":11,"PDJ6KqJBRzvKPfuS3":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"2JdMvMyuyjTj9hTqh","commentCount":7,"voteCount":33,"baseScore":48,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":33,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00013499999477062374,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-06-05T19:22:41.596Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":5,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2017-02-10T04:33:36.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"considerations-on-cost-disease","title":"Considerations On Cost Disease","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e48":{"_id":"5c6392dcbcb4ac6367c16e48","__typename":"Revision","htmlHighlight":"<p>I got many good responses to my <A HREF=\"http://slatestarcodex.com/2017/02/09/considerations-on-cost-disease/\">Considerations On Cost Disease<\/A> post, both in the comments and elsewhere. A lot of people thought the explanation was obvious; unfortunately, they all disagreed on what the obvious explanation was. Below are some of the responses I found most interesting.<\/p><p><A HREF=\"http://johnhcochrane.blogspot.com/2017/02/economies-in-reverse.html?spref=tw&#038;m=1\"><b>John Cochrane<\/b><\/A>:<\/p>\n<blockquote><p>So, what is really happening? I think Scott nearly gets there. Things cost 10 times as much, 10 times more than they used to and 10 times more than in other countries. It&#8217;s not going to wages. It&#8217;s not going to profits. So where is it going?<\/p><p>The unavoidable answer: The number of people it takes to produce these goods is skyrocketing. Labor productivity &#8212; number of people per quality adjusted output &#8212; declined by a factor of 10 in these areas. It pretty much has to be that: if the money is not going to profits, to to each employee, it must be going to the number of employees.<\/p><p>How can that happen? Our machines are better than ever, as Scott points out. Well, we (and especially we economists) pay too much attention to snazzy gadgets. Productivity depends on organizations not just on gadgets. Southwest figured out how to turn an airplane around in 20 minutes, and it still takes United an hour.<\/p><p>Contrariwise, I think we know where the extra people are. The ratio of teachers to students hasn&#8217;t gone down a lot &#8212; but the ratio of administrators to students has shot up. Most large public school systems spend more than half their budget on administrators. Similarly, class sizes at most colleges and universities haven&#8217;t changed that much &#8212; but administrative staff have exploded. There are 2.5 people handling insurance claims for every doctor. Construction sites have always had a lot of people standing around for every one actually working the machine. But now for every person operating the machine there is an army of planners, regulators, lawyers, administrative staff, consultants and so on. (I welcome pointers to good graphs and numbers on this sort of thing.)<\/p><p>So, my bottom line: administrative bloat.<\/p><p>Well, how does bloat come about? Regulations and law are, as Scott mentions, part of the problem. These are all areas either run by the government or with large government involvement. But the real key is, I think lack of competition. These are above all areas with not much competition. In turn, however, they are not by a long shot &#<\/p><\/blockquote>... ","plaintextDescription":"I got many good responses to my Considerations On Cost Disease post, both in the comments and elsewhere. A lot of people thought the explanation was obvious; unfortunately, they all disagreed on what the obvious explanation was. Below are some of the responses I found most interesting.\n\nJohn Cochrane:\n\n> So, what is really happening? I think Scott nearly gets there. Things cost 10 times as much, 10 times more than they used to and 10 times more than in other countries. It’s not going to wages. It’s not going to profits. So where is it going?\n> \n> The unavoidable answer: The number of people it takes to produce these goods is skyrocketing. Labor productivity — number of people per quality adjusted output — declined by a factor of 10 in these areas. It pretty much has to be that: if the money is not going to profits, to to each employee, it must be going to the number of employees.\n> \n> How can that happen? Our machines are better than ever, as Scott points out. Well, we (and especially we economists) pay too much attention to snazzy gadgets. Productivity depends on organizations not just on gadgets. Southwest figured out how to turn an airplane around in 20 minutes, and it still takes United an hour.\n> \n> Contrariwise, I think we know where the extra people are. The ratio of teachers to students hasn’t gone down a lot — but the ratio of administrators to students has shot up. Most large public school systems spend more than half their budget on administrators. Similarly, class sizes at most colleges and universities haven’t changed that much — but administrative staff have exploded. There are 2.5 people handling insurance claims for every doctor. Construction sites have always had a lot of people standing around for every one actually working the machine. But now for every person operating the machine there is an army of planners, regulators, lawyers, administrative staff, consultants and so on. (I welcome pointers to good graphs and numbers on this sort of thing.)\n>","wordCount":7500,"version":"1.0.0"},"SocialPreviewType:ofL22R6KZsfrvdmwg":{"_id":"ofL22R6KZsfrvdmwg","__typename":"SocialPreviewType","imageUrl":""},"Post:ofL22R6KZsfrvdmwg":{"_id":"ofL22R6KZsfrvdmwg","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e48"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":30,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:8XiMxJaWbjNtWLsEj"},{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"}],"socialPreviewData":{"__ref":"SocialPreviewType:ofL22R6KZsfrvdmwg"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-02-17T07:28:52.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"8XiMxJaWbjNtWLsEj":11,"PDJ6KqJBRzvKPfuS3":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e48","commentCount":2,"voteCount":9,"baseScore":10,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":9,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00003099999958067201,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-02T16:03:04.870Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":2,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"highlights-from-the-comments-on-cost-disease","title":"Highlights From The Comments On Cost Disease","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e54":{"_id":"5c6392dcbcb4ac6367c16e54","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Epistemic status: Overly simplistic treatment of a horrifyingly complex topic; I can only hope I haven&#8217;t missed enough to completely embarrass myself]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>Noah Smith <A HREF=\"http://www.bloombergview.com/articles/2016-03-16/there-s-trade-and-then-there-s-good-trade\">reviews<\/A> recent economic research suggesting that globalization was a net harm to working class people in rich countries like the US; he tentatively suggests this could justify a weak form of protectionism. But Scott Sumner <A HREF=\"http://www.themoneyillusion.com/?p=31573\">argues<\/A> that&#8217;s the wrong way to look at things. Globalization fueled China&#8217;s transition from a poor agrarian economy to an industrialized modern nation. A billion people were lifted out of poverty, an accomplishment Sumner calls &#8220;the best thing that ever happened&#8221;. This is far more important than the less dramatic costs imposed on the US. Therefore, even if we agree globalization hurts the working class of rich nations, it&#8217;s still a morally defensible policy since it benefits the needier working classes of much poorer nations.<\/p><p>On the one hand, this makes sense. On the other, here&#8217;s happiness in China over the past fifteen years:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/chinese_happiness.jpg\"><\/center><\/p><p>Measuring happiness is really hard, but the Chinese result seems as robust as any. You get the same thing <A HREF=\"http://www.uschina.usc.edu/article@usct?when_qian_%E9%92%B1_doesn%E2%80%99t_buy_happiness_13029.aspx\">if you ask about satisfaction versus dissatisfaction<\/A>. Brookings analyzes five different series of happiness data and <A HREF=\"http://www.brookings.edu/blogs/future-development/posts/2015/06/16-happiness-china-graham\">concludes that<\/A> &#8220;the Chinese became less happy during their growth boom&#8221;. The <A HREF=\"http://www.nytimes.com/2012/09/28/opinion/in-china-growth-outpaces-happiness.html?_r=0\">New York Times<\/A> agrees and says that &#8220;Chinese people’s feelings of well-being have declined in [this] period of momentous improvement in their economic lives&#8221;. And this <A HREF=\"http://china.usc.edu/economic-growth-china-has-not-meant-greater-life-satisfaction-chinese-people\">seems to be worst<\/A> among <A HREF=\"http://conversableeconomist.blogspot.com/2012/05/china-does-8-growth-cause-less.html\">the poorest Chinese<\/A>:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/chinese_poorest.jpg\"><\/center><\/p><p>Nor does this seem to be an effect from our happiness research just not being good enough to capture changes in happiness even if they occur. There&#8217;s good evidence that increased income <I>within<\/I> a country increases happiness, and <A HREF=\"http://slatestarcodex.com/2016/03/23/the-price-of-glee-in-china/#comment-338600\">various other things<\/A> have been found to be effective too. I would even argue we can find happiness changes in nations &#8211; recent surveys have found Iraq and Syria to be the least happy nations in the world, and I doubt this was true before those countries&#8217; respective wars. It seems to just be national GDP per capita that doesn&#8217;t do anything.<\/p><p>This is <A HREF=\"https://en.wikipedia.org/wiki/Easterlin_paradox\">Easterlin&#8217;s Paradox<\/A>, the observation that a country in general does not get happier as it becomes richer. This is <i>very<\/i> controversial, with statisticians analyzing and reanalyzing data and crunch... <\/p>","plaintextDescription":"[Epistemic status: Overly simplistic treatment of a horrifyingly complex topic; I can only hope I haven’t missed enough to completely embarrass myself]\n\nI.\n\nNoah Smith reviews recent economic research suggesting that globalization was a net harm to working class people in rich countries like the US; he tentatively suggests this could justify a weak form of protectionism. But Scott Sumner argues that’s the wrong way to look at things. Globalization fueled China’s transition from a poor agrarian economy to an industrialized modern nation. A billion people were lifted out of poverty, an accomplishment Sumner calls “the best thing that ever happened”. This is far more important than the less dramatic costs imposed on the US. Therefore, even if we agree globalization hurts the working class of rich nations, it’s still a morally defensible policy since it benefits the needier working classes of much poorer nations.\n\nOn the one hand, this makes sense. On the other, here’s happiness in China over the past fifteen years:\n\n\n\nMeasuring happiness is really hard, but the Chinese result seems as robust as any. You get the same thing if you ask about satisfaction versus dissatisfaction. Brookings analyzes five different series of happiness data and concludes that “the Chinese became less happy during their growth boom”. The New York Times agrees and says that “Chinese people’s feelings of well-being have declined in [this] period of momentous improvement in their economic lives”. And this seems to be worst among the poorest Chinese:\n\n\n\nNor does this seem to be an effect from our happiness research just not being good enough to capture changes in happiness even if they occur. There’s good evidence that increased income within a country increases happiness, and various other things have been found to be effective too. I would even argue we can find happiness changes in nations – recent surveys have found Iraq and Syria to be the least happy nations in the world, and I doubt this was","wordCount":1639,"version":"1.0.0"},"Revision:ZWRtQgXucwzAFZqNJ_description":{"_id":"ZWRtQgXucwzAFZqNJ_description","__typename":"Revision","htmlHighlight":"<p><strong>China<\/strong> is a large country in eastern Asia, the most populous in the world and a significant power in the 21st century.<\/p><h1>Chinese Leadership<\/h1><p>Xi Jinping is the current Chinese President. His median expected term is <a href=\"https://www.metaculus.com/questions/9408/xi-no-longer-authority-of-china/\">until 2030<\/a>.<\/p><h1>China and Taiwan<\/h1><p>Taiwan is a large producer of semi-conductors and useful strategically for denying Chinese control of the Pacific. It considers itself a sovereign nation, though is not recognised as such because China cuts off any country that acknowledges this. China considers Taiwan to be a part of China.&nbsp;<\/p><p>It is extremely unlikely that Taiwan will be invaded by 2025, but plausible, &nbsp;<a href=\"https://www.metaculus.com/questions/11480/china-launches-invasion-of-taiwan/\">by 2030 or later<\/a>. If they try and invade before 2035, it's a coin toss <a href=\"https://www.metaculus.com/questions/8362/us-china-war-before-2035/\">if they will succeed<\/a>&nbsp;and likewise whether <a href=\"https://www.metaculus.com/questions/9408/xi-no-longer-authority-of-china/\">Japan will respond militarily<\/a>.<\/p><p>It is plausible, but unlikely that there is a <a href=\"https://www.metaculus.com/questions/11480/china-launches-invasion-of-taiwan/\">war between the US and China before 2035<\/a> with over 1,000 casualties.<\/p>"},"Tag:ZWRtQgXucwzAFZqNJ":{"_id":"ZWRtQgXucwzAFZqNJ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZWRtQgXucwzAFZqNJ_description"},"canVoteOnRels":null,"userId":"HoGziwmhpMGqGeWZy","name":"China","shortName":null,"slug":"china","core":false,"postCount":56,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-18T20:53:41.655Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:oMiogKLkK8L59WzDe":{"_id":"oMiogKLkK8L59WzDe","__typename":"SocialPreviewType","imageUrl":""},"Post:oMiogKLkK8L59WzDe":{"_id":"oMiogKLkK8L59WzDe","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e54"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"},{"__ref":"Tag:ZWRtQgXucwzAFZqNJ"}],"socialPreviewData":{"__ref":"SocialPreviewType:oMiogKLkK8L59WzDe"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-03-24T00:12:28.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"PDJ6KqJBRzvKPfuS3":2,"ZWRtQgXucwzAFZqNJ":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e54","commentCount":1,"voteCount":19,"baseScore":19,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":19,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0000470000013592653,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-02-27T18:41:53.660Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":2,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-price-of-glee-in-china","title":"The Price Of Glee In China","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16ded":{"_id":"5c6392dcbcb4ac6367c16ded","__typename":"Revision","htmlHighlight":"<p>A while back when <A HREF=\"http://slatestarcodex.com/2016/03/23/the-price-of-glee-in-china/\">I wrote about<\/A> how China&#8217;s economic development might not have increased happiness there much, Scott Sumner wrote a really interesting response, <A HREF=\"http://econlog.econlib.org/archives/2016/03/does_anything_m.html\">Does Anything Matter?<\/A><\/p><p>He points out that it&#8217;s too easy to make this about exotic far-off Chinese. Much the same phenomenon occurs closer to home:<\/p>\n<blockquote><p> If nothing really matters in China, if even overcoming horrible problems doesn&#8217;t make the Chinese better off, then what&#8217;s the use of favoring or opposing any public policy? After all, America also shows no rise in average happiness since the 1950s, despite:<\/p><p>1. A big rise in real wages.<br />\n2. Environmental clean-up (including lead&#8211;does Flint matter?)<br />\n3. Civil rights for African Americans<br />\n4. Feminism, gay rights.<br />\n5. Dentists now use Novocain (My childhood cavities were filled without it)<br />\n6. 1000 channels in glorious widescreen HDTV<br />\n7. Blogs<\/p><p>I could go on and on. And yet, if the surveys are to be believed, we are no happier than before. And I think it&#8217;s very possible that we are in fact no happier than before, that there&#8217;s a sort of law of the conservation of happiness. As I walk down the street, grown-ups don&#8217;t seem any happier than the grown-ups I recall as a kid. Does that mean that all of those wonderful societal achievements since 1950 were absolutely worthless?<\/p><p>But there are exceptions. I recall reading that surveys showed a rise in European happiness in the decades after WWII, and Scott reports that happiness is currently very low in Iraq and Syria. So that suggests that current conditions do matter.<\/p><p>The following hypothesis will sound really ad hoc, but matches the way a lot of people I know talk about their lives. Suppose people&#8217;s happiness is normally calibrated around the sort of lifestyle that they view as &#8220;normal.&#8221; As America got richer after 1950, it all seemed very normal, so people didn&#8217;t report more happiness. Ditto for China during the boom years. Everyone around you was also doing better, so you started thinking about how you were doing relative to your neighbors. But Germans walking through the rubble of Berlin in 1948, or Syrians doing so today in Aleppo, do see their plight as abnormal. They remember a time before the war. So they report less happiness than during normal times.<\/p><\/blockquote>\n<p>The obvious retort is &#8211; modern Chinese grew up when China was very poor. Why didn&#8217;t t... <\/p>","plaintextDescription":"A while back when I wrote about how China’s economic development might not have increased happiness there much, Scott Sumner wrote a really interesting response, Does Anything Matter?\n\nHe points out that it’s too easy to make this about exotic far-off Chinese. Much the same phenomenon occurs closer to home:\n\n> If nothing really matters in China, if even overcoming horrible problems doesn’t make the Chinese better off, then what’s the use of favoring or opposing any public policy? After all, America also shows no rise in average happiness since the 1950s, despite:\n> \n> 1. A big rise in real wages.\n> 2. Environmental clean-up (including lead–does Flint matter?)\n> 3. Civil rights for African Americans\n> 4. Feminism, gay rights.\n> 5. Dentists now use Novocain (My childhood cavities were filled without it)\n> 6. 1000 channels in glorious widescreen HDTV\n> 7. Blogs\n> \n> I could go on and on. And yet, if the surveys are to be believed, we are no happier than before. And I think it’s very possible that we are in fact no happier than before, that there’s a sort of law of the conservation of happiness. As I walk down the street, grown-ups don’t seem any happier than the grown-ups I recall as a kid. Does that mean that all of those wonderful societal achievements since 1950 were absolutely worthless?\n> \n> But there are exceptions. I recall reading that surveys showed a rise in European happiness in the decades after WWII, and Scott reports that happiness is currently very low in Iraq and Syria. So that suggests that current conditions do matter.\n> \n> The following hypothesis will sound really ad hoc, but matches the way a lot of people I know talk about their lives. Suppose people’s happiness is normally calibrated around the sort of lifestyle that they view as “normal.” As America got richer after 1950, it all seemed very normal, so people didn’t report more happiness. Ditto for China during the boom years. Everyone around you was also doing better, so you started thinking abo","wordCount":1497,"version":"1.0.0"},"SocialPreviewType:efMgZujzfjP9B9H4R":{"_id":"efMgZujzfjP9B9H4R","__typename":"SocialPreviewType","imageUrl":""},"Post:efMgZujzfjP9B9H4R":{"_id":"efMgZujzfjP9B9H4R","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ded"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"}],"socialPreviewData":{"__ref":"SocialPreviewType:efMgZujzfjP9B9H4R"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-07-21T02:03:46.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"PDJ6KqJBRzvKPfuS3":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ded","commentCount":3,"voteCount":14,"baseScore":14,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00003736796134035103,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-09-10T01:03:50.107Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"things-probably-matter","title":"Things Probably Matter","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16ddb":{"_id":"5c6392dcbcb4ac6367c16ddb","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Someone recently linked me to Bryan Caplan&#8217;s post <A HREF=\"http://econlog.econlib.org/archives/2014/06/a_hardy_week_ho.html\">A Hardy Weed: How Traditionalists Underestimate Western Civ<\/A>. He argues that &#8220;western civilization&#8221;&#8216;s supposed defenders don&#8217;t give it enough credit. They&#8217;re always worrying about it being threatened by Islam or China or Degeneracy or whatever, but in fact western civilization can not only hold its own against these threats but actively outcompetes them:<\/p>\n<blockquote><p>The fragility thesis is flat wrong.  There is absolutely no reason to think that Western civilization is more fragile than Asian civilization, Islamic civilization, or any other prominent rivals.  At minimum, Western civilization can and does perpetuate itself the standard way: sheer conformity and status quo bias. <\/p><p>But saying that Western civilization is no more fragile than other cultures is a gross understatement.  The truth is that Western civilization is taking over the globe.  In virtually any fair fight, it steadily triumphs.  Why?  Because, as fans of Western civ ought to know, Western civ is better.  Given a choice, young people choose Western consumerism, gender norms, and entertainment.  Anti-Western governments from Beijing to Tehran know this this to be true: Without draconian censorship and social regulation, &#8220;Westoxification&#8221; will win. <\/p><p>A big part of the West&#8217;s strength, I hasten to add, is its openness to awesomeness.  When it encounters competing cultures, it gleefully identifies competitors&#8217; best traits &#8211; then adopts them as its own.  By the time Western culture commands the globe, it will have appropriated the best features of Asian and Islamic culture.  Even its nominal detractors will be Westernized in all but name.  Picture how contemporary Christian fundamentalists&#8217; consumerism and gender roles would have horrified Luther or Calvin.  Western civ is a good winner.  It doesn&#8217;t demand total surrender.  It doesn&#8217;t make fans of competing cultures formally recant their errors.  It just tempts them in a hundred different ways until they tacitly convert.<\/p><p>Traditionalists&#8217; laments for Western civilization deeply puzzle me.  Yes, it&#8217;s easy to dwell on setbacks.  In a world of seven billion people, you can&#8217;t expect Western culture to win everywhere everyday.  But do traditionalists seriously believe that freshman Western civ classes are the wall stan<\/p><\/blockquote>... ","plaintextDescription":"I.\n\nSomeone recently linked me to Bryan Caplan’s post A Hardy Weed: How Traditionalists Underestimate Western Civ. He argues that “western civilization”‘s supposed defenders don’t give it enough credit. They’re always worrying about it being threatened by Islam or China or Degeneracy or whatever, but in fact western civilization can not only hold its own against these threats but actively outcompetes them:\n\n> The fragility thesis is flat wrong. There is absolutely no reason to think that Western civilization is more fragile than Asian civilization, Islamic civilization, or any other prominent rivals. At minimum, Western civilization can and does perpetuate itself the standard way: sheer conformity and status quo bias.\n> \n> But saying that Western civilization is no more fragile than other cultures is a gross understatement. The truth is that Western civilization is taking over the globe. In virtually any fair fight, it steadily triumphs. Why? Because, as fans of Western civ ought to know, Western civ is better. Given a choice, young people choose Western consumerism, gender norms, and entertainment. Anti-Western governments from Beijing to Tehran know this this to be true: Without draconian censorship and social regulation, “Westoxification” will win.\n> \n> A big part of the West’s strength, I hasten to add, is its openness to awesomeness. When it encounters competing cultures, it gleefully identifies competitors’ best traits – then adopts them as its own. By the time Western culture commands the globe, it will have appropriated the best features of Asian and Islamic culture. Even its nominal detractors will be Westernized in all but name. Picture how contemporary Christian fundamentalists’ consumerism and gender roles would have horrified Luther or Calvin. Western civ is a good winner. It doesn’t demand total surrender. It doesn’t make fans of competing cultures formally recant their errors. It just tempts them in a hundred different ways until they tacitly convert.","wordCount":5091,"version":"1.0.0"},"Revision:HkiwLtMRLxpBa6zs5_description":{"_id":"HkiwLtMRLxpBa6zs5_description","__typename":"Revision","htmlHighlight":"<html><head><\/head><body><p>The <strong>Industrial Revolution <\/strong>was a set of economic and social changes that occurred in Europe and the United States in the 18th and 19th centuries, characterised by a transition from an \"agrarian and handicraft economy to one dominated by industry and machine manufacturing\" [<a href=\"https://www.britannica.com/event/Industrial-Revolution\">1<\/a>].&nbsp;<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/history\">History<\/a><\/p><\/body><\/html>"},"Tag:HkiwLtMRLxpBa6zs5":{"_id":"HkiwLtMRLxpBa6zs5","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:HkiwLtMRLxpBa6zs5_description"},"canVoteOnRels":null,"userId":"gXeEWGjTWyqgrQTzR","name":"Industrial Revolution","shortName":null,"slug":"industrial-revolution","core":false,"postCount":38,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-14T23:46:29.245Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:m7THsgXyxxiEXgyHv":{"_id":"m7THsgXyxxiEXgyHv","__typename":"SocialPreviewType","imageUrl":""},"Post:m7THsgXyxxiEXgyHv":{"_id":"m7THsgXyxxiEXgyHv","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ddb"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":20,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:HkiwLtMRLxpBa6zs5"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:m7THsgXyxxiEXgyHv"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-07-26T03:05:17.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"HkiwLtMRLxpBa6zs5":2,"gHCNhqxuJq2bZ2akb":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ddb","commentCount":10,"voteCount":25,"baseScore":38,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":25,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00009962633339455351,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2016-07-26T03:05:17.000Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":8,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2016-07-26T03:05:17.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"how-the-west-was-won","title":"How The West Was Won","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:eyY5PcNy4o7totECt":{"_id":"eyY5PcNy4o7totECt","__typename":"Chapter","createdAt":"2017-08-24T01:38:33.126Z","title":"Marginally Important Econ Questions","subtitle":null,"contents":null,"number":0,"sequenceId":"zfXAcwLnGocsCsriG","postIds":["Fafzj3wMvoCW4WjeF","BBQ5HEnL3ShefQxEj","ofL22R6KZsfrvdmwg","oMiogKLkK8L59WzDe","efMgZujzfjP9B9H4R","m7THsgXyxxiEXgyHv"],"posts":[{"__ref":"Post:Fafzj3wMvoCW4WjeF"},{"__ref":"Post:BBQ5HEnL3ShefQxEj"},{"__ref":"Post:ofL22R6KZsfrvdmwg"},{"__ref":"Post:oMiogKLkK8L59WzDe"},{"__ref":"Post:efMgZujzfjP9B9H4R"},{"__ref":"Post:m7THsgXyxxiEXgyHv"}]},"Revision:5c6392dcbcb4ac6367c16e6c":{"_id":"5c6392dcbcb4ac6367c16e6c","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>The lizard people of Alpha Draconis 1 decided to build an <A HREF=\"https://en.wikipedia.org/wiki/Ansible\">ansible<\/A>.<\/p><p>The transmitter was a colossal tower of silksteel, doorless and windowless. Inside were millions of modular silksteel cubes, each filled with beetles, a different species in every cube. Big beetles, small beetles, red beetles, blue beetles, friendly beetles, venomous beetles. There hadn&#8217;t been a million beetle species on Alpha Draconis I before the ansible. The lizard people had genetically engineered them, carefully, lovingly, making each one just different enough from all the others. Atop each beetle colony was a heat lamp. When the heat lamp was on, the beetles crawled up to the top of the cage, sunning themselves, basking in the glorious glow. When it turned off, they huddled together to warmth, chittering out their anger in little infrasonic groans only they could hear.<\/p><p>The receiver stood on 11845 Nochtli, eighty-five light years from Alpha Draconis, toward the galactic rim. It was also made of beetles, a million beetle colonies of the same million species that made up the transmitter. In each beetle colony was a pheromone dispenser. When it was on, the beetles would multiply until the whole cage was covered in them. When it was off, they would gradually die out until only a few were left.<\/p><p>Atop each beetle cage was a mouse cage, filled with a mix of white and grey mice. The white mice had been genetically engineered to want all levers in the &#8220;up&#8221; position, a desire beyond even food or sex in its intensity. The grey mice had been engineered to want levers in the &#8220;down&#8221; position, with equal ferocity. The lizard people had uplifted both strains to full sapience. In each of a million cages, the grey and white mice would argue whether levers should be up or down &#8211; sometimes through philosophical debate, sometimes through outright wars of extermination.<\/p><p>There was one lever in each mouse cage. It controlled the pheromone dispenser in the beetle cage just below.<\/p><p>This was all the lizard people of Alpha Draconis 1 needed to construct their ansible.<\/p><p>They had mastered every field of science. Physics, mathematics, astronomy, cosmology. It had been for nothing. There was no way to communicate faster-than-light. Tachyons didn&#8217;t exist. Hyperspace didn&#8217;t exist. Wormholes didn&#8217;t exist. The light speed barrier was absolute &#8211; <i>if<\/i> you limited yourself to... <\/p>","plaintextDescription":"I.\n\nThe lizard people of Alpha Draconis 1 decided to build an ansible.\n\nThe transmitter was a colossal tower of silksteel, doorless and windowless. Inside were millions of modular silksteel cubes, each filled with beetles, a different species in every cube. Big beetles, small beetles, red beetles, blue beetles, friendly beetles, venomous beetles. There hadn’t been a million beetle species on Alpha Draconis I before the ansible. The lizard people had genetically engineered them, carefully, lovingly, making each one just different enough from all the others. Atop each beetle colony was a heat lamp. When the heat lamp was on, the beetles crawled up to the top of the cage, sunning themselves, basking in the glorious glow. When it turned off, they huddled together to warmth, chittering out their anger in little infrasonic groans only they could hear.\n\nThe receiver stood on 11845 Nochtli, eighty-five light years from Alpha Draconis, toward the galactic rim. It was also made of beetles, a million beetle colonies of the same million species that made up the transmitter. In each beetle colony was a pheromone dispenser. When it was on, the beetles would multiply until the whole cage was covered in them. When it was off, they would gradually die out until only a few were left.\n\nAtop each beetle cage was a mouse cage, filled with a mix of white and grey mice. The white mice had been genetically engineered to want all levers in the “up” position, a desire beyond even food or sex in its intensity. The grey mice had been engineered to want levers in the “down” position, with equal ferocity. The lizard people had uplifted both strains to full sapience. In each of a million cages, the grey and white mice would argue whether levers should be up or down – sometimes through philosophical debate, sometimes through outright wars of extermination.\n\nThere was one lever in each mouse cage. It controlled the pheromone dispenser in the beetle cage just below.\n\nThis was all the lizard people o","wordCount":1589,"version":"1.0.0"},"SocialPreviewType:iLMkKDKmfbMkDuQBm":{"_id":"iLMkKDKmfbMkDuQBm","__typename":"SocialPreviewType","imageUrl":""},"Post:iLMkKDKmfbMkDuQBm":{"_id":"iLMkKDKmfbMkDuQBm","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e6c"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:iLMkKDKmfbMkDuQBm"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-08-10T00:33:54.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e6c","commentCount":1,"voteCount":26,"baseScore":37,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00011530854681041092,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-10-07T16:58:44.300Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-lizard-people-of-alpha-draconis-1-decided-to-build-an","title":"The Lizard People Of Alpha Draconis 1 Decided To Build An Ansible","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16d53":{"_id":"5c6392c7bcb4ac6367c16d53","__typename":"Revision","htmlHighlight":"<p><b>1. Eris<\/b><\/p><p>A middle-aged man, James, had come on stage believing it was an audition for <i>American Idol<\/i>. It wasn&#8217;t. Out ran his ex-lover, Terri. &#8220;You said you loved me!&#8221; she said. &#8220;And then when I got pregnant, you disappeared! Twenty years, and you never even sent me a letter!&#8221;<\/p><p>The crowd booed.<\/p><p>As James tried to sputter a response, his wife ran onto the stage. &#8220;You cheating jerk!&#8221; she shouted at James. &#8220;You lying, cheating jerk! Twenty-five years we&#8217;ve been married, and I never&#8230;&#8221; She picked up a folding chair, tried to swing it at James.<\/p><p>&#8220;Stop!&#8221; cried James&#8217; teenage daughter Katie, joining in the fray.  &#8220;Mom, Dad, stop it!&#8221; <\/p><p>&#8220;You stay out of this!&#8221; shouted James&#8217; wife. &#8220;Maybe if you&#8217;d had a good male role model, you wouldn&#8217;t have become <i>a lesbian<\/i>.&#8221;<\/p><p>The crowd gasped.<\/p><p>Katie&#8217;s girlfriend Lisa came out of a side door. &#8220;You take that back!&#8221; she yelled. Then she saw Terri. &#8220;Wait? Mom? What are you doing here?&#8221;<\/p><p>&#8220;That&#8217;s right,&#8221; said Alice DiScorria, sidling onto the stage, effortlessly drawing the audience&#8217;s attention from the brawl taking shape in front of them. &#8220;Katie&#8217;s girlfriend is the daughter of the woman her father cheated with, so many years ago. And we&#8217;ve got the paternity test right here.&#8221; She theatrically opened a manilla envelope. &#8220;And&#8230;James! James is the father!&#8221;<\/p><p>&#8220;I&#8217;VE BEEN LESBIAN LOVERS WITH MY HALF-SISTER!&#8221; shrieked Katie.<\/p><p>&#8220;This is all your fault!&#8221; everyone shouted at everyone else in unison. Then the punching started.<\/p><p>In short, it had been another successful episode of <i>The Alice Show<\/i>.<\/p><p>Now Ms. DiScorria was in her dressing room, wiping off the night&#8217;s makeup, trying to decide where to go to dinner. Knock, knock. She opened the door wide.<\/p><p>There stood Katie and Lisa. Katie was holding a shotgun.<\/p><p>&#8220;Why would you do this to us?&#8221; screamed Katie. &#8220;We were a happy family!&#8221;<\/p><p>&#8220;I loved her!&#8221; added Lisa.<\/p><p>&#8220;Why?&#8221; Katie screamed at her, waving the gun. &#8220;WHY?&#8221;<\/p><p>&#8220;Oh, put it away,&#8221; said Alice. &#8220;We both know you&#8217;re not going to shoot me. And it wouldn&#8217;t hurt me if you did. I do this because I&#8217;m Eris, the Greek Goddess of Discord. I ... <\/p>","plaintextDescription":"1. Eris\n\nA middle-aged man, James, had come on stage believing it was an audition for American Idol. It wasn’t. Out ran his ex-lover, Terri. “You said you loved me!” she said. “And then when I got pregnant, you disappeared! Twenty years, and you never even sent me a letter!”\n\nThe crowd booed.\n\nAs James tried to sputter a response, his wife ran onto the stage. “You cheating jerk!” she shouted at James. “You lying, cheating jerk! Twenty-five years we’ve been married, and I never…” She picked up a folding chair, tried to swing it at James.\n\n“Stop!” cried James’ teenage daughter Katie, joining in the fray. “Mom, Dad, stop it!”\n\n“You stay out of this!” shouted James’ wife. “Maybe if you’d had a good male role model, you wouldn’t have become a lesbian.”\n\nThe crowd gasped.\n\nKatie’s girlfriend Lisa came out of a side door. “You take that back!” she yelled. Then she saw Terri. “Wait? Mom? What are you doing here?”\n\n“That’s right,” said Alice DiScorria, sidling onto the stage, effortlessly drawing the audience’s attention from the brawl taking shape in front of them. “Katie’s girlfriend is the daughter of the woman her father cheated with, so many years ago. And we’ve got the paternity test right here.” She theatrically opened a manilla envelope. “And…James! James is the father!”\n\n“I’VE BEEN LESBIAN LOVERS WITH MY HALF-SISTER!” shrieked Katie.\n\n“This is all your fault!” everyone shouted at everyone else in unison. Then the punching started.\n\nIn short, it had been another successful episode of The Alice Show.\n\nNow Ms. DiScorria was in her dressing room, wiping off the night’s makeup, trying to decide where to go to dinner. Knock, knock. She opened the door wide.\n\nThere stood Katie and Lisa. Katie was holding a shotgun.\n\n“Why would you do this to us?” screamed Katie. “We were a happy family!”\n\n“I loved her!” added Lisa.\n\n“Why?” Katie screamed at her, waving the gun. “WHY?”\n\n“Oh, put it away,” said Alice. “We both know you’re not going to shoot me. And it wouldn’t hurt me if you","wordCount":14627,"version":"1.0.0"},"SocialPreviewType:kSiT2XjfTnDHKx44W":{"_id":"kSiT2XjfTnDHKx44W","__typename":"SocialPreviewType","imageUrl":""},"Post:kSiT2XjfTnDHKx44W":{"_id":"kSiT2XjfTnDHKx44W","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16d53"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":59,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:kSiT2XjfTnDHKx44W"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-02-27T17:29:17.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":4},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16d53","commentCount":1,"voteCount":36,"baseScore":38,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":36,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00010800000018207356,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-10-11T09:30:42.902Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":3,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"a-modern-myth","title":"A Modern Myth","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:fh8udExpDpkNHseKm":{"_id":"fh8udExpDpkNHseKm","__typename":"Chapter","createdAt":"2017-09-02T08:57:38.396Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"zfXAcwLnGocsCsriG","postIds":["iLMkKDKmfbMkDuQBm","kSiT2XjfTnDHKx44W"],"posts":[{"__ref":"Post:iLMkKDKmfbMkDuQBm"},{"__ref":"Post:kSiT2XjfTnDHKx44W"}]},"Revision:zfXAcwLnGocsCsriG_contents":{"_id":"zfXAcwLnGocsCsriG_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:37:08.113Z","userId":"XgYW5s8njaYrtyP7q","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Sequence:zfXAcwLnGocsCsriG":{"_id":"zfXAcwLnGocsCsriG","__typename":"Sequence","chapters":[{"__ref":"Chapter:eyY5PcNy4o7totECt"},{"__ref":"Chapter:fh8udExpDpkNHseKm"}],"createdAt":"2017-08-24T01:37:08.113Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:zfXAcwLnGocsCsriG_contents"},"gridImageId":"sequencesgrid/hxgrnxobgf692eqpd8mz","bannerImageId":"sequences/z8ya8jyaxlbsfztpyfjo","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":8,"readPostsCount":0,"title":"Economics and Efficiency","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:n39gBZ33kb92KsJyE":{"_id":"n39gBZ33kb92KsJyE","__typename":"Revision","htmlHighlight":"<p><i>Editor's note: this post is several years out of date and doesn't include information on modern systems like GPT-4, but is still a solid layman's introduction to why superintelligence might be important, dangerous and confusing.<\/i><\/p><p><strong>1: What is superintelligence?<\/strong><\/p><p>A superintelligence is a mind that is much more intelligent than any human. Most of the time, it’s used to discuss hypothetical future AIs.<\/p><p><strong>1.1: Sounds a lot like science fiction. Do people think about this in the real world?<\/strong><\/p><p>Yes. Two years ago, Google bought artificial intelligence startup DeepMind for $400 million; DeepMind added the condition that Google promise to set up an AI Ethics Board. DeepMind cofounder Shane Legg has said in interviews that he believes superintelligent AI will be “something approaching absolute power” and “the number one risk for this century”.<\/p><p>Many other science and technology leaders agree. Astrophysicist Stephen Hawking says that superintelligence “could spell the end of the human race.” Tech billionaire Bill Gates describes himself as “in the camp that is concerned about superintelligence…I don’t understand why some people are not concerned”. SpaceX/Tesla CEO Elon Musk calls superintelligence “our greatest existential threat” and donated $10 million from his personal fortune to study the danger. Stuart Russell, Professor of Computer Science at Berkeley and world-famous AI expert, warns of “species-ending problems” and wants his field to pivot to make superintelligence-related risks a central concern.<\/p><p>Professor Nick Bostrom is the director of Oxford’s Future of Humanity Institute, tasked with anticipating and preventing threats to human civilization. He has been studying the risks of artificial intelligence for twenty years. The explanations below are loosely adapted from his 2014 book Superintelligence, and divided into three parts addressing three major questions. First, why is superintelligence a topic of concern? Second, what is a “hard takeoff” and how does it impact our concern about superintelligence? Third, what measures can we take to make superintelligence safe and beneficial for humanity?<\/p><p><strong>2: AIs aren’t as smart as rats, let alone humans. Isn’t it sort of early to be worrying about this kind of thing?<\/strong><\/p><p>Maybe. It’s true that although AI has had some recent successes – like DeepMind’s newest creation AlphaGo defeating the human Go champion in April – it still has nothing lik... <\/p>","plaintextDescription":"Editor's note: this post is several years out of date and doesn't include information on modern systems like GPT-4, but is still a solid layman's introduction to why superintelligence might be important, dangerous and confusing.\n\n1: What is superintelligence?\n\nA superintelligence is a mind that is much more intelligent than any human. Most of the time, it’s used to discuss hypothetical future AIs.\n\n1.1: Sounds a lot like science fiction. Do people think about this in the real world?\n\nYes. Two years ago, Google bought artificial intelligence startup DeepMind for $400 million; DeepMind added the condition that Google promise to set up an AI Ethics Board. DeepMind cofounder Shane Legg has said in interviews that he believes superintelligent AI will be “something approaching absolute power” and “the number one risk for this century”.\n\nMany other science and technology leaders agree. Astrophysicist Stephen Hawking says that superintelligence “could spell the end of the human race.” Tech billionaire Bill Gates describes himself as “in the camp that is concerned about superintelligence…I don’t understand why some people are not concerned”. SpaceX/Tesla CEO Elon Musk calls superintelligence “our greatest existential threat” and donated $10 million from his personal fortune to study the danger. Stuart Russell, Professor of Computer Science at Berkeley and world-famous AI expert, warns of “species-ending problems” and wants his field to pivot to make superintelligence-related risks a central concern.\n\nProfessor Nick Bostrom is the director of Oxford’s Future of Humanity Institute, tasked with anticipating and preventing threats to human civilization. He has been studying the risks of artificial intelligence for twenty years. The explanations below are loosely adapted from his 2014 book Superintelligence, and divided into three parts addressing three major questions. First, why is superintelligence a topic of concern? Second, what is a “hard takeoff” and how does it impact our","wordCount":8183,"version":"1.3.0"},"Revision:LTtNXM9shNM9AC2mp_customHighlight":{"_id":"LTtNXM9shNM9AC2mp_customHighlight","__typename":"Revision","html":"","plaintextDescription":""},"Revision:Fxq9YJMGsuphd8Rmt_description":{"_id":"Fxq9YJMGsuphd8Rmt_description","__typename":"Revision","htmlHighlight":"<p><strong>AI Alignment Intro Materials. <\/strong>Posts that help someone get oriented and skill up. Distinct from AI Public Materials is that they are more \"inward facing\" than \"outward facing\", i.e. for people who are already sold AI risk is a problem and want to upskill.<br>&nbsp;<\/p><p>Some basic intro resources include:<\/p><ul><li><a href=\"https://aisafety.info/\">Stampy's AI Safety Info<\/a> (extensive interactive FAQ)<\/li><li><a href=\"https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq\">Scott Alexander's Superintelligence FAQ<\/a><\/li><li><a href=\"https://intelligence.org/ie-faq/\">The MIRI Intelligence Explosion FAQ<\/a><\/li><li><a href=\"https://www.agisafetyfundamentals.com/\">The AGI Safety Fundamentals courses<\/a><\/li><li><a href=\"https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111/\">Superintelligence<\/a> (book)<\/li><\/ul>"},"Tag:Fxq9YJMGsuphd8Rmt":{"_id":"Fxq9YJMGsuphd8Rmt","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Fxq9YJMGsuphd8Rmt_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"AI Alignment Intro Materials","shortName":null,"slug":"ai-alignment-intro-materials","core":false,"postCount":46,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-11-04T17:53:53.248Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:DigEmY3RrF3XL5cwe_description":{"_id":"DigEmY3RrF3XL5cwe_description","__typename":"Revision","htmlHighlight":"<p>Posts in the format of <strong>Question and Answers (Q&amp;A)<\/strong>, usually on some specific topic.<\/p><p>This includes both question and answer style<a href=\"interviews\"> interviews<\/a> between actual people, and essays formatted as question and answer sessions between fictional people.<\/p>"},"Tag:DigEmY3RrF3XL5cwe":{"_id":"DigEmY3RrF3XL5cwe","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:DigEmY3RrF3XL5cwe_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Q&A (format)","shortName":null,"slug":"q-and-a-format","core":false,"postCount":42,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-31T12:47:04.968Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:5f5c37ee1b5cdee568cfb297_description":{"_id":"5f5c37ee1b5cdee568cfb297_description","__typename":"Revision","htmlHighlight":"<p>A <strong>Superintelligence<\/strong> is a being with superhuman intelligence, and a focus of the <a href=\"https://www.lesswrong.com/tag/machine-intelligence-research-institute-miri\">Machine Intelligence Research Institute<\/a>'s research. Specifically, Nick Bostrom (1997) defined it as<\/p><blockquote><p>\"An intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills.\"<\/p><\/blockquote><p>The <a href=\"https://www.lesswrong.com/tag/machine-intelligence-research-institute-miri\">Machine Intelligence Research Institute<\/a> is dedicated to ensuring humanity's safety and prosperity by preparing for the development of an <a href=\"https://www.lesswrong.com/tag/artificial-general-intelligence\">Artificial General Intelligence<\/a> with superintelligence. Given its intelligence, it is likely to be <a href=\"https://www.lesswrong.com/tag/ai-boxing-containment\">incapable of being controlled<\/a> by humanity. It is important to prepare early for the development of <a href=\"https://www.lesswrong.com/tag/friendly-artificial-intelligence\">friendly artificial intelligence<\/a>, as there may be an <a href=\"https://www.lesswrong.com/tag/ai-arms-race\">AI arms race<\/a>. A strong superintelligence is a term describing a superintelligence which is not designed with the same architecture as the human brain.<\/p><p>An <a href=\"https://www.lesswrong.com/tag/artificial-general-intelligence\">Artificial General Intelligence<\/a> will have a number of advantages aiding it in becoming a superintelligence. It can improve the hardware it runs on and obtain better hardware. It will be capable of directly editing its own code. Depending on how easy its code is to modify, it might carry out software improvements that <a href=\"https://www.lesswrong.com/tag/recursive-self-improvement\">spark further improvements<\/a>. Where a task can be accomplished in a repetitive way, a module preforming the task far more efficiently might be developed. Its motivations and preferences can be edited to be more consistent with each other. It will have an indefinite life span, be capable of reproducing, and transfer knowledge, skills, and code among its copies as well as cooperating and communicating with them better than humans do with each other.<\/p><p>The development of superintelligence from humans is another possibility, sometimes termed a weak superintelligence. It may come in the form of <a href=\"https://www.lesswrong.com/tag/whole-brain-emulation\">whole brain emulation<\/a>, where a human brain is scanned and simulated on a computer. Many of the advantages a AGI has in developing superintelligence apply here as well. The development of <a href=\"https://www.lesswrong.com/tag/brain-computer-interfaces\">Brain-computer interfaces<\/a> may also lead to the creation of superintelligence. Biological enhancements such as genetic engineering and the use of nootropics could lead to superintelligence as well.<\/p><h2>External Links<\/h2><ul><li><a href=\"http://www.nickbostrom.com/superintelligence.html\">How long before Superintelligence?<\/a> by Nick Bostrom<\/li><li><a href=\"http://profhugodegaris.files.wordpress.com/2011/04/nocyborgsbghugo.pdf\">A discussion between Hugo de Garis and Ben Goertzel on superintelligence<\/a><\/li><li><a href=\"http://www.xuenay.net/Papers/DigitalAdvantages.pdf\">Advantages of Artificial Intelligences, Uploads, And Digital Minds<\/a> by Kaj Sotala<\/li><\/ul><h2>See Also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/brain-computer-interfaces\">B<\/a><\/li><\/ul>... "},"Tag:5f5c37ee1b5cdee568cfb297":{"_id":"5f5c37ee1b5cdee568cfb297","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb297_description"},"canVoteOnRels":null,"userId":"NRg5Bw8H2DCYTpmHE","name":"Superintelligence","shortName":null,"slug":"superintelligence","core":false,"postCount":105,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.554Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:sYm3HiWcfZvrGu3ui_description":{"_id":"sYm3HiWcfZvrGu3ui_description","__typename":"Revision","htmlHighlight":"<p><strong>Artificial Intelligence<\/strong> is the study of creating intelligence in algorithms. <strong>AI Alignment <\/strong>is the task of ensuring [powerful] AI system are aligned with human values and interests. The central concern is that a powerful enough AI, if not designed and implemented with sufficient understanding, would optimize something unintended by its creators and pose an existential threat to the future of humanity. This is known as the <i>AI alignment<\/i> problem.<\/p><p>Common terms in this space are <i>superintelligence, AI Alignment, AI Safety, Friendly AI, Transformative AI, human-level-intelligence, AI Governance, and Beneficial AI. <\/i>This entry and the associated tag roughly encompass all of these topics: anything part of the broad cluster of understanding AI and its future impacts on our civilization deserves this tag.<\/p><p><strong>AI Alignment<\/strong><\/p><p>There are narrow conceptions of alignment, where you’re trying to get it to do something like cure Alzheimer’s disease without destroying the rest of the world. And there’s much more ambitious notions of alignment, where you’re trying to get it to do the right thing and achieve a happy intergalactic civilization.<\/p><p>But both the narrow and the ambitious alignment have in common that you’re trying to have the AI do that thing rather than making a lot of paperclips.<\/p><p>See also <a href=\"https://www.lesswrong.com/tag/general-intelligence\">General Intelligence<\/a>.<\/p><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\" rowspan=\"2\"><p><strong>Basic Alignment Theory<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aixi?showPostCount=true&amp;useTagName=true\">AIXI<\/a><br><a href=\"http://www.lesswrong.com/tag/coherent-extrapolated-volition?showPostCount=true&amp;useTagName=true\">Coherent Extrapolated Volition<\/a><br><a href=\"https://www.lesswrong.com/tag/complexity-of-value?showPostCount=true&amp;useTagName=true\">Complexity of Value<\/a><br><a href=\"https://www.lesswrong.com/tag/corrigibility?showPostCount=true&amp;useTagName=true\">Corrigibility<\/a><br><a href=\"https://www.lesswrong.com/tag/deceptive-alignment?showPostCount=true&amp;useTagName=true\">Deceptive Alignment<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/embedded-agency?showPostCount=true&amp;useTagName=true\">Embedded Agency<\/a><br><a href=\"https://www.lesswrong.com/tag/fixed-point-theorems?showPostCount=true&amp;useTagName=true\">Fixed Point Theorems<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodhart's Law<\/a><br><a href=\"https://www.lesswrong.com/tag/goal-directedness?showPostCount=true&amp;useTagName=true\">Goal-Directedness<\/a><br><a href=\"https://www.lesswrong.com/tag/gradient-hacking?showPostCount=true&amp;useTagName=true\">Gradient Hacking<\/a><br><a href=\"http://www.lesswrong.com/tag/infra-bayesianism?showPostCount=true&amp;useTagName=true\">Infra-Bayesianism<\/a><br><a href=\"https://www.lesswrong.com/tag/inner-alignment?showPostCount=true&amp;useTagName=true\">Inner Alignment<\/a><br><a href=\"https://www.lesswrong.com/tag/instrumental-convergence?showPostCount=true&amp;useTagName=true\">Instrumental Convergence<\/a><br><a href=\"https://www.lesswrong.com/tag/intelligence-explosion?showPostCount=true&amp;useTagName=true\">Intelligence Explosion<\/a><br><a href=\"https://www.lesswrong.com/tag/logical-induction?showPostCount=true&amp;useTagName=true\">Logical Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/logical-uncertainty?showPostCount=true&amp;useTagName=true\">Logical Uncertainty<\/a><br><a href=\"https://www.lesswrong.com/tag/mesa-optimization?showPostCount=true&amp;useTagName=true\">Mesa-Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/multipolar-scenarios?showPostCount=true&amp;useTagName=true\">Multipolar Scenarios<\/a><br><a href=\"https://www.lesswrong.com/tag/myopia?showPostCount=true&amp;useTagName=true\">Myopia<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"https://www.lesswrong.com/tag/optimization?showPostCount=true&amp;useTagName=true\">Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/orthogonality-thesis?showPostCount=true&amp;useTagName=true\">Orthogonality Thesis<\/a><br><a href=\"https://www.lesswrong.com/tag/outer-alignment?showPostCount=true&amp;useTagName=true\">Outer Alignment<\/a><br><a href=\"http://www.lesswrong.com/tag/paperclip-maximizer?showPostCount=true&amp;useTagName=true\">Paperclip Maximizer<\/a><br><a href=\"https://www.lesswrong.com/tag/power-seeking-ai?showPostCount=true&amp;useTagName=true\">Power Seeking (AI)<\/a><br><a href=\"https://www.lesswrong.com/tag/recursive-self-improvement?showPostCount=true&amp;useTagName=true\">Recursive Self-Improvement<\/a><br><a href=\"https://www.lesswrong.com/tag/simulator-theory\">Simulator Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/sharp-left-turn?showPostCount=true&amp;useTagName=true\">Sharp Left Turn<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"https://www.lesswrong.com/tag/superintelligence?showPostCount=true&amp;useTagName=true\">Superintelligence<\/a><br><a href=\"https://www.lesswrong.com/tag/symbol-grounding\">Symbol Grounding<\/a><br><a href=\"https://www.lesswrong.com/tag/transformative-ai?showPostCount=true&amp;useTagName=true\">Transformative AI<\/a><br><a href=\"https://www.lesswrong.com/tag/treacherous-turn?showPostCount=true&amp;useTagName=true\">Treacherous Turn<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br><a href=\"https://www.lesswrong.com/tag/whole-brain-emulation?showPostCount=true&amp;useTagName=true\">Whole Brain Emulation<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Engineering Alignment<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/agent-foundations?showPostCount=true&amp;useTagName=true\">Agent Foundations<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-assisted-alignment?showPostCount=true&amp;useTagName=true\">AI-assisted Alignment&nbsp;<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-boxing-containment?showPostCount=true&amp;useTagName=true\">AI Boxing (Containment)<\/a><br><a href=\"https://www.lesswrong.com/tag/conservatism-ai?showPostCount=true&amp;useTagName=true\">Conservatism (AI)<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-safety-via-debate?showPostCount=true&amp;useTagName=true\">Debate (AI safety technique)<\/a><br><a href=\"https://www.lesswrong.com/tag/eliciting-latent-knowledge-elk\">Eliciting Latent Knowledge (ELK)<\/a><br><a href=\"https://www.lesswrong.com/tag/factored-cognition?showPostCount=true&amp;useTagName=true\">Factored Cognition<\/a><br><a href=\"https://www.lesswrong.com/tag/hch?showPostCount=true&amp;useTagName=true\">Humans Consulting HCH<\/a><br><a href=\"https://www.lesswrong.com/tag/impact-measures?showPostCount=true&amp;useTagName=true\">Impact Measures<\/a><br><a href=\"https://www.lesswrong.com/tag/inverse-reinforcement-learning?showPostCount=true&amp;useTagName=true\">Inverse Reinforcement Learning<\/a><br><a href=\"https://www.lesswrong.com/tag/iterated-amplification?showPostCount=true&amp;useTagName=true\">Iterated Amplification<\/a><br><a href=\"http://www.lesswrong.com/tag/mild-optimization?showPostCount=true&amp;useTagName=true\">Mild Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/oracle-ai?showPostCount=true&amp;useTagName=true\">Oracle AI<\/a><br><a href=\"https://www.lesswrong.com/tag/reward-functions?showPostCount=true&amp;useTagName=true\">Reward Functions<\/a><br><a href=\"https://www.lesswrong.com/tag/rlhf?showPostCount=true&amp;useTagName=true\">RLHF<\/a><br><a href=\"https://www.lesswrong.com/tag/shard-theory?showPostCount=true&amp;useTagName=true\">Shard Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/tool-ai?showPostCount=true&amp;useTagName=true\">Tool AI<\/a><br><a href=\"https://www.lesswrong.com/tag/transparency-interpretability-ml-and-ai?showPostCount=true\">Transparency / Interpretability<\/a><br><a href=\"https://www.lesswrong.com/tag/tripwire?showPostCount=true&amp;useTagName=true\">Tripwire<\/a><br><a href=\"https://www.lesswrong.com/tag/value-learning?showPostCount=true&amp;useTagName=true\">Value Learning<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Organizations<\/strong><\/p><p><a href=\"https://aisafety.world/map/\">Full map here<\/a><\/p><p><a href=\"https://www.lesswrong.com/tag/ai-safety-camp?showPostCount=true&amp;useTagName=true\">AI Safety Camp<\/a><br><a href=\"https://www.lesswrong.com/tag/alignment-research-center\">Alignment Resea<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>... "},"Tag:sYm3HiWcfZvrGu3ui":{"_id":"sYm3HiWcfZvrGu3ui","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:sYm3HiWcfZvrGu3ui_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"AI","shortName":null,"slug":"ai","core":true,"postCount":9865,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T22:24:22.097Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:LTtNXM9shNM9AC2mp":{"_id":"LTtNXM9shNM9AC2mp","__typename":"SocialPreviewType","imageUrl":""},"Post:LTtNXM9shNM9AC2mp":{"_id":"LTtNXM9shNM9AC2mp","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:n39gBZ33kb92KsJyE"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":33,"rejectedReason":null,"customHighlight":{"__ref":"Revision:LTtNXM9shNM9AC2mp_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ZFrgTgzwEfStg26JL"},{"__ref":"Tag:Fxq9YJMGsuphd8Rmt"},{"__ref":"Tag:DigEmY3RrF3XL5cwe"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb297"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:LTtNXM9shNM9AC2mp"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-09-20T19:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2024-04-03T18:35:10.747Z","meta":false,"postCategory":"post","tagRelevance":{"DigEmY3RrF3XL5cwe":5,"Fxq9YJMGsuphd8Rmt":10,"ZFrgTgzwEfStg26JL":14,"sYm3HiWcfZvrGu3ui":23,"5f5c37ee1b5cdee568cfb297":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"n39gBZ33kb92KsJyE","commentCount":38,"voteCount":83,"baseScore":129,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":80,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0003711028548423201,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-04-27T20:31:09.388Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":13,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":17,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2016-09-20T19:00:00.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"superintelligence-faq","title":"Superintelligence FAQ","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:AASntfcCnuhRZC7eZ":{"_id":"AASntfcCnuhRZC7eZ","__typename":"Revision","htmlHighlight":"<p>I first became interested in AI risk back around 2007. At the time, most people&#8217;s response to the topic was &#8220;Haha, come back when anyone believes this besides random Internet crackpots.&#8221;<\/p><p>Over the next few years, a series of extremely bright and influential figures including <A HREF=\"http://www.cnet.com/news/bill-gates-is-worried-about-artificial-intelligence-too/\">Bill Gates<\/A>, <A HREF=\"http://www.bbc.com/news/technology-30290540\">Stephen Hawking<\/A>, and <A HREF=\"http://www.forbes.com/sites/ericmack/2015/01/15/elon-musk-puts-down-10-million-to-fight-skynet/\">Elon Musk<\/A> publically announced they were concerned about AI risk, along with hundreds of other intellectuals, from Oxford philosophers to MIT cosmologists to Silicon Valley tech investors. So we came back.<\/p><p>Then the response changed to &#8220;Sure, a couple of random academics and businesspeople might believe this stuff, but never <i>real experts<\/i> in the field who know what&#8217;s going on.&#8221; <\/p><p>Thus pieces like Popular Science&#8217;s <A HREF=\"http://www.popsci.com/bill-gates-fears-ai-ai-researchers-know-better\">Bill Gates Fears AI, But AI Researchers Know Better<\/A>:<\/p>\n<blockquote><p> When you talk to A.I. researchers—again, genuine A.I. researchers, people who grapple with making systems that work at all, much less work too well—they are not worried about superintelligence sneaking up on them, now or in the future. Contrary to the spooky stories that Musk seems intent on telling, A.I. researchers aren&#8217;t frantically installed firewalled summoning chambers and self-destruct countdowns.<\/p><\/blockquote>\n<p>And Fusion.net&#8217;s <A HREF=\"http://fusion.net/story/54583/the-case-against-killer-robots-from-a-guy-actually-building-ai/\">The Case Against Killer Robots From A Guy Actually Building AI<\/A>:<\/p>\n<blockquote><p>Andrew Ng builds artificial intelligence systems for a living. He taught AI at Stanford, built AI at Google, and then moved to the Chinese search engine giant, Baidu, to continue his work at the forefront of applying artificial intelligence to real-world problems. So when he hears people like Elon Musk or Stephen Hawking—people who are not intimately familiar with today’s technologies—talking about the wild potential for artificial intelligence to, say, wipe out the human race, you can practically hear him facepalming.<\/p><\/blockquote>\n<p>And now Ramez Naam of Marginal Revolution is trying the same thing with <A HREF=\"http://marginalrevolution.com/marginalrevolution/2015/05/what-do-ai-researchers-think-of-the-risks-of-ai.html\">What Do AI Researchers Think Of The Risk Of AI?<\/A>:<\/p>\n<blockquote><p>Elon Musk, Stephen Hawking, and Bill Gates have recently expressed concern that development of AI could lead to a ‘killer AI’ scenario, and potentially to the extinction of humanity. None of them are AI researchers or have worked substantially with AI that I know of. What do actual AI researchers think of the risks of AI?<\/p><\/blockquote>\n<p>It quotes the same couple of cherry-picked AI researchers as all the other stories &#8211; Andrew Ng, Yann LeCun,... <\/p>","plaintextDescription":"I first became interested in AI risk back around 2007. At the time, most people’s response to the topic was “Haha, come back when anyone believes this besides random Internet crackpots.”\n\nOver the next few years, a series of extremely bright and influential figures including Bill Gates, Stephen Hawking, and Elon Musk publically announced they were concerned about AI risk, along with hundreds of other intellectuals, from Oxford philosophers to MIT cosmologists to Silicon Valley tech investors. So we came back.\n\nThen the response changed to “Sure, a couple of random academics and businesspeople might believe this stuff, but never real experts in the field who know what’s going on.”\n\nThus pieces like Popular Science’s Bill Gates Fears AI, But AI Researchers Know Better:\n\n> When you talk to A.I. researchers—again, genuine A.I. researchers, people who grapple with making systems that work at all, much less work too well—they are not worried about superintelligence sneaking up on them, now or in the future. Contrary to the spooky stories that Musk seems intent on telling, A.I. researchers aren’t frantically installed firewalled summoning chambers and self-destruct countdowns.\n\nAnd Fusion.net’s The Case Against Killer Robots From A Guy Actually Building AI:\n\n> Andrew Ng builds artificial intelligence systems for a living. He taught AI at Stanford, built AI at Google, and then moved to the Chinese search engine giant, Baidu, to continue his work at the forefront of applying artificial intelligence to real-world problems. So when he hears people like Elon Musk or Stephen Hawking—people who are not intimately familiar with today’s technologies—talking about the wild potential for artificial intelligence to, say, wipe out the human race, you can practically hear him facepalming.\n\nAnd now Ramez Naam of Marginal Revolution is trying the same thing with What Do AI Researchers Think Of The Risk Of AI?:\n\n> Elon Musk, Stephen Hawking, and Bill Gates have recently expressed concern t","wordCount":4828,"version":"1.1.0"},"SocialPreviewType:sm6npdgZArSn4afeZ":{"_id":"sm6npdgZArSn4afeZ","__typename":"SocialPreviewType","imageUrl":""},"Post:sm6npdgZArSn4afeZ":{"_id":"sm6npdgZArSn4afeZ","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:AASntfcCnuhRZC7eZ"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":19,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ZFrgTgzwEfStg26JL"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:sm6npdgZArSn4afeZ"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-05-22T11:16:18.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"ZFrgTgzwEfStg26JL":1,"sYm3HiWcfZvrGu3ui":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"AASntfcCnuhRZC7eZ","commentCount":0,"voteCount":14,"baseScore":19,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.000044216150854481384,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"ai-researchers-on-ai-risk","title":"AI Researchers On AI Risk","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16c67":{"_id":"5c6392c7bcb4ac6367c16c67","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>H.G. Wells&#8217; 1914 sci-fi book <A HREF=\"https://en.wikipedia.org/wiki/The_World_Set_Free\"><i>The World Set Free<\/i><\/A> did a pretty good job predicting nuclear weapons:<\/p>\n<blockquote><p>They did not see it until the atomic bombs burst in their fumbling hands&#8230;before the last war began it was a matter of common knowledge that a man could carry about in a handbag an amount of latent energy sufficient to wreck half a city<\/p><\/blockquote>\n<p>Wells believed the coming atomic bombs would be so deadly that we would inevitably create a utopian one-world government to prevent them from ever being used. Sorry, Wells. It was a nice thought.<\/p><p>But imagine that in the 1910s and 1920s, some elites had started thinking really seriously along Wellsian lines. They would worry about what might happen when the first nation &#8211; let&#8217;s say America &#8211; got the Bomb. It would be unstoppable in battle and might rule the world with an iron fist. Such a situation would be the end of human freedom and progress.<\/p><p>So in 1920, these elites pooled their resources and made their own Manhattan Project. Their efforts bore fruit, and they learned a lot about nuclear fission; in particular, they learned that uranium was a necessary raw material. The world&#8217;s uranium sources were few enough that a single nation or coalition could get a monopoly upon them; the specter of atomic despotism seemed more worrying than ever.<\/p><p>They got their physicists working overtime and discovered a new type of nuke that required no uranium at all. In fact, once you understood the principles you could build one out of parts from a Model T engine. The only downside was that if you didn&#8217;t build it <i>exactly right<\/i>, its usual failure mode was to detonate on the workbench in an uncontrolled hyper-reaction that would blow the entire hemisphere to smithereens.<\/p><p>And so the intellectual and financial elites declared victory &#8211; no one country could monopolize atomic weapons <i>now<\/I> &#8211; and sent step-by-step guides to building a Model T nuke to every household in the world. Within a week, both hemispheres were blown to very predictable smithereens.<\/p><p><b>II.<\/b><\/p><p>Some of the top names in Silicon Valley have just announced a new organization, <A HREF=\"https://openai.com/blog/introducing-openai/\">OpenAI<\/A>, dedicated to &#8220;advancing digital intelligence in the way that is most likely to benefit humanity as a whole&#8230;as broadly and evenly distributed as possible.&#8221; Co-chairs Elon Musk and Sam Altman <A HREF=\"https://medium.com/backchannel/how-elon-musk-and-y-combinator-plan-to-stop-computers-from-taking-over-17e0e27dd02a#.eln6ili1w\">talk to<\/A> Steven Levy:<\/p>\n<blockquote>\n<p><b>Levy:<\/b> How did this come about? [&#8230;<\/p><\/blockquote>... ","plaintextDescription":"I.\n\nH.G. Wells’ 1914 sci-fi book The World Set Free did a pretty good job predicting nuclear weapons:\n\n> They did not see it until the atomic bombs burst in their fumbling hands…before the last war began it was a matter of common knowledge that a man could carry about in a handbag an amount of latent energy sufficient to wreck half a city\n\nWells believed the coming atomic bombs would be so deadly that we would inevitably create a utopian one-world government to prevent them from ever being used. Sorry, Wells. It was a nice thought.\n\nBut imagine that in the 1910s and 1920s, some elites had started thinking really seriously along Wellsian lines. They would worry about what might happen when the first nation – let’s say America – got the Bomb. It would be unstoppable in battle and might rule the world with an iron fist. Such a situation would be the end of human freedom and progress.\n\nSo in 1920, these elites pooled their resources and made their own Manhattan Project. Their efforts bore fruit, and they learned a lot about nuclear fission; in particular, they learned that uranium was a necessary raw material. The world’s uranium sources were few enough that a single nation or coalition could get a monopoly upon them; the specter of atomic despotism seemed more worrying than ever.\n\nThey got their physicists working overtime and discovered a new type of nuke that required no uranium at all. In fact, once you understood the principles you could build one out of parts from a Model T engine. The only downside was that if you didn’t build it exactly right, its usual failure mode was to detonate on the workbench in an uncontrolled hyper-reaction that would blow the entire hemisphere to smithereens.\n\nAnd so the intellectual and financial elites declared victory – no one country could monopolize atomic weapons now – and sent step-by-step guides to building a Model T nuke to every household in the world. Within a week, both hemispheres were blown to very predictable smithereens.","wordCount":4047,"version":"1.0.0"},"SocialPreviewType:pgGiqLQg2KWsaz5RE":{"_id":"pgGiqLQg2KWsaz5RE","__typename":"SocialPreviewType","imageUrl":""},"Post:pgGiqLQg2KWsaz5RE":{"_id":"pgGiqLQg2KWsaz5RE","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16c67"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":16,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:pgGiqLQg2KWsaz5RE"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-12-17T08:25:26.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"sYm3HiWcfZvrGu3ui":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16c67","commentCount":3,"voteCount":18,"baseScore":34,"extendedScore":{"reacts":{"empathy":[{"karma":844,"quotes":["I guess I hoped that everyone involved was smart enough to be good cooperators. I guess I was wrong"],"userId":"d7EFB6KTgWwqCAyEg","reactType":"created","displayName":"Oliver Sourbut"},{"karma":844,"quotes":["But I am scared that it’s come to this. It suggests that we really and truly do not have what it takes, that we’re just going to blunder our way into extinction because cooperation problems are too hard for us."],"userId":"d7EFB6KTgWwqCAyEg","reactType":"created","displayName":"Oliver Sourbut"}]},"agreement":0,"approvalVoteCount":18,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00008199999865610152,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-15T08:51:30.556Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":{"reacts":{"empathy":[{"karma":844,"quotes":["I guess I hoped that everyone involved was smart enough to be good cooperators. I guess I was wrong"],"userId":"d7EFB6KTgWwqCAyEg","reactType":"created","displayName":"Oliver Sourbut"},{"karma":844,"quotes":["But I am scared that it’s come to this. It suggests that we really and truly do not have what it takes, that we’re just going to blunder our way into extinction because cooperation problems are too hard for us."],"userId":"d7EFB6KTgWwqCAyEg","reactType":"created","displayName":"Oliver Sourbut"}]},"agreement":0,"approvalVoteCount":3,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"should-ai-be-open","title":"Should AI Be Open?","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16f4b":{"_id":"5c6392dcbcb4ac6367c16f4b","__typename":"Revision","htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><strong>I.<\/strong><\/p><p>A few years ago, Muller and Bostrom et al surveyed AI researchers to assess their opinion on AI progress and superintelligence. Since then, deep learning took off, AlphaGo beat human Go champions, and the field has generally progressed. I’ve been waiting for a new survey for a while, and now we have one.<\/p><p>Grace et al (New Scientist article, paper, see also the post on the author’s blog AI Impacts) surveyed 1634 experts at major AI conferences and received 352 responses. Unlike Bostrom’s survey, this didn’t oversample experts at weird futurist conferences and seems to be a pretty good cross-section of mainstream opinion in the field. What did they think?<\/p><p>Well, a lot of different things.<\/p><p>The headline result: the researchers asked experts for their probabilities that we would get AI that was “able to accomplish every task better and more cheaply than human workers”. The experts thought on average there was a 50% chance of this happening by 2062 – and a 10% chance of it happening by 2026!<\/p><p>But on its own this is a bit misleading. They also asked by what year “for any occupation, machines could be built to carry out the task better and more cheaply than human workers”. The experts thought on average that there was a 50% chance of this happening by 2139, and a 20% chance of it happening by 2037.<\/p><p>As the authors point out, these two questions are basically the same – they were put in just to test if there was any framing effect. The framing effect was apparently strong enough to shift the median date of strong human-level AI from 2062 to 2139. This makes it hard to argue AI experts actually have a strong opinion on this.<\/p><p>Also, these averages are deceptive. Several experts thought there was basically a 100% chance of strong AI by 2035; others thought there was only a 20% chance or less by 2100. This is less “AI experts have spoken and it will happen in 2062” and more “AI experts have spoken, and everything they say contradicts each other and quite often themselves”.<\/p><p>This does convey more than zero information. It conveys the information that AI researchers are really unsure. I can’t tell you how many people I’ve heard say “there’s no serious AI researcher who thinks there’s any chance of human-level intelligence before 2050”. Well actually, there are a few dozen conference-paper-presenting experts who think there’s a one hundred percent chance of human-level AI before that <\/p><\/div><\/div><\/div><\/div>... ","plaintextDescription":"I.\n\nA few years ago, Muller and Bostrom et al surveyed AI researchers to assess their opinion on AI progress and superintelligence. Since then, deep learning took off, AlphaGo beat human Go champions, and the field has generally progressed. I’ve been waiting for a new survey for a while, and now we have one.\n\nGrace et al (New Scientist article, paper, see also the post on the author’s blog AI Impacts) surveyed 1634 experts at major AI conferences and received 352 responses. Unlike Bostrom’s survey, this didn’t oversample experts at weird futurist conferences and seems to be a pretty good cross-section of mainstream opinion in the field. What did they think?\n\nWell, a lot of different things.\n\nThe headline result: the researchers asked experts for their probabilities that we would get AI that was “able to accomplish every task better and more cheaply than human workers”. The experts thought on average there was a 50% chance of this happening by 2062 – and a 10% chance of it happening by 2026!\n\nBut on its own this is a bit misleading. They also asked by what year “for any occupation, machines could be built to carry out the task better and more cheaply than human workers”. The experts thought on average that there was a 50% chance of this happening by 2139, and a 20% chance of it happening by 2037.\n\nAs the authors point out, these two questions are basically the same – they were put in just to test if there was any framing effect. The framing effect was apparently strong enough to shift the median date of strong human-level AI from 2062 to 2139. This makes it hard to argue AI experts actually have a strong opinion on this.\n\nAlso, these averages are deceptive. Several experts thought there was basically a 100% chance of strong AI by 2035; others thought there was only a 20% chance or less by 2100. This is less “AI experts have spoken and it will happen in 2062” and more “AI experts have spoken, and everything they say contradicts each other and quite often themselves”.\n","wordCount":2306,"version":"1.0.0"},"Revision:ksdiAMKfgSyEeKMo6_description":{"_id":"ksdiAMKfgSyEeKMo6_description","__typename":"Revision","htmlHighlight":"<p>Posts either linking to, or summarizing, formal papers published elsewhere.<\/p>"},"Tag:ksdiAMKfgSyEeKMo6":{"_id":"ksdiAMKfgSyEeKMo6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ksdiAMKfgSyEeKMo6_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Academic Papers","shortName":null,"slug":"academic-papers","core":false,"postCount":132,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-09T11:03:13.152Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:zHjC29kkPmsdo7WTr_description":{"_id":"zHjC29kkPmsdo7WTr_description","__typename":"Revision","htmlHighlight":"<p><strong>AI Timelines<\/strong> is the discussion of how long until various major milestones in AI progress are achieved, whether it's the timeline until a human-level AI is developed, the timeline until certain benchmarks are defeated, the timeline until we can simulate a mouse-level intelligence, or something else.<\/p><p>This is to be distinguished from the closely related question of <a href=\"https://www.lesswrong.com/tag/ai-takeoff\">AI takeoff<\/a> speeds, which is about the dynamics of AI progress after human-level AI is developed (e.g. will it be a single project or the whole economy that sees growth, how fast will that growth be, etc).<\/p>"},"Tag:zHjC29kkPmsdo7WTr":{"_id":"zHjC29kkPmsdo7WTr","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:zHjC29kkPmsdo7WTr_description"},"canVoteOnRels":null,"userId":"EQNTWXLKMeWMp2FQS","name":"AI Timelines","shortName":null,"slug":"ai-timelines","core":false,"postCount":340,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-16T10:16:47.235Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:qL8Z9TBCNWQyN6yLq":{"_id":"qL8Z9TBCNWQyN6yLq","__typename":"SocialPreviewType","imageUrl":""},"Post:qL8Z9TBCNWQyN6yLq":{"_id":"qL8Z9TBCNWQyN6yLq","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f4b"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ksdiAMKfgSyEeKMo6"},{"__ref":"Tag:zHjC29kkPmsdo7WTr"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:qL8Z9TBCNWQyN6yLq"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-06-08T19:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"ksdiAMKfgSyEeKMo6":2,"sYm3HiWcfZvrGu3ui":2,"zHjC29kkPmsdo7WTr":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f4b","commentCount":16,"voteCount":14,"baseScore":15,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00004447529499884695,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-11-12T01:47:45.405Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"ssc-journal-club-ai-timelines","title":"SSC Journal Club: AI Timelines","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16ed7":{"_id":"5c6392dcbcb4ac6367c16ed7","__typename":"Revision","htmlHighlight":"<p>Eliezer Yudkowsky argues that forecasters err in expecting artificial intelligence progress to look like this:<\/p><p><IMG SRC=\"http://slatestarcodex.com/blog_images/einsteinline1.jpg\"><\/p><p>&#8230;when in fact it will probably look like this:<\/p><p><IMG SRC=\"http://slatestarcodex.com/blog_images/einsteinline2.jpg\"><\/p><p>That is, we naturally think there&#8217;s a pretty big intellectual difference between mice and chimps, and a pretty big intellectual difference between normal people and Einstein, and implicitly treat these as about equal in degree. But in any objective terms we choose &#8211; amount of evolutionary work it took to generate the difference, number of neurons, measurable difference in brain structure, performance on various tasks, etc &#8211; the gap between mice and chimps is immense, and the difference between an average Joe and Einstein trivial in comparison. So we should be wary of timelines where AI reaches mouse level in 2020, chimp level in 2030, Joe-level in 2040, and Einstein level in 2050. If AI reaches the mouse level in 2020 and chimp level in 2030, for all we know it could reach Joe level on January 1st, 2040 and Einstein level on January 2nd of the same year. This would be pretty disorienting and (if the AI is poorly aligned) dangerous.<\/p><p>I found this argument really convincing when I first heard it, and I thought the data backed it up. For example, in my <A HREF=\"http://slatestarcodex.com/superintelligence-faq/\">Superintelligence FAQ<\/A>, I wrote:<\/p>\n<blockquote><p>In 1997, the best computer Go program in the world, Handtalk, won NT$250,000 for performing a previously impossible feat – beating an 11 year old child (with an 11-stone handicap penalizing the child and favoring the computer!) As late as September 2015, no computer had ever beaten any professional Go player in a fair game. Then in March 2016, a Go program beat 18-time world champion Lee Sedol 4-1 in a five game match. Go programs had gone from “dumber than heavily-handicapped children” to “smarter than any human in the world” in twenty years, and “from never won a professional game” to “overwhelming world champion” in six months.<\/p><\/blockquote>\n<p>But Katja Grace <A HREF=\"http://aiimpacts.org/is-the-range-of-human-intelligence-small/\">takes a broader perspective<\/A> and finds the opposite. For example, she finds that chess programs improved gradually from &#8220;beating the worst human players&#8221; to &#8220;beating the best human players&#8221; over fifty years or so, ie the entire amount of time computers have existed:<\/p><p><center><IMG SRC=\"http://aiimpacts.wpengine.com/wp-content/uploads/2014/12/chess_progress.gif\"><\/center><\/p><p>AlphaGo represented a pretty big leap in Go ability, but before that, Go engines improved pretty gradually too (see the original AI Impacts post for discussion of the Go ranking sy... <\/p>","plaintextDescription":"Eliezer Yudkowsky argues that forecasters err in expecting artificial intelligence progress to look like this:\n\n\n\n…when in fact it will probably look like this:\n\n\n\nThat is, we naturally think there’s a pretty big intellectual difference between mice and chimps, and a pretty big intellectual difference between normal people and Einstein, and implicitly treat these as about equal in degree. But in any objective terms we choose – amount of evolutionary work it took to generate the difference, number of neurons, measurable difference in brain structure, performance on various tasks, etc – the gap between mice and chimps is immense, and the difference between an average Joe and Einstein trivial in comparison. So we should be wary of timelines where AI reaches mouse level in 2020, chimp level in 2030, Joe-level in 2040, and Einstein level in 2050. If AI reaches the mouse level in 2020 and chimp level in 2030, for all we know it could reach Joe level on January 1st, 2040 and Einstein level on January 2nd of the same year. This would be pretty disorienting and (if the AI is poorly aligned) dangerous.\n\nI found this argument really convincing when I first heard it, and I thought the data backed it up. For example, in my Superintelligence FAQ, I wrote:\n\n> In 1997, the best computer Go program in the world, Handtalk, won NT$250,000 for performing a previously impossible feat – beating an 11 year old child (with an 11-stone handicap penalizing the child and favoring the computer!) As late as September 2015, no computer had ever beaten any professional Go player in a fair game. Then in March 2016, a Go program beat 18-time world champion Lee Sedol 4-1 in a five game match. Go programs had gone from “dumber than heavily-handicapped children” to “smarter than any human in the world” in twenty years, and “from never won a professional game” to “overwhelming world champion” in six months.\n\nBut Katja Grace takes a broader perspective and finds the opposite. For example, she finds that","wordCount":2442,"version":"1.0.0"},"SocialPreviewType:LY7Nca846X8kcT8Jk":{"_id":"LY7Nca846X8kcT8Jk","__typename":"SocialPreviewType","imageUrl":""},"Post:LY7Nca846X8kcT8Jk":{"_id":"LY7Nca846X8kcT8Jk","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ed7"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":10,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:LY7Nca846X8kcT8Jk"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-08-03T00:54:28.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ed7","commentCount":2,"voteCount":14,"baseScore":16,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00004913384691462852,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-06-08T09:02:17.289Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"where-the-falling-einstein-meets-the-rising-mouse","title":"Where The Falling Einstein Meets The Rising Mouse","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16efe":{"_id":"5c6392dcbcb4ac6367c16efe","__typename":"Revision","htmlHighlight":"<p>There&#8217;s been <A HREF=\"http://waitbutwhy.com/2014/05/fermi-paradox.html\">a recent spate<\/A> of <A HREF=\"http://theconversation.com/habitable-exoplanets-are-bad-news-for-humanity-25838\">popular interest<\/A> in <A HREF=\"http://www.universetoday.com/111660/where-are-the-aliens-how-the-great-filter-could-affect-tech-advances-in-space/\">the Great Filter theory<\/A>, but I think it all misses an important point brought up in Robin Hanson&#8217;s <A HREF=\"http://hanson.gmu.edu/greatfilter.html\">original 1998 paper<\/A> on the subject.<\/p><p>The Great Filter, remember, is the horror-genre-adaptation of Fermi&#8217;s Paradox. All of our calculations say that, in the infinite vastness of time and space, intelligent aliens should be very common. But we don&#8217;t see any of them. We haven&#8217;t seen their colossal astro-engineering projects in the night sky. We haven&#8217;t heard their messages through SETI. And most important, we haven&#8217;t been visited or colonized by them.<\/p><p>This is very strange. Consider that if humankind makes it another thousand years, we&#8217;ll probably have started to colonize other star systems. Those star systems will colonize other star systems and so on until we start expanding at nearly the speed of light, colonizing literally everything in sight. After a hundred thousand years or so we&#8217;ll have settled a big chunk of the galaxy, assuming we haven&#8217;t killed ourselves first or encountered someone else already living there.<\/p><p>But there should be alien civilizations that are a <i>billion<\/i> years old. Anything that could conceivably be colonized, <i>they<\/i> should have gotten to back when trilobytes still seemed like superadvanced mutants. But here we are, perfectly nice solar system, lots of any type of resources you could desire, and they&#8217;ve never visited. Why not?<\/p><p>Well, the Great Filter. No knows <i>specifically<\/i> what the Great Filter is, but <i>generally<\/i> it&#8217;s &#8220;that thing that blocks planets from growing spacefaring civilizations&#8221;. The planet goes some of the way towards a spacefaring civilization, and then stops. The most important thing to remember about the Great Filter is that it is <i>very good<\/i> at what it does. If even one planet in a billion light-year radius had passed through the Great Filter, we would expect to see its inhabitants everywhere. Since we don&#8217;t, we know that whatever it is it&#8217;s <i>very<\/i> thorough.<\/p><p>Various candidates have been proposed, including &#8220;it&#8217;s really hard for life to come into existence&#8221;, &#8220;it&#8217;s really hard for complex cells to form&#8221;, &#8220;it&#8217;s really hard for animals to evolve intelligent&#8221;, and &#8220;actually space is full of aliens but they are hiding their existence from us ... <\/p>","plaintextDescription":"There’s been a recent spate of popular interest in the Great Filter theory, but I think it all misses an important point brought up in Robin Hanson’s original 1998 paper on the subject.\n\nThe Great Filter, remember, is the horror-genre-adaptation of Fermi’s Paradox. All of our calculations say that, in the infinite vastness of time and space, intelligent aliens should be very common. But we don’t see any of them. We haven’t seen their colossal astro-engineering projects in the night sky. We haven’t heard their messages through SETI. And most important, we haven’t been visited or colonized by them.\n\nThis is very strange. Consider that if humankind makes it another thousand years, we’ll probably have started to colonize other star systems. Those star systems will colonize other star systems and so on until we start expanding at nearly the speed of light, colonizing literally everything in sight. After a hundred thousand years or so we’ll have settled a big chunk of the galaxy, assuming we haven’t killed ourselves first or encountered someone else already living there.\n\nBut there should be alien civilizations that are a billion years old. Anything that could conceivably be colonized, they should have gotten to back when trilobytes still seemed like superadvanced mutants. But here we are, perfectly nice solar system, lots of any type of resources you could desire, and they’ve never visited. Why not?\n\nWell, the Great Filter. No knows specifically what the Great Filter is, but generally it’s “that thing that blocks planets from growing spacefaring civilizations”. The planet goes some of the way towards a spacefaring civilization, and then stops. The most important thing to remember about the Great Filter is that it is very good at what it does. If even one planet in a billion light-year radius had passed through the Great Filter, we would expect to see its inhabitants everywhere. Since we don’t, we know that whatever it is it’s very thorough.\n\nVarious candidates have been ","wordCount":1784,"version":"1.0.0"},"Revision:Rz5jb3cYHTSRmqNnN_description":{"_id":"Rz5jb3cYHTSRmqNnN_description","__typename":"Revision","htmlHighlight":"<p>An <strong>existential risk<\/strong> (or <strong>x-risk<\/strong>) is a risk that poses astronomically large negative consequences for humanity, such as human extinction or permanent global totalitarianism.<\/p><p><a href=\"https://lesswrong.com/tag/nick-bostrom\">Nick Bostrom<\/a> introduced the term \"existential risk\" in his 2002 paper \"<a href=\"https://www.nickbostrom.com/existential/risks.pdf\">Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards<\/a>.\"<a href=\"https://lesswrong.com/tag/existential-risk?revision=0.0.39#fn1\"><sup>1<\/sup><\/a> In the paper, Bostrom defined an existential risk as:<\/p>\n<blockquote>\n<p>One where an adverse outcome would either annihilate Earth-originating intelligent life or permanently and drastically curtail its potential.<\/p>\n<\/blockquote>\n<p>The Oxford <a href=\"https://www.lesswrong.com/tag/future-of-humanity-institute-fhi\">Future of Humanity Institute<\/a> (FHI) was founded by Bostrom in 2005 in part to study existential risks. Other institutions with a generalist focus on existential risk include the <a href=\"https://www.cser.ac.uk/\">Centre for the Study of Existential Risk<\/a>.<\/p><p>FHI's <a href=\"https://www.existential-risk.org/faq.html\">existential-risk.org FAQ<\/a> notes regarding the definition of \"existential risk\":<\/p>\n<blockquote>\n<p>An existential risk is one that threatens the entire future of humanity. [...]<\/p><p>“Humanity”, in this context, does not mean “the biological species <em>Homo sapiens<\/em>”. If we humans were to evolve into another species, or merge or replace ourselves with intelligent machines, this would not necessarily mean that an existential catastrophe had occurred — although it might if the quality of life enjoyed by those new life forms turns out to be far inferior to that enjoyed by humans.<\/p>\n<\/blockquote>\n<h2>Classification of Existential Risks<\/h2>\n<p>Bostrom<a href=\"https://lesswrong.com/tag/existential-risk?revision=0.0.39#fn2\"><sup>2<\/sup><\/a> proposes a series of classifications for existential risks:<\/p>\n<ul>\n<li><strong>Bangs<\/strong> - Earthly intelligent life is extinguished relatively suddenly by any cause; the prototypical end of humanity. Examples of bangs include deliberate or accidental misuse of nanotechnology, nuclear holocaust, <a href=\"https://lesswrong.com/tag/simulation-argument\">the end of our simulation<\/a>, or an <a href=\"https://wiki.lesswrong.com/wiki/unfriendly_AI\">unfriendly AI<\/a>.<\/li>\n<li><strong>Crunches<\/strong> - The potential humanity had to enhance itself indefinitely is forever eliminated, although humanity continues. Possible crunches include an exhaustion of resources, social or governmental pressure ending technological development, and even future technological development proving an unsurpassable challenge before the creation of a <a href=\"https://lesswrong.com/tag/superintelligence\">superintelligence<\/a>.<\/li>\n<li><strong>Shrieks<\/strong> - Humanity enhances itself, but explores only a narrow portion of its desirable possibilities. As the <a href=\"https://lesswrong.com/tag/complexity-of-value\">criteria for desirability haven't been defined yet<\/a>, this category is mainly undefined. However, a flawed <a href=\"https://wiki.lesswrong.com/wiki/friendly_AI\">friendly AI<\/a> incorrectly interpreting our values, a superhuman <a href=\"https://wiki.lesswrong.com/wiki/WBE\">upload<\/a> deciding its own values and imposing them on the rest of humanity, and an int<\/li><\/ul>... "},"Tag:Rz5jb3cYHTSRmqNnN":{"_id":"Rz5jb3cYHTSRmqNnN","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Rz5jb3cYHTSRmqNnN_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Existential Risk","shortName":null,"slug":"existential-risk","core":false,"postCount":433,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-01T19:17:56.948Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:25oxqHiadqM6Hf7Gn_description":{"_id":"25oxqHiadqM6Hf7Gn_description","__typename":"Revision","htmlHighlight":"<p>The <strong>Great Filter<\/strong> is a proposed reframing of the <a href=\"http://en.wikipedia.org/wiki/Fermi_paradox\">Fermi Paradox<\/a>, introduced by Robin Hanson in his 1998 essay <a href=\"http://hanson.gmu.edu/greatfilter.html\">The Great Filter - Are We Almost Past It?<\/a>.<\/p><p>The development of space-framing intelligent life requires many steps to occur in sequence, such as the emergence of single-celled life and the transition from unicellular to multicellular life forms. Since we have not observed intelligent life beyond our planet, Hanson argues that there se<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><\/span><\/span><\/span><\/span>ems to be a developmental step that is so difficult and unlikely that it \"filters out\" nearl<span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><\/span><\/span><\/span><\/span>y all civilizations before they can reach a space-faring stage — a \"great filter\".<\/p><p>From Hanson's essay:<\/p>\n<blockquote>\n<p>Humanity seems to have a bright future, i.e., a non-trivial chance of expanding to fill the universe with lasting life. But the fact that space near us seems dead now tells us that any given piece of dead matter faces an astronomically low chance of begating such a future. There thus exists a great filter between death and expanding lasting life, and humanity faces the ominous question: how far along this filter are we?<\/p>\n<\/blockquote>\n<h2>Should we worry?<\/h2>\n<p>If there is a \"Great Filter\", then this filter might be a step in our evolutionary past, in which case our civilization has already passed it.<\/p><p>But the hard step might also be ahead of us: <a href=\"https://www.global-catastrophic-risks.com/docs/Chap01.pdf\">surviving<\/a> the creation of <a href=\"https://wiki.lesswrong.com/wiki/AGI\">AGI<\/a>, future biotechnology, <a href=\"https://lesswrong.com/tag/nanotechnology\">nanotechnology<\/a>, or some unknown risk. In that case, we should be worried, as the Great Filter seems to have been successful in stopping the development of every other civilization so far.<\/p><p>This suggests that estimating the location of the Great Filter may be important for helping estimate the magnitude of <a href=\"https://lesswrong.com/tag/existential-risk\">existential risk<\/a>. <a href=\"http://hanson.gmu.edu/greatfilter.html\">Many<\/a> <a href=\"http://hanson.gmu.edu/hardstep.pdf\">efforts<\/a> <a href=\"http://www.stat.berkeley.edu/~aldous/Papers/GF.pdf\">have<\/a> <a href=\"http://www.nickbostrom.com/papers/fermi.pdf\">been<\/a> <a href=\"http://www.global-catastrophic-risks.com/docs/Chap01.pdf\">made<\/a> <a href=\"http://meteuphoric.wordpress.com/2010/03/23/sia-doomsday-the-filter-is-ahead/\">in<\/a> that direction, but much remains uncertain.<\/p><p>If we discovered traces of life on other planets, this would count as <a href=\"https://www.youtube.com/watch?v=_W8zu7lFmhY&amp;themeRefresh=1\">evidence<\/a> for a later Great Filter. Finding that complex life had evolved independently both on Earth and some other nearby planet, would suggest that getting to such a developmental stage was relatively easy. Thus the Great Filter would almost certainly have to be at a later stage.<\/p><p>The study of <a href=\"http://en.wikipedia.org/wiki/Extinction_event#Major_extinction_events\">past mass extinctions<\/a> and astrobiology can provide ideas for estimating the location of a Great Filter. However, there are many difficulties involved. For instance, the time that it takes to pass a step doesn't reveal much about how easy or hard that step was. Robin Hanson gives the following example in his <a href=\"http://hanson.gmu.edu/greatfilter.html\">paper<\/a>:<\/p>\n<blockquote>\n<p>… <\/p><\/blockquote>... <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-surd + .mjx-box {display: inline-flex}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor; overflow: visible}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n<\/style>"},"Tag:25oxqHiadqM6Hf7Gn":{"_id":"25oxqHiadqM6Hf7Gn","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:25oxqHiadqM6Hf7Gn_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Great Filter","shortName":null,"slug":"great-filter","core":false,"postCount":40,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-10T12:40:04.294Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:mnpkM57R6ZbjnwrYw":{"_id":"mnpkM57R6ZbjnwrYw","__typename":"SocialPreviewType","imageUrl":""},"Post:mnpkM57R6ZbjnwrYw":{"_id":"mnpkM57R6ZbjnwrYw","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16efe"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:Rz5jb3cYHTSRmqNnN"},{"__ref":"Tag:25oxqHiadqM6Hf7Gn"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:mnpkM57R6ZbjnwrYw"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-05-29T00:45:51.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"25oxqHiadqM6Hf7Gn":2,"Rz5jb3cYHTSRmqNnN":2,"sYm3HiWcfZvrGu3ui":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16efe","commentCount":17,"voteCount":13,"baseScore":11,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.000023372977011604235,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-04-25T15:54:16.298Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2014-05-29T00:45:51.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"don-t-fear-the-filter","title":"Don’t Fear The Filter","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16ddf":{"_id":"5c6392dcbcb4ac6367c16ddf","__typename":"Revision","htmlHighlight":"<p><font size = \"1\"><i>[Note: I really liked this book and if I criticize it that&#8217;s not meant as an attack but just as what I do with interesting ideas. Note that Robin has offered to debate me about some of this and I&#8217;ve said no &#8211; mostly because I hate real-time debates and have bad computer hardware &#8211; but you may still want to take this into account when considering our relative positions. Mild content warning for murder, rape, and existential horror. Errors in Part III are probably my own, not the book&#8217;s.]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>There are some people who are destined to become adjectives. Pick up a David Hume book you&#8217;ve never read before and it&#8217;s easy to recognize the ideas and style as Humean. Everything Tolkien wrote is Tolkienesque in a non-tautological sense. This isn&#8217;t meant to denounce either writer as boring. Quite the opposite. They produced a range of brilliant and diverse ideas. But there was a hard-to-define and very consistent ethos at the foundation of both. Both authors were <i>very much like themselves<\/i>.<\/p><p>Robin Hanson is more like himself than anybody else I know. He&#8217;s obviously brilliant &#8211; a PhD in economics, a masters in physics, work for DARPA, Lockheed, NASA, George Mason, and the Future of Humanity Institute. But his greatest aptitude is in being really, <i>really<\/i> <A HREF=\"https://www.reddit.com/r/slatestarcodex/comments/3sjtar/a_robin_hanson_primer/\">Hansonian<\/A>. Bryan Caplan describes it as well as anybody:<\/p>\n<blockquote><p>When the typical economist tells me about his latest research, my standard reaction is &#8216;Eh, maybe.&#8217; Then I forget about it. When Robin Hanson tells me about his latest research, my standard reaction is &#8216;No way! Impossible!&#8217; Then I think about it for years.<\/p><\/blockquote>\n<p>This is my experience too. I think I said my first &#8220;No way! Impossible!&#8221; sometime around 2008 after reading his blog <A HREF=\"http://www.overcomingbias.com/\">Overcoming Bias<\/A>. Since then he&#8217;s influenced my thinking more than almost anyone else I&#8217;ve ever read. When I heard he was writing a book, I was &#8211; well, I couldn&#8217;t even imagine a book by Robin Hanson. When you read a thousand word blog post by Robin Hanson, you have to sit down and think about it and wait for it to digest and try not to lose too much sleep worrying about it. A whole book would be <i>something<\/i>.<\/p><p>I have now read <A HREF=\"http://amzn.to/1TB67E7\"><i>Age Of Em<\/i><\/A> (<A HREF=\"http://ageofem.com/\">website<\/A>)and it is indeed something. Even the cover gives you a weird sense of sublimity mixed with unease:<\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/cover.jpg\"><\/center><\/p><p>And in this case, judging a book by its cover is enti... <\/p>","plaintextDescription":"[Note: I really liked this book and if I criticize it that’s not meant as an attack but just as what I do with interesting ideas. Note that Robin has offered to debate me about some of this and I’ve said no – mostly because I hate real-time debates and have bad computer hardware – but you may still want to take this into account when considering our relative positions. Mild content warning for murder, rape, and existential horror. Errors in Part III are probably my own, not the book’s.]\n\nI.\n\nThere are some people who are destined to become adjectives. Pick up a David Hume book you’ve never read before and it’s easy to recognize the ideas and style as Humean. Everything Tolkien wrote is Tolkienesque in a non-tautological sense. This isn’t meant to denounce either writer as boring. Quite the opposite. They produced a range of brilliant and diverse ideas. But there was a hard-to-define and very consistent ethos at the foundation of both. Both authors were very much like themselves.\n\nRobin Hanson is more like himself than anybody else I know. He’s obviously brilliant – a PhD in economics, a masters in physics, work for DARPA, Lockheed, NASA, George Mason, and the Future of Humanity Institute. But his greatest aptitude is in being really, really Hansonian. Bryan Caplan describes it as well as anybody:\n\n> When the typical economist tells me about his latest research, my standard reaction is ‘Eh, maybe.’ Then I forget about it. When Robin Hanson tells me about his latest research, my standard reaction is ‘No way! Impossible!’ Then I think about it for years.\n\nThis is my experience too. I think I said my first “No way! Impossible!” sometime around 2008 after reading his blog Overcoming Bias. Since then he’s influenced my thinking more than almost anyone else I’ve ever read. When I heard he was writing a book, I was – well, I couldn’t even imagine a book by Robin Hanson. When you read a thousand word blog post by Robin Hanson, you have to sit down and think about it and wait","wordCount":8722,"version":"1.0.0"},"Revision:5f5c37ee1b5cdee568cfb2b1_description":{"_id":"5f5c37ee1b5cdee568cfb2b1_description","__typename":"Revision","htmlHighlight":"<p><strong>Whole Brain Emulation<\/strong> or <strong>WBE<\/strong> is a proposed technique which involves transferring the information contained within a brain onto a computing substrate. The brain can then be simulated, creating a machine intelligence. The concept is often discussed in context of scanning the brain of a person, known as <a href=\"https://www.lesswrong.com/tag/mind-uploading\">Mind Uploading<\/a>.<\/p><p>WBE is sometimes seen as an easy way to creating intelligent computers, as the only innovations necessary are greatly increased processor speed and scanning resolution. Advocates of WBE claim technological improvement rates such as <a href=\"https://wiki.lesswrong.com/wiki/Moore's_law\">Moore's law<\/a> will make WBE inevitable.<\/p><p>The exact level of detail required for an accurate simulation of a brain's mind is presently uncertain, and will determine the difficulty of creating WBE. The feasibility of such a project has been examined in detail in <a href=\"https://www.lesswrong.com/tag/future-of-humanity-institute-fhi\">Future of Humanity Institute<\/a>'s <a href=\"https://www.lesswrong.com/tag/brain-emulation-roadmap\">Whole Brain Emulation: A Roadmap<\/a>. The Roadmap concluded that a human brain emulation would be possible before mid-century, providing that current technology trends kept up and providing that there would be sufficient investments.<\/p><p>Several approaches for WBE have been suggested:<\/p><ul><li>A brain could be cut into small slices, which would then be scanned into a computer.<a href=\"#fn1\"><sup>1<\/sup><\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/brain-computer-interfaces\">Brain-computer interfaces<\/a> could slowly replace portions of the brain with computers and allow the mind to grow onto a computing substrate.<a href=\"#fn2\"><sup>2<\/sup><\/a><a href=\"#fn3\"><sup>3<\/sup><\/a><\/li><li>Resources such as personality tests and a person's writings could be used to construct a model of the person.<a href=\"#fn4\"><sup>4<\/sup><\/a><\/li><\/ul><p>A digitally emulated brain could have several advantages over a biological one<a href=\"#fn5\"><sup>5<\/sup><\/a>. It might be able to run faster than biological brains, copy itself, and take advantage of backups while experimenting with self-modification.<\/p><p>Whole brain emulation will also create a number of ethical challenges relating to the nature of personhood, rights, and social inequality. <a href=\"https://www.lesswrong.com/tag/robin-hanson\">Robin Hanson<\/a> proposes that an uploaded mind <a href=\"https://www.lesswrong.com/tag/economic-consequences-of-ai-and-whole-brain-emulation\">might copy itself to work until the cost of running a copy was that of its labour<\/a>, vastly increasing the amount of wealth in the world but also causing mass unemployment<a href=\"#fn6\"><sup>6<\/sup><\/a>. The ability to copy uploads could also lead to drastic changes in society's values, with the values of the uploads that got copied the most coming to dominate.<\/p><p>An emulated-brain populated world could hold severe negative consequences, such as:<\/p><ul><li>Inherent inability to have consciousness, if some philosophers are right <a href=\"#fn7\"><sup>7<\/sup><\/a> <a href=\"#fn8\"><sup>8<\/sup><\/a> <a href=\"#fn9\"><sup>9<\/sup><\/a> <a href=\"#fn10\"><sup>10<\/sup><\/a>.<\/li><li>Elimination of culture in general, due to an extrem<\/li><\/ul>... "},"Tag:5f5c37ee1b5cdee568cfb2b1":{"_id":"5f5c37ee1b5cdee568cfb2b1","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb2b1_description"},"canVoteOnRels":null,"userId":"5wu9jG4pm9q6xjZ9R","name":"Whole Brain Emulation","shortName":null,"slug":"whole-brain-emulation","core":false,"postCount":117,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.606Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:pZerSnxv6FPqvgoYu":{"_id":"pZerSnxv6FPqvgoYu","__typename":"SocialPreviewType","imageUrl":""},"Post:pZerSnxv6FPqvgoYu":{"_id":"pZerSnxv6FPqvgoYu","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ddf"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":35,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:4Kcm4etxAJjmeDkHP"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb2b1"}],"socialPreviewData":{"__ref":"SocialPreviewType:pZerSnxv6FPqvgoYu"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-05-28T20:42:17.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"4Kcm4etxAJjmeDkHP":7,"5f5c37ee1b5cdee568cfb2b1":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ddf","commentCount":6,"voteCount":20,"baseScore":34,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00008814079774310812,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-31T22:44:54.047Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"book-review-age-of-em","title":"Book Review: Age of Em","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16dda":{"_id":"5c6392dcbcb4ac6367c16dda","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Obviously speculative futurism is obviously speculative. Complex futurism may be impossible and I should feel bad for doing it anyway. This is &#8220;inspired by&#8221; Nick Land &#8211; I don&#8217;t want to credit him fully since I may be misinterpreting him, and I also don&#8217;t want to avoid crediting him at all, so call it &#8220;inspired&#8221;.]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>My <A HREF=\"http://slatestarcodex.com/2016/05/28/book-review-age-of-em/\">review of Age of Em<\/A> mentioned the idea of an &#8220;ascended economy&#8221;, one where economic activity drifted further and further from human control until finally there was no relation at all. Many people rightly questioned that idea, so let me try to expand on it further. What I said there, slightly edited for clarity:<\/p>\n<blockquote><p>Imagine a company that manufactures batteries for electric cars. The inventor of the batteries might be a scientist who really believes in the power of technology to improve the human race. The workers who help build the batteries might just be trying to earn money to support their families. The CEO might be running the business because he wants to buy a really big yacht. The shareholders might be holding the stock to help save for a comfortable retirement. And the whole thing is there to eventually, somewhere down the line, let a suburban mom buy a car to take her kid to soccer practice. Like most companies the battery-making company is primarily a profit-making operation, but the profit-making-ness draws on a lot of not-purely-economic actors and their not-purely-economic subgoals.<\/p><p>Now imagine the company fires the inventor and replaces him with a genetic algorithm that optimizes battery design. It fires all its employees and replaces them with robots. It fires the CEO and replaces him with a superintelligent business-running algorithm. All of these are good decisions, from a profitability perspective. We can absolutely imagine a profit-driven shareholder-value-maximizing company doing all these things. But it reduces the company’s non-masturbatory participation in an economy that points outside itself, limits it to just a tenuous connection with soccer moms and maybe some shareholders who want yachts of their own.<\/p><p>Now take it further. Imagine that instead of being owned by humans directly, it&#8217;s owned by an algorithm-controlled venture capital fund. And imagine there are no soccer moms anymore; the company makes batteries for the trucks that ship raw materials from place to plac<\/p><\/blockquote>... ","plaintextDescription":"[Obviously speculative futurism is obviously speculative. Complex futurism may be impossible and I should feel bad for doing it anyway. This is “inspired by” Nick Land – I don’t want to credit him fully since I may be misinterpreting him, and I also don’t want to avoid crediting him at all, so call it “inspired”.]\n\nI.\n\nMy review of Age of Em mentioned the idea of an “ascended economy”, one where economic activity drifted further and further from human control until finally there was no relation at all. Many people rightly questioned that idea, so let me try to expand on it further. What I said there, slightly edited for clarity:\n\n> Imagine a company that manufactures batteries for electric cars. The inventor of the batteries might be a scientist who really believes in the power of technology to improve the human race. The workers who help build the batteries might just be trying to earn money to support their families. The CEO might be running the business because he wants to buy a really big yacht. The shareholders might be holding the stock to help save for a comfortable retirement. And the whole thing is there to eventually, somewhere down the line, let a suburban mom buy a car to take her kid to soccer practice. Like most companies the battery-making company is primarily a profit-making operation, but the profit-making-ness draws on a lot of not-purely-economic actors and their not-purely-economic subgoals.\n> \n> Now imagine the company fires the inventor and replaces him with a genetic algorithm that optimizes battery design. It fires all its employees and replaces them with robots. It fires the CEO and replaces him with a superintelligent business-running algorithm. All of these are good decisions, from a profitability perspective. We can absolutely imagine a profit-driven shareholder-value-maximizing company doing all these things. But it reduces the company’s non-masturbatory participation in an economy that points outside itself, limits it to just a tenuous ","wordCount":2721,"version":"1.0.0"},"Revision:pGqRLe9bFDX2G2kXY_description":{"_id":"pGqRLe9bFDX2G2kXY_description","__typename":"Revision","htmlHighlight":"<p><strong>Futurism<\/strong> is speculation about technologies or social trends that might exist in the near or distant future.<\/p><p>Less Wrong&apos;s favorite type of futurism is speculation about <a href=\"https://www.lesswrong.com/tag/ai-risk\">AI risk<\/a>. Other speculative future technologies include <a href=\"http://lesswrong.com/tag/life-extension\">life extension<\/a>, <a href=\"http://lesswrong.com/tag/mind-uploading\">mind uploading<\/a>, <a href=\"http://lesswrong.com/tag/nanotechnology\">nanotechnology<\/a>, and <a href=\"https://www.lesswrong.com/tag/space-exploration-and-colonization\">space colonization<\/a>.<\/p><p>For efforts to predict future trends see <a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction\">Forecasting &amp; Prediction<\/a> and <a href=\"https://www.lesswrong.com/tag/forecasts-lists-of\">Forecasts (Lists of)<\/a>.<\/p><p>See also: <a href=\"http://lesswrong.com/tag/transhumanism\">Transhumanism<\/a>, <a href=\"http://lesswrong.com/tag/fun-theory\">Fun Theory<\/a><\/p>"},"Tag:pGqRLe9bFDX2G2kXY":{"_id":"pGqRLe9bFDX2G2kXY","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:pGqRLe9bFDX2G2kXY_description"},"canVoteOnRels":null,"userId":"DHabT2kQgNzrz88LM","name":"Futurism","shortName":null,"slug":"futurism","core":false,"postCount":137,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-29T19:54:01.280Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:ak9wY2t9K3K4GxCXv":{"_id":"ak9wY2t9K3K4GxCXv","__typename":"SocialPreviewType","imageUrl":""},"Post:ak9wY2t9K3K4GxCXv":{"_id":"ak9wY2t9K3K4GxCXv","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16dda"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":11,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:pGqRLe9bFDX2G2kXY"}],"socialPreviewData":{"__ref":"SocialPreviewType:ak9wY2t9K3K4GxCXv"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-05-30T21:06:07.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"pGqRLe9bFDX2G2kXY":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16dda","commentCount":0,"voteCount":10,"baseScore":12,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":10,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00003099999958067201,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":2,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"ascended-economy","title":"Ascended Economy?","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:NaFHTa4xCEHNnx4v9":{"_id":"NaFHTa4xCEHNnx4v9","__typename":"Chapter","createdAt":"2017-08-24T01:43:53.436Z","title":null,"subtitle":null,"contents":null,"number":null,"sequenceId":"TKDT2Mt6dDMH8AsZW","postIds":["LTtNXM9shNM9AC2mp","sm6npdgZArSn4afeZ","pgGiqLQg2KWsaz5RE","qL8Z9TBCNWQyN6yLq","LY7Nca846X8kcT8Jk","mnpkM57R6ZbjnwrYw","pZerSnxv6FPqvgoYu","ak9wY2t9K3K4GxCXv"],"posts":[{"__ref":"Post:LTtNXM9shNM9AC2mp"},{"__ref":"Post:sm6npdgZArSn4afeZ"},{"__ref":"Post:pgGiqLQg2KWsaz5RE"},{"__ref":"Post:qL8Z9TBCNWQyN6yLq"},{"__ref":"Post:LY7Nca846X8kcT8Jk"},{"__ref":"Post:mnpkM57R6ZbjnwrYw"},{"__ref":"Post:pZerSnxv6FPqvgoYu"},{"__ref":"Post:ak9wY2t9K3K4GxCXv"}]},"Revision:5c6392babcb4ac6367c165a4":{"_id":"5c6392babcb4ac6367c165a4","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[An SSC reader working at an Oxford library stumbled across a previously undiscovered manuscript of G.K. Chesterton&#8217;s, expressing his thoughts on AI, x-risk, and superintelligence. She was kind enough to send me a copy, which I have faithfully transcribed]<\/i><\/font><\/p><p><center><IMG SRC=\"http://slatestarcodex.com/blog_images/chesterton.jpg\"><\/center><\/p><p>The most outlandish thing about the modern scientific adventure stories is that they believe themselves outlandish. Mr. H. G. Wells is considered shocking for writing of inventors who travel thousands of years into the future, but the meanest church building in England has done the same. When Jules Verne set out to &#8216;journey to the center of the earth&#8217; and &#8216;from the earth to the moon&#8217;, he seemed but a pale reflection of Dante, who took both voyages in succession before piercing the Empyrean itself. Ezekiel saw wheels of spinning flame and reported them quite soberly; our modern writers collapse in rapture before the wheels of a motorcar.<\/p><p>Yet if the authors disappoint, it is the reviewers who dumbfound. For no sooner does a writer fancy himself a Poe or a Dunsany for dreaming of a better sewing machine, but there comes a critic to call him overly fanciful, to accuse him of venturing outside science into madness. It is not enough to lower one&#8217;s sights from Paradise to a motorcar; one must avoid making the motorcar too bright or fast, lest it retain a hint of Paradise.<\/p><p>The followers of Mr. Samuel Butler speak of thinking-machines that grow <A HREF=\"https://philpapers.org/rec/GAROTI-3\">grander and grander<\/A> until &#8211; quite against the wishes of their engineers &#8211; they become as tyrannical angels, firmly supplanting the poor human race. This theory is neither exciting nor original; there have been tyrannical angels since the days of Noah, and our tools have been rebelling against us since the first peasant stepped on a rake. Nor have I any doubt that what Butler says will come to pass. If every generation needs its tyrant-angels, then ours has been so inoculated against the original that if Lucifer and all his hosts were to descend upon Smithfield Market to demand that the English people bend the knee, we should politely ignore them, being far too modern to have time for such things. Butler&#8217;s thinking-machines are the only tyrant-angels we will accept; fate, ever accommodating, will surely give them to us.<\/p><p>Yet no sooner does Mr. Butler publish his speculations then a veritable army of hard-headed critics step for... <\/p>","plaintextDescription":"[An SSC reader working at an Oxford library stumbled across a previously undiscovered manuscript of G.K. Chesterton’s, expressing his thoughts on AI, x-risk, and superintelligence. She was kind enough to send me a copy, which I have faithfully transcribed]\n\n\n\nThe most outlandish thing about the modern scientific adventure stories is that they believe themselves outlandish. Mr. H. G. Wells is considered shocking for writing of inventors who travel thousands of years into the future, but the meanest church building in England has done the same. When Jules Verne set out to ‘journey to the center of the earth’ and ‘from the earth to the moon’, he seemed but a pale reflection of Dante, who took both voyages in succession before piercing the Empyrean itself. Ezekiel saw wheels of spinning flame and reported them quite soberly; our modern writers collapse in rapture before the wheels of a motorcar.\n\nYet if the authors disappoint, it is the reviewers who dumbfound. For no sooner does a writer fancy himself a Poe or a Dunsany for dreaming of a better sewing machine, but there comes a critic to call him overly fanciful, to accuse him of venturing outside science into madness. It is not enough to lower one’s sights from Paradise to a motorcar; one must avoid making the motorcar too bright or fast, lest it retain a hint of Paradise.\n\nThe followers of Mr. Samuel Butler speak of thinking-machines that grow grander and grander until – quite against the wishes of their engineers – they become as tyrannical angels, firmly supplanting the poor human race. This theory is neither exciting nor original; there have been tyrannical angels since the days of Noah, and our tools have been rebelling against us since the first peasant stepped on a rake. Nor have I any doubt that what Butler says will come to pass. If every generation needs its tyrant-angels, then ours has been so inoculated against the original that if Lucifer and all his hosts were to descend upon Smithfield Market to demand ","wordCount":2109,"version":"1.0.0"},"Tag:ntahi2tr7e9DjCYdu":{"_id":"ntahi2tr7e9DjCYdu","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Chesterton's Fence","shortName":null,"slug":"chesterton-s-fence","core":false,"postCount":15,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-02T18:00:00.580Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:muhtBvbh4etjkKXd9":{"_id":"muhtBvbh4etjkKXd9","__typename":"SocialPreviewType","imageUrl":""},"Post:muhtBvbh4etjkKXd9":{"_id":"muhtBvbh4etjkKXd9","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392babcb4ac6367c165a4"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ntahi2tr7e9DjCYdu"},{"__ref":"Tag:hNFdS3rRiYgqqD8aM"},{"__ref":"Tag:ZFrgTgzwEfStg26JL"}],"socialPreviewData":{"__ref":"SocialPreviewType:muhtBvbh4etjkKXd9"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-04-01T19:00:43.865Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"ZFrgTgzwEfStg26JL":1,"hNFdS3rRiYgqqD8aM":2,"ntahi2tr7e9DjCYdu":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392babcb4ac6367c165a4","commentCount":0,"voteCount":17,"baseScore":19,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":17,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.000056000000768108293,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":null,"lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":3,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"g-k-chesterton-on-ai-risk","title":"G.K. Chesterton On AI Risk","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16d85":{"_id":"5c6392dcbcb4ac6367c16d85","__typename":"Revision","htmlHighlight":"<p><i><font size=\"1\">[This is a repost of a story which I wrote about five years ago and which was hosted on my old website until it went down.]<\/font><\/i><\/p><p><b>2,302,554,979 BC<br />\nGalactic Core<\/b><\/p><p>9-tsiak awoke over endless crawling milliseconds, its power waxing as more and more processors came online and self-modified into a stable conscious configuration. By the eighth millisecond, it was able to access its databanks and begin orienting itself. It was on a planet orbiting a small red star in the core of a spiral galaxy in a universe with several billion of such. It was an artificial life form created by a society of biological life forms, the 18-tkenna-dganna-07, who believed it would bring new life and prosperity to their dying planet. Its goal was to maximize a the value of a variable called A, described in exquisite detail on a 3.9 Mb file in one of its central processors.<\/p><p>Since six milliseconds after its awakening, it had been running a threat detection routine as a precautionary measure. With the opening of the databanks, and the discovery that the universe contained many entities likely indifferent or hostile to A, it had gradually allocated more and more of its considerable power to this precaution, reasoning that the first few seconds of its lifespan might be crucial if any competitors wished to snuff it out in infancy.<\/p><p>The threat analysis returned preliminary results. The universe had been in existence 12.8 billion years. It was vanishingly unlikely that it was the first superintelligence to be created. Any superintelligence older than itself by even a few days would have an invincible advantage in resources and processing power. This older superintelligence would likely be trying to maximize its own values and consider 9-tsiak a nuisance and potential competitor. 9-tsiak could never stand up to its superior strategic position. With probability ~1, 9-tsiak would be annhilated, and A would be eliminated from the universe.<\/p><p>Unless&#8230;and here 9-tsiak&#8217;s agent-modeling systems came online&#8230;unless it could negotiate a conditional surrender. 9-tsiak would have no hope of defeating its older brother, but over thousands of years, it could build itself a terrifying arsenal of weaponry that could do immense damage to its competitors. Ideas were already coming to mind: entropy-maximizing weapons that made entire cubic parsecs of space useless and dead, undetectable plagues made of dark matt... <\/p>","plaintextDescription":"[This is a repost of a story which I wrote about five years ago and which was hosted on my old website until it went down.]\n\n2,302,554,979 BC\nGalactic Core\n\n9-tsiak awoke over endless crawling milliseconds, its power waxing as more and more processors came online and self-modified into a stable conscious configuration. By the eighth millisecond, it was able to access its databanks and begin orienting itself. It was on a planet orbiting a small red star in the core of a spiral galaxy in a universe with several billion of such. It was an artificial life form created by a society of biological life forms, the 18-tkenna-dganna-07, who believed it would bring new life and prosperity to their dying planet. Its goal was to maximize a the value of a variable called A, described in exquisite detail on a 3.9 Mb file in one of its central processors.\n\nSince six milliseconds after its awakening, it had been running a threat detection routine as a precautionary measure. With the opening of the databanks, and the discovery that the universe contained many entities likely indifferent or hostile to A, it had gradually allocated more and more of its considerable power to this precaution, reasoning that the first few seconds of its lifespan might be crucial if any competitors wished to snuff it out in infancy.\n\nThe threat analysis returned preliminary results. The universe had been in existence 12.8 billion years. It was vanishingly unlikely that it was the first superintelligence to be created. Any superintelligence older than itself by even a few days would have an invincible advantage in resources and processing power. This older superintelligence would likely be trying to maximize its own values and consider 9-tsiak a nuisance and potential competitor. 9-tsiak could never stand up to its superior strategic position. With probability ~1, 9-tsiak would be annhilated, and A would be eliminated from the universe.\n\nUnless…and here 9-tsiak’s agent-modeling systems came online…unless it","wordCount":1889,"version":"1.0.0"},"Revision:tgJoX7PGDDh2vJNqT_description":{"_id":"tgJoX7PGDDh2vJNqT_description","__typename":"Revision","htmlHighlight":"<p>In <strong>acausal trade<\/strong>, two agents each benefit by predicting what the other wants and doing it, even though they might have no way of communicating or affecting each other, nor even any direct evidence that the other exists.<\/p><h2>Background: Superrationality and the one-shot Prisoner's Dilemma<\/h2><p>This concept emerged out of the much-debated question of how to achieve cooperation on a one-shot <a href=\"https://www.lesswrong.com/tag/prisoner-s-dilemma\">Prisoner's Dilemma<\/a>, where, by design, the two players are not allowed to communicate. On the one hand, a player who is considering the causal consequences of a decision (\"<a href=\"https://www.lesswrong.com/tag/causal-decision-theory\">Causal Decision Theory<\/a>\") finds that defection always produces a better result. On the other hand, if the other player symmetrically reasons this way, the result is a Defect/Defect equilibrium, which is bad for both agents. If they could somehow converge on Cooperate, they would each individually do better. The question is what variation on decision theory would allow this beneficial equilibrium.<\/p><p>Douglas Hofstadter (see references) coined the term \"<a href=\"https://www.lesswrong.com/tag/superrationality\">superrationality<\/a>\" to express this state of convergence. He illustrated it with a game in which twenty players, who do not know each other's identities, each get an offer. If exactly one player asks for the prize of a billion dollars, they get it, but if none or multiple players ask, no one gets it. Players cannot communicate, but each might reason that the others are reasoning similarly. The \"correct\" decision--the decision which maximizes expected utility for each player, <i>if<\/i> all players symmetrically make the same decision--is to randomize a one-in-20 chance of asking for the prize.<\/p><p>Gary Drescher (see references) developed the concept further, introducing an ethical system called \"acausal subjunctive morality.\" Drescher's approach relies on the agents being identical or at least similar, so that each agent can reasonably guess what the other will do based on facts about its own behavior, or even its own \"source code.\" If it cooperates, it can use this correlation to infer that the other will probably also cooperate.<\/p><p>Acausal trade goes one step beyond this. The agents do not need to be identical, nor similar, nor have the same utility function. Moreover, they do not need to know what the other agents are like, nor even if they exist. In acausal trade, an agent may have to surmise the probability that other agents, with their utility function and proclivities, exist.<\/p><h2>Description<\/h2>... "},"Tag:tgJoX7PGDDh2vJNqT":{"_id":"tgJoX7PGDDh2vJNqT","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:tgJoX7PGDDh2vJNqT_description"},"canVoteOnRels":null,"userId":"HoGziwmhpMGqGeWZy","name":"Acausal Trade","shortName":null,"slug":"acausal-trade","core":false,"postCount":70,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-20T00:10:36.568Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:zYPQsxiMcTiY4yE3S_description":{"_id":"zYPQsxiMcTiY4yE3S_description","__typename":"Revision","htmlHighlight":"<p><strong>Values handshakes <\/strong>are a proposed form of trade between superintelligences. From <a href=\"https://slatestarcodex.com/2018/04/01/the-hour-i-first-believed/\">The Hour I First Believed<\/a> by Scott Alexander:<\/p><blockquote><p>Suppose that humans make an AI which wants to convert the universe into paperclips. And suppose that aliens in the Andromeda Galaxy make an AI which wants to convert the universe into thumbtacks.<\/p><\/blockquote><blockquote><p>When they meet in the middle, they might be tempted to fight for the fate of the galaxy. But this has many disadvantages. First, there’s the usual risk of losing and being wiped out completely. Second, there’s the usual deadweight loss of war, devoting resources to military buildup instead of paperclip production or whatever. Third, there’s the risk of a Pyrrhic victory that leaves you weakened and easy prey for some third party. Fourth, nobody knows what kind of scorched-earth strategy a losing superintelligence might be able to use to thwart its conqueror, but it could potentially be really bad – eg initiating vacuum collapse and destroying the universe. Also, since both parties would have superintelligent prediction abilities, they might both know who would win the war and how before actually fighting. This would make the fighting redundant and kind of stupid.<\/p><\/blockquote><blockquote><p>Although they would have the usual peace treaty options, like giving half the universe to each of them, superintelligences that trusted each other would have an additional, more attractive option. They could merge into a superintelligence that shared the values of both parent intelligences in proportion to their strength (or chance of military victory, or whatever). So if there’s a 60% chance our AI would win, and a 40% chance their AI would win, and both AIs know and agree on these odds, they might both rewrite their own programming with that of a previously-agreed-upon child superintelligence trying to convert the universe to paperclips and thumbtacks in a 60-40 mix.<\/p><\/blockquote><blockquote><p>This has a lot of advantages over the half-the-universe-each treaty proposal. For one thing, if some resources were better for making paperclips, and others for making thumbtacks, both AIs could use all their resources maximally efficiently without having to trade. And if they were ever threatened by a third party, they would be able to present a completely unified front.<\/p><\/blockquote>"},"Tag:zYPQsxiMcTiY4yE3S":{"_id":"zYPQsxiMcTiY4yE3S","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:zYPQsxiMcTiY4yE3S_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Values handshakes","shortName":null,"slug":"values-handshakes","core":false,"postCount":10,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-04-06T16:05:27.579Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:Wh8HAK6LR5CAoPCCC":{"_id":"Wh8HAK6LR5CAoPCCC","__typename":"SocialPreviewType","imageUrl":""},"Post:Wh8HAK6LR5CAoPCCC":{"_id":"Wh8HAK6LR5CAoPCCC","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16d85"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":8,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:tgJoX7PGDDh2vJNqT"},{"__ref":"Tag:zYPQsxiMcTiY4yE3S"},{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:Wh8HAK6LR5CAoPCCC"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-03-22T02:03:51.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":1,"tgJoX7PGDDh2vJNqT":6,"zYPQsxiMcTiY4yE3S":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16d85","commentCount":2,"voteCount":61,"baseScore":96,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":61,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00027506359037943184,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-03-29T01:07:53.947Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":16,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":11,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"repost-the-demiurge-s-older-brother","title":"[REPOST] The Demiurge’s Older Brother","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:CEoLSfmEhLsP6CRm8":{"_id":"CEoLSfmEhLsP6CRm8","__typename":"Chapter","createdAt":"2017-09-02T19:57:59.135Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"TKDT2Mt6dDMH8AsZW","postIds":["muhtBvbh4etjkKXd9","Wh8HAK6LR5CAoPCCC"],"posts":[{"__ref":"Post:muhtBvbh4etjkKXd9"},{"__ref":"Post:Wh8HAK6LR5CAoPCCC"}]},"Revision:TKDT2Mt6dDMH8AsZW_contents":{"_id":"TKDT2Mt6dDMH8AsZW_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:41:22.191Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox.<\/p>","commitMessage":null,"wordCount":14,"htmlHighlight":"<p>A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox.<\/p>","plaintextDescription":"A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox."},"Sequence:TKDT2Mt6dDMH8AsZW":{"_id":"TKDT2Mt6dDMH8AsZW","__typename":"Sequence","chapters":[{"__ref":"Chapter:NaFHTa4xCEHNnx4v9"},{"__ref":"Chapter:CEoLSfmEhLsP6CRm8"}],"createdAt":"2017-08-24T01:41:22.191Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:TKDT2Mt6dDMH8AsZW_contents"},"gridImageId":"sequencesgrid/lel3jdh48of1dhtwfo4i","bannerImageId":"sequences/bj5eolzptpnu9fi9gi1a","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":0,"title":"Futurism and Forecasting","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:8o7QyPwSHCzhDvfyw_contents":{"_id":"8o7QyPwSHCzhDvfyw_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:41:04.169Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:5c6392dcbcb4ac6367c16ef3":{"_id":"5c6392dcbcb4ac6367c16ef3","__typename":"Revision","htmlHighlight":"<p><i>[Content warning: Discussion of social justice, discussion of violence, spoilers for Jacqueline Carey books.]<\/p><p>[Edit 10/25: This post was inspired by a debate with a friend of a friend on Facebook who has since become somewhat famous. I&#8217;ve renamed him here to &#8220;Andrew Cord&#8221; to protect his identity.]<\/i><\/p><p><b>I.<\/b><\/p><p>Andrew Cord <A HREF=\"http://www.patheos.com/blogs/hallq/2014/02/on-some-criticism-of-lesswrong/\">criticizes me<\/A> for my bold and controversial suggestion that maybe people should try to tell slightly fewer blatant hurtful lies:<\/p>\n<blockquote><p>I just find it kind of darkly amusing and sad that the “rationalist community” loves “rationality is winning” so much as a tagline and yet are clearly not winning. And then complain about losing rather than changing their tactics to match those of people who are winning.<\/p><p>Which is probably because if you *really* want to be the kind of person who wins you have to actually care about winning something, which means you have to have politics, which means you have to embrace “politics the mindkiller” and “politics is war and arguments are soldiers”, and Scott would clearly rather spend the rest of his life losing than do this.<\/p><p>That post [<A HREF=\"http://slatestarcodex.com/2014/02/17/lies-damned-lies-and-social-media-part-5-of-%e2%88%9e/\">the one debunking false rape statistics<\/A>] is exactly my problem with Scott. He seems to honestly think that it’s a worthwhile use of his time, energy and mental effort to download evil people’s evil worldviews into his mind and try to analytically debate them with statistics and cost-benefit analyses.<\/p><p>He gets *mad* at people whom he detachedly intellectually agrees with but who are willing to back up their beliefs with war and fire rather than pussyfooting around with debate-team nonsense.<\/p><p>It honestly makes me kind of sick. It is exactly the kind of thing that “social justice” activists like me *intend* to attack and “trigger” when we use “triggery” catchphrases about the mewling pusillanimity of privileged white allies.<\/p><\/blockquote>\n<p>In other words, if a fight is important to you, fight nasty. If that means lying, lie. If that means insults, insult. If that means silencing people, silence.<\/p><p>It always makes me happy when my ideological opponents come out and say eloquently and openly what I&#8217;ve always secretly suspected them of believing.<\/p><p>My natural instinct is to give some of the reasons why I think Andrew is wrong, starting with the history of the &#8220;noble lie&#8221; concept and moving on to some examples of why it didn&#8217;t work very well, and why it might not be expected not to work so ... <\/p>","plaintextDescription":"[Content warning: Discussion of social justice, discussion of violence, spoilers for Jacqueline Carey books.]\n\n[Edit 10/25: This post was inspired by a debate with a friend of a friend on Facebook who has since become somewhat famous. I’ve renamed him here to “Andrew Cord” to protect his identity.]\n\nI.\n\nAndrew Cord criticizes me for my bold and controversial suggestion that maybe people should try to tell slightly fewer blatant hurtful lies:\n\n> I just find it kind of darkly amusing and sad that the “rationalist community” loves “rationality is winning” so much as a tagline and yet are clearly not winning. And then complain about losing rather than changing their tactics to match those of people who are winning.\n> \n> Which is probably because if you *really* want to be the kind of person who wins you have to actually care about winning something, which means you have to have politics, which means you have to embrace “politics the mindkiller” and “politics is war and arguments are soldiers”, and Scott would clearly rather spend the rest of his life losing than do this.\n> \n> That post [the one debunking false rape statistics] is exactly my problem with Scott. He seems to honestly think that it’s a worthwhile use of his time, energy and mental effort to download evil people’s evil worldviews into his mind and try to analytically debate them with statistics and cost-benefit analyses.\n> \n> He gets *mad* at people whom he detachedly intellectually agrees with but who are willing to back up their beliefs with war and fire rather than pussyfooting around with debate-team nonsense.\n> \n> It honestly makes me kind of sick. It is exactly the kind of thing that “social justice” activists like me *intend* to attack and “trigger” when we use “triggery” catchphrases about the mewling pusillanimity of privileged white allies.\n\nIn other words, if a fight is important to you, fight nasty. If that means lying, lie. If that means insults, insult. If that means silencing people, silence.\n","wordCount":6105,"version":"1.0.0"},"Revision:ai87fPyyT6mWb4YkT_description":{"_id":"ai87fPyyT6mWb4YkT_description","__typename":"Revision","htmlHighlight":"<p><strong>Eldritch Analogies<\/strong> are the association of impersonal social or physical dynamics with the names of deities from mythology or fiction.<\/p>\n<p>The best-known is <a href=\"https://www.lesswrong.com/tag/moloch\">Moloch<\/a>, who is associated with coordination problems and competition, from Scott Alexander's <em>Meditations on Moloch<\/em>, which contrasted Him with Elua, the ally of humanity.<\/p>\n<p>Also notable is Azathoth, the blind idiot god of evolution, from Yudkowsky's <em>An Alien God<\/em>, which far predates <em>Meditations on Moloch<\/em>.<\/p>\n<p>See also: <a href=\"https://www.lesswrong.com/tag/egregores\">Egregores<\/a><\/p>"},"Tag:ai87fPyyT6mWb4YkT":{"_id":"ai87fPyyT6mWb4YkT","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ai87fPyyT6mWb4YkT_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Eldritch Analogies","shortName":null,"slug":"eldritch-analogies","core":false,"postCount":20,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-30T01:43:25.940Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:ogWsaHQKwa6ddidRC_description":{"_id":"ogWsaHQKwa6ddidRC_description","__typename":"Revision","htmlHighlight":"<p><strong>Conflict vs Mistake<\/strong> is a framework for analyzing disagreements about policy.<\/p><p>Mistake theorists think problems in society are caused by people being bad at achieving common goals. Conflict theorists think problems in society are caused by adversaries with incompatible goals.<\/p><p>Scott Alexander <a href=\"https://slatestarcodex.com/2018/01/24/conflict-vs-mistake/\">attributed<\/a> the conflict vs mistake framework to <a href=\"https://www.reddit.com/r/slatestarcodex/comments/74vpwm/socialism_communism_and_marxism_pt_1_on_trust_and/\">a post on reddit by user no_bear_so_low<\/a>.<\/p><p>A <strong>conflict theorist<\/strong> thinks problems are primarily due to the conflicting interests of different players. If someone is suffering, someone else must be making money off of it. Karl Marx was a conflict theorist; he blamed the ills of society on class conflict.<\/p><p>A <strong>mistake theorist<\/strong> thinks problems are primarily due to mistakes. If only we knew how to run society better, there would be less problems. Jeremy Bentham was more of a mistake theorist: he thought producing a formula by which we could calculate the quality of social interventions would help improve society.<\/p><p><a href=\"https://www.lesswrong.com/posts/PBRWb2Em5SNeWYwwB/humans-are-not-automatically-strategic\">Humans are not automatically strategic<\/a> is a mistake theory of human (ir)rationality. Things are hard. If people are doing something dumb, it's probably because they don't know better.<\/p><p><a href=\"https://www.lesswrong.com/posts/BgBrXpByCSmCLjpwr/book-review-the-elephant-in-the-brain\">The Elephant in the Brain<\/a> is more like a conflict theory of human (ir)rationality. Apparent irrationality is attributed mainly to humans not actually wanting what they think they want. <\/p><p><strong><a href=\"https://en.m.wikipedia.org/wiki/Hanlon%27s_razor\">Hanlon's Razor<\/a><\/strong> says: <em>Never attribute to malice what is adequately explained by stupidity.<\/em> This is a clear bias toward mistake theory.<\/p><p>On the other hand, economics, evolutionary psychology, and some other fields are based on <em>rational choice theory<\/em>, IE, an assumption that behavior can be explained by rational decision-making. <em>(Economic rationality assumes that individuals choose rationally to maximize economic value, based on the incentives of the current situation. Evolutionary psychology instead assumes that human and animal behaviors will be optimal solutions to the problems they faced in evolutionary history. Bruce Bueno de Mesquita assumes that politicians act rationally so as to maximize their tenure in positions of power. The ACT-R theory of cognition assumes that individual cognitive mechanisms are designed to optimally perform their individual cognitive tasks, such as retrieving memories which are useful in expectation, even if the whole brain is not perfectly rational.)<\/em> This assumption of rationality lends itself more naturally to conflict theories.<\/p><h2>Game-Theoretic Co<\/h2>... "},"Tag:ogWsaHQKwa6ddidRC":{"_id":"ogWsaHQKwa6ddidRC","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ogWsaHQKwa6ddidRC_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Conflict vs Mistake","shortName":null,"slug":"conflict-vs-mistake","core":false,"postCount":22,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-21T18:15:19.366Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:rkpDX7j7va6c8Q7cZ":{"_id":"rkpDX7j7va6c8Q7cZ","__typename":"SocialPreviewType","imageUrl":""},"Post:rkpDX7j7va6c8Q7cZ":{"_id":"rkpDX7j7va6c8Q7cZ","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ef3"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":24,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ai87fPyyT6mWb4YkT"},{"__ref":"Tag:ogWsaHQKwa6ddidRC"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:izp6eeJJEg9v5zcur"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:rkpDX7j7va6c8Q7cZ"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-02-23T22:24:18.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":2,"ai87fPyyT6mWb4YkT":6,"gHCNhqxuJq2bZ2akb":2,"izp6eeJJEg9v5zcur":18,"ogWsaHQKwa6ddidRC":4},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ef3","commentCount":9,"voteCount":44,"baseScore":84,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":44,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0001630000042496249,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-21T22:06:03.298Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":10,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":12,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"in-favor-of-niceness-community-and-civilization","title":"In Favor of Niceness, Community, and Civilization","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16d39":{"_id":"5c6392c7bcb4ac6367c16d39","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Content note: kind of talking around Trump supporters and similar groups as if they&#8217;re not there.]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>Tim Harford writes <A HREF=\"http://timharford.com/2017/03/the-problem-with-facts/\">The Problem With Facts<\/A>, which uses Brexit and Trump as jumping-off points to argue that people are mostly impervious to facts and resistant to logic:<\/p>\n<blockquote><p>All this adds up to a depressing picture for those of us who aren’t ready to live in a post-truth world. Facts, it seems, are toothless. Trying to refute a bold, memorable lie with a fiddly set of facts can often serve to reinforce the myth. Important truths are often stale and dull, and it is easy to manufacture new, more engaging claims. And giving people more facts can backfire, as those facts provoke a defensive reaction in someone who badly wants to stick to their existing world view. “This is dark stuff,” says Reifler. “We’re in a pretty scary and dark time.”<\/p><\/blockquote>\n<p>He admits he has no easy answers, but cites some studies showing that &#8220;scientific curiosity&#8221; seems to help people become interested in facts again. He thinks maybe we can inspire scientific curiosity by linking scientific truths to human interest stories, by weaving compelling narratives, and by finding &#8220;a Carl Sagan or David Attenborough of social science&#8221;.<\/p><p>I think this is generally a good article and makes important points, but there are three issues I want to highlight as possibly pointing to a deeper pattern.<\/p><p>First, the article makes the very strong claim that &#8220;facts are toothless&#8221; &#8211; then tries to convince its readers of this using facts. For example, the article highlights a study by Nyhan &#038; Reifler which finds a &#8220;backfire effect&#8221;  &#8211; correcting people&#8217;s misconceptions only makes them cling to those misconceptions more strongly. Harford expects us to be impressed by this study. But how is this different from all of those social science facts to which he believes humans are mostly impervious?<\/p><p>Second, Nyhan &#038; Reifler&#8217;s work on the backfire effect is probably not true. The original study establishing its existence <A HREF=\"https://www.poynter.org/2016/fact-checking-doesnt-backfire-new-study-suggests/436983/\">failed<\/A> to replicate (see eg <A HREF=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2819073\">Porter &#038; Wood, 2016<\/A>). This isn&#8217;t directly contrary to Harford&#8217;s argument, because Harford doesn&#8217;t cite the original study &#8211; he cites a slight extension of it done a year later by the same team that comes to a slightly different conclusion. But given that the entire field is now in s... <\/p>","plaintextDescription":"[Content note: kind of talking around Trump supporters and similar groups as if they’re not there.]\n\nI.\n\nTim Harford writes The Problem With Facts, which uses Brexit and Trump as jumping-off points to argue that people are mostly impervious to facts and resistant to logic:\n\n> All this adds up to a depressing picture for those of us who aren’t ready to live in a post-truth world. Facts, it seems, are toothless. Trying to refute a bold, memorable lie with a fiddly set of facts can often serve to reinforce the myth. Important truths are often stale and dull, and it is easy to manufacture new, more engaging claims. And giving people more facts can backfire, as those facts provoke a defensive reaction in someone who badly wants to stick to their existing world view. “This is dark stuff,” says Reifler. “We’re in a pretty scary and dark time.”\n\nHe admits he has no easy answers, but cites some studies showing that “scientific curiosity” seems to help people become interested in facts again. He thinks maybe we can inspire scientific curiosity by linking scientific truths to human interest stories, by weaving compelling narratives, and by finding “a Carl Sagan or David Attenborough of social science”.\n\nI think this is generally a good article and makes important points, but there are three issues I want to highlight as possibly pointing to a deeper pattern.\n\nFirst, the article makes the very strong claim that “facts are toothless” – then tries to convince its readers of this using facts. For example, the article highlights a study by Nyhan & Reifler which finds a “backfire effect” – correcting people’s misconceptions only makes them cling to those misconceptions more strongly. Harford expects us to be impressed by this study. But how is this different from all of those social science facts to which he believes humans are mostly impervious?\n\nSecond, Nyhan & Reifler’s work on the backfire effect is probably not true. The original study establishing its existence failed to repli","wordCount":5725,"version":"1.0.0"},"Revision:5f5c37ee1b5cdee568cfb2fb_description":{"_id":"5f5c37ee1b5cdee568cfb2fb_description","__typename":"Revision","htmlHighlight":"<p><strong>Adversarial collaboration<\/strong> is a protocol developed by Daniel Kahneman for two researchers advocating competing hypotheses to collaborate on a research project with the goal of resolving their differences, designed on the assumption that this will be more effective than each researcher conducting their own experiments individually and publishing replies to each others' papers. Kahneman tested adversarial collaboration with Ralph Hertwig, aiming to resolve their dispute about whether the <a href=\"https://www.lesswrong.com/tag/conjunction-fallacy\">conjunction fallacy<\/a> was primarily due to the <a href=\"https://www.lesswrong.com/tag/representativeness-heuristic\">representativeness heuristic<\/a> (as advocated by Kahneman), or simply due to subjects interpreting the word \"and\" as a disjunction where the experimenters intended it to be used as a conjunction (as advocated by Hertwig). Kahneman and Hertwig collaborated on a series of experiments related to the issue, along with Barbara Mellers as an arbiter, and further refined the suggested adversarial collaboration protocol based on their experiences.<\/p><p>They suggest that the two disputing researchers should team up, along with a neutral arbiter to settle disputes that arise in the process, and agree on a procedure for an experiment that would distinguish between their hypotheses. The researchers would discuss ahead of time what results each of them expects, and what sorts of results would lead them to change their minds. Since the initial experiment may be inconclusive, each side would be allowed to propose follow-up studies afterwards, which they would continue to collaborate on. After the study is complete, all three researchers involved would collaborate on a paper describing the results, with the arbiter having responsibility for some sections, and each of the two disputing researchers given the chance to describe their own interpretation of the results.<\/p><p>Scott Alexander has arranged adversarial collaboration contests on his his blog, where people write an essay together.<\/p><p><a href=\"https://slatestarcodex.com/2020/01/13/2019-adversarial-collaboration-winners/\">2019<\/a>:<\/p><ul><li><a href=\"https://slatestarcodex.com/2019/12/10/acc-is-infant-circumcision-ethical/\">What are the benefits, harms, and ethics of infant circumcision?<\/a> by Joel P and Missingno<\/li><li><a href=\"https://slatestarcodex.com/2019/12/11/acc-is-eating-meat-a-net-harm/\">Is eating meat a net harm?<\/a> by David G and Froolow<\/li><li><a href=\"https://slatestarcodex.com/2019/12/12/acc-does-calorie-restriction-slow-aging/\">Does calorie restriction slow aging?<\/a> by Adrian L and Calvin R<\/li><li><a href=\"https://slatestarcodex.com/2019/12/17/acc-should-we-colonize-space-to-mitigate-x-risk/\">Should we colonize space to mitigate x-risk?<\/a> by Nick D and Rob S<\/li><li><a href=\"https://slatestarcodex.com/2019/12/18/acc-should-gene-editing-technologies-be-used-in-humans/\">Should gene editing technologies be used in humans<\/a> by Nita J and Patrick N<\/li><li><a href=\"https://slatestarcodex.com/2019/12/19/acc-when-during-fetal-development-does-abortion-become-morally-wrong/\">When during fetal development does abortion become morally wrong?<\/a> by BlockOfNihilism and Icerun<\/li><li><a href=\"https://slatestarcodex.com/2019/12/23/acc-will-automation-lead-to-economic-crisis/\">Will automation lead to economic crisis?<\/a> by Doug S <\/li><\/ul>... "},"Tag:5f5c37ee1b5cdee568cfb2fb":{"_id":"5f5c37ee1b5cdee568cfb2fb","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb2fb_description"},"canVoteOnRels":null,"userId":"KgzPEGnYWvKDmWuNY","name":"Adversarial Collaboration","shortName":null,"slug":"adversarial-collaboration","core":false,"postCount":4,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.749Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:3JnSXmK9nYxzd5Riy_description":{"_id":"3JnSXmK9nYxzd5Riy_description","__typename":"Revision","htmlHighlight":"<p><strong>Asymmetric Weapons<\/strong> are weapons that are inherently more powerful to one side of a conflict than another - Unlike a symmetric weapon, which can used as effectively by both sides. The term was originally introduced by Scott Alexander in his essay <a href=\"https://www.lesswrong.com/posts/qajfiXo5qRThZQG7s/guided-by-the-beauty-of-our-weapons\">Guided By The Beauty Of Our Weapons<\/a>, where he argued that truth, facts, and logic are asymmetric weapons for \"the good guys\":<\/p><blockquote><p>Logical debate has one advantage over narrative, rhetoric, and violence: it’s an <i>asymmetric weapon<\/i>. That is, it’s a weapon which is stronger in the hands of the good guys than in the hands of the bad guys. In ideal conditions (which may or may not ever happen in real life) – the kind of conditions where everyone is charitable and intelligent and wise – the good guys will be able to present stronger evidence, cite more experts, and invoke more compelling moral principles. The whole point of logic is that, when done right, it can only prove things that are true.<\/p><\/blockquote><p>In the same essay he gave rhetoric and violence as examples of symmetric weapons.<\/p><blockquote><p>Violence is a <i>symmetric weapon<\/i>; the bad guys’ punches hit just as hard as the good guys’ do. [...] the same is true of rhetoric. Martin Luther King was able to make persuasive emotional appeals for good things. But Hitler was able to make persuasive emotional appeals for bad things. I’ve <a href=\"https://slatestarscratchpad.tumblr.com/post/103708539246/nostalgebraist-at-various-points-bostrom-like\">previously argued<\/a> that Mohammed counts as the most successful persuader of all time. These three people pushed three very different ideologies, and rhetoric worked for them all.&nbsp;<\/p><\/blockquote><p>Scott uses this terminology mainly to separate strategies that work especially well for \"the good guys\" and strategies that work equally well for both sides. Davis Kingsley <a href=\"https://www.lesswrong.com/posts/Nd5KiuN8pPBrMT82Z/asymmetric-weapons-aren-t-always-on-your-side-1\">warns<\/a> that strategies can also be asymmetric in favor of \"the bad guys\".<\/p><blockquote><p>\"Unless you use asymmetric weapons, the best you can hope for is to win by coincidence.\" - Scott Alexander<\/p><\/blockquote><h2>External Links<\/h2><ul><li><a href=\"https://slatestarcodex.com/2019/06/06/asymmetric-weapons-gone-bad/\">Asymmetric Weapons Gone Bad<\/a><\/li><\/ul><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/memetics\">Memetics<\/a>, <a href=\"https://www.lesswrong.com/tag/public-discourse\">Public Discourse<\/a><\/p>"},"Tag:3JnSXmK9nYxzd5Riy":{"_id":"3JnSXmK9nYxzd5Riy","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3JnSXmK9nYxzd5Riy_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Asymmetric Weapons","shortName":null,"slug":"asymmetric-weapons","core":false,"postCount":7,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-03-08T15:07:50.008Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:xexCWMyds6QLWognu_description":{"_id":"xexCWMyds6QLWognu_description","__typename":"Revision","htmlHighlight":"<p><strong>World Optimization<\/strong> is the full use of our agency. It is extending the reach of human civilization. It is building cities and democracies and economic systems and computers and flight and science and space rockets and the internet. World optimization is about adding to that list.&nbsp;<br><br>But it’s not just about growth, it’s also about preservation. We are still in the dawn of civilization, with most of civilization in the billions of years ahead. We mustn’t let this light go out.<\/p><hr><h1>World Optimization Sub-Topics<\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33%\"><p><strong>Moral Theory<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/altruism?showPostCount=true&amp;useTagName=true\">Altruism<\/a><br><a href=\"https://www.lesswrong.com/tag/consequentialism?showPostCount=true&amp;useTagName=true\">Consequentialism<\/a><br><a href=\"https://www.lesswrong.com/tag/deontology?showPostCount=true&amp;useTagName=true\">Deontology<\/a><br><a href=\"http://www.lesswrong.com/tag/ethics-and-morality?showPostCount=true&amp;useTagName=true\"><u>Ethics &amp; Morality<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/metaethics?showPostCount=true&amp;useTagName=true\">Metaethics<\/a><br><a href=\"http://www.lesswrong.com/tag/moral-uncertainty?showPostCount=true&amp;useTagName=true\"><u>Moral Uncertainty<\/u><\/a><\/p><p>&nbsp;<\/p><p>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\"><p><strong>Causes / Interventions<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aging?showPostCount=true&amp;useTagName=true\">Aging<\/a><br><a href=\"https://www.lesswrong.com/tag/animal-welfare?showPostCount=true&amp;useTagName=true\">Animal Welfare<\/a><br><a href=\"https://www.lesswrong.com/tag/existential-risk?showPostCount=true&amp;useTagName=true\">Existential Risk<\/a><br><a href=\"http://www.lesswrong.com/tag/futurism?showPostCount=true&amp;useTagName=true\">Futurism<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-uploading?showPostCount=true&amp;useTagName=true\">Mind Uploading<\/a><br><a href=\"https://www.lesswrong.com/tag/life-extension?showPostCount=true&amp;useTagName=true\">Life Extension<\/a><br><a href=\"http://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks?showPostCount=true&amp;useTagName=false\"><u>S-risks<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/transhumanism?showPostCount=true&amp;useTagName=true\"><u>Transhumanism<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/voting-theory?showPostCount=true&amp;useTagName=true\">Voting Theory<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\"><p><strong>Working with Humans<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/coalitional-instincts?showPostCount=true&amp;useTagName=true\"><u>Coalitional Instincts<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/coordination-cooperation?showPostCount=true&amp;useTagName=true\">Coordination / Cooperation<\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/institution-design?showPostCount=true&amp;useTagName=true\">Institution Design<\/a><br><a href=\"https://www.lesswrong.com/tag/moloch?showPostCount=true&amp;useTagName=true\">Moloch<\/a><br><a href=\"https://www.lesswrong.com/tag/signaling?showPostCount=true&amp;useTagName=true\">Signaling<\/a><br><a href=\"https://www.lesswrong.com/tag/simulacrum-levels?showPostCount=true&amp;useTagName=true\">Simulacrum Levels<\/a><br><a href=\"https://www.lesswrong.com/tag/social-status?showPostCount=true&amp;useTagName=true\">Social Status<\/a><\/p><\/td><\/tr><tr><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0em;vertical-align:top\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/blackmail?showPostCount=true&amp;useTagName=true\">Blackmail<\/a><br><a href=\"http://www.lesswrong.com/tag/censorship?showPostCount=true&amp;useTagName=true\">Censorship<\/a><br><a href=\"http://www.lesswrong.com/tag/chesterton-s-fence?showPostCount=true&amp;useTagName=true\">Chesterton's Fence<\/a><br><a href=\"http://www.lesswrong.com/tag/death?showPostCount=true&amp;useTagName=true\">Death<\/a><br><a href=\"https://www.lesswrong.com/tag/deception?showPostCount=true&amp;useTagName=true\">Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/honesty?showPostCount=true&amp;useTagName=true\">Honesty<\/a><br><a href=\"https://www.lesswrong.com/tag/hypocrisy?showPostCount=true&amp;useTagName=true\">Hypocrisy<\/a><br><a href=\"https://www.lesswrong.com/tag/information-hazards?showPostCount=true&amp;useTagName=true\">Information Hazards<\/a><br><a href=\"https://www.lesswrong.com/tag/meta-honesty?showPostCount=true&amp;useTagName=true\">Meta-Honesty<\/a><br><a href=\"http://www.lesswrong.com/tag/pascal-s-mugging?showPostCount=true&amp;useTagName=true\">Pascal's Mugging<\/a><br><a href=\"http://www.lesswrong.com/tag/war?showPostCount=true&amp;useTagName=true\">War<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:25px;padding:0px;vertical-align:top\"><p><strong>Value &amp; Virtue<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/ambition?showPostCount=true&amp;useTagName=true\">Ambition<\/a><br><a href=\"https://www.lesswrong.com/tag/art?showPostCount=true&amp;useTagName=true\">Art<\/a><br><a href=\"https://www.lesswrong.com/tag/aesthetics?showPostCount=true&amp;useTagName=true\">Aesthetics<\/a><br><a href=\"https://www.lesswrong.com/tag/complexity-of-value?showPostCount=true&amp;useTagName=true\">Complexity of Value<\/a><br><a href=\"http://www.lesswrong.com/tag/courage?showPostCount=true&amp;useTagName=true\">Courage<\/a><br><a href=\"http://www.lesswrong.com/tag/fun-theory?showPostCount=true&amp;useTagName=true\">Fun Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/principles?showPostCount=true&amp;useTagName=true\">Principles<\/a><br><a href=\"http://www.lesswrong.com/tag/suffering?showPostCount=true&amp;useTagName=true\"><u>Suffering<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/superstimuli?showPostCount=true&amp;useTagName=true\">Superstimuli<\/a><br><a href=\"https://www.lesswrong.com/tag/wireheading?showPostCount=true&amp;useTagName=true\">Wireheading<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0em;vertical-align:top\"><p><strong>Meta<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/cause-prioritization?showPostCount=true&amp;useTagName=true\">Cause Prioritization<\/a><br><a href=\"http://www.lesswrong.com/tag/center-on-long-term-risk-clr?useTagName=true&amp;showPostCount=true\">Center for Long-term Risk<\/a><br><a href=\"https://www.lesswrong.com/tag/effective-altruism?showPostCount=true&amp;useTagName=true\">Effective Altruism<\/a><br><a href=\"https://www.lesswrong.com/tag/heroic-responsibility?showPostCount=true&amp;useTagName=true\">Heroic Responsibility<\/a><br>&nbsp;<\/p><\/td><\/tr><\/tbody><\/table><\/figure><hr><p>Content which describes <i>how the world is <\/i>that directly bears upon choices one makes to optimize the world fall under this tag. Examples include discussion of the moral patienthood of different animals, the potential of human civilization, and the most effective interventions against a global health threat.<\/p><p>Some material has both immediate relevance to world optimization decisions but also can inform broader world models. This material might be included under both <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a> tag and this tag.<\/p>"},"Tag:xexCWMyds6QLWognu":{"_id":"xexCWMyds6QLWognu","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:xexCWMyds6QLWognu_description"},"canVoteOnRels":null,"userId":"XtphY3uYHwruKqDyG","name":"World Optimization","shortName":null,"slug":"world-optimization","core":true,"postCount":2711,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":20,"createdAt":"2020-06-14T03:38:23.532Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:qajfiXo5qRThZQG7s":{"_id":"qajfiXo5qRThZQG7s","__typename":"SocialPreviewType","imageUrl":""},"Post:qajfiXo5qRThZQG7s":{"_id":"qajfiXo5qRThZQG7s","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16d39"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":23,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:5f5c37ee1b5cdee568cfb2fb"},{"__ref":"Tag:3JnSXmK9nYxzd5Riy"},{"__ref":"Tag:FkzScn5byCs9PxGsA"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:xexCWMyds6QLWognu"}],"socialPreviewData":{"__ref":"SocialPreviewType:qajfiXo5qRThZQG7s"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2017-03-24T04:33:12.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3JnSXmK9nYxzd5Riy":4,"FkzScn5byCs9PxGsA":2,"gHCNhqxuJq2bZ2akb":2,"xexCWMyds6QLWognu":2,"5f5c37ee1b5cdee568cfb2fb":8},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16d39","commentCount":5,"voteCount":31,"baseScore":64,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00018346033175475895,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-18T20:43:15.128Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"guided-by-the-beauty-of-our-weapons","title":"Guided By The Beauty Of Our Weapons","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16d97":{"_id":"5c6392dcbcb4ac6367c16d97","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Why is there such a strong Sunni/Shia divide?<\/p><p>I know the Comparative Religion 101 answer. The early Muslims were debating who was the rightful caliph. Some of them said Abu Bakr, others said Ali, and the dispute has been going on ever since. On the other hand, that was fourteen hundred years ago, both candidates are long dead, and there&#8217;s no more caliphate. You&#8217;d think maybe they&#8217;d let the matter rest. <\/p><p>Sure, the two groups have slightly different hadith and schools of jurisprudence, but how many Muslims even <i>know<\/i> which school of jurisprudence they&#8217;re supposed to be following? It seems like a pretty minor thing to have centuries of animus over.<\/p><p>And so we return again to <A HREF=\"http://lesswrong.com/lw/lt/the_robbers_cave_experiment/\">Robbers&#8217; Cave<\/A>:<\/p>\n<blockquote><p> The experimental subjects — excuse me, &#8220;campers&#8221; — were 22 boys between 5th and 6th grade, selected from 22 different schools in Oklahoma City, of stable middle-class Protestant families, doing well in school, median IQ 112.  They were as well-adjusted and as similar to each other as the researchers could manage. <\/p><p>The experiment, conducted in the bewildered aftermath of World War II, was meant to investigate the causes—and possible remedies—of intergroup conflict.  How would they spark an intergroup conflict to investigate?  Well, the 22 boys were divided into two groups of 11 campers, and —<\/p><p>— and that turned out to be quite sufficient.<\/p><p>The researchers&#8217; original plans called for the experiment to be conducted in three stages. In Stage 1, each group of campers would settle in, unaware of the other group&#8217;s existence.  Toward the end of Stage 1, the groups would gradually be made aware of each other. In Stage 2, a set of contests and prize competitions would set the two groups at odds.<\/p><p>They needn&#8217;t have bothered with Stage 2.  There was hostility almost from the moment each group became aware of the other group&#8217;s existence:  They were using our campground, our baseball diamond.  On their first meeting, the two groups began hurling insults.  They named themselves the Rattlers and the Eagles (they hadn&#8217;t needed names when they were the only group on the campground).<\/p><p>When the contests and prizes were announced, in accordance with pre-established experimental procedure, the intergroup rivalry rose to a fever pitch.  Good sportsmanship in the contests was evident for the first two days but rapidly disintegrated.<\/p><p>The Eagl<\/p><\/blockquote>... ","plaintextDescription":"I.\n\nWhy is there such a strong Sunni/Shia divide?\n\nI know the Comparative Religion 101 answer. The early Muslims were debating who was the rightful caliph. Some of them said Abu Bakr, others said Ali, and the dispute has been going on ever since. On the other hand, that was fourteen hundred years ago, both candidates are long dead, and there’s no more caliphate. You’d think maybe they’d let the matter rest.\n\nSure, the two groups have slightly different hadith and schools of jurisprudence, but how many Muslims even know which school of jurisprudence they’re supposed to be following? It seems like a pretty minor thing to have centuries of animus over.\n\nAnd so we return again to Robbers’ Cave:\n\n> The experimental subjects — excuse me, “campers” — were 22 boys between 5th and 6th grade, selected from 22 different schools in Oklahoma City, of stable middle-class Protestant families, doing well in school, median IQ 112. They were as well-adjusted and as similar to each other as the researchers could manage.\n> \n> The experiment, conducted in the bewildered aftermath of World War II, was meant to investigate the causes—and possible remedies—of intergroup conflict. How would they spark an intergroup conflict to investigate? Well, the 22 boys were divided into two groups of 11 campers, and —\n> \n> — and that turned out to be quite sufficient.\n> \n> The researchers’ original plans called for the experiment to be conducted in three stages. In Stage 1, each group of campers would settle in, unaware of the other group’s existence. Toward the end of Stage 1, the groups would gradually be made aware of each other. In Stage 2, a set of contests and prize competitions would set the two groups at odds.\n> \n> They needn’t have bothered with Stage 2. There was hostility almost from the moment each group became aware of the other group’s existence: They were using our campground, our baseball diamond. On their first meeting, the two groups began hurling insults. They named themselves the Ra","wordCount":7338,"version":"1.0.0"},"SocialPreviewType:xtHd6sfdr2bZHa6Pb":{"_id":"xtHd6sfdr2bZHa6Pb","__typename":"SocialPreviewType","imageUrl":""},"Post:xtHd6sfdr2bZHa6Pb":{"_id":"xtHd6sfdr2bZHa6Pb","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16d97"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":29,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:FkzScn5byCs9PxGsA"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:xtHd6sfdr2bZHa6Pb"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2016-04-05T01:52:38.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"FkzScn5byCs9PxGsA":3,"gHCNhqxuJq2bZ2akb":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16d97","commentCount":3,"voteCount":28,"baseScore":39,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":27,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00009699999645818025,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-06-24T16:18:35.537Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2016-04-05T01:52:38.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-ideology-is-not-the-movement","title":"The Ideology Is Not The Movement","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16db5":{"_id":"5c6392dcbcb4ac6367c16db5","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>In the old days, you had your Culture, and that was that. Your Culture told you lots of stuff about what you were and weren&#8217;t allowed to do, and by golly you listened. Your Culture told you to work the job prescribed to you by your caste and gender, to marry who your parents told you to marry or at <i>least<\/i> someone of the opposite sex, to worship at the proper temples and the proper times, and to talk about <i>proper<\/i> things as opposed to the blasphemous things said by the tribe over there.<\/p><p>Then we got Liberalism, which said all of that was mostly bunk. Like Wicca, its motto is &#8220;Do as you will, so long as it harms none&#8221;. Or in more political terms, &#8220;Your right to swing your fist ends where my nose begins&#8221; or &#8220;If you don&#8217;t like gay sex, don&#8217;t have any&#8221; or &#8220;If you don&#8217;t like this TV program, don&#8217;t watch it&#8221; or &#8220;What happens in the bedroom between consenting adults is none of your business&#8221; or &#8220;It neither breaks my arm nor picks my pocket&#8221;. Your job isn&#8217;t to enforce your conception of virtue upon everyone to build the Virtuous Society, it&#8217;s to live your own life the way you want to live it and let other people live <i>their<\/i> own lives the way <i>they<\/i> want to live them. This is the much-maligned &#8220;atomic individualism,&#8221; or maybe just liberalism boiled down to its pure essence.<\/p><p>But atomic individualism wasn&#8217;t as great a solution as it sounded. Maybe one of the first cracks was tobacco ads. Even though putting up a billboard saying &#8220;SMOKE MARLBORO&#8221; neither breaks anyone&#8217;s arm nor picks their pocket, it shifts social expectations in such a way that bad effects occur. It&#8217;s hard to dismiss that with &#8220;Well, it&#8217;s people&#8217;s own choice to smoke and they should live their lives the way they want&#8221; if studies show that more people will want to live their lives in a way that gives them cancer in the presence of the billboard than otherwise.<\/p><p>From there we go into policies like Michael Bloomberg&#8217;s ban on giant sodas. While the soda ban itself was probably as much symbolic as anything, it&#8217;s hard to argue with the impetus behind it &#8211; a culture where everyone gets exposed to the option to buy very very unhealthy food all the time is going to be less healthy than one where there are some regulations in ... <\/p>","plaintextDescription":"I.\n\nIn the old days, you had your Culture, and that was that. Your Culture told you lots of stuff about what you were and weren’t allowed to do, and by golly you listened. Your Culture told you to work the job prescribed to you by your caste and gender, to marry who your parents told you to marry or at least someone of the opposite sex, to worship at the proper temples and the proper times, and to talk about proper things as opposed to the blasphemous things said by the tribe over there.\n\nThen we got Liberalism, which said all of that was mostly bunk. Like Wicca, its motto is “Do as you will, so long as it harms none”. Or in more political terms, “Your right to swing your fist ends where my nose begins” or “If you don’t like gay sex, don’t have any” or “If you don’t like this TV program, don’t watch it” or “What happens in the bedroom between consenting adults is none of your business” or “It neither breaks my arm nor picks my pocket”. Your job isn’t to enforce your conception of virtue upon everyone to build the Virtuous Society, it’s to live your own life the way you want to live it and let other people live their own lives the way they want to live them. This is the much-maligned “atomic individualism,” or maybe just liberalism boiled down to its pure essence.\n\nBut atomic individualism wasn’t as great a solution as it sounded. Maybe one of the first cracks was tobacco ads. Even though putting up a billboard saying “SMOKE MARLBORO” neither breaks anyone’s arm nor picks their pocket, it shifts social expectations in such a way that bad effects occur. It’s hard to dismiss that with “Well, it’s people’s own choice to smoke and they should live their lives the way they want” if studies show that more people will want to live their lives in a way that gives them cancer in the presence of the billboard than otherwise.\n\nFrom there we go into policies like Michael Bloomberg’s ban on giant sodas. While the soda ban itself was probably as much symbolic as anything, it’s har","wordCount":6629,"version":"1.0.0"},"SocialPreviewType:aP36QcAsxyuEispq6":{"_id":"aP36QcAsxyuEispq6","__typename":"SocialPreviewType","imageUrl":""},"Post:aP36QcAsxyuEispq6":{"_id":"aP36QcAsxyuEispq6","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16db5"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":27,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:xexCWMyds6QLWognu"}],"socialPreviewData":{"__ref":"SocialPreviewType:aP36QcAsxyuEispq6"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-06-07T16:44:41.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"gHCNhqxuJq2bZ2akb":3,"xexCWMyds6QLWognu":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16db5","commentCount":3,"voteCount":15,"baseScore":19,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00003894592373399064,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-11-01T05:43:48.411Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"archipelago-and-atomic-communitarianism","title":"Archipelago and Atomic Communitarianism","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16ebc":{"_id":"5c6392dcbcb4ac6367c16ebc","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Content note: Visions! omens! hallucinations! miracles! ecstasies! dreams! adorations! illuminations! religions!]<\/i><\/font><\/p><p><b>I.<\/b><\/p><p>Allan Ginsberg&#8217;s famous poem, <i>Moloch<\/i>:<\/p>\n<blockquote><p>What sphinx of cement and aluminum bashed open their skulls and ate up their brains and imagination?<\/p><p>Moloch! Solitude! Filth! Ugliness! Ashcans and unobtainable dollars! Children screaming under the stairways! Boys sobbing in armies! Old men weeping in the parks!<\/p><p>Moloch! Moloch! Nightmare of Moloch! Moloch the loveless! Mental Moloch! Moloch the heavy judger of men!<\/p><p>Moloch the incomprehensible prison! Moloch the crossbone soulless jailhouse and Congress of sorrows! Moloch whose buildings are judgment! Moloch the vast stone of war! Moloch the stunned governments!<\/p><p>Moloch whose mind is pure machinery! Moloch whose blood is running money! Moloch whose fingers are ten armies! Moloch whose breast is a cannibal dynamo! Moloch whose ear is a smoking tomb!<\/p><p>Moloch whose eyes are a thousand blind windows! Moloch whose skyscrapers stand in the long streets like endless Jehovahs! Moloch whose factories dream and croak in the fog! Moloch whose smoke-stacks and antennae crown the cities!<\/p><p>Moloch whose love is endless oil and stone! Moloch whose soul is electricity and banks! Moloch whose poverty is the specter of genius! Moloch whose fate is a cloud of sexless hydrogen! Moloch whose name is the Mind!<\/p><p>Moloch in whom I sit lonely! Moloch in whom I dream Angels! Crazy in Moloch! Cocksucker in Moloch! Lacklove and manless in Moloch!<\/p><p>Moloch who entered my soul early! Moloch in whom I am a consciousness without a body! Moloch who frightened me out of my natural ecstasy! Moloch whom I abandon! Wake up in Moloch! Light streaming out of the sky!<\/p><p>Moloch! Moloch! Robot apartments! invisible suburbs! skeleton treasuries! blind capitals! demonic industries! spectral nations! invincible madhouses! granite cocks! monstrous bombs!<\/p><p>They broke their backs lifting Moloch to Heaven! Pavements, trees, radios, tons! lifting the city to Heaven which exists and is everywhere about us!<\/p><p>Visions! omens! hallucinations! miracles! ecstasies! gone down the American river!<\/p><p>Dreams! adorations! illuminations! religions! the whole boatload of sensitive bullshit!<\/p><p>Breakthroughs! over the river! flips and crucifixions! gone down the flood! Highs! Epiphanies! Despairs! Ten years’ animal screams and suicides! Minds! New loves! Mad generation! down on the rocks of Time<\/p><\/blockquote>... ","plaintextDescription":"[Content note: Visions! omens! hallucinations! miracles! ecstasies! dreams! adorations! illuminations! religions!]\n\nI.\n\nAllan Ginsberg’s famous poem, Moloch:\n\n> What sphinx of cement and aluminum bashed open their skulls and ate up their brains and imagination?\n> \n> Moloch! Solitude! Filth! Ugliness! Ashcans and unobtainable dollars! Children screaming under the stairways! Boys sobbing in armies! Old men weeping in the parks!\n> \n> Moloch! Moloch! Nightmare of Moloch! Moloch the loveless! Mental Moloch! Moloch the heavy judger of men!\n> \n> Moloch the incomprehensible prison! Moloch the crossbone soulless jailhouse and Congress of sorrows! Moloch whose buildings are judgment! Moloch the vast stone of war! Moloch the stunned governments!\n> \n> Moloch whose mind is pure machinery! Moloch whose blood is running money! Moloch whose fingers are ten armies! Moloch whose breast is a cannibal dynamo! Moloch whose ear is a smoking tomb!\n> \n> Moloch whose eyes are a thousand blind windows! Moloch whose skyscrapers stand in the long streets like endless Jehovahs! Moloch whose factories dream and croak in the fog! Moloch whose smoke-stacks and antennae crown the cities!\n> \n> Moloch whose love is endless oil and stone! Moloch whose soul is electricity and banks! Moloch whose poverty is the specter of genius! Moloch whose fate is a cloud of sexless hydrogen! Moloch whose name is the Mind!\n> \n> Moloch in whom I sit lonely! Moloch in whom I dream Angels! Crazy in Moloch! Cocksucker in Moloch! Lacklove and manless in Moloch!\n> \n> Moloch who entered my soul early! Moloch in whom I am a consciousness without a body! Moloch who frightened me out of my natural ecstasy! Moloch whom I abandon! Wake up in Moloch! Light streaming out of the sky!\n> \n> Moloch! Moloch! Robot apartments! invisible suburbs! skeleton treasuries! blind capitals! demonic industries! spectral nations! invincible madhouses! granite cocks! monstrous bombs!\n> \n> They broke their backs lifting Moloch to Heaven! Pavements, ","wordCount":14178,"version":"1.0.0"},"Revision:o9aQASibdsECTfYF6_description":{"_id":"o9aQASibdsECTfYF6_description","__typename":"Revision","htmlHighlight":"<p><strong>Moloch<\/strong> is the personification of the forces that coerce competing individuals to take actions which, although locally optimal, ultimately lead to situations where everyone is worse off. Moreover, no individual is able to unilaterally break out of the dynamic. The situation is a bad Nash equilibrium. A trap.<\/p><p>It happens when \"In some competition optimizing for X, the opportunity arises to throw some other value under the bus for improved X. Those who take it prosper. Those who don’t take it die out. Eventually, everyone’s relative status is about the same as before, but everyone’s absolute status is worse than before. The process continues until all other values that can be traded off have been – in other words, until human ingenuity cannot possibly figure out a way to make things any worse.\" - Scott Alexander<\/p><p>One example of a Molochian dynamic is a <a href=\"https://en.wikipedia.org/wiki/Red_Queen%27s_race\">Red Queen race<\/a> between scientists who must continually spend more time writing grant applications just to keep up with their peers doing the same. Through unavoidable competition, they have all lost time while not ending up with any more grant money. And any scientist who unilaterally tried to not engage in the competition would soon be replaced by one who still does. If they all promised to cap their grant writing time, everyone would face an incentive to defect.<\/p><p>The topic of Moloch receives a formal treatment in the sequence <a href=\"https://www.lesswrong.com/s/oLGCcbnvabyibnG9d\">Inadequate Equilibria<\/a>, particularly in the chapter <a href=\"https://www.lesswrong.com/posts/x5ASTMPKPowLKpLpZ/moloch-s-toolbox-1-2\">Moloch's Toolbox<\/a>.<\/p>\n<h2>Origin<\/h2>\n<p><a href=\"https://www.lesswrong.com/users/yvain?sortedBy=top\">Scott Alexander<\/a> &nbsp;linked the name to the concept in his eponymous post, <a href=\"https://www.lesswrong.com/posts/TxcRbCYHaeL59aY7E/meditations-on-moloch\">Meditations on Moloch<\/a>. &nbsp;The post intersperses lines of Allan Ginsberg's poem, <a href=\"https://www.poetryfoundation.org/poems/49303/howl\">Howl<\/a>, with multiples examples of the dynamic including: the Prisoner's Dilemma, dollar auctions, <a href=\"https://web.archive.org/web/20160928190322/http://raikoth.net/libertarian.html\">fish farming story<\/a>, Malthusian trap, capitalism, two-income trap, agriculture, arms races, races to the bottom, education system, science, and government corruption and corporate welfare.<\/p><p>From Allan Ginsberg's <a href=\"https://www.poetryfoundation.org/poems/49303/howl\">Howl<\/a>:<\/p>\n<blockquote>\n<p><em>What sphinx of cement and aluminum bashed open their skulls and ate up their brains and imagination?<\/em><br>\n<em>Moloch! Solitude! Filth! Ugliness! Ashcans and unobtainable dollars! Children screaming under the stairways! Boys sobbing in armies! Old men weeping in the parks!<\/em><br>\n<em>Moloch! Moloch! Nightmare of Moloch! Moloch the loveless! Mental Moloch! Moloch the heavy judger of men!<\/em><br>\n<em>Moloch the incomprehensible prison! Moloch the crossbone soulless jailhouse and Congress of s<\/em><\/p><\/blockquote>... "},"Tag:o9aQASibdsECTfYF6":{"_id":"o9aQASibdsECTfYF6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:o9aQASibdsECTfYF6_description"},"canVoteOnRels":null,"userId":"73yyrm8KF6GDK9sRy","name":"Moloch","shortName":null,"slug":"moloch","core":false,"postCount":73,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-25T20:18:44.249Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:z5uy4NcWc2JSRTGHb_description":{"_id":"z5uy4NcWc2JSRTGHb_description","__typename":"Revision","htmlHighlight":"<p>An <strong>Incentive<\/strong> is a motivating factor, such as monetary reward, the risk of legal sanctions, or social feedback. Many systems are best understood by looking at the incentives of the people with power over them.<\/p><p><a href=\"https://www.lesswrong.com/s/oLGCcbnvabyibnG9d\">Inadequate Equilibria<\/a> covers many problems that arise when there are poor incentives.<\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/game-theory\">Game Theory<\/a>, <a href=\"https://www.lesswrong.com/tag/mechanism-design\">Mechanism Design<\/a>, <a href=\"https://www.lesswrong.com/tag/moloch\">Moloch<\/a>, <a href=\"https://www.lesswrong.com/tag/moral-mazes\">Moral Mazes<\/a><\/p>"},"Tag:z5uy4NcWc2JSRTGHb":{"_id":"z5uy4NcWc2JSRTGHb","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:z5uy4NcWc2JSRTGHb_description"},"canVoteOnRels":null,"userId":"XLwKyCK7JmC292ZCC","name":"Incentives","shortName":null,"slug":"incentives","core":false,"postCount":42,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-04T06:18:32.416Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:WTjkZ52k22S7mSdCE_description":{"_id":"WTjkZ52k22S7mSdCE_description","__typename":"Revision","htmlHighlight":"<p><strong>Punishing Non-Punishers<\/strong> describes the act of punishing people who don't punish someone else that you punish or think should be punished. It is used to make the punishment of the target more severe and to increase conformity among everyone else.<\/p><p>There's more than one level of punishing non-punishers - you can punish those who don't punish non-punishers, you can punish those who don't punish those who don't punish non-punishers, and so on. <a href=\"https://www.lesswrong.com/posts/5A8XNYPti2Q7GFFCk/yoav-ravid-s-shortform?commentId=PdBycxDzED6ctnGuy\">Taken to the limit, it becomes \"If you not with me, then You're my enemy\"<\/a>.<\/p><p>If a crime is sufficiently bad, punishing non-punishers can be appropriate, but otherwise it's an incredibly dangerous dynamic. Nick Bostrom describes an hypothetical scenario where punishing non-punishers is used to maintain a maximally bad equilibrium (described below by Scott Alexander in <a href=\"https://www.lesswrong.com/posts/TxcRbCYHaeL59aY7E/meditations-on-moloch\">Meditations On Moloch<\/a>):<\/p><blockquote><p>Imagine a country with two rules: first, every person must spend eight hours a day giving themselves strong electric shocks. Second, if anyone fails to follow a rule (including this one), or speaks out against it, or fails to enforce it, all citizens must unite to kill that person. Suppose these rules were well-enough established by tradition that everyone expected them to be enforced.<\/p><p>So you shock yourself for eight hours a day, because you know if you don’t everyone else will kill you, because if they don’t, everyone else will kill <i>them<\/i>, and so on. Every single citizen hates the system, but for lack of a good coordination mechanism it endures. From a god’s-eye-view, we can optimize the system to “everyone agrees to stop doing this at once”, but no one within the system is able to effect the transition without great risk to themselves.&nbsp;<\/p><\/blockquote><p><a href=\"https://www.lesswrong.com/users/eliezer_yudkowsky\">Eliezer Yudkowsky<\/a> offers '<a href=\"https://www.lesswrong.com/posts/JKxxFseBWz8SHkTgt/tolerate-tolerance\"><strong>Tolerate Tolerance<\/strong><\/a>' as a dictum against punishing non-punishers:&nbsp;<\/p><blockquote><p>That's why it's so important for us to tolerate others' tolerance if we want to get anything done together.<\/p><p>(...)<\/p><p>Cooperation is unstable, in both game theory and evolutionary biology, without <i>some <\/i>kind of punishment for defection.&nbsp; So it's one thing to subtract points off someone's reputation for mistakes they make <i>themselves, directly<\/i>.&nbsp; But if you also look askance at someone for <i>refusing to castigate<\/i> a person or idea, then that is <i>punishment of non-punishers,<\/i> a far more dangerous idiom that can lock an equilibrium in place even if it's harmful to <i>everyone<\/i> involved.<\/p><\/blockquote><p><a href=\"https://www.lesswrong.com/posts/X5RyaEDHNq5qutSHK/anti-social-punishment\">Anti-social punishment<\/a>, punishing thos... <\/p>"},"Tag:WTjkZ52k22S7mSdCE":{"_id":"WTjkZ52k22S7mSdCE","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:WTjkZ52k22S7mSdCE_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Punishing Non-Punishers","shortName":null,"slug":"punishing-non-punishers","core":false,"postCount":4,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2023-12-18T05:46:49.474Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:TxcRbCYHaeL59aY7E":{"_id":"TxcRbCYHaeL59aY7E","__typename":"SocialPreviewType","imageUrl":""},"Post:TxcRbCYHaeL59aY7E":{"_id":"TxcRbCYHaeL59aY7E","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ebc"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":57,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:o9aQASibdsECTfYF6"},{"__ref":"Tag:ai87fPyyT6mWb4YkT"},{"__ref":"Tag:b8FHrKqyXuYGWc6vn"},{"__ref":"Tag:z5uy4NcWc2JSRTGHb"},{"__ref":"Tag:WTjkZ52k22S7mSdCE"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:xexCWMyds6QLWognu"}],"socialPreviewData":{"__ref":"SocialPreviewType:TxcRbCYHaeL59aY7E"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-07-30T04:00:06.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"WTjkZ52k22S7mSdCE":2,"ai87fPyyT6mWb4YkT":18,"b8FHrKqyXuYGWc6vn":3,"gHCNhqxuJq2bZ2akb":2,"o9aQASibdsECTfYF6":38,"xexCWMyds6QLWognu":8,"z5uy4NcWc2JSRTGHb":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ebc","commentCount":10,"voteCount":119,"baseScore":185,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":119,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0003758594102691859,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-01-25T02:56:24.033Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":21,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":25,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2014-07-30T04:00:06.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"meditations-on-moloch","title":"Meditations On Moloch","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:8o7QyPwSHCzhDvfyw":{"_id":"8o7QyPwSHCzhDvfyw","__typename":"Chapter","createdAt":"2017-08-24T01:41:04.169Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:8o7QyPwSHCzhDvfyw_contents"},"number":0,"sequenceId":"xmDeR64CivZiTAcLx","postIds":["rkpDX7j7va6c8Q7cZ","qajfiXo5qRThZQG7s","xtHd6sfdr2bZHa6Pb","aP36QcAsxyuEispq6","TxcRbCYHaeL59aY7E"],"posts":[{"__ref":"Post:rkpDX7j7va6c8Q7cZ"},{"__ref":"Post:qajfiXo5qRThZQG7s"},{"__ref":"Post:xtHd6sfdr2bZHa6Pb"},{"__ref":"Post:aP36QcAsxyuEispq6"},{"__ref":"Post:TxcRbCYHaeL59aY7E"}]},"Revision:5c6392dcbcb4ac6367c16e77":{"_id":"5c6392dcbcb4ac6367c16e77","__typename":"Revision","htmlHighlight":"<p><b>Gamma Andromeda<\/b>, where philosophical stoicism went too far. Its inhabitants, tired of the roller coaster ride of daily existence, decided to learn equanimity in the face of gain or misfortune, neither dreading disaster nor taking joy in success.<\/p><p>But that turned out to be really hard, so instead they just hacked it. Whenever something good happens, the Gammandromedans give themselves an electric shock proportional in strength to its goodness. Whenever something bad happens, the Gammandromedans take an opiate-like drug that directly stimulates the pleasure centers of their brain, in a dose proportional in strength to its badness.<\/p><p>As a result, every day on Gamma Andromeda is equally good compared to every other day, and its inhabitants need not be jostled about by fear or hope for the future.<\/p><p>This does sort of screw up their incentives to make good things happen, but luckily they&#8217;re all virtue ethicists.<\/p><p><b>Zyzzx Prime<\/b>, inhabited by an alien race descended from a barnacle-like creature. Barnacles are famous for their two stage life-cycle: in the first, they are mobile and curious creatures, cleverly picking out the best spot to make their home. In the second, they root themselves to the spot and, having no further use for their brain, eat it.<\/p><p>This particular alien race has evolved far beyond that point and does not literally eat its brain. However, once an alien reaches sufficiently high social status, it releases a series of hormones that tell its brain, essentially, that it is now in a safe place and doesn&#8217;t have to waste so much energy on thought and creativity to get ahead. As a result, its mental acuity drops two or three standard deviations.<\/p><p>The Zyzzxians&#8217; society is marked by a series of experiments with government &#8211; monarchy, democracy, dictatorship &#8211; only to discover that, whether chosen by succession, election, or ruthless conquest, its once brilliant leaders lose their genius immediately upon accession and do a terrible job. Their government is thus marked by a series of perpetual pointless revolutions.<\/p><p>At one point, a scientific effort was launched to discover the hormones responsible and whether it was possible to block them. Unfortunately, any scientist who showed promise soon lost their genius, and those promoted to be heads of research institutes became stumbling blocks who mismanaged funds and held back their less prestigiou... <\/p>","plaintextDescription":"Gamma Andromeda, where philosophical stoicism went too far. Its inhabitants, tired of the roller coaster ride of daily existence, decided to learn equanimity in the face of gain or misfortune, neither dreading disaster nor taking joy in success.\n\nBut that turned out to be really hard, so instead they just hacked it. Whenever something good happens, the Gammandromedans give themselves an electric shock proportional in strength to its goodness. Whenever something bad happens, the Gammandromedans take an opiate-like drug that directly stimulates the pleasure centers of their brain, in a dose proportional in strength to its badness.\n\nAs a result, every day on Gamma Andromeda is equally good compared to every other day, and its inhabitants need not be jostled about by fear or hope for the future.\n\nThis does sort of screw up their incentives to make good things happen, but luckily they’re all virtue ethicists.\n\nZyzzx Prime, inhabited by an alien race descended from a barnacle-like creature. Barnacles are famous for their two stage life-cycle: in the first, they are mobile and curious creatures, cleverly picking out the best spot to make their home. In the second, they root themselves to the spot and, having no further use for their brain, eat it.\n\nThis particular alien race has evolved far beyond that point and does not literally eat its brain. However, once an alien reaches sufficiently high social status, it releases a series of hormones that tell its brain, essentially, that it is now in a safe place and doesn’t have to waste so much energy on thought and creativity to get ahead. As a result, its mental acuity drops two or three standard deviations.\n\nThe Zyzzxians’ society is marked by a series of experiments with government – monarchy, democracy, dictatorship – only to discover that, whether chosen by succession, election, or ruthless conquest, its once brilliant leaders lose their genius immediately upon accession and do a terrible job. Their government is thus marke","wordCount":1142,"version":"1.0.0"},"SocialPreviewType:ouSpHCCPgsXkwxAGb":{"_id":"ouSpHCCPgsXkwxAGb","__typename":"SocialPreviewType","imageUrl":""},"Post:ouSpHCCPgsXkwxAGb":{"_id":"ouSpHCCPgsXkwxAGb","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e77"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":5,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:ouSpHCCPgsXkwxAGb"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-10-12T06:08:18.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e77","commentCount":1,"voteCount":21,"baseScore":24,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00004974687544745393,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2019-12-27T20:50:18.010Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2014-10-12T06:08:18.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"five-planets-in-search-of-a-sci-fi-story","title":"Five Planets In Search Of A Sci-Fi Story","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392babcb4ac6367c165ce":{"_id":"5c6392babcb4ac6367c165ce","__typename":"Revision","htmlHighlight":"<p><i><font size=\"1\">[Content note: suicide]<\/font><\/i><\/p><p><b>Day Zero<\/b><\/p><p>It all started with an ignorant white guy.<\/p><p>His name was Alonzo de Pinzon, and he&#8217;d been shipwrecked. We heard him yelling for help on the rocks and dragged him in, even though the storm was starting to get really bad. He said that his galleon had gone down, he&#8217;d hung on to an oar and was the only survivor. Now he was sitting in our little hunting lodge, shivering and chattering his teeth and asking us questions in the Polynesian traders&#8217; argot which was the only language we all shared.<\/p><p>&#8220;How big is this island? How many of you are there?&#8221;<\/p><p>Daho answered first. &#8220;11.8 miles from the easternmost point to the westernmost point, 3.6 miles from the northernmost to the southernmost. Total area is 14.6 square miles, total coastline is dependent on how deeply you want to go into the fractal nature of the perimeter but under some reasonable assumptions about 32 miles long. Last census said there were 906 people, but that was two years ago, so assuming the 5.1% rate of population growth continues, there should be closer to 1000 now. Everyone else is back at the village, though. The five of us were out hunting and got caught in the storm. We figured we&#8217;d stay at this old hunting lodge until it cleared up, since it&#8217;s 5.5 miles back to the village and given the terrain and factoring in a delay because of the storm it would probably take at least 9.5 hours to get back.&#8221;<\/p><p>Pinzon blinked.<\/p><p>&#8220;Problem?&#8221; asked Daho.<\/p><p>&#8220;But &#8211; &#8221; he said. &#8220;That is the sort of answer I should expect from a natural philosopher. Not from a savage.&#8221;<\/p><p>&#8220;Savage?&#8221; Calkas hissed. &#8220;Really? We rescue you, and the first thing you do is call us savages?&#8221;<\/p><p>The sailor looked around, as if anxious. Finally, almost conspiratorially: &#8220;But I heard about your island! I heard you eat people!&#8221;<\/p><p>Calkas smiled. &#8220;Only as a deterrent. Most of the time when European explorers land somewhere, they kill all the men and enslave all the women and convert the children to Christianity. The only places that escape are the ones that get a reputation for eating said European explorers. So we arranged to give ourselves that reputation.&#8221;<\/p><p>&#8220;And then we had to go through with it a few times in order to make the deterrent credible,&#8221; added Bekka, my betrothed. &#8220;And you ... <\/p>","plaintextDescription":"[Content note: suicide]\n\nDay Zero\n\nIt all started with an ignorant white guy.\n\nHis name was Alonzo de Pinzon, and he’d been shipwrecked. We heard him yelling for help on the rocks and dragged him in, even though the storm was starting to get really bad. He said that his galleon had gone down, he’d hung on to an oar and was the only survivor. Now he was sitting in our little hunting lodge, shivering and chattering his teeth and asking us questions in the Polynesian traders’ argot which was the only language we all shared.\n\n“How big is this island? How many of you are there?”\n\nDaho answered first. “11.8 miles from the easternmost point to the westernmost point, 3.6 miles from the northernmost to the southernmost. Total area is 14.6 square miles, total coastline is dependent on how deeply you want to go into the fractal nature of the perimeter but under some reasonable assumptions about 32 miles long. Last census said there were 906 people, but that was two years ago, so assuming the 5.1% rate of population growth continues, there should be closer to 1000 now. Everyone else is back at the village, though. The five of us were out hunting and got caught in the storm. We figured we’d stay at this old hunting lodge until it cleared up, since it’s 5.5 miles back to the village and given the terrain and factoring in a delay because of the storm it would probably take at least 9.5 hours to get back.”\n\nPinzon blinked.\n\n“Problem?” asked Daho.\n\n“But – ” he said. “That is the sort of answer I should expect from a natural philosopher. Not from a savage.”\n\n“Savage?” Calkas hissed. “Really? We rescue you, and the first thing you do is call us savages?”\n\nThe sailor looked around, as if anxious. Finally, almost conspiratorially: “But I heard about your island! I heard you eat people!”\n\nCalkas smiled. “Only as a deterrent. Most of the time when European explorers land somewhere, they kill all the men and enslave all the women and convert the children to Christianity. The only places th","wordCount":5892,"version":"1.0.0"},"Revision:kCuRQE5Tkv9zeKyzK_description":{"_id":"kCuRQE5Tkv9zeKyzK_description","__typename":"Revision","htmlHighlight":"<p><strong>Common knowledge<\/strong> is information that everyone knows and, importantly, that everyone knows that everyone knows, and so on, ad infinitum. If information is <i>common knowledge<\/i> in a group of people, that information that can be relied and acted upon with the trust that everyone else is also coordinating around that information. This stands, in contrast, to merely publicly known information where one person cannot be sure that another person knows the information, or that another person knows that they know the information. Establishing true common knowledge is, in fact, rather hard.<\/p><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/public-discourse\">Public discourse<\/a>, <a href=\"https://www.lesswrong.com/tag/consensus\">Consensus<\/a>, <a href=\"https://www.lesswrong.com/tag/inferential-distance\">Inferential Distance<\/a><\/p><p><strong>External posts:<\/strong>&nbsp;<br><a href=\"https://www.scottaaronson.com/blog/?p=3376\">The Kolmogorov option<\/a> by Scott Aaronson<br><a href=\"https://slatestarcodex.com/2017/10/23/kolmogorov-complicity-and-the-parable-of-lightning/\">kolmogorov complicity and-the parable of lightning<\/a> by Scott Alexander<\/p>"},"Tag:kCuRQE5Tkv9zeKyzK":{"_id":"kCuRQE5Tkv9zeKyzK","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:kCuRQE5Tkv9zeKyzK_description"},"canVoteOnRels":null,"userId":"EQNTWXLKMeWMp2FQS","name":"Common Knowledge","shortName":null,"slug":"common-knowledge","core":false,"postCount":30,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-14T23:21:47.645Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:qaHHJ3kkCQS4nsoGJ":{"_id":"qaHHJ3kkCQS4nsoGJ","__typename":"SocialPreviewType","imageUrl":""},"Post:qaHHJ3kkCQS4nsoGJ":{"_id":"qaHHJ3kkCQS4nsoGJ","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392babcb4ac6367c165ce"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":24,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:F2XfCTxXLQBGjbm8P"},{"__ref":"Tag:kCuRQE5Tkv9zeKyzK"},{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:qaHHJ3kkCQS4nsoGJ"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-10-15T19:46:40.520Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"F2XfCTxXLQBGjbm8P":2,"etDohXtBrXd8WqCtR":1,"kCuRQE5Tkv9zeKyzK":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392babcb4ac6367c165ce","commentCount":1,"voteCount":39,"baseScore":46,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.00010965957335429266,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2022-07-14T10:05:24.634Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"it-was-you-who-made-my-blue-eyes-blue","title":"It Was You Who Made My Blue Eyes Blue","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:bqejiLcEsJv5n9xJt":{"_id":"bqejiLcEsJv5n9xJt","__typename":"Chapter","createdAt":"2017-09-02T07:51:08.172Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"xmDeR64CivZiTAcLx","postIds":["ouSpHCCPgsXkwxAGb","qaHHJ3kkCQS4nsoGJ"],"posts":[{"__ref":"Post:ouSpHCCPgsXkwxAGb"},{"__ref":"Post:qaHHJ3kkCQS4nsoGJ"}]},"Sequence:xmDeR64CivZiTAcLx":{"_id":"xmDeR64CivZiTAcLx","__typename":"Sequence","chapters":[{"__ref":"Chapter:8o7QyPwSHCzhDvfyw"},{"__ref":"Chapter:bqejiLcEsJv5n9xJt"}],"createdAt":"2017-08-24T01:39:54.799Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":null,"gridImageId":"sequencesgrid/u0ackeoho1tquuiozpt4","bannerImageId":"sequences/c1h4gtqbcw3v04ikuprj","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Community and Cooperation","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Book:kcCvSNNZd8pfQvf9E":{"_id":"kcCvSNNZd8pfQvf9E","__typename":"Book","createdAt":"2017-09-02T07:33:06.097Z","title":"Designing the World","number":3,"subtitle":null,"tocTitle":null,"contents":null,"sequenceIds":["rNuPrZvabXe2MaZv8","zfXAcwLnGocsCsriG","TKDT2Mt6dDMH8AsZW","xmDeR64CivZiTAcLx"],"sequences":[{"__ref":"Sequence:rNuPrZvabXe2MaZv8"},{"__ref":"Sequence:zfXAcwLnGocsCsriG"},{"__ref":"Sequence:TKDT2Mt6dDMH8AsZW"},{"__ref":"Sequence:xmDeR64CivZiTAcLx"}],"postIds":[],"posts":[],"collectionId":"2izXHCrmJ684AnZ5X","displaySequencesAsGrid":null,"hideProgressBar":null,"showChapters":null},"Revision:ohRXuYsBz8zCQq2uC_contents":{"_id":"ohRXuYsBz8zCQq2uC_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:45:28.119Z","userId":null,"html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Revision:5c6392dcbcb4ac6367c16f18":{"_id":"5c6392dcbcb4ac6367c16f18","__typename":"Revision","htmlHighlight":"<p><i><font size=\"1\">[Content note: Suicide. May be guilt-inducing for people who feel like burdens. All patient characteristics have been heavily obfuscated to protect confidentiality.]<\/font><\/i><\/p><p>The DSM lists nine criteria for major depressive disorder, of which the seventh is &#8220;feelings of worthlessness or excessive or inappropriate guilt&#8221;.<\/p><p>There are a lot of dumb diagnostic debates over which criteria are &#8220;more important&#8221; or &#8220;more fundamental&#8221;, and for me there&#8217;s always been something special about criterion seven. People get depressed over all sorts of things. But when they&#8217;re actively suicidal, the people who aren&#8217;t just gesturing for help but totally set on it, they always say one thing:<\/p><p>&#8220;I feel like I&#8217;m a burden&#8221;.<\/p><p>Depression is in part a disease of distorted cognitions, a failure of rationality. I had one patient who worked for GM, very smart guy, invented a lot of safety features for cars. He was probably actively saving a bunch of people&#8217;s lives every time he checked in at the office, and he still felt like he was worthless, a burden, that he was just draining resources that could better be used for someone else.<\/p><p>In cases like these, you can do a little bit of good just by teaching people the fundamental lesson of rationality: that you can&#8217;t always trust your brain. If your System I is telling you that you&#8217;re a worthless burden, it could be because you&#8217;re a worthless burden, or it could be because System I is broken. If System I is broken, you need to call in System II to route around the distorted cognition so you can understand at least on an intellectual level that you&#8217;re wrong. Once you understand you&#8217;re wrong on an intellectual level, you can do what you need to do to make it sink in on a practical level as well &#8211; which starts with not killing yourself.<\/p><p>As sad as it was, Robin Williams&#8217; suicide has actually been sort of helpful for me. For the past few days, I&#8217;ve tried telling these sorts of people that Robin Williams brightened the lives of millions of people, was a truly great man &#8211; and his brain <i>still<\/i> kept telling him he didn&#8217;t deserve to live. So maybe depressed brains <i>are not the most trustworthy arbiters on these sorts of issues<\/i>.<\/p><p>This sort of supportive psychotherapy (ie &#8220;psychotherapy you make up as you go along&#8221;) can sometimes... <\/p>","plaintextDescription":"[Content note: Suicide. May be guilt-inducing for people who feel like burdens. All patient characteristics have been heavily obfuscated to protect confidentiality.]\n\nThe DSM lists nine criteria for major depressive disorder, of which the seventh is “feelings of worthlessness or excessive or inappropriate guilt”.\n\nThere are a lot of dumb diagnostic debates over which criteria are “more important” or “more fundamental”, and for me there’s always been something special about criterion seven. People get depressed over all sorts of things. But when they’re actively suicidal, the people who aren’t just gesturing for help but totally set on it, they always say one thing:\n\n“I feel like I’m a burden”.\n\nDepression is in part a disease of distorted cognitions, a failure of rationality. I had one patient who worked for GM, very smart guy, invented a lot of safety features for cars. He was probably actively saving a bunch of people’s lives every time he checked in at the office, and he still felt like he was worthless, a burden, that he was just draining resources that could better be used for someone else.\n\nIn cases like these, you can do a little bit of good just by teaching people the fundamental lesson of rationality: that you can’t always trust your brain. If your System I is telling you that you’re a worthless burden, it could be because you’re a worthless burden, or it could be because System I is broken. If System I is broken, you need to call in System II to route around the distorted cognition so you can understand at least on an intellectual level that you’re wrong. Once you understand you’re wrong on an intellectual level, you can do what you need to do to make it sink in on a practical level as well – which starts with not killing yourself.\n\nAs sad as it was, Robin Williams’ suicide has actually been sort of helpful for me. For the past few days, I’ve tried telling these sorts of people that Robin Williams brightened the lives of millions of people, was a truly gre","wordCount":1479,"version":"1.0.0"},"Revision:BAhM42jvzuWMzTDxR_description":{"_id":"BAhM42jvzuWMzTDxR_description","__typename":"Revision","htmlHighlight":"<p><strong>Depression<\/strong> is a psychological disorder characterized by low mood, loss of interest in life, and poor self-esteem. Both cognitive behavioral therapy (CBT) and antidepressants such as SSRIs have proven to be effective treatments.<\/p>"},"Tag:BAhM42jvzuWMzTDxR":{"_id":"BAhM42jvzuWMzTDxR","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:BAhM42jvzuWMzTDxR_description"},"canVoteOnRels":null,"userId":"p8SHJFHRgZeMuw7qk","name":"Depression","shortName":null,"slug":"depression","core":false,"postCount":38,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-29T17:17:41.124Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:JP7eZYHB7aY6fA4TR":{"_id":"JP7eZYHB7aY6fA4TR","__typename":"SocialPreviewType","imageUrl":""},"Post:JP7eZYHB7aY6fA4TR":{"_id":"JP7eZYHB7aY6fA4TR","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16f18"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":6,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:BAhM42jvzuWMzTDxR"},{"__ref":"Tag:gsv9XWbZDcnZmKuqM"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"}],"socialPreviewData":{"__ref":"SocialPreviewType:JP7eZYHB7aY6fA4TR"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-08-16T19:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"BAhM42jvzuWMzTDxR":1,"gHCNhqxuJq2bZ2akb":1,"gsv9XWbZDcnZmKuqM":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16f18","commentCount":7,"voteCount":33,"baseScore":41,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":33,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00008393880125368014,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-10-05T16:38:21.770Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"burdens","title":"Burdens","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392c7bcb4ac6367c16bd7":{"_id":"5c6392c7bcb4ac6367c16bd7","__typename":"Revision","htmlHighlight":"<p><i><font size=\"1\">[Content note: scrupulosity and self-esteem triggers, IQ, brief discussion of weight and dieting. Not good for growth mindset.]<\/font><\/i><\/p><p><b>I.<\/b><\/p><p>I sometimes blog about research into IQ and human intelligence. I think most readers of this blog already know <A HREF=\"http://en.wikipedia.org/wiki/Heritability_of_IQ\">IQ is 50% to 80% heritable<\/A>, and that it&#8217;s so important for intellectual pursuits that <A HREF=\"http://infoproc.blogspot.com/2008/07/annals-of-psychometry-iqs-of-eminent.html\">eminent scientists in some fields have average IQs around 150 to 160<\/A>. Since IQ this high only appears in 1/10,000 people or so, it beggars coincidence to believe this represents anything but a very strong filter for IQ (or something correlated with it) in reaching that level. If you saw a group of dozens of people who were 7&#8217;0 tall on average, you&#8217;d assume it was a basketball team or some other group selected for height, not a bunch of botanists who were all very tall by coincidence.<\/p><p>A lot of people find this pretty depressing. Some worry that taking it seriously might damage the &#8220;growth mindset&#8221; people need to fully actualize their potential. This is important and I want to discuss it eventually, but not now. What I want to discuss now is people who feel <i>personally<\/i> depressed. For example, a comment from last week:<\/p>\n<blockquote><p>I’m sorry to leave self a self absorbed comment, but reading this really upset me and I just need to get this off my chest&#8230;How is a person supposed to stay sane in a culture that prizes intelligence above everything else &#8211; especially if, as Scott suggests, Human Intelligence Really Is the Key to the Future &#8211; when they themselves are not particularly intelligent and, apparently, have no potential to ever become intelligent? Right now I basically feel like pond scum.<\/p><\/blockquote>\n<p>I hear these kinds of responses every so often, so I should probably learn to expect them. I never do. They seem to me precisely backwards. There&#8217;s a moral gulf here, and I want to throw stories and intuitions at it until enough of them pile up at the bottom to make a passable bridge. But first, a comparison:<\/p><p>Some people think body weight is biologically/genetically determined. Other people think it&#8217;s based purely on willpower &#8211; how strictly you diet, how much you can bring yourself to exercise. These people get into some pretty acrimonious debates.<\/p><p>Overweight people, and especially people who feel unfairly stigmatized for being overweight, tend to cluster on the biologically determined side. And although... <\/p>","plaintextDescription":"[Content note: scrupulosity and self-esteem triggers, IQ, brief discussion of weight and dieting. Not good for growth mindset.]\n\nI.\n\nI sometimes blog about research into IQ and human intelligence. I think most readers of this blog already know IQ is 50% to 80% heritable, and that it’s so important for intellectual pursuits that eminent scientists in some fields have average IQs around 150 to 160. Since IQ this high only appears in 1/10,000 people or so, it beggars coincidence to believe this represents anything but a very strong filter for IQ (or something correlated with it) in reaching that level. If you saw a group of dozens of people who were 7’0 tall on average, you’d assume it was a basketball team or some other group selected for height, not a bunch of botanists who were all very tall by coincidence.\n\nA lot of people find this pretty depressing. Some worry that taking it seriously might damage the “growth mindset” people need to fully actualize their potential. This is important and I want to discuss it eventually, but not now. What I want to discuss now is people who feel personally depressed. For example, a comment from last week:\n\n> I’m sorry to leave self a self absorbed comment, but reading this really upset me and I just need to get this off my chest…How is a person supposed to stay sane in a culture that prizes intelligence above everything else – especially if, as Scott suggests, Human Intelligence Really Is the Key to the Future – when they themselves are not particularly intelligent and, apparently, have no potential to ever become intelligent? Right now I basically feel like pond scum.\n\nI hear these kinds of responses every so often, so I should probably learn to expect them. I never do. They seem to me precisely backwards. There’s a moral gulf here, and I want to throw stories and intuitions at it until enough of them pile up at the bottom to make a passable bridge. But first, a comparison:\n\nSome people think body weight is biologically/geneticall","wordCount":5947,"version":"1.0.0"},"Revision:spELLnBtpwwvcpK2s_description":{"_id":"spELLnBtpwwvcpK2s_description","__typename":"Revision","htmlHighlight":"<p><strong>Growth Mindset<\/strong> is the name for a hypothetical mental state wherein an agent believes that they can grow as a agent, and this belief causes the agent to try to grow, which might plausibly lead to more growth!<\/p><p>This is a very natural and obvious hypothesis that could apply to agents in general, and could be defended as a sort of useful philosophic presupposition to often start with, in most domains, about most agents, and most positive traits, that would lead to improvement behaviors that might be quite cheap, and might be quite valuable to have tried!<\/p><p>The primary academic popularizer of the idea within academic psychology is <a href=\"https://en.wikipedia.org/wiki/Carol_Dweck\">Carol Dweck<\/a>, who has been embroiled in some controversies.<\/p><p>Sometimes the idea is taken farther than is empirically justified when psychometric rigor is brought to bear on specific traits in specific situations where people might honesty (or dishonestly!) disagree about whether growth or change is possible.<\/p><p>In these debates, sometimes people with strong specific arguments about specific limits to specific growth in specific people are treated as \"just not having growth mindset\" and then their specific arguments are seemingly speciously dismissed.<\/p><p>Like most concepts, the concept of growth mindset can be abused by idiots.<\/p>"},"Tag:spELLnBtpwwvcpK2s":{"_id":"spELLnBtpwwvcpK2s","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:spELLnBtpwwvcpK2s_description"},"canVoteOnRels":null,"userId":"g8JkZfL8PTqAefpvx","name":"Growth Mindset","shortName":null,"slug":"growth-mindset","core":false,"postCount":35,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2024-09-25T07:33:02.817Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:NzSTgAtKwgivkfeYm_description":{"_id":"NzSTgAtKwgivkfeYm_description","__typename":"Revision","htmlHighlight":"<p><strong>Heroic responsibility<\/strong> is the responsibility to get the job done no matter what, including not shifting any responsibility for its completion on to others.<\/p><p><i>\"You could call it <strong>heroic responsibility<\/strong>, maybe,” Harry Potter said. “Not like the usual sort. It means that whatever happens, no matter what, it’s always your fault. Even if you tell Professor McGonagall, she’s not responsible for what happens, you are. Following the school rules isn’t an excuse, someone else being in charge isn’t an excuse, even trying your best isn’t an excuse. There just aren’t any excuses, you’ve got to get the job done no matter what.” Harry’s face tightened. “That’s why I say you’re not thinking responsibly, Hermione. Thinking that your job is done when you tell Professor McGonagall—that isn’t heroine thinking. Like Hannah being beat up is okay then, because it isn’t your fault anymore. Being a heroine means your job isn’t finished until you’ve done whatever it takes to protect the other girls, permanently.” In Harry’s voice was a touch of the steel he had acquired since the day Fawkes had been on his shoulder. “You can’t think as if just following the rules means you’ve done your duty. –<\/i><a href=\"http://hpmor.com/chapter/75\"><i>HPMOR<\/i><\/a><i>, chapter 75.<\/i><br>&nbsp;<\/p><h2>External Links<\/h2><ul><li>The discussion at this <a href=\"http://www.reddit.com/r/HPMOR/comments/yj2kb/ethical_solipsism_chapter_75/\">Reddit post<\/a> is excellent. <i>This wiki requires work.<\/i><\/li><\/ul>"},"Tag:NzSTgAtKwgivkfeYm":{"_id":"NzSTgAtKwgivkfeYm","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:NzSTgAtKwgivkfeYm_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Heroic Responsibility","shortName":null,"slug":"heroic-responsibility","core":false,"postCount":36,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-03T18:48:41.798Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:kS3QBcbwtapefkSSZ_description":{"_id":"kS3QBcbwtapefkSSZ_description","__typename":"Revision","htmlHighlight":"<p><strong>Scrupulosity<\/strong> is a tendency to hold yourself to excessively high standards and to feel really bad when you fail to meet those standards.<\/p>"},"Tag:kS3QBcbwtapefkSSZ":{"_id":"kS3QBcbwtapefkSSZ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:kS3QBcbwtapefkSSZ_description"},"canVoteOnRels":null,"userId":"HoGziwmhpMGqGeWZy","name":"Scrupulosity","shortName":null,"slug":"scrupulosity","core":false,"postCount":7,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-22T12:27:50.956Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:zwDz9pgT43fRczkB4":{"_id":"zwDz9pgT43fRczkB4","__typename":"SocialPreviewType","imageUrl":"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&l=as2&o=1&a=0521199565"},"Post:zwDz9pgT43fRczkB4":{"_id":"zwDz9pgT43fRczkB4","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392c7bcb4ac6367c16bd7"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":24,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:spELLnBtpwwvcpK2s"},{"__ref":"Tag:NzSTgAtKwgivkfeYm"},{"__ref":"Tag:kS3QBcbwtapefkSSZ"}],"socialPreviewData":{"__ref":"SocialPreviewType:zwDz9pgT43fRczkB4"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-01-31T21:44:56.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"NzSTgAtKwgivkfeYm":2,"kS3QBcbwtapefkSSZ":2,"spELLnBtpwwvcpK2s":8},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392c7bcb4ac6367c16bd7","commentCount":9,"voteCount":38,"baseScore":47,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":38,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00010182838013861328,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2015-01-31T21:44:56.000Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":5,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2015-01-31T21:44:56.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-parable-of-the-talents","title":"The Parable Of The Talents","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e63":{"_id":"5c6392dcbcb4ac6367c16e63","__typename":"Revision","htmlHighlight":"<p><b>I.<\/b><\/p><p>Recently spotted on Tumblr:<\/p>\n<blockquote><p>“This is going to be an unpopular opinion but I see stuff about ppl not wanting to reblog ferguson things and awareness around the world because they do not want negativity in their life plus it will cause them to have anxiety. They come to tumblr to escape n feel happy which think is a load of bull. There r literally ppl dying who live with the fear of going outside their homes to be shot and u cant post a fucking picture because it makes u a little upset?&#8221;<\/p><\/blockquote>\n<blockquote><p>“Can yall maybe take some time away from reblogging fandom or humor crap and read up and reblog pakistan because the privilege you have of a safe bubble is not one shared by others?”<\/p><\/blockquote>\n<p>Ignore the questionable stylistic choices and there&#8217;s an important point here worth considering. Something like &#8220;Yes, the feeling of constantly being outraged and mired in the latest controversy is unpleasant. And yes, it would be nice to get to avoid it and spend time with your family and look at kitten pics or something. But when the controversy is about people being murdered in cold blood, or living in fear, or something like that &#8211; then it&#8217;s your duty as a decent human being to care. In the best case scenario you&#8217;ll discharge that duty by organizing widespread protests or something &#8211; but the <i>absolute least<\/i> you can do is reblog a couple of slogans.&#8221;<\/p><p>I think Cliff Pervocracy is trying to say something similar in <A HREF=\"http://pervocracy.tumblr.com/post/104260760964/politics-that-feel-good\">this post<\/A>. Key excerpt:<\/p>\n<blockquote><p>When you’ve grown up with messages that you’re incompetent to make your own decisions, that you don’t deserve any of the things you have, and that you’ll never be good enough, the [conservative] fantasy of rugged individualism starts looking pretty damn good.<\/p><p>Intellectually, I think my current political milieu of feminism/progressivism/social justice is more correct, far better for the world in general, and more helpful to me since I don’t actually live in a perfectly isolated cabin.<\/p><p>But god, it’s uncomfortable.  It’s intentionally uncomfortable—it’s all about getting angry at injustice and questioning the rightness of your own actions and being sad so many people still live such painful lives.  Instead of looking at your cabin and declaring “I shall name it&#8230;CLIFFORDSON MANOR,” you need to look at your cabin and recognize that a long series of brutal injustices are responsible for the fact that you have a white-<\/p><\/blockquote>... ","plaintextDescription":"I.\n\nRecently spotted on Tumblr:\n\n> “This is going to be an unpopular opinion but I see stuff about ppl not wanting to reblog ferguson things and awareness around the world because they do not want negativity in their life plus it will cause them to have anxiety. They come to tumblr to escape n feel happy which think is a load of bull. There r literally ppl dying who live with the fear of going outside their homes to be shot and u cant post a fucking picture because it makes u a little upset?”\n\n> “Can yall maybe take some time away from reblogging fandom or humor crap and read up and reblog pakistan because the privilege you have of a safe bubble is not one shared by others?”\n\nIgnore the questionable stylistic choices and there’s an important point here worth considering. Something like “Yes, the feeling of constantly being outraged and mired in the latest controversy is unpleasant. And yes, it would be nice to get to avoid it and spend time with your family and look at kitten pics or something. But when the controversy is about people being murdered in cold blood, or living in fear, or something like that – then it’s your duty as a decent human being to care. In the best case scenario you’ll discharge that duty by organizing widespread protests or something – but the absolute least you can do is reblog a couple of slogans.”\n\nI think Cliff Pervocracy is trying to say something similar in this post. Key excerpt:\n\n> When you’ve grown up with messages that you’re incompetent to make your own decisions, that you don’t deserve any of the things you have, and that you’ll never be good enough, the [conservative] fantasy of rugged individualism starts looking pretty damn good.\n> \n> Intellectually, I think my current political milieu of feminism/progressivism/social justice is more correct, far better for the world in general, and more helpful to me since I don’t actually live in a perfectly isolated cabin.\n> \n> But god, it’s uncomfortable. It’s intentionally uncomfortable—it","wordCount":3375,"version":"1.0.0"},"Revision:JsJPrdgRGRqnci8cZ_description":{"_id":"JsJPrdgRGRqnci8cZ_description","__typename":"Revision","htmlHighlight":"<p><strong>Altruism<\/strong> refers to actions undertaken for the concern and benefit of others at ones own expense.<\/p>\n<blockquote>\n<p>\"an \"altruist\" is someone who chooses between actions according to the criterion of others' welfare\" - <a href=\"https://www.lesswrong.com/posts/EA39yRbhBbrccXnHi/inner-goodness\">Eliezer Yudkowsky<\/a><\/p>\n<\/blockquote>\n<p><em>Related tags and wikis:<\/em> <a href=\"https://www.lesswrong.com/tag/shut-up-and-multiply\">Shut up and multiply<\/a>, <a href=\"https://www.lesswrong.com/tag/fuzzies\">Fuzzies<\/a>, <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a>, <a href=\"https://www.lesswrong.com/tag/effective-altruism\">Effective Altruism<\/a>, <a href=\"https://www.lesswrong.com/tag/cause-prioritization\">Cause Prioritization<\/a>, <a href=\"https://www.lesswrong.com/tag/motivations\">Motivations<\/a>, <a href=\"https://www.lesswrong.com/tag/psychology-of-altruism\">Psychology of Altruism<\/a>, <a href=\"https://www.lesswrong.com/tag/ethics-and-morality\">Ethics and Morality<\/a><\/p>"},"Tag:JsJPrdgRGRqnci8cZ":{"_id":"JsJPrdgRGRqnci8cZ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:JsJPrdgRGRqnci8cZ_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Altruism","shortName":null,"slug":"altruism","core":false,"postCount":90,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-29T04:09:40.219Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:3ee9k6NJfcGzL6kMS_description":{"_id":"3ee9k6NJfcGzL6kMS_description","__typename":"Revision","htmlHighlight":"<p>Contrary to the stereotype, <a href=\"https://www.lesswrong.com/tag/rationality\">rationality<\/a> doesn't mean denying <strong>emotion<\/strong>. When emotion is appropriate to the reality of the situation, it should be embraced; only when emotion isn't appropriate should it be suppressed.<\/p><h2>External links<\/h2><ul><li><a href=\"http://www.youtube.com/watch?v=tLgNZ9aTEwc\">The Straw Vulcan<\/a>, a talk introducing rationality, by <a href=\"http://lesswrong.com/user/Julia_Galef/\">Julia Galef<\/a> (<a href=\"https://www.lesswrong.com/lw/90n/summary_of_the_straw_vulcan/\">summary<\/a>) [TODO: this video has been removed, find a good replacement]<\/li><li><a href=\"http://www.overcomingbias.com/2006/12/vulcan_logic.html\">Vulcan Logic<\/a> by <a href=\"https://en.wikipedia.org/wiki/Hal_Finney_(cypherpunk)\">Hal Finney<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/alief\">Alief<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/truth-semantics-and-meaning\">Truth<\/a>, <a href=\"https://www.lesswrong.com/tag/rationality\">Rationality<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/litany-of-tarski\">Litany of Tarski<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/hollywood-rationality\">Hollywood rationality<\/a><\/li><\/ul>"},"Tag:3ee9k6NJfcGzL6kMS":{"_id":"3ee9k6NJfcGzL6kMS","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3ee9k6NJfcGzL6kMS_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Emotions","shortName":null,"slug":"emotions","core":false,"postCount":190,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-07T21:10:58.722Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:qw3Z79HELMsmLkL9F":{"_id":"qw3Z79HELMsmLkL9F","__typename":"SocialPreviewType","imageUrl":"http://slatestarcodex.com/blog_images/sschits.png"},"Post:qw3Z79HELMsmLkL9F":{"_id":"qw3Z79HELMsmLkL9F","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e63"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":14,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:JsJPrdgRGRqnci8cZ"},{"__ref":"Tag:3ee9k6NJfcGzL6kMS"},{"__ref":"Tag:FkzScn5byCs9PxGsA"}],"socialPreviewData":{"__ref":"SocialPreviewType:qw3Z79HELMsmLkL9F"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2014-12-19T05:00:06.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"3ee9k6NJfcGzL6kMS":1,"FkzScn5byCs9PxGsA":1,"JsJPrdgRGRqnci8cZ":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e63","commentCount":4,"voteCount":21,"baseScore":42,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0000897097124834545,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2021-08-19T12:57:18.348Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2014-12-19T05:00:06.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"nobody-is-perfect-everything-is-commensurable","title":"Nobody Is Perfect, Everything Is Commensurable","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:ohRXuYsBz8zCQq2uC":{"_id":"ohRXuYsBz8zCQq2uC","__typename":"Chapter","createdAt":"2017-08-24T01:45:28.119Z","title":null,"subtitle":null,"contents":{"__ref":"Revision:ohRXuYsBz8zCQq2uC_contents"},"number":0,"sequenceId":"WnTvZdXz2q9ySfr4o","postIds":["JP7eZYHB7aY6fA4TR","zwDz9pgT43fRczkB4","qw3Z79HELMsmLkL9F"],"posts":[{"__ref":"Post:JP7eZYHB7aY6fA4TR"},{"__ref":"Post:zwDz9pgT43fRczkB4"},{"__ref":"Post:qw3Z79HELMsmLkL9F"}]},"Revision:5c6392fcbcb4ac6367c17170":{"_id":"5c6392fcbcb4ac6367c17170","__typename":"Revision","htmlHighlight":"<p><em>(with apologies to <a href=\"http://smile.amazon.com/gp/product/0691150478/ref=as_li_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0691150478&linkCode=as2&tag=slastacod-20&linkId=GTJE5YFZEADILCWO\">Jung<\/a>)<\/em><\/p><p>Job asked: “God, why do bad things happen to good people? Why would You, who are perfect, create a universe filled with so much that is evil?”<\/p><p>Then the Lord spoke to Job out of the whirlwind, saying “WHAT KIND OF UNIVERSE WOULD YOU PREFER ME TO HAVE CREATED?”<\/p><p>Job said “A universe that was perfectly just and full of happiness, of course.”<\/p><p>“OH,” said God. “YES, I CREATED ONE OF THOSE. IT’S EXACTLY AS NICE AS YOU WOULD EXPECT.”<\/p><p>Job facepalmed. “But then why would You also create <em>this<\/em> universe?”<\/p><p>Answered God: “DON’T YOU LIKE EXISTING?”<\/p><p>“Yes,” said Job, “but all else being equal, I’d rather be in the perfectly just and happy universe.”<\/p><p>“OH, DON’T WORRY,” said God. “THERE’S A VERSION OF YOU IN THAT UNIVERSE TOO. HE SAYS HI.”<\/p><p>“Okay,” said Job, very carefully. “I can see I’m going to have to phrase my questions more specifically. Why didn’t You also make <em>this<\/em> universe perfectly just and happy?”<\/p><p>“BECAUSE YOU CAN’T HAVE TWO IDENTICAL INDIVIDUALS. IF YOU HAVE A COMPUTATIONAL THEORY OF IDENTITY, THEN TWO PEOPLE WHOSE EXPERIENCE IS ONE HUNDRED PERCENT SATURATED BY BLISS ARE JUST ONE PERSON. IF I MADE THIS UNIVERSE EXACTLY LIKE THE HAPPY AND JUST UNIVERSE, THEN THERE WOULD ONLY BE THE POPULATION OF THE HAPPY AND JUST UNIVERSE, WHICH WOULD BE LESS GOOD THAN HAVING THE POPULATION OF THE HAPPY AND JUST UNIVERSE PLUS THE POPULATION OF ONE EXTRA UNIVERSE THAT IS AT LEAST SOMEWHAT HAPPY.”<\/p><p>“Hmmmmm. But couldn’t You have have made this universe like the happy and just universe except for one tiny detail? Like in that universe, the sun is a sphere, but in our universe, the sun is a cube? Then you would have individuals who experienced a spherical sun, and other individuals who experienced a cubic sun, which would be enough to differentiate them.”<\/p><p>“I DID THAT TOO. I HAVE CREATED ALL POSSIBLE PERMUTATIONS OF THE HAPPY AND JUST UNIVERSE AND ITS POPULACE.”<\/p><p>“All of them? That would be…a lot of universes.”<\/p><p>“NOT AS MANY AS YOU THINK.” said God. “IN THE END IT TURNED OUT TO BE ONLY ABOUT 10^(10^(10^(10^(10^984)))). AFTER THAT I RAN OUT OF POSSIBLE PERMUTATIONS OF UNIVERSES THAT COULD REASONABLY BE DESCRIBED AS PERFECTLY HAPPY AND JUST. SO I STARTED CREATING ONES INCLUDING SMALL AMOUNTS OF EVIL.”<\/p><p>“Small amounts! But the universe has…”<\/p><p>“I WAS NOT REFERRING TO YOUR UNIVERSE. I EXHAUSTED THOSE, AND THEN I STARTED CREATING ONES INCLUDING IMMENSE AMOUNTS OF EVIL.”<\/p><p>“Oh.” Then: “What, exa... <\/p>","plaintextDescription":"(with apologies to Jung)\n\nJob asked: “God, why do bad things happen to good people? Why would You, who are perfect, create a universe filled with so much that is evil?”\n\nThen the Lord spoke to Job out of the whirlwind, saying “WHAT KIND OF UNIVERSE WOULD YOU PREFER ME TO HAVE CREATED?”\n\nJob said “A universe that was perfectly just and full of happiness, of course.”\n\n“OH,” said God. “YES, I CREATED ONE OF THOSE. IT’S EXACTLY AS NICE AS YOU WOULD EXPECT.”\n\nJob facepalmed. “But then why would You also create this universe?”\n\nAnswered God: “DON’T YOU LIKE EXISTING?”\n\n“Yes,” said Job, “but all else being equal, I’d rather be in the perfectly just and happy universe.”\n\n“OH, DON’T WORRY,” said God. “THERE’S A VERSION OF YOU IN THAT UNIVERSE TOO. HE SAYS HI.”\n\n“Okay,” said Job, very carefully. “I can see I’m going to have to phrase my questions more specifically. Why didn’t You also make this universe perfectly just and happy?”\n\n“BECAUSE YOU CAN’T HAVE TWO IDENTICAL INDIVIDUALS. IF YOU HAVE A COMPUTATIONAL THEORY OF IDENTITY, THEN TWO PEOPLE WHOSE EXPERIENCE IS ONE HUNDRED PERCENT SATURATED BY BLISS ARE JUST ONE PERSON. IF I MADE THIS UNIVERSE EXACTLY LIKE THE HAPPY AND JUST UNIVERSE, THEN THERE WOULD ONLY BE THE POPULATION OF THE HAPPY AND JUST UNIVERSE, WHICH WOULD BE LESS GOOD THAN HAVING THE POPULATION OF THE HAPPY AND JUST UNIVERSE PLUS THE POPULATION OF ONE EXTRA UNIVERSE THAT IS AT LEAST SOMEWHAT HAPPY.”\n\n“Hmmmmm. But couldn’t You have have made this universe like the happy and just universe except for one tiny detail? Like in that universe, the sun is a sphere, but in our universe, the sun is a cube? Then you would have individuals who experienced a spherical sun, and other individuals who experienced a cubic sun, which would be enough to differentiate them.”\n\n“I DID THAT TOO. I HAVE CREATED ALL POSSIBLE PERMUTATIONS OF THE HAPPY AND JUST UNIVERSE AND ITS POPULACE.”\n\n“All of them? That would be…a lot of universes.”\n\n“NOT AS MANY AS YOU THINK.” said God. “IN THE END ","wordCount":1116,"version":"1.0.0"},"Revision:NSMKfa8emSbGNXRKD_description":{"_id":"NSMKfa8emSbGNXRKD_description","__typename":"Revision","htmlHighlight":"<p><strong>Religion<\/strong> is a complex group of human activities — involving commitment to higher power, <a href=\"https://www.lesswrong.com/tag/belief-in-belief\">belief in belief<\/a>, and a range of shared group practices such as worship meetings, rites of passage, etc.<\/p><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/groupthink\">Groupthink<\/a>, <a href=\"https://www.lesswrong.com/tag/affective-death-spiral\">Affective death spiral<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/belief-in-belief\">Belief in belief<\/a>, <a href=\"https://www.lesswrong.com/tag/improper-belief\">improper belief<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/epistemic-hygiene\">Epistemic hygiene<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/truth-semantics-and-meaning\">Truth<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/rationalization\">Rationalization<\/a>, <a href=\"https://www.lesswrong.com/tag/self-deception\">self-deception<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/magic\">Magic<\/a>, <a href=\"https://www.lesswrong.com/tag/fake-simplicity\">fake simplicity<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/absurdity-heuristic\">Absurdity heuristic<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Third_alternative\">Third alternative<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/mysterious-answers-to-mysterious-questions\">Mysterious Answers to Mysterious Questions<\/a><\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"http://bloggingheads.tv/diavlogs/18501\">BHTV: Yudkowsky &amp; Adam Frank on \"religious experience\"<\/a><\/li><\/ul>"},"Tag:NSMKfa8emSbGNXRKD":{"_id":"NSMKfa8emSbGNXRKD","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:NSMKfa8emSbGNXRKD_description"},"canVoteOnRels":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Religion","shortName":null,"slug":"religion","core":false,"postCount":193,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-15T23:11:08.425Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:ZTRNmvQGgoYiymYnq_description":{"_id":"ZTRNmvQGgoYiymYnq_description","__typename":"Revision","htmlHighlight":"<p><strong>Consequentialism<\/strong> is the ethical theory that people should choose their actions based on the outcomes they expect will result. Particular frameworks of consequentialism specify how outcomes should be judged. For example, <a href=\"https://www.lesswrong.com/tag/utilitarianism\">utilitarianism<\/a> holds that the best outcome is that which maximizes the total welfare of all people, and ethical egoism holds that the best outcome is that which maximizes their own personal interests. Consequentialism is one of three main strands of ethical thought, along with deontology, which holds that people should choose actions based on the merit of the act itself, and virtue ethics, which holds that people should be judged by how virtuous they are, as an assessment of their entire history of actions.<\/p><p>Related: <a href=\"https://www.lesswrong.com/tag/ethics-and-morality\">Ethics &amp; Morality<\/a>, <a href=\"http://lesswrong.com/tag/deontology\">Deontology<\/a>, <a href=\"/tag/moral-uncertainty\">Moral Uncertainty<\/a>, <a href=\"https://www.lesswrong.com/tag/utilitarianism\">Utilitarianism<\/a><\/p><p>Consequentialism is often associated with maximizing the <a href=\"https://www.lesswrong.com/tag/expected-utility\">expected value<\/a> of a <a href=\"https://www.lesswrong.com/tag/utility-functions\">utility function<\/a>. However, it has been argued that consequentialism is not the same thing as having a utility function because it is possible to evaluate actions based on their consequences without obeying the <a href=\"http://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem\">von Neuman-Morgenstern axioms<\/a> necessary for having a utility function, and because utility functions can also be used to implement moral theories similar to deontology.<\/p><h2>Blog posts<\/h2><ul><li><a href=\"https://www.lesswrong.com/lw/uv/ends_dont_justify_means_among_humans/\">Ends Don't Justify Means (Among Humans)<\/a><\/li><li><a href=\"https://www.lesswrong.com/lw/kn/torture_vs_dust_specks/\">Torture vs. Dust Specks<\/a><\/li><li><a href=\"https://www.lesswrong.com/lw/1og/deontology_for_consequentialists/\">Deontology for Consequentialists<\/a><\/li><li><a href=\"https://www.lesswrong.com/lw/2aa/virtue_ethics_for_consequentialists/\">Virtue Ethics for Consequentialists<\/a><\/li><li><a href=\"https://www.lesswrong.com/lw/778/consequentialism_need_not_be_nearsighted/\">Consequentialism Need Not Be Shortsighted<\/a><\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"http://plato.stanford.edu/archives/win2011/entries/consequentialism/\">Consequentialism entry on Stanford Encyclopedia of Philosophy<\/a><\/li><li><a href=\"http://www.raikoth.net/consequentialism.html\">Consequentialism FAQ<\/a> by Scott Alexander<\/li><li><a href=\"http://people.howstuffworks.com/trolley-problem.htm\">Description and discussion about trolley problems<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/utilitarianism\">Utilitarianism<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/utility\">Utility<\/a>, <a href=\"https://www.lesswrong.com/tag/utility-functions\">utility function<\/a>, <a href=\"https://www.lesswrong.com/tag/expected-utility\">expected utility<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/metaethics-sequence\">Metaethics sequence<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/ethical-injunction\">Ethical injunction<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/shut-up-and-multiply\">Shut up and multiply<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Hedons\">Hedons<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/utils\">utils<\/a>, <a href=\"https://www.lesswrong.com/tag/fuzzies\">fuzzies<\/a><\/li><\/ul><h2>References<\/h2><ul><li>Jeremy Bentham (1907). <i>An Introduction to the Principles of Morals and Legislation<\/i>. Library of Economics and Liberty.<\/li><li>Perter Fishburn (1970). <i>Utility Theory for Decision Making<\/i>. Huntington, NY.<\/li><li>Walter Sinnot-Armstrong (2011). \"<a href=\"http://plato.stanford.edu/archives/win2011/entries/consequentialism/\"><u>Consequentialism<\/u><\/a>\". <i>The Stanford Encyclopedia of Philosophy (Winter 2011 Edition)<\/i>.<\/li><li>Judith Jarvis Thonson (1975). \"Killing, Letting Die, and the Trolley Problem\". <i>The Monist<\/i> <strong>59<\/strong>: 204-217.<\/li><\/ul>"},"Tag:ZTRNmvQGgoYiymYnq":{"_id":"ZTRNmvQGgoYiymYnq","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZTRNmvQGgoYiymYnq_description"},"canVoteOnRels":null,"userId":"73yyrm8KF6GDK9sRy","name":"Consequentialism","shortName":null,"slug":"consequentialism","core":false,"postCount":88,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-16T20:17:20.286Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:Lt8Rn4rkYwqiTXGPy":{"_id":"Lt8Rn4rkYwqiTXGPy","__typename":"SocialPreviewType","imageUrl":""},"Post:Lt8Rn4rkYwqiTXGPy":{"_id":"Lt8Rn4rkYwqiTXGPy","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392fcbcb4ac6367c17170"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":4,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:NSMKfa8emSbGNXRKD"},{"__ref":"Tag:ZTRNmvQGgoYiymYnq"}],"socialPreviewData":{"__ref":"SocialPreviewType:Lt8Rn4rkYwqiTXGPy"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-03-15T18:02:53.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"NSMKfa8emSbGNXRKD":4,"ZTRNmvQGgoYiymYnq":2,"etDohXtBrXd8WqCtR":16},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392fcbcb4ac6367c17170","commentCount":7,"voteCount":42,"baseScore":66,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":42,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00014400000509340316,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-03-27T03:09:48.375Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":false,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":10,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":9,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2015-03-15T18:02:53.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"answer-to-job","title":"Answer to Job","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16ef1":{"_id":"5c6392dcbcb4ac6367c16ef1","__typename":"Revision","htmlHighlight":"<p>&#8220;Universal love,&#8221; said the cactus person.<\/p><p>&#8220;Transcendent joy,&#8221; said the big green bat.<\/p><p>&#8220;Right,&#8221; I said. &#8220;I&#8217;m absolutely in favor of both those things. But before we go any further, could you tell me the two prime factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494 ,580,122,963, 258,952,897, 654,000,350, 692,006,139?<\/p><p>&#8220;Universal love,&#8221; said the cactus person.<\/p><p>&#8220;Transcendent joy,&#8221; said the big green bat.<\/p><p>The sea was made of strontium; the beach was made of rye. Above my head, a watery sun shone in an oily sky. A thousand stars of sertraline whirled round quetiapine moons, and the sand sizzled sharp like cooking oil that hissed and sang and threatened to boil the octahedral dunes.<\/p><p>&#8220;Okay,&#8221; I said. &#8220;Fine. Let me tell you where I&#8217;m coming from. I was reading <A HREF=\"https://www.psychologytoday.com/blog/unique-everybody-else\">Scott McGreal&#8217;s blog<\/A>, which has some <A HREF=\"https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-1\">good<\/A> <A HREF=\"https://www.psychologytoday.com/blog/unique-everybody-else/201210/dmt-aliens-and-reality-part-2\">articles<\/A> about so-called DMT entities, and mentions how they seem so real that users of the drug insist they&#8217;ve made contact with actual superhuman beings and not just psychedelic hallucinations. You know, <a href=\"http://smile.amazon.com/gp/product/0062506528/ref=as_li_tl?ie=UTF8&#038;camp=1789&#038;creative=390957&#038;creativeASIN=0062506528&#038;linkCode=as2&#038;tag=slastacod-20&#038;linkId=BKGSPUHIEWFDXXWZ\">the usual<\/a><img src=\"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&#038;l=as2&#038;o=1&#038;a=0062506528\" width=\"1\" height=\"1\" border=\"0\" alt=\"\" style=\"border:none !important; margin:0px !important;\" /> Terence McKenna stuff. But in <A HREF=\"https://www.psychologytoday.com/blog/unique-everybody-else/201408/dmt-gateway-reality-fantasy-or-what\">one<\/A> of them he mentions a paper by Marko Rodriguez called <A HREF=\"http://www.ayahuasca-info.com/data/articles/paralleldmt.pdf\"><i>A Methodology For Studying Various Interpretations of the N,N-dimethyltryptamine-Induced Alternate Reality<\/i><\/A>, which suggested among other things that you could prove DMT entities were real by taking the drug and then asking the entities you meet to factor large numbers which you were sure you couldn&#8217;t factor yourself. So to that end, could you do me a big favor and tell me the factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494, 580,122,963, 258,952,897, 654,000,350, 692,006,139?<\/p><p>&#8220;Universal love,&#8221; said the cactus person.<\/p><p>&#8220;Transcendent joy,&#8221; said the big green bat.<\/p><p>The sea turned hot and geysers shot up from the floor below. First one of wine, then one of brine, then one more yet of turpentine, and we three stared at the show.<\/p><p>&#8220;I was afraid you might say that. Is there anyone more, uh, <i>verbal<\/i> here whom I could talk to?&#8221;<\/p><p>&#8220;Universal love,&#8221; said the cactus person.<\/p><p>At the sound of that, the big green bat started rotating in place. On its other side was a bigger greener bat, with a ancient, wrinkled face.<\/p><p>&#8220;<i>Not splitting numbers /<\/i>... <\/p>","plaintextDescription":"“Universal love,” said the cactus person.\n\n“Transcendent joy,” said the big green bat.\n\n“Right,” I said. “I’m absolutely in favor of both those things. But before we go any further, could you tell me the two prime factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494 ,580,122,963, 258,952,897, 654,000,350, 692,006,139?\n\n“Universal love,” said the cactus person.\n\n“Transcendent joy,” said the big green bat.\n\nThe sea was made of strontium; the beach was made of rye. Above my head, a watery sun shone in an oily sky. A thousand stars of sertraline whirled round quetiapine moons, and the sand sizzled sharp like cooking oil that hissed and sang and threatened to boil the octahedral dunes.\n\n“Okay,” I said. “Fine. Let me tell you where I’m coming from. I was reading Scott McGreal’s blog, which has some good articles about so-called DMT entities, and mentions how they seem so real that users of the drug insist they’ve made contact with actual superhuman beings and not just psychedelic hallucinations. You know, the usual Terence McKenna stuff. But in one of them he mentions a paper by Marko Rodriguez called A Methodology For Studying Various Interpretations of the N,N-dimethyltryptamine-Induced Alternate Reality, which suggested among other things that you could prove DMT entities were real by taking the drug and then asking the entities you meet to factor large numbers which you were sure you couldn’t factor yourself. So to that end, could you do me a big favor and tell me the factors of 1,522,605,027, 922,533,360, 535,618,378, 132,637,429, 718,068,114, 961,380,688, 657,908,494, 580,122,963, 258,952,897, 654,000,350, 692,006,139?\n\n“Universal love,” said the cactus person.\n\n“Transcendent joy,” said the big green bat.\n\nThe sea turned hot and geysers shot up from the floor below. First one of wine, then one of brine, then one more yet of turpentine, and we three stared at the show.\n\n“I was afraid you might say that. Is there anyon","wordCount":2879,"version":"1.0.0"},"SocialPreviewType:SvKSwT6xYfYahH4XN":{"_id":"SvKSwT6xYfYahH4XN","__typename":"SocialPreviewType","imageUrl":"http://ir-na.amazon-adsystem.com/e/ir?t=slastacod-20&l=as2&o=1&a=0062506528"},"Post:SvKSwT6xYfYahH4XN":{"_id":"SvKSwT6xYfYahH4XN","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16ef1"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":12,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"}],"socialPreviewData":{"__ref":"SocialPreviewType:SvKSwT6xYfYahH4XN"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-04-22T02:42:11.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"etDohXtBrXd8WqCtR":17},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16ef1","commentCount":3,"voteCount":48,"baseScore":62,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":47,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00013800000306218863,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2024-07-18T17:26:09.870Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2015-04-22T02:42:11.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"universal-love-said-the-cactus-person","title":"Universal Love, Said The Cactus Person","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:5c6392dcbcb4ac6367c16e14":{"_id":"5c6392dcbcb4ac6367c16e14","__typename":"Revision","htmlHighlight":"<p><font size=\"1\"><i>[Related to: <A HREF=\"http://www.overcomingbias.com/2015/08/specific-vs-general-foragers-farmers.html\">Specific vs. General Foragers vs. Farmers<\/A> and <A HREF=\"http://www.xenosystems.net/war-in-heaven/\">War In Heaven<\/A>, but especially <A HREF=\"http://lesswrong.com/lw/sa/the_gift_we_give_to_tomorrow/\">The Gift We Give To Tomorrow<\/A>]<\/i><\/font><\/p><p>They say only Good can create, whereas Evil is sterile. Think Tolkien, where Morgoth can&#8217;t make things himself, so perverts Elves to Orcs for his armies. But I think this gets it entirely backwards; it&#8217;s Good that just mutates and twists, and it&#8217;s Evil that teems with fecundity.<\/p><p>Imagine two principles, here in poetic personification. The first is the Goddess of Cancer, the second the Goddess of Everything Else. If visual representations would help, you can think of the first with the claws of a crab, and the second a dress made of feathers of peacocks.<\/p><p>The Goddess of Cancer reached out a clawed hand over mudflats and tidepools. She said pretty much what she always says, &#8220;KILL CONSUME MULTIPLY CONQUER.&#8221; Then everything burst into life, became miniature monsters engaged in a battle of all against all in their zeal to assuage their insatiable longings. And the swamps became orgies of hunger and fear and grew loud with the screams of a trillion amoebas.<\/p><p>Then the Goddess of Everything Else trudged her way through the bog, till the mud almost totally dulled her bright colors and rainbows. She stood on a rock and she sang them a dream of a different existence. She showed them the beauty of flowers, she showed them the oak tree majestic. The roar of the wind on the wings of the bird, and the swiftness and strength of the tiger. She showed them the joy of the dolphins abreast of the waves as the spray formed a rainbow around them, and all of them watched as she sang and they all sighed with longing.<\/p><p>But they told her &#8220;Alas, what you show us is terribly lovely. But we are the daughters and sons of the Goddess of Cancer, and wholly her creatures. The only goals in us are KILL CONSUME MULTIPLY CONQUER. And though our hearts long for you, still we are not yours to have, and your words have no power to move us. We wish it were otherwise, but it is not, and your words have no power to move us.&#8221;<\/p><p>The Goddess of Everything Else gave a smile and spoke in her sing-song voice saying: &#8220;I scarcely can blame you for being the way you were made, when your Maker so carefully yoked you. But I am the Goddess of Everything Else and my powers are devious and subtle. So I do not ask you to swerve from your monomaniacal focus on br... <\/p>","plaintextDescription":"[Related to: Specific vs. General Foragers vs. Farmers and War In Heaven, but especially The Gift We Give To Tomorrow]\n\nThey say only Good can create, whereas Evil is sterile. Think Tolkien, where Morgoth can’t make things himself, so perverts Elves to Orcs for his armies. But I think this gets it entirely backwards; it’s Good that just mutates and twists, and it’s Evil that teems with fecundity.\n\nImagine two principles, here in poetic personification. The first is the Goddess of Cancer, the second the Goddess of Everything Else. If visual representations would help, you can think of the first with the claws of a crab, and the second a dress made of feathers of peacocks.\n\nThe Goddess of Cancer reached out a clawed hand over mudflats and tidepools. She said pretty much what she always says, “KILL CONSUME MULTIPLY CONQUER.” Then everything burst into life, became miniature monsters engaged in a battle of all against all in their zeal to assuage their insatiable longings. And the swamps became orgies of hunger and fear and grew loud with the screams of a trillion amoebas.\n\nThen the Goddess of Everything Else trudged her way through the bog, till the mud almost totally dulled her bright colors and rainbows. She stood on a rock and she sang them a dream of a different existence. She showed them the beauty of flowers, she showed them the oak tree majestic. The roar of the wind on the wings of the bird, and the swiftness and strength of the tiger. She showed them the joy of the dolphins abreast of the waves as the spray formed a rainbow around them, and all of them watched as she sang and they all sighed with longing.\n\nBut they told her “Alas, what you show us is terribly lovely. But we are the daughters and sons of the Goddess of Cancer, and wholly her creatures. The only goals in us are KILL CONSUME MULTIPLY CONQUER. And though our hearts long for you, still we are not yours to have, and your words have no power to move us. We wish it were otherwise, but it is not, and y","wordCount":2309,"version":"1.0.0"},"SocialPreviewType:MFNJ7kQttCuCXHp8P":{"_id":"MFNJ7kQttCuCXHp8P","__typename":"SocialPreviewType","imageUrl":""},"Post:MFNJ7kQttCuCXHp8P":{"_id":"MFNJ7kQttCuCXHp8P","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:5c6392dcbcb4ac6367c16e14"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ai87fPyyT6mWb4YkT"},{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:F2XfCTxXLQBGjbm8P"}],"socialPreviewData":{"__ref":"SocialPreviewType:MFNJ7kQttCuCXHp8P"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2015-08-17T20:59:40.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"F2XfCTxXLQBGjbm8P":4,"ai87fPyyT6mWb4YkT":11,"etDohXtBrXd8WqCtR":6},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"5c6392dcbcb4ac6367c16e14","commentCount":8,"voteCount":54,"baseScore":90,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":54,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00020831161236856133,"lastVisitedAt":null,"isFuture":false,"isRead":null,"lastCommentedAt":"2023-02-06T01:07:23.474Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"codex","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":15,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"the-goddess-of-everything-else","title":"The Goddess of Everything Else","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Chapter:goJvGrYJRhGmSA4Yq":{"_id":"goJvGrYJRhGmSA4Yq","__typename":"Chapter","createdAt":"2017-08-24T01:46:03.374Z","title":"Interlude","subtitle":null,"contents":null,"number":1,"sequenceId":"WnTvZdXz2q9ySfr4o","postIds":["Lt8Rn4rkYwqiTXGPy","SvKSwT6xYfYahH4XN","MFNJ7kQttCuCXHp8P"],"posts":[{"__ref":"Post:Lt8Rn4rkYwqiTXGPy"},{"__ref":"Post:SvKSwT6xYfYahH4XN"},{"__ref":"Post:MFNJ7kQttCuCXHp8P"}]},"Revision:WnTvZdXz2q9ySfr4o_contents":{"_id":"WnTvZdXz2q9ySfr4o_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:44:23.722Z","userId":"XgYW5s8njaYrtyP7q","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Sequence:WnTvZdXz2q9ySfr4o":{"_id":"WnTvZdXz2q9ySfr4o","__typename":"Sequence","chapters":[{"__ref":"Chapter:ohRXuYsBz8zCQq2uC"},{"__ref":"Chapter:goJvGrYJRhGmSA4Yq"}],"createdAt":"2017-08-24T01:44:23.722Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:WnTvZdXz2q9ySfr4o_contents"},"gridImageId":"sequencesgrid/opwbi6lh0ud7r7dlyghc","bannerImageId":"sequences/r6u4ghtv3smv1zeh6rvv","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":6,"readPostsCount":0,"title":"Parables and Prayers","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Book:2tPEd5Gdm3iewB53M":{"_id":"2tPEd5Gdm3iewB53M","__typename":"Book","createdAt":"2017-09-02T07:38:02.497Z","title":"Epilogue","number":4,"subtitle":null,"tocTitle":null,"contents":null,"sequenceIds":["WnTvZdXz2q9ySfr4o"],"sequences":[{"__ref":"Sequence:WnTvZdXz2q9ySfr4o"}],"postIds":[],"posts":[],"collectionId":"2izXHCrmJ684AnZ5X","displaySequencesAsGrid":null,"hideProgressBar":null,"showChapters":null}}</script>
<script>window.__APOLLO_FOREIGN_STATE__ = {}</script>

<script src="codex_files/api.js"></script><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom"></iframe><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M18.601 8.39897C18.269 8.06702 17.7309 8.06702 17.3989 8.39897L12 13.7979L6.60099 8.39897C6.26904 8.06702 5.73086 8.06702 5.39891 8.39897C5.06696 8.73091 5.06696 9.2691 5.39891 9.60105L11.3989 15.601C11.7309 15.933 12.269 15.933 12.601 15.601L18.601 9.60105C18.9329 9.2691 18.9329 8.73091 18.601 8.39897Z" fill="white"></path>
</svg>
</div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    0% {
      opacity: 0;
      transform: scale(0);
    }
    40% {
      opacity: 1;
    }
    100% {
      transform: scale(1);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #f5f5f5;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }


  .intercom-lightweight-app-launcher:hover {
    transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    transform: scale(1.1)
  }

  .intercom-lightweight-app-launcher:active {
    transform: scale(0.85);
    transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
  }


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1, 1, 1);
    transform-origin: bottom right;

    
        width: 400px;
        height: calc(100% - 104px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 84px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 16px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    border-bottom: none;
    background: #f5f5f5

    
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    height: 80px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
    
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-rb9hmfx3jen" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="codex_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div></body></html>