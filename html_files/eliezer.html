<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<link rel="preload" as="style" href="eliezer_files/allStyles.css"><link rel="stylesheet" type="text/css" href="eliezer_files/icon.css"><link rel="stylesheet" type="text/css" href="eliezer_files/reset-min.css"><link rel="stylesheet" type="text/css" href="eliezer_files/css.css"><link rel="stylesheet" type="text/css" href="eliezer_files/jvr1gjm.css"><link rel="stylesheet" type="text/css" href="eliezer_files/tqv5rhd.css"><script type="text/javascript" async="" charset="utf-8" src="eliezer_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-0uUcqAX/lKvnfFMvCM7U5wcjfgBvv/1q+xxZKV6ZhBH4ikGcgTDEC4vEZPTt3l8O"></script><script async="" src="eliezer_files/google-analytics_analytics.js"></script><script>window.publicInstanceSettings = {"forumType":"LessWrong","title":"LessWrong","siteNameWithArticle":"LessWrong","sentry":{"url":"https://1ab1949fc8d04608b43132f37bb2a1b0@sentry.io/1301611","environment":"production","release":"69f0f3c5d57b596e8249571383f8a280eff9bb23"},"debug":false,"aboutPostId":"bJ2haLkcGeLtTWaD5","faqPostId":"2rWKkWuPrgTMpLRbp","contactPostId":"ehcYkvyz7dh9L7Wt8","expectedDatabaseId":"production","tagline":"A community blog devoted to refining the art of rationality","faviconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","faviconWithBadge":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_with_badge.ico","forumSettings":{"headerTitle":"LESSWRONG","shortForumTitle":"LW","tabTitle":"LessWrong"},"analytics":{"environment":"lesswrong.com"},"cluster":{"enabled":true,"numWorkers":2},"testServer":false,"fmCrosspost":{"siteName":"the EA Forum","baseUrl":"https://forum.effectivealtruism.org/"},"allowTypeIIIPlayer":true,"hasRejectedContentSection":true,"hasCuratedPosts":true,"performanceMetricLogging":{"enabled":true,"batchSize":100},"reviewBotId":"tBchiz3RM7rPwujrJ","recombee":{"databaseId":"lightcone-infrastructure-lesswrong-prod-2","publicApiToken":"sb95OJbQ7mKLQAm1abPog2m5vCPj7XqZlVYdHGyANcjzqaHT5fX6HEgB0vCfiLav"},"taggingName":"wikitag","taggingUrlCustomBase":"w","homepagePosts":{"feeds":[{"name":"forum-classic","label":"Latest","description":"The classic LessWrong frontpage algorithm that combines karma with time discounting, plus any tag-based weighting if applied.","showToLoggedOut":true},{"name":"recombee-hybrid","label":"Enriched","description":"An equal mix of Latest and Recommended.","showSparkleIcon":true,"defaultTab":true,"showToLoggedOut":true},{"name":"recombee-lesswrong-custom","label":"Recommended","description":"Personalized recommendations from the history of LessWrong, using a machine learning model that takes into account posts you've read and/or voted on.","showSparkleIcon":true,"showToLoggedOut":true},{"name":"forum-subscribed-authors","label":"Subscribed","description":"Posts and comments by people you've explicitly subscribed to.","isInfiniteScroll":true},{"name":"vertex-default","label":"Vertex","description":"Experimental feed for Google Vertex recommendations.","showLabsIcon":true,"adminOnly":true},{"name":"forum-bookmarks","label":"Bookmarks","description":"A list of posts you saved because you wanted to have them findable later."},{"name":"forum-continue-reading","label":"Resume Reading","description":"Further posts in post sequences that you started reading.","disabled":true}]}}</script><link rel="shortcut icon" href="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico"><script>window.publicSettings = {"forum":{"numberOfDays":10,"postInterval":30,"numberOfWeeks":4,"numberOfYears":4,"maxPostsPerDay":5,"numberOfMonths":4},"type3":{"cutoffDate":"2023-07-01","explicitlyAllowedPostIds":["SvKSwT6xYfYahH4XN","2weRdcvqANDq3zdPH","Zm7WAJMTaFvuh2Wc7","HcjL8ydHxPezj6wrt","pgGiqLQg2KWsaz5RE","jFzovY2CERF5bd2EW","sm6npdgZArSn4afeZ","CfX6pGepdjQYELSpK","NyFuuKQ8uCEDtd2du","LCjtqsQWapoSfDHqK","MxyRNd6qJsYAcXKuw","reG3g4wwzwJcKnFfh","zfeWGvTrS6wKQeeoF","oHsMeXehPy4jHcmwy","ofL22R6KZsfrvdmwg","655TmdcwAgryPGPWS","hhrv8aAcmkzJxvP58","iqQJiKcephtMgzJgN","mnpkM57R6ZbjnwrYw","6mRv7Cr57AJAtRFHv","ak9wY2t9K3K4GxCXv","Ay6GBGNcCgP55dRQ7","aH4mjhgqNPyYvJT85","JpoLCHytYiCm7fwNA","efMgZujzfjP9B9H4R","BjLxPLsev54LFCS3A","HTGCGASf9xfB6edAh","H6LnGwjKiGvDyR5yo","qL8Z9TBCNWQyN6yLq","F4xwRTrFQyazHufjD","LY7Nca846X8kcT8Jk","K9aLcuxAPyf5jGyFX","2AuvBPw6Rb7yxkvKc","muhtBvbh4etjkKXd9","ALEYMFAuFSCz8v5YE","CJxSgaqG6y7z6Rbij","k5TpDCEHeK4qwnJt8","4Y2J7NtuweW2B8JvB","BpYDqQNZ2NZNCqPp6","oMiogKLkK8L59WzDe","TyQSMmoJpRG3HBv5S","8KHR3tfa4SJjMSkXd","g4pi2jfQHFF6mPdjw","znEhB9hJtwXica5s3","Sd2r7H8bCmd9ChGbX","P2nYKqwmHdYKARTG8","FW3DEYbKPZJh5A8Bj","K3hFLRn7MvYacL466","ouSpHCCPgsXkwxAGb","w9SuQtRJLbDpeir6L","yPQGYn9rSme9RRpiQ","BD6WYC4GT6dnWaJRN","c8khnHoRTSGjmHLLf","TaPr4YSBbiakeKdwX","pyNPXST7feDX45ygt","ERPL3v2Y976W7XG3j","XpXQ4KNzLa9ZHYw8p","PBhrHw5X8sDmHDWkX","8KhThQXzsAEZ59iko","iYJo382hY28K7eCrP","KrEwDMN4YXp5YWD45","rNJ39yQmzTnseh8nL","hMQPyLDbg3bA7P6aN","3Jqz6JE8K6vyQ9hJ5","SQAfPKZBAAKYMjx25","Y345zuBetHqGnotwm","pZerSnxv6FPqvgoYu","3bPH2az479gzxDMbf","QXShCBvPydkwafekn","iLMkKDKmfbMkDuQBm","iNCg6mjw584r9BWZK","9oqF382ASmjaGBo7z","DdNB42JgBzbbvmAum","JP7eZYHB7aY6fA4TR","snwX7hXgLFikqDBr6","CsKrQdQJJCFPjfKjF","vhxywjnBH6ioRnnt3","A4MK9RQqSAJZjanQD","PCpzG9NJeviXM5YSq","KCcdhZK7omEMwBdju","kdmCm5NQTpqhJmGm6","2p8BWvcJvKkXGMsch","FLnDFnXyWrKr6eiT6","2gWs8SScqeDFidqyv","2HafkDSNdtMzptzcN","cTQRGJTQ2eGKm5G9g","qaHHJ3kkCQS4nsoGJ","gS8Jmcfoa9FAh92YK","eRhFaibbTeGbjdaaf","xij43oLTBRnEQv2bT","BZMc9Xzqw5WcCMHrr","2jZykdLg9fBGqKd46","gBChm3THPGFcrq5eH","9HSwh2mE3tX6xvZ2W","tEHJXNhw6t87foqJL","T5McDuWDeCvDZKeSj","PeTL97v92LxRJBsrM","Cq45AuedYnzekp3LX","pfmZ5cYQCahABGZzi","3wBj8BPquskZAbXu9","xPJKZyPCvap4Fven8","BPKvZuLRyiJBjfNbg","um7w5RogAHhxGy8Ti","CcyGR3pp3FCDuW6Pf","BfaAADSQ88cuxLQoD","ckuuDa8DmJ4pdFeD8","pczHfyxmnFhtKthqR","dymK5c7BkpgXH4acw","B4AyJXYPpGbBmxQzd","xNBRkPNHAGQ6EQaLS","88TN6y9M5xxAHHNwW","Lt8Rn4rkYwqiTXGPy","QdXrkWoK2Pp6XhNuQ","NjzBrtvDS4jXi5Krp","ZWC3n9c6v4s35rrZ3","Fy2b55mLtghd4fQpx","eaczwARbFnrisFx8E","KLjQedNYNEP4tW73W","DSnamjnW7Ad8vEEKd","7iDtkfyn322nPzTP4","eaSJtg8Kvc56bFBdt","AmaWMMWPzuQ62Ernf","jkf2YjuH8Z2E7hKBA","BroeiXGh9PrKZEkJ5","9Tw5RqnEzqEtaoEkq","EMJ3egz48BtZS8Pws","MkKcnPdTZ3pQ9F5yC","kjArXFinD3deRZNRu","Q8zqoBWBBHD2RjDuS","ePA4NDzZkunz98tLx","4xKeNKFXFB458f5N8","irbREZtZzPi7WEYex","QxZs5Za4qXBegXCgu","ZmQv4DFx6y4jFbhLy","M7rwT264CSYY6EdR3","z3cTkXbA7jgwGWPcv","9thqSN8HDLM3LTxK5","MtNnFg4uN32YPoKNa","Ep2Z42hYqj68QZz6w","ibk7q8msSYxZXmfCf","EgDpZS4HHeh5vqJPe","5dhWhjfxn4tPfFQdi","Wh8HAK6LR5CAoPCCC","Yy7mgec8tsbTAuTqb","azoP7WeKYYfgCozoh","Zh9AiXNjQaYXjmNaC","bJiyYJeCyh4HcKHub","aPrCzeFfbBmRsvzby","vXCK3kptLLggEfojX","M2LWXsJxKS626QNEA","LQp9cZPzJncFKh5c8","CZnBQtvDw33rmWpBD","miHttwTgajY2sjY3L","K2JBqDeETX2yEgyyZ","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","mja6jZ6k9gAwki9Nu","qjSHfbjmSyMnGR9DS","Sx26Aj3xuMzmnKE4A","P3uavjFmZD5RopJKk","pJJdcZgB6mPNWoSWr","oGezscrQvPDgGvrbt","AYbhqi65SWzHzy7Xx","E4cKD9iTWHaE7f3AJ","x9FNKTEt68Rz6wQ6P","HAEPbGaMygJq8L59k","znBJwbuT3f5eWgM4E","yJfBzcDL9fBHJfZ6P","YAkpzvjC768Jm2TYb","LTtNXM9shNM9AC2mp","9hR2RmpJmxT8dyPo4","WQWhXzALcrzrJtqRh","p7WXmG6Fbo3eaSwm3","KheBaeW8Pi7LwewoF","A2Qam9Bd9xpbb2wLQ","asmZvCPHcB4SkSCMW","euJm4RwkAptZnP89i","r8stxYL29NF9w53am","6yTShbTdtATxKonY5","yDRX2fdkm3HqfTpav","EhEZoTFzys9EDmEXn","YSWa8rYeD3aDaofSP","rwkkcgSpnAyE8oNo3","HmfxSWnqnK265GEFM","Ltey8BS83qSkd9M3u","atcJqdhCxTZiJSxo2","pC47ZTsPNAkjavkXs","wJnm5cBiZGmKn595f","GrtbTAPfkJa4D6jjH","LgavAYtzFQZKg95WC","reitXJgJXFzKpdKyd","ZiQqsgGX6a42Sfpii","neQ7eXuaXpiYw7SBy","hQHuXuRGZxxWXaPgg","9kcTNWopvXFncXgPy","baTWMegR42PAsH9qJ","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","R6M4vmShiowDn56of","6Fpvch8RR29qLEWNH","N6WM6hs7RQMKDhYjB","pdaGN6pQyQarFHXF4","SA9hDewwsYgnuscae","i9xyZBS3qzA8nFXNQ","bx3gkHJehRCYZAF3r","Jk9yMXpBLMWNTFLzh","JvZhhzycHu2Yd57RN","vzfz4AS6wbooaTeQk","gHefoxiznGfsbiAu9","sbcmACvB6DqYXYidL","kipMvuaK3NALvFHc9","xdwbX9pFEr7Pomaxv","XvN2QQpKTuEzgkZHY","uFNgRumrDTpBfQGrs","ii4xtogen7AyYmN6B","kpPnReyBC54KESiSn","FRv7ryoqtvSuqBxuT","u8GMcpEN9Z6aQiCvp","B2CfMNfay2P8f2yyc","JD7fwtRQ27yc8NoqS","mRwJce3npmzbKfxws","3rxMBRCYEmHCNDLhu","FWvzwCDRgcjb9sigb","KrJfoZzpSDpnrv9va","LpM3EAakwYdS6aRKf","Cf2xxC3Yx9g6w7yXN","qHCDysDnvhteW7kRd","mELQFMi9egPn5EAjK","qDmnyEMtJkE9Wrpau","4ZvJab25tDebB8FGE","4QemtxDFaGXyGSrGD","Psr9tnQFuEXiuqGcR","qmXqHKpgRfg83Nif9","ximou2kyQorm6MPjX","eccTPEonRe4BAvNpD","2cYebKxNp47PapHTL","pv7Qpu8WSge8NRbpB","PqMT9zGrNsGJNfiFR","B9kP6x5rpmuCzpfWb","zB4f7QqKhBHa5b37a","qc7P2NwfxQMC3hdgm","RcifQCKkRc9XTjxC2","YABJKJ3v97k9sbxwg","bNXdnRTpSXk9p4zmi","fRsjBseRuvRhMPPE5","MzKKi7niyEqkBPnyu","NQgWL7tvAPgN2LTLn","cujpciCqNbawBihhQ","wEebEiPpEwjYvnyqq","AqbWna2S85pFTsHH4","Nwgdq6kHke5LY692J","8xLtE3BwgegJ7WBbf","SWxnP5LZeJzuT3ccd","Tr7tAyt5zZpdTwTQK","ax695frGJEzGxFBK4","FkgsxrGf3QxhfLWHG","vJ7ggyjuP4u2yHNcP","X5RyaEDHNq5qutSHK","xhD6SHAAE9ghKZ9HS","AyNHoTWWAJ5eb99ji","F5ktR95qqpmGXXmLq","znfkdCoHMANwqc2WE","jbE85wCkRr9z7tqmD","4K5pJnKBGkqqTbyxx","yeADMcScw8EW9yxpH","9QxnfMYccz9QRgZ5z","X2i9dQQK3gETCyqh2","4XRjPocTprL4L8tmB","D6trAzh6DApKPhbv4","BcYfsi7vmhDvzQGiF","i42Dfoh4HtsCAfXxL","zp5AEENssb8ZDnoZR","KwdcMts8P8hacqwrX","RQpNHSiWaXTvDxt6R","nSjavaKcBrtNktzGa","hNqte2p48nqKux3wS","7im8at9PmhbT4JHsW","SwcyMEgLyd4C3Dern","AHhCrJ2KpTjsCSwbt","rz73eva3jv267Hy7B","E4zGWYzh6ZiG85b2z","hvGoYXi2kgnS3vxqb","D4hHASaZuLCW92gMy","v7c47vjta3mavY3QC","G5TwJ9BGxcgh5DsmQ","YRgMCXMbkKBZgMz4M","ham9i5wf4JCexXnkN","a4jRN9nbD79PAhWTB","xJyY5QkQvNJpZLJRo","ivpKSjM4D6FbqF4pZ","p7x32SEt43ZMC9r7r","f886riNJcArmpFahm","xhE4TriBSPywGuhqi","ThvvCE2HsLohJYd7b","diruo47z32eprenTg","JJFphYfMsdFMuprBy","ZDZmopKquzHYPRNxq","KkwtLtroaNToWs2H6","vKErZy7TFhjxtyBuG","3L46WGauGpr7nYubu","CSZnj2YNMKGfsMbZA","G2Lne2Fi7Qra5Lbuf","x6hpkYyzMG6Bf8T3W","aFaKhG86tTrKvtAnT","PrCmeuBPC4XLDQz8C","dYspinGtiba5oDCcv","9cbEPEuCa9E7uHMXT","N5Jm6Nj4HkNKySA5Z","asmZvCPHcB4SkSCMW","duxy4Hby5qMsv42i8","Djs38EWYZG8o7JMWY","A8iGaZ3uHNNGgJeaD","XYYyzgyuRH5rFN64K","2jfiMgKkh7qw9z8Do","JPan54R525D68NoEt","o4cgvYmNZnfS4xhxL","CeZXDmp8Z363XaM6b","DQKgYhEYP86PLW7tZ","niQ3heWwF6SydhS7R","gvK5QWRLk3H8iqcNy","fnkbdwckdfHS2H22Q","YicoiQurNBxSp7a65","JBFHzfPkXHB2XfDGj","tj8QP2EFdP8p54z6i","9fB4gvoooNYa4t56S","zTfSXQracE7TW8x4w","YcdArE79SDxwWAuyF","8xRSjC76HasLnMGSf","CvKnhXTu9BPcdKE4W","DtcbfwSrcewFubjxp","NxF5G6CJiof6cemTw","4ZwGqkMTyAvANYEDw","EF5M6CmKRd6qZk27Z","cCMihiwtZx7kdcKgt","Qz6w4GYZpgeDp6ATB","TPjbTXntR54XSZ3F2","x3fNwSe5aWZb5yXEG","bnY3L48TtDrKTzGRb","ZFtesgbY9XwtqqyZ5","S7csET9CgBtpi7sCh","tTWL6rkfEuQN9ivxj","L6Ktf952cwdMJnzWm","P6fSj3t4oApQQTB7E","4s2gbwMHSdh2SByyZ","sTwW3QLptTQKuyRXx","EYd63hYSzadcNnZTD","tF8z9HBoBn783Cirz","hyShz2ABiKX56j5tJ","YN6daWakNnkXEeznB","6DuJxY8X45Sco4bS2","TMFNQoRZxM4CuRCY6","q3JY4iRzjq56FyjGF","diutNaWF669WgEt3v","5okDRahtDewnWfFmz","r3NHPD3dLFNk9QE2Y","ALkH4o53ofm862vxc","N9oKuQKuf7yvCCtfq","WjsyEBHgSstgfXTvm","2G8j8D5auZKKAjSfY","rBkZvbGDQZhEymReM","nNqXfnjiezYukiMJi","36Dhz325MZNq3Cs6B","f2GF3q6fgyx8TqZcn","byewoxJiAfwE6zpep","nEBbw2Bc2CnN2RMxy","w4aeAFzSAguvqA5qu","xFotXGEotcKouifky","rzqACeBGycZtqCfaX","DoPo4PDjgSySquHX8","o3RLHYviTE4zMb9T9","5gfqG3Xcopscta3st","GNhMPAWcfBCASy8e6","uXH4r6MmKPedk8rMA","Gg9a4y8reWKtLe3Tn","bBdfbWfWxHN9Chjcq","sT6NxFxso6Z9xjS7o","k9dsbn8LZ6tTesDS3","exa5kmvopeRyfJgCy","YTJp5WBcktBimdxBG","X79Rc5cA5mSWBexnd","SvKpaPbZ2tibeDpgh","rQKstXH8ZMAdN5iqD","vQKbgEKjGZcpbCqDs","Z9cbwuevS9cqaR96h","pHHaNkG8xDcaq5DJF","sjRG35aq5fosJ6mdG","pPWiLGsWCtN92vLwu","D5BP9CxKHkcjA7gLv","57sq9qA3wurjres4K","t2LGSDwT7zSnAGybG","7Pq9KwZhG6vejmYpo","g3PwPgcdcWiP33pYn","zcriHTKgKNehSSdyG","kvLPC5YWgSujcHSkY","HnC29723hm6kJT7KP","CRiJuJxgArjBMJLvK","dyJfGeWo5GX2u6NGi","QLmSFeFexgTLsNeeA","kmT47aLQmqzcw329Y","givHhuPu6G43g8kWN","83DimRqppcaoyYAsy","vvzfFcbmKgEsDBRHh","FfNEt8mpi6qanNmXg","MrAfiomDNWCzxjei5","73kwTFKgi4AagxFHJ","iBBK4j6RWC7znEiDv","W8vSrHAM9qoWdzFoP","Rx9GLepCxctXDqCPc","4X9JLr2SpB6v68twG","yxTP9FckrwoMjxPc4","FuZ7MoR3dJEJuoRbN","xRyLxfytmLFZ6qz5s","mwGAyWmsSqzMz4WMd","xxC3Ka7axphW8kJ9E","KT8Mf3ey6uwQAkWek","GDT6tKH5ajphXHGny","ZXaRHHLsxaTTQQsZb","CHdsSaQGAvtkXBzmJ","HAEPbGaMygJq8L59k","SmDziGM9hBjW9DKmf","8NKu9WES7KeKRWEKK","NfdHG6oHBJ8Qxc26s","LTtNXM9shNM9AC2mp","uKp6tBFStnsvrot5t","baTWMegR42PAsH9qJ","Xqcorq5EyJBpZcCrN","7cAsBPGh98pGyrhz9","ZbgCx2ntD5eu8Cno9","9kcTNWopvXFncXgPy","HxWdXMqoQtjDhhNGA","xwBuoE9p8GE7RAuhd","inedT6KkbLSDwZvfd","sWLLdG6DWJEy3CH7n","dhj9dhiwhq3DX6W8z","yLLkWMDbC9ZNKbjDG","P3Yt66Wh5g7SbkKuT","brXr7PJ2W4Na2EW2q","45mNHCMaZgsvfDXbw","7izSBpNJSEXSAbaFh","pfoZSkZ389gnz5nZm","jfG6vdJZCwTQmG7kb","sGnPTfjE5JthAStqg","gvA4j8pGYG4xtaTkw","PZtsoaoSLpKjjbMqM","jnDibtfvWNHLucf4D","GrtbTAPfkJa4D6jjH","zEWJBFFMvQ835nq6h","64FdKLwmea8MCLWkE","Dx9LoqsEh3gHNJMDk","FMkQtPvzsriQAow5q","XuLG6M7sHuenYWbfC","PGv9THs68ArPur7yP","NcGBmDEe5qXB7dFBF","tEDXpFgsHsm5T8sWz","7gsehrZnvXo2YGiT7","x4n4jcoDP7xh5LWLq","boBZkTqPdboX5u7g9","CJw2tNHaEimx6nwNy","CcC8MocynqKPmMPwL","Rrt7uPJ8r3sYuLrXo","rwjv8bZfSuE9ZAigH","khYYedgupgrHonWNc","wrkEnGrTTrM2mnmGa","f9s7pHub6hbsX7YKT","YduZEfz8usGbJXN4x","55SHk8kh9dDvaDTCC","SFG9Cm7mf5eP4juKs","eLRSCC7r4KinuxqZX","oW6mbA3XHzcfJTwNq","kWMkDoy3izRTobZFe","LtsJLfnP4YwhGdaCf","w9kwayt5SWqBQe8Nx","h5CGM5qwivGk2f5T9","iPGpENE4ARKbzzQmt","PQ3nutgxfTgvq69Xt","3zZjF3YKJ257x79mu","9Qwignbzu4ddXLTsT","aiCtrN9EF2FjKz5sv","JcpwEKbmNHdwhpq5n","idipkijjz5PoxAwju","F7RgpHHDpZYBjZGia","xWTSHJASRaLABgHWc","Fg8dtE8HHkDoiGcwt","zPJE7MDtL25RpN7Cc","qqhdj3W3vSfB5E9ss","9SE67uz98kh6x2CxR","gR6H3egpRPNYnoTrA","qPoaA5ZSedivA4xJa","H6L7fuEN9qXDanQ6W","gfexKxsBDM6v2sCMo","7uJnA3XDpTgemRH2c","stb3Jjumzhv49zCEb","XjMkPyaPYTf7LrKiT","XuyRMxky6G8gq7a69","huRxRzwcvwTzvtEPY","8bWbNwiSGbGi9jXPS","sq3WkpyqGANT7hGRP","AyfDnnAdjG7HHeD3d","WmfapdnpFfHWzkdXY","8rYxw9xZfwy86jkpG","zFhhDCxz87yKwqYQf","doiMq8aH2yiZaCJsT","MQzbaHoiQutiHkx2M","ra9Pt2JkEDnKW4jsc","9YDk52NPrfq7nqLvd","KTEciTeFwL2tTujZk","6bSjRezJDxR2omHKE","r5H6YCmnn8DMtBtxt","JbcWQCxKWn3y49bNB","R4FX6wDmppvZ2JqpB","9vnWFwng8QzEnBT8z","XCtFBWoMeFwG8myYh","6uwLq8kofo4Tzxfe2","G993PFTwqqdQv4eTg","DWgWbXRfXLGHPgZJM","K7wtTqTEoKXC9Kb24","hmai5Lru5kWXpH7Ju","w4jjwDPa853m9P4ag","xvAkpCSdqgtYhEceo","6vMBpZtoRw4ia2JrK","Wzjjynmp8gMmdX6dt","CsN6WxwDnPzxAFhps","CLXkgEerPi9MpJCem","BKjJJH2cRpJcAnP7T","qXtbBAxmFkAQLQEJE","jES7mcPvKpfmzMTgC","D7epkkJb3CqDTYgX9","FpcgSoJDNNEZ4BQfj","mF8dkhZF9hAuLHXaD","camG6t6SxzfasF42i","HALKHS4pMbfghxsjD","HDXLTFnSndhpLj2XZ","fgYQjTktBmNZvMqce","fwNskn4dosKng9BCB","B5auLtDfQrvwEkw4Q","z7YvA5osMotdL5F4w","Hoh6umyMWSqzPGMJZ","vHSrtmr3EBohcw6t8","nsCwdYJEpmW5Hw5Xm","LKAXgTen4Xbqb8eZY","22GrdspteQc8EonMn","TSaJ9Zcvc3KWh3bjX","sJK6HN5vTPPnuuNgQ","mh3xapTix6fFtd3xM","JBnaLpsrYXLXjFocu","uR8c2NPp4bWHQ5u45","d4YGxMpzmvxknHfbe","wcNEXDHowiWkRxDNv","scNCmwaduCgJmCBYh","LsXtcLyzyfGg3gT5R","McN9BNtNcbYNfdCB5","4tzEAgdbNTwB6nKyL","sCFGEhwcB8MX3FQf5","G4uMdBzgDsxMsTNmr","34Gkqus9vusXRevR8","7MCqRnZzvszsxgtJi","HXxHcRCxR4oHrAsEr","cmrtpfG7hGEL9Zh9f","oHk9T3jbx2J5zJ39P","sYt3ZCrBq2QAf3rak","r8stxYL29NF9w53am","zymnWfGwf6BdDt64c","yyDrMYBfvYtKbmPmm","4gevjbK77NQS6hybY","jnjjzkH8Fdzg4D6EK","XKfQF73YnyMRiRf9a","gYfgWSxCpFdk2cZfE","CQsEwAyJP6NYvKZw6","JiLcxpWzCrnwkndsT","gpk8dARHBi7Mkmzt9","GrbeyZzp6NwzSWpds","9MZdwQ7u53oaRiBYX","gFyJgnu5vAbzELBM8","ouQNu3hhfKLBRuwR7","m5AH78nscsGjMbBwv","oKYWbXioKaANATxKY","cq5x4XDnLcBrYbb66","KjdP2WjWng6skwbY7","wfpdejMWog4vEDLDg","7F5jo5LD9FD7DpxCX","kDjKF2yFhFEWe4hgC","pWi5WmvDcN4Hn7Bo6","NGc3Yjecg9pDMznWq","xxvKhjpcTAJwvtbWM","DJnvFsZ2maKxPi7v7","zo9zKcz47JxDErFzQ","fyZBtNB3Ki3fM4a6Y","H4kadKrC2xLK24udn","BxersHYN2qcFoonwg","Ck5cgNS2Eozc8mBeJ","wr9dH2GjztvCz6pYX","EzAt4SbtQcXtDNhHK","syeBtmGoKvjJTH6sH","eWqFy8wESHbxNod7i","8cWMX6L8St8k9pPRC","jP583FwKepjiWbeoQ","rMfpnorsMoRwyn4iP","TKk7rShf9d5ePN7vR","fNJvYD6XqnX82i4jA","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","3GAnfeG9KmsbsWeTj","JKgGvJCzNoBQss2bq","JjGs6mDZxeCWkg3ii","AzKx6EjaoaMuk595v","duAkuSqJhGDcfMaTA","pXLqpguHJzxSjDdx7","FbJYEn6eWA5JnGeGP","8GiTowD6XqTNzgCz7","qfDgEreMoSEtmLTws","96N8BT9tJvybLbn5z","SCs4KpcShb23hcTni","bDMoMvw2PYgijqZCC","nqwzrpkPvviLHWXaE","YuZXRxWSqaCoZHEXr","6YYmkpumigAmh3efu","SgszmZwrDHwG3qurr","9EyzaH3jzH3PyQtM5","eR7Su77N2nK3e5YRZ","GSBCw94DsxLgDat6r","cpdsMuAHSWhWnKdog","avvXAvGhhGgkJDDso","KnPN7ett8RszE79PH","ptmmK9PWgYTuWToaZ","XNhfw5Bqsi4SGNNBk","PKy8NuNPknenkDY74","3yqf6zJSwBF34Zbys","YpyW97jRbtvBAncAr","LwcKYR8bykM6vDHyo","H6hMugfY3tDQGfqYL","iyRpsScBa6y4rduEt","mLuQfS7gmfr4nwTdv","TrvkWBwYvvJjSqSCj","yXHcqrCpiHC5tDuEc","HKfBeWN8ufNdFgzG6","P8yeoeJ2bwmnD93mZ","kxW6q5YdTGWh5sWby","ksatPnddyZjHwZWwG","st7DiQP23YQSxumCt","tE7y8FZe7wSSzoRaS","L4HQ3gnSrBETRdcGu","eqxqgFxymP8hXDTt5","uKWXktrR7KpbgZAs4","h4vWsBBjASgiQ2pn6","DXBziiT2RFLcmLY9J","k42G2aaNhRNB7hdCJ","XSKQLeQnBupFo7GGC","BnDF5kejzQLqd5cjH","AMmqk74zWmvP8tXEJ","NQQzXpahhkb6f6ZCe","Tk5ovpucaqweCu4tu","9WX59u7g2sdKqnjDm","Xht9swezkGZLAxBrd","8c8AZq5hgifmnHKSN","nMNi86hgNjaNnh8iu","s3rAKTkdSHb6Hwwoz","rqnbrJhDKCoZvNGEZ","Ea8pt2dsrS6D4P54F","uN3wjp2K6TEQ2oAML","DAc4iuy4D3EiNBt9B","jqCz2X49FRn5Bgb5b","8hxvfZiqH24oqyr6y","puYfAEJJomeodeSsi","S54HKhxQyttNLATKu","igSPcmvTigCHxWt8x","4esQ684vtR9zcjHgW","yGaw4NqRha8hgx5ny","eHnupDgggBqDqT5eg","k7oxdbNaGATZbtEg3","bbGEiSmNiTpPrFhcQ","Z6dmoLyfBdmo6HEss","QcXuwQvvPkqcKZmXS","7FJRnxbRtT7Sbzizs","oBTkthd7h8sDpkiu2","cmiRk9XtT9Psnd3Yr","G6npMHwgRGSQDKavX","hwxj4gieR7FWNwYfa","yGycR8tFA3JJbvApp","jxy7rBcQink8a7C9b","vQNJrJqebXEWjJfnz","kjmpq33kHg7YpeRYW","FwYMuD2sNcaEpE5on","4rwABGAd9kZG8nf2P","GkXKvkLAcTm5ackCq","TrmMcujGZt5JAtMGg","gBpYo7mt2zNBmtBJd","aNRYQFnMQbA7uu99u","YMokuZdoY9tEDHjzv","MG8Yhsxqu9JY4xRPr","zEvqFtT4AtTztfYC4","fzeoYhKoYPR3tDYFT","8npC4KRcAJtGdErTq","AYbhqi65SWzHzy7Xx","N99KgncSXewWqkzMA","2KacvW34BbXFmDBtQ","tSgcorrgBnrCH8nL3","NHuLAS3oKZWr2X9hP","9hR2RmpJmxT8dyPo4","fwSDKTZvraSdmwFsj","Cf2zBkoocqcjnrNFD","MPj7t2w3nk4s9EYYh","TTPux7QFBpKxZtMKE","shcSdHGPhnLQkpSbX","M4w2rdYgCKctbADMn","hMjFMSQZb4swKugfv","mkrvsNi8cYGSjGqkh","DXcezGmnBcAYL2Y2u","Aq8BQMXRZX3BoFd4c","FoJSa8mgLPT83g9e8","Xt85tj6GQJCuuXT68","JAAHjm4iZ2j5Exfo2","sAiHxHkQrsYsRpKFP","6phFYpNQH9SmWL9Jt","Rkxj7TFxhbm59AKJh","rNFzvii8LtCL5joJo","Hw26MrLuhGWH7kBLm","Zvu6ZP47dMLHXMiG3","HByDKLLdaWEcA2QQD","7qhtuQLCCvmwCPfXK","FgjcHiWvADgsocE34","Lp4Q9kSGsJHLfoHX3","3xF66BNSC5caZuKyC","BseaxjsiDPKvGtDrm","Q924oPJzK92FifuFg","oJwJzeZ6ar2Hr7KAX","H7Rs8HqrwBDque8Ru","gEKHX8WKrXGM4roRC","FKB7iEergZaC7PvQf","suxvE2ddnYMPJN9HD","iETtCZcfmRyHp69w4","mz3hwS4c9bc9EHAm9","KFLdfuw35qkgjzWer","RApxEu3A4GnvGoEe2","XLbDQL2qYi9FDozvL","p4XpZWcQksSiCPG72","mB95aqTSJLNR9YyjH","2NaAhMPGub8F2Pbr7","BbM47qBPzdSRruY4z","dYnHLWMXCYdm9xu5j","qHpazCw3ryvBojGSa","wyYubb3eC5FS365nk","wmjPGE8TZKNLSKzm4","CBWSDdzjqfnexBurB","gBnSRErajRtvhMnDr","BfBF6T6HA82zBxPrv","dbDHEQyKqnMDDqq2G","doPejjd84w8BmERqj","PT8vSxsusqWuN7JXp","dKxX76SCfCvceJXHv","DSzpr8Y9299jdDLc9","hnLutdvjC8kPScPAj","vit9oWGj6WgXpRhce","CsKboswS3z5iaiutC","kjQXzkTGuixoJtQnq","RgJicDmXHDxcJ9Fsw","L6iFpR9ZyTmzHvYci","Z5ZBPEgufmDsm7LAv","PRAyQaiMWg2La7XQy","x6Kv7nxKHfLGtPJej","3pjv6uDvY9sqmsnvY","Aet2mbnK7GDDfrEQu","scL68JtnSr3iakuc6","3SG4WbNPoP8fsuZgs","XfpJ6WQBDcEcC8Mu4","iprqfLaDLCGoJFeiZ","frApEhpyKQAcFvbXJ","znBJwbuT3f5eWgM4E","cR7Zfrc4BtnFes46y","hbmsW2k9DxED5Z4eJ","SzecSPYxqRa5GCaSF","hxaq9MCaSrwWPmooZ","FSmPtu7foXwNYpWiB","WQWhXzALcrzrJtqRh","jYNT3Qihn2aAYaaPb","gebzzEwn2TaA6rGkc","WhHFvzFsYfMxgYCdo","tjxgbovwc5Ft7wrtc","2brqzQWfmNx5Agdrx","QaDwBio8MLqRvTREH","Jko7pt7MwwTBrfG3A","A9tJFJY7DsGTFKKkh","Wnqua6eQkewL3bqsF","DJB82jKwgJE5NsWgT","5b6YcFbEBCZbX6YSK","zk6RK3xFaDeJHsoym","FQqcejhNWGG8vHDch","srge9MCLHSiwzaX6r","DJRe5obJd7kqCkvRr","D8ds9idKWbwzCseCh","hTMFt3h7QqA2qecn7","9LXxgXySTFsnookkw","CHtwDXy63BsLkQx4n","u5RLu5F3zKTB3Qjnu","4tke3ibK9zfnvh9sE","2WngsveoLhFubuLMH","ADwayvunaJqBLzawa","NG6FrXgmqPd5Wn3mh","Ww5xKq5brC4xAJY7o","HL6x8zHo9BkuK3tic","PKBXczqhry7iK3Ruw","oBBzqkZwkxDvsKBGB","HuFZJkGptWDtRbkWs","iQWk5jYeDg5ACCmpx","RdpqsQ6xbHzyckW9m","sizjfDgCgAsuLJQmm","X3p8mxE5dHYDZNxCm","wZGpoZgDANdkwTrwt","uAc7bWgpEhrGwFcv7","3nDR23ksSQJ98WNDm","sMsvcdxbK2Xqx8EHr","evYFijNMdjfbPaCho","Psp8ZpYLCDJjshpRb","Zupr296Zy74wpihXT","68dHanLWsS6SEyZp9","x9FNKTEt68Rz6wQ6P","DWHkxqX4t79aThDkg","xLm9mgJRPvmPGpo7Q","6LzKRP88mhL9NKNrS","XYDsYSbBjqgPAgcoQ","eRohP4gbxuBuhqTbe","Wpf3Gsa8A89mmjkk8","PfcQguFpT8CDHcozj","XPwEptSSFRCnfHqFk","pohTfSGsNQZYbGpCy","zcPLNNw4wgBX5k8kQ","2meuc3kPRkBcRpj3R","bzhGBHrGrFfQss4Df","2269iGRnWruLHsZ5r","kj37Hzb2MsALwLqWt","Qz9GvoPbnFwGrHHQB","pJJdcZgB6mPNWoSWr","dtmmP4YdJEfK9y4Rc","QPqm5aj2meRmE7kR8","2oybbEw697CQgcRE5","TYTEJxzeK3jBMq2TZ","K4eDzqS2rbcBDsCLZ","FcRt3xAF4ynojfj6G","gMXsyhPiEJbGerF6F","9sguwESkteCgqFMbj","mvPfao35Moah8py46","kuDKtwwbsksAW4BG2","pL56xPoniLvtMDQ4J","ENBzEkoyvdakz4w5d","wM4bcDxEh75NDkhjo","YAkpzvjC768Jm2TYb","ExssKjAaXEEYcnzPd","n3LAgnHg6ashQK3fF","GMCs73dCPTL8dWYGq","8gapy2nLy4wysXSGL","dgFcJtHaYfaoByAK9","HhWhaSzQr6xmBki8F","CpvyhFy9WvCNsifkY","aan3jPEEwPhrcGZjj","mhA4vkeaRn9cpxkag","iA25AvZqAr6G8mAXR","C4tR3BEpuWviT7Sje","FghubkDy6Dp6mnxk7","RKz7pc6snBttndxXz","jiJquD34sa9Lyo5wc","c8EeJtqnsKyXdLtc5","ZGGGBR9sDgtLgMDaA","uM6mENiJi2pNPpdnC","o9dnstYoc7cwpgdhg","YSWa8rYeD3aDaofSP","pC47ZTsPNAkjavkXs","QtyKq4BDyuJ3tysoK","bYrF8rXFYwPqnfxTp","KbyRPCAsWv5GtfrbG","c2RzFadrxkzyRAFXa","9ZodFr54FtpLThHZh","xmoYza9vgcRvWD5PA","sbb9bZgojmEa7Yjrc","6yTShbTdtATxKonY5","BHYBdijDcAKQ6e45Z","qGEqpy7J78bZh3awf","KJbQyFbXiiYDDWbaS","PYtus925Gcg7cqTEq","yTvBSFrXhZfL8vr5a","Aud7CL7uhz55KL8jG","bXTNKjsD4y3fabhwR","AmNjHo8xXMKnZEWRS","CHD5m9fnosr7L3dto","MN4NRkMw7ggt9587K","CDXDnruBJe23rpdfC","y5GftLezdozEHdXkL","d6yNW5T6J9rtnGizc","pT48swb8LoPowiAzR","27AWRKbKyXuzQoaSk","vNHf7dx5QZA4SLSZb","KwbJFexa4MEdhJbs4","mja6jZ6k9gAwki9Nu","fW9n8bEuMpLwkxCx6","muXfZr5EYCfZqLmsb","5PBWgHiCiiJHjPRSn","PAYMMgPi2L3MPP967","RaxaXBNmStYe289gC","DMxe4XKXnjyMEAAGw","xF7gBJYsy6qenmmCS","gMszBSAX23uqYhytR","HbXXd2givHBBLxr3d","Z5wF8mdonsM2AuGgt","utySCY9nJt9xGYGGQ","gCz7cB6JG66EhweSS","krHDNc7cDvfEL8z9a","aNAFrGbzXddQBMDqh","sksP9Lkv9wqaAhXsA","p3s8RvkcyTwzu27ps","8ccTZ9ZxpJrvnxt4F","p7WXmG6Fbo3eaSwm3","CPBmbgYZpsGqkiz2R","yDRX2fdkm3HqfTpav","WbLAA8qZQNdbRgKte","75dnjiD8kv2khe9eQ","JZZENevaLzLLeC3zn","MgFDzAfCku9MSDLuw","PQtEqmyqHWDa2vf5H","zbqLuTgTCu365MNu9","P3uavjFmZD5RopJKk","8gqrbnW758qjHFTrH","pZaPhGg2hmmPwByHc","4hLcbXaqudM9wSeor","WxW6Gc6f2z3mzmqKs","j9HoG56Y6KuopSzdn","GhFoAxG49RXFzze5Y","rD57ysqawarsbry6v","LCfaLXcWnk8pujnX4","tAXrD8Y6hcJ8dt6Nt","af9MjBqF2hgu3EN6r","FRRb6Gqem8k69ocbi","LbyxFk8JmPKPAQBvL","PHmYhE4sKnwzYgvkh","fZJRxYLtNNzpbWZAA","kgmkdf3C7EkDX7dnT","Gs29k3beHiqWFZqnn","MMAK6eeMCH3JGuqeZ","cdB5f2adKoLGW8Ytc","5e49dHLDJoDpeXGnh","Ccsx339LE9Jhoii9K","PHnMDhfiadQt6Gj23","Jo89KvfAs9z7owoZp","fri4HdDkwhayCYFaE","tD9zEiHfkvakpnNam","xggxWfyzZmnz7hydm","JgBBuDf5uZHmpEMDs","vbcjYg6h3XzuqaaN8","hRohhttbtpY3SHmmD","6KzFwcDy7hsCkzJKY","F2DZXsMdhGyX4FPAd","esRZaPXSHgWzyB2NL","AqsjZwxHNqH64C2b6","4psQW7vRwt7PE5Pnj","voLHQgNncnjjgAPH7","aaHDA4X6cTzFrvuSX","LHtMNz7ua8zu4rSZr","zjMKpSB2Xccn9qi5t","BAzCGCys4BkzGDCWR","goC9qv4PWf2cjfnbm","Z2CuyKtkCmWGQtAEh","c3iQryHA4tnAvPZEv","vwLxd6hhFvPbvKmBH","Js34Ez9nrDeJCTYQL","fJvjin8ETkzhFdadC","W59Nb72sYJhMJKGB8","xiPMaYGTm2xfsB8WF","oPEWyxJjRo4oKHzMu","PjfsbKrK5MnJDDoFr","sBBGxdvhKcppQWZZE","vwM7hnT9ysE3suwfk","BzYmJYECAc3xyCTt6","uiyWHaTrz3ML7JqDX","vZssZr2wq7YrG3FMa","73QyjLymEak4L8RDC","6vcxuRHzeM99jYcYd","bG4PR9uSsZqHg2gYY","HoQ5Rp7Gs6rebusNP","9iA87EfNKnREgdTJN","QEYWkRoCn4fZxXQAY","kAgJJa3HLSZxsuSrf","FZaDFYbnRoHmde7F6","BNfL58ijGawgpkh9b","4gDbqL3Tods8kHDqs","DwqgLXn5qYC7GqExF","atcJqdhCxTZiJSxo2","zRn6cLtxyNodudzhw","P32AuYu9MqM2ejKKY","K2JBqDeETX2yEgyyZ","3FoMuCLqZggTxoC3S","LcEzxX2FNTKbB6KXS","o5F2p3krzT4JgzqQc","cy3BhHrGinZCp3LXE","zsG9yKcriht2doRhM","WYmmC3W6ZNhEgAmWG","EL4HNa92Z95FKL9R2","EKu66pFKDHFYPaZ6q","Pa5NqtxHBkGuCh98G","JKj5Krff5oKMb8TjT","vwt3wKXWaCvqZyF74","4basF9w9jaPZpoC8R","Bfq6ncLfYdtCb6sat","jDQm7YJxLnMnSNHFu","FDJnZt8Ks2djouQTZ","f3o9ydY7iPjFF2fyk","KnQs55tjxWopCzKsk","Ww2dxwWpSfkQB4NZb","ZawRiFR8ytvpqfBPX","ZGzDNfNCXzfx6hYAH","rFjhz5Ks685xHbMXW","Mrz2srZWc7EzbADSo","B4DuwmtqF3HhNwvua","zQKgKjecvR4W7oJw5","BSpdshJWGAW6TuNzZ","JHcTP4Ad8QAmRTCZm","GGn8MBiY8Xz6NdNdH","hQysqfSEzciRazx8k","AtfQFj8umeyBBkkxa","r99tazGiLgzqFX7ka","uFYQaGCRwt3wKtyZP","BFamedwSgRdGGKXQQ","teaxCFgtmCQ3E9fy8","ka8eveZpT7hXLhRTM","euJm4RwkAptZnP89i","LLRtjkvh9AackwuNB","yPLr2tnXbiFXkMWvk","ervaGwJ2ZcwqfCcLx","4AHXDwcGab5PhKhHT","NuueGqPZdotjMQKLu","qjSHfbjmSyMnGR9DS","xtzvtJBNofk4FPAtt","SkcM4hwgH3AP6iqjs","Br4xDbYu4Frwrb64a","HvcZmKS43SLCbJvRb","BEtzRE2M5m9YEAQpX","EhEZoTFzys9EDmEXn","bmoQ2wy7Nd7EiJdpg","pYcFPMBtQveAjcSfH","zb3hWt99i9Fm93KPq","W9rJv26sxs4g2B9bL","Dod9AWz8Rp4Svdpof","hQHuXuRGZxxWXaPgg","zB3ukZJqt3pQDw9jz","KheBaeW8Pi7LwewoF","Ek7M3xGAoXDdQkPZQ","guDcrPqLsnhEjrPZj","7XbcDaeigMaxW43EB","ttGbpJQ8shBi8hDhh","wJnm5cBiZGmKn595f","puhPJimawPuNZ5wAR","eoHbneGvqDu25Hasc","gHgs2e2J5azvGFatb","x5ASTMPKPowLKpLpZ","EhAbh2pQoAXkm9yor","jfq2BH5kfQqu2vYv3","Mf2MCkYgSZSJRz5nM","mXgsd5o9uuYaQKHMz","YM6Qgiz9RT7EmeFpp","PcfHSSAMNFMgdqFyB","uX3HjXo6BWos3Zgy5","nzmCvRvPm4xJuqztv","CMt3ijXYuCynhPWXa","Ndtb22KYBxpBsagpj","yFJ7vCjefBxnTchmG","SQ9cZtfrzDJmw9A2m","PJLABqQ962hZEqhdB","HmfxSWnqnK265GEFM","i3BTagvt3HbPMx6PN","ZEgQGAjQm5rTAnGuM","ctpkTaqTKbmm6uRgC","qEweugBipR5P2cMyK","xnPFYBuaGhpq869mY","YtvZxRpZjcFNwJecS","ido3qfidfDJbigTEQ","85J8hjEn48FicYfvp","N6vZEnCn6A95Xn39p","tJQsxD34maYw2g5E4","96TBXaHwLbFyeAxrg","ixZLTmFfnKRbaStA5","2x7fwbwb35sG8QmEt","oaqKjHbgsoqEXBMZ2","t2NN6JwMFaqANuLqH","J9pNx22bj5RuiRjAj","AN2cBr6xKWCB8dRQG","G5eMM3Wp3hbCuKKPE","y5jAuKqkShdjMNZab","vADtvr9iDeYsCDfxd","x4GmqcwjFTnWeRiud","5ntgky9ShzKKWu7us","z8usYeKX7dtTWsEnk","3S4nyoNEEuvNsbXt8","EEv9JeuY5xfuDDSgF","ASpGaS3HGEQCbJbjS","AXXaXJvf7WcTessog","QL7J9wmS6W2fWpofd","osYFcQtxnRKB4F4HA","MajyZJrsf8fAywWgY","bvqC4Ci7rXq4sN9df","GctJD5oCDRxCspEaZ","A9NxPTwbw6r6Awuwt","dKTh9Td3KaJ8QW6gw","oTX2LXHqXqYg2u4g6","LuXb6CZG4x7pDRBP8","hamma4XgeNrsvAJv5","BfTW9jmDzujYkhjAb","DoHcgTvyxdorAMquE","EbFABnst8LsidYs5Y","Sdx6A6yLByRRs8iLY","qbHLGo5vu8HD3JqEM","48WeP7oTec3kBEada","LgavAYtzFQZKg95WC","5QpufhoH2ASnppsjs","Kz9zMgWB5C27Pmdkh","qy5dF7bQcFjSKaW58","wkuDgmpxwbu2M2k3w","JcpzFpPBSmzuksmWM","zMxrkFrB6ka4Lb7fM","PX7AdEkpuChKqrNoj","ui6mDLdqXkaXiDMJ5","uXn3LyA8eNqpvdoZw","FwiPfF8Woe5JrzqEu","hzuSDMx7pd2uxFc5w","mHqQxwKuzZS69CXX5","yKXKcyoBzWtECzXrE","zHS4FJhByRjqsuH4o","a5JAiTdytou3Jg749","HEn2qiMxk5BggN83J","tYAvXXgSwHCzNTK8f","WXvt8bxYnwBYpy9oT","kLR5H4pbaBjzZxLv6","CtXaFo3hikGMWW4C9","4DBBQkEQvNEWafkek","qwdupkFd6kmeZHYXy","EHbJ69JDs4suovpLw","w5F4w8tNZc6LcBKRP","xqkGmfikqapbJ2YMj","yRAo2KEGWenKYZG9K","scwoBEju75C45W5n3","qJgz2YapqpFEDTLKn","aSQy7yHj6nPD44RNo","Ltey8BS83qSkd9M3u","9Yc7Pp7szcjPgPsjf","hN2aRnu798yas5b2k","ERWeEA8op6s6tYCKy","yJfBzcDL9fBHJfZ6P","BZ6XaCwN4QGgH9CxF","3nMpdmt8LrzxQnkGp","TNHQLZK5pHbxdnz4e","F6ZTtBXn2cFLmWPdM","neQ7eXuaXpiYw7SBy","k2SNji3jXaLGhBeYP","WsSybGTqpBoHpXJyQ","jtMXj24Masrnq3SpS","jqTeghCJ2anMHPPjG","B7P97C27rvHPz3s9B","uK6sQCNMw8WKzJeCQ","hurF9uFGkJYXzpHEE","xEHy9oivifjgFbnvc","33KewgYhNSxFpbpXg","c5GHf2kMGhA4Tsj4g","dC7mP5nSwvpL65Qu5","hpjou9ZnLZkSJR7sd","bshZiaLefDejvPKuS","AvjbBjAAbKBk73v5F","XqvnWFtRD2keJdwjX","KJ9MFBPwXGwNpadf2","37sHjeisS9uJufi4u","5iZTwGHv2tNfFmeDa","gziZACDg6EBpGZbJe","RYcoJdvmoBbi5Nax7","9o3QBg2xJXcRCxGjS","vs3kzjLhbdKsndnBy","bZ2w99pEAeAbKnKqo","bjjbp5i5G8bekJuxv","vwqLfDfsHmiavFAGP","Yp2vYb4zHXEeoTkJc","z6QQJbtpkEAX3Aojj","ubPAo3zGeJNqtZDqT","pfibDHFZ3waBo6pAc","cumc876woKaZLmQs5","Ty2tjPwv8uyPK9vrz","ZiQqsgGX6a42Sfpii","ybYBCK9D7MZCcdArB","pNcFYZnPdXyL2RfgA","rEBXN3x6kXgD4pLxs","no5jDTut5Byjqb4j5","qCsxiojX7BSLuuBgQ","uyBeAN5jPEATMqKkX","aHaqgTNnFzD7NGLMx","bQ6zpf6buWgP939ov","mkbGjzxD8d8XqKHzA","CKpByWmsZ8WmpHtYa","midXmMb2Xg37F2Kgn","reitXJgJXFzKpdKyd","LFNXiQuGrar3duBzJ","KcvJXhKqx4itFNWty","RWu8eZqbwgB9zaerh","EFQ3F6kmt4WHXRqik","FfPukic3Qskd9ZAkk","A2Qam9Bd9xpbb2wLQ","t9svvNPNmFf5Qa3TA","n5TqCuizyJDfAPjkr","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","Kyc5dFDzBg4WccrbK","RWo4LwFzpHNQCTcYt","vbWBJGWyWyKyoxLBe","PsEppdvgRisz5xAHG","tscc3e5eujrsEeFN4","GG2rtBReAm6o3mrtn","E4cKD9iTWHaE7f3AJ","yCWPkLi8wJvewPbEp","AcKRB8wDpdaN6v6ru","LbrPTJ4fmABEdEnLf","rtM3jFaoQn3eoAiPh","eDicGjD9yte6FLSie","xg3hXCYQPJkwHyik2","bJ2haLkcGeLtTWaD5","PBRWb2Em5SNeWYwwB","7hFeMWC6Y5eaSixbD","aMHq4mA2PHSM2TMoH","wpZJvgQ4HvJE2bysy","2brqzQWfmNx5Agdrx","GLMFmFvXGyAcG25ni","NLBbCQeNLFvBJJkrt","bYrF8rXFYwPqnfxTp","v7c47vjta3mavY3QC","3MvaoZbGPxtRFCijw","TappK5n3kZmQzWEWD","tSemJckYr29Gnxod2","WdkLDpBGMCWhfByAY","EctieqKwDQcQHhqZy","hNqte2p48nqKux3wS","qw3Z79HELMsmLkL9F","zwDz9pgT43fRczkB4","Fafzj3wMvoCW4WjeF","kxW6q5YdTGWh5sWby","G5eMM3Wp3hbCuKKPE","kSiT2XjfTnDHKx44W","DSzpr8Y9299jdDLc9","wZGpoZgDANdkwTrwt","qajfiXo5qRThZQG7s","rRzZzBBQ36CrqhZTY","aP36QcAsxyuEispq6","TxcRbCYHaeL59aY7E","MFNJ7kQttCuCXHp8P","PQ3nutgxfTgvq69Xt","JJFphYfMsdFMuprBy","ythFNoiAotjvuEGkg","GZSzMqr8hAB2dR8pk","BBQ5HEnL3ShefQxEj","fzeoYhKoYPR3tDYFT","bXuAXCbzw9hsJSuEN","mbCccXJuuRBZdXdpH","m7THsgXyxxiEXgyHv","xtHd6sfdr2bZHa6Pb","pfaTqpWFghfrbvzaD","u8GMcpEN9Z6aQiCvp","gBpYo7mt2zNBmtBJd","rkpDX7j7va6c8Q7cZ","NGkBfd8LTqcpbQn5Z","GEPX7jgLMB8vR2qaK"]},"locale":"en-US","mapbox":{"apiKey":"pk.eyJ1IjoiaGFicnlrYSIsImEiOiJjaWxvcnhidzgwOGlodHJrbmJ2bmVmdjRtIn0.inr-_5rWOOslGQxY8iDFOA"},"petrov":{"afterTime":1727400080403,"beforeTime":1727376805595,"petrovPostId":"6LJ6xcHEjKF9zWKzs","petrovServerUrl":"https://forum.effectivealtruism.org/graphql","petrovGamePostId":"KTEciTeFwL2tTujZk"},"reacts":{"addNewReactKarmaThreshold":10,"downvoteExistingReactKarmaThreshold":20,"addNameToExistingReactKarmaThreshold":5},"stripe":{"publicKey":"pk_live_51HtKAwA2QvoATZCZiy9f2nc6hA52YS1BE81cFu9FEV1IKar0Bwx6hIpxxxYHnhaxO9KM7kRYofZId3sUUI7Q0NeO00tGni3Wza"},"algolia":{"appId":"fakeAppId","searchKey":"fakeSearchKey","indexPrefix":"test_"},"llmChat":{"userIds":["McgHKH6MMYSnPwQcm","6Fx2vQtkYSZkaCvAg","MEu8MdhruX5jfGsFQ","YaNNYeR5HjKLDBefQ","hBEAsEpoNHaZfefxR","NFmcwmaFeTWfgrvBN","ZnpELPxzzD2CiigNy","Q7NW4XaWQmfPfdcFj","NXeHNNSFHGESrYkPv","QDNJ93vrjoaRBesk2","iMBN2523tmh4Yicc3","5iPRfSnjako6iM6LG","aBHfQ4C5fSM4TPyTn","n4M37rPXGyL6p8ivK","e9ToWWzhwWp5GSE7P","TCjNiBLBPyhZq5BuM","XLwKyCK7JmC292ZCC","S3ydcLKdejjkodNut","ENgxBL95Sc7MRwYty","KCExMGwS2ETzN3Ksr","XGEcH5rmq4yGvD82A","YFiFbXgjBpDKZT93g","dZMo8p7fGCgPMfdfD","Pdca6FNZBrXj9z28n","LHbu27FubhwFv8ZJt","gYxdDBQ3AZbde8HgZ","5JqkvjdNcxwN8D86a","6c2KCEXTGogBZ9KoE","haTrhurXNmNN8EiXc","cJnvyeYrotgZgfG8W"]},"logoUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1498011194/LessWrong_Logo_skglnw.svg","ckEditor":{"uploadUrl":"https://39669.cke-cs.com/easyimage/upload/","webSocketUrl":"39669.cke-cs.com/ws"},"recombee":{"enabled":true},"hasEvents":true,"logRocket":{"apiKey":"mtnxzn/lesswrong","sampleDensity":5},"reCaptcha":{"apiKey":"6LfFgqEUAAAAAHKdMgzGO-1BRBhHw1x6_8Ly1cXc"},"siteImage":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg","cloudinary":{"cloudName":"lesswrong-2-0","uploadPresetBanner":"navcjwf7","uploadPresetGridImage":"tz0mgw2s","uploadPresetSocialPreview":"nn5tppry"},"googleMaps":{"apiKey":"AIzaSyA3C48rl26gynG3qIuNuS-3Bh_Zz9jFXkY"},"adminAccount":{"email":"team@lesswrong.com","username":"LessWrong"},"annualReview":{"end":"2024-02-01T08:00:00Z","start":"2023-12-04T00:10:00Z","reviewPhaseEnd":"2024-01-15T08:00:00Z","votingPhaseEnd":"2024-02-01T08:00:00Z","nominationPhaseEnd":"2023-12-17T08:00:00Z","votingResultsPostId":"TSaJ9Zcvc3KWh3bjX","announcementPostPath":"/posts/B6CxEApaatATzown6/the-lesswrong-2022-review","reviewWinnerSectionsInfo":{"modeling":{"tag":"World Modeling","order":2,"title":"World","coords":{"leftXPct":0.05,"leftYPct":0,"rightXPct":0.57,"rightYPct":0,"middleXPct":0.31,"middleYPct":0,"leftFlipped":true,"leftWidthPct":0.26,"rightWidthPct":0.26,"middleWidthPct":0.26},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753450/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_15ba02c3-b268-45f1-a780-322bbaa6fc22_eu9l0l.png"},"ai safety":{"tag":"AI","order":5,"title":"Technical AI Safety","coords":{"leftXPct":0.2,"leftYPct":0.3,"rightXPct":0.554,"rightYPct":0.3,"middleXPct":0.467,"middleYPct":0.3,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,fl_progressive,q_auto/v1708570131/lwbot_topographic_watercolor_artwork_of_a_giant_robot_hand_gent_e4e9f305-9611-4787-8768-d7af3d702ed4_ta2ii9.png"},"practical":{"tag":"Practical","order":3,"title":"Practical","coords":{"leftXPct":0.2,"leftYPct":0.05,"rightXPct":0.634,"rightYPct":0.05,"middleXPct":0.417,"middleYPct":0.05,"leftFlipped":false,"leftWidthPct":0.217,"rightWidthPct":0.217,"middleWidthPct":0.217},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708974564/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_4f6449e2-569b-48a3-b878-a400315b3ef0_hqutxe.png"},"ai strategy":{"tag":"AI","order":4,"title":"AI Strategy","coords":{"leftXPct":0,"leftYPct":0,"rightXPct":0.66,"rightYPct":0,"middleXPct":0.33,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753570/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_8dda30ee-71d6-4b24-80c7-a8499a5b25c6_uacvgk.png"},"rationality":{"tag":"Rationality","order":0,"title":"Rationality","coords":{"leftXPct":0.12,"leftYPct":0,"rightXPct":0.72,"rightYPct":0,"middleXPct":0.42,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.3,"rightFlipped":true,"rightWidthPct":0.3,"middleWidthPct":0.3},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753260/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_09275054-eb84-43c4-9cfa-4a05e1818c9e_rmov5i.png"},"optimization":{"tag":"World Optimization","order":1,"title":"Optimization","coords":{"leftXPct":0.1,"leftYPct":0.2,"rightXPct":0.7,"rightYPct":0.2,"middleXPct":0.4,"middleYPct":0.2,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753382/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_242eda7f-95a9-4c3b-8090-991a1b11286f_xcjhxq.png"}},"reviewWinnerYearGroupsInfo":{"2018":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008323/ruby37_green_on_white_aquarelle_sketch_by_thomas_schaller_of_ri_7a3fa89a-ac7a-466f-929f-b396cb4d9bd5_p8rh9t.png"},"2019":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008331/ruby37_blue_on_white_aquarelle_sketch_by_thomas_schaller_of_gre_f421cc99-2bb5-4357-b164-d05c2f4fe84e_aib1co.png"},"2020":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.01,"rightXPct":0.72,"rightYPct":0.01,"middleXPct":0.34,"middleYPct":0.01,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008346/ruby37_aquarelle_sketch_of_futuristic_landscape_by_thomas_schal_f07d5805-9fb0-4dcc-9295-7f063624e28c_slcokh.png"},"2021":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.545,"rightYPct":0.1,"middleXPct":0.278,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/a_270/q_auto,f_auto/ohabryka_Topographic_aquarelle_book_cover_by_Thomas_W._Schaller_f9c9dbbe-4880-4f12-8ebb-b8f0b900abc1_m4k6dy_734413"},"2022":{"tag":null,"coords":{"leftXPct":0,"leftYPct":0.1,"rightXPct":0.79,"rightYPct":0.1,"middleXPct":0.43,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008351/ruby37_aquarelle_sketch_of_a_woman_focusing_hard_studying_in_an_2ac568ef-408e-4561-acc8-84c76bb42fba_gwt8uq.png"}},"showReviewOnFrontPageIfActive":true},"googleVertex":{"enabled":false},"intercomAppId":"wtb8z7sj","commentInterval":15,"googleDocImport":{"enabled":true},"moderationEmail":"team@lesswrong.com","timeDecayFactor":1.15,"googleTagManager":{"apiKey":"GTM-TRC765W"},"textReplacements":{"Less Wrong":"Down Bad","Alignment Forum":"Standards Committee","Artificial Intelligence":"Fake News"},"alternateHomePage":false,"gatherTownMessage":"Schelling social hours on Tues 1pm and Thurs 6pm PT","bookDisplaySetting":false,"gardenOpenToPublic":false,"karmaRewarderId100":"iqWr6C3oEB4yWpzn5","legacyRouteAcronym":"lw","maxRenderQueueSize":3,"recommendationsTab":{"manuallyStickiedPostIds":[]},"frontpageScoreBonus":0,"karmaRewarderId1000":"mBBmKWkmw8bgJmGiG","lightconeFundraiser":{"active":false,"postId":"5n2ZQcbc7r4R8mvqc","paymentLinkId":"plink_1QPdGLBlb9vL5IMTvkJ3LZ6v","unsyncedAmount":2082623.2,"thermometerBgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/q_auto,f_auto,h_400/v1732869999/Group_1_b4ap4h.png","thermometerGoalAmount":1000000,"thermometerGoal2Amount":2000000},"defaultVisibilityTags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10}],"enableGoodHeartProject":false,"maxDocumentsPerRequest":5000,"defaultSequenceBannerId":"sequences/vnyzzznenju0hzdv6pqb.jpg","defaultModeratorComments":[{"id":"FfMok764BCY6ScqWm","label":"Option A"},{"id":"yMHoNoYZdk5cKa3wQ","label":"Option B"}],"newUserIconKarmaThreshold":50,"dialogueMatchmakingEnabled":true,"hideUnreviewedAuthorComments":"2023-04-04T18:54:35.895Z","gatherTownUserTrackingIsBroken":true,"postModerationWarningCommentId":"sLay9Tv65zeXaQzR4","commentModerationWarningCommentId":"LbGNE5Ssnvs6MYnLu","performanceMetricLoggingEnax5bled":true,"firstCommentAcknowledgeMessageCommentId":"QgwD7PkQHFp3nfhjj"}</script><script>window.tabId = "dopBqbwKdkci9M36v"</script><script>window.isReturningVisitor = true</script><script async="" src="eliezer_files/bundle.js"></script><title>Eliezer Yudkowsky - LessWrong</title><meta data-react-helmet="true" charset="utf-8"><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" http-equiv="delegate-ch" content="sec-ch-dpr https://res.cloudinary.com;"><meta data-react-helmet="true" http-equiv="Accept-CH" content="DPR, Viewport-Width, Width"><link data-react-helmet="true" rel="alternate" type="application/rss+xml" href="https://www.lesswrong.com/feed.xml"><meta name="twitter:card" content="summary"><script>window.themeOptions = {"name":"default"}</script><style id="jss-insertion-point"></style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: rgba(0, 0, 0, 0.54);
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(0, 0, 0, 0.26);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-moz-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-moz-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-moz-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(0,0,0,0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,gill-sans-nova,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(0, 0, 0, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-contained {
  color: rgba(0, 0, 0, 0.87);
  box-shadow: 0px 1px 5px 0px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 3px 1px -2px rgba(0,0,0,0.12);
  background-color: #e0e0e0;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
  box-shadow: none;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:hover {
  background-color: #d5d5d5;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #e0e0e0;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-containedPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(0,0,0,0.2),0px 12px 17px 2px rgba(0,0,0,0.14),0px 5px 22px 4px rgba(0,0,0,0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: rgba(0, 0, 0, 0.54);
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiPopover">
.MuiPopover-paper {
  outline: none;
  position: absolute;
  min-width: 16px;
  max-width: calc(100% - 32px);
  overflow-y: auto;
  overflow-x: hidden;
  min-height: 16px;
  max-height: calc(100% - 32px);
}
</style><style data-jss="" data-meta="MuiMenu">
.MuiMenu-paper {
  max-height: calc(100% - 96px);
  -webkit-overflow-scrolling: touch;
}
</style><style data-jss="" data-meta="MuiBadge">
.MuiBadge-root {
  display: inline-flex;
  position: relative;
  vertical-align: middle;
}
.MuiBadge-badge {
  top: -11px;
  right: -11px;
  width: 22px;
  height: 22px;
  display: flex;
  z-index: 1;
  position: absolute;
  flex-wrap: wrap;
  font-size: 0.75rem;
  align-items: center;
  font-family: GreekFallback,Calibri,gill-sans-nova,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  align-content: center;
  border-radius: 50%;
  flex-direction: row;
  justify-content: center;
}
.MuiBadge-colorPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiBadge-colorSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiBadge-colorError {
  color: #fff;
  background-color: #bf360c;
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(0, 0, 0, 0.12);
}
</style><style data-jss="">
.jss101 {
  top: 0;
  left: 0;
  bottom: 0;
  z-index: 1199;
  position: fixed;
}
.jss102 {
  right: auto;
}
.jss103 {
  left: auto;
  right: 0;
}
.jss104 {
  right: 0;
  bottom: auto;
}
.jss105 {
  top: auto;
  right: 0;
  bottom: 0;
}
</style><style data-jss="" data-meta="MuiTooltip">
.MuiTooltip-popper {
  z-index: 1500;
  opacity: 0.9;
}
.MuiTooltip-tooltip {
  color: #fff;
  padding: 9.1px;
  z-index: 10000000;
  font-size: 13px;
  max-width: 300px;
  font-family: GreekFallback,Calibri,gill-sans-nova,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  background-color: rgba(75,75,75,.94);
}
.MuiTooltip-touch {
  padding: 8px 16px;
  font-size: 0.875rem;
  line-height: 1.14286em;
}
.MuiTooltip-tooltipPlacementLeft {
  margin: 0 24px ;
  transform-origin: right center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementLeft {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementRight {
  margin: 0 24px;
  transform-origin: left center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementRight {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementTop {
  margin: 24px 0;
  transform-origin: center bottom;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementTop {
    margin: 14px 0;
  }
}
.MuiTooltip-tooltipPlacementBottom {
  margin: 24px 0;
  transform-origin: center top;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementBottom {
    margin: 14px 0;
  }
}
</style><style id="jss-insertion-start"></style><style data-name="ForumIcon" data-priority="-2">.ForumIcon-root {
  width: var(--icon-size, 1em);
  height: var(--icon-size, 1em);
  display: inline-block;
  font-size: var(--icon-size, 24px);
  user-select: none;
  flex-shrink: 0;
}
.ForumIcon-linkRotation {
  transform: rotate(-45deg);
}
.ForumIcon-linkRotation.MuiListItemIcon-root {
  margin-right: 12px;
}</style><style data-name="CommentsItemDate" data-priority="0">.CommentsItemDate-root {
  z-index: 3;
  position: relative;
  margin-left: 2px;
  white-space: nowrap;
  margin-right: 16px;
}
.CommentsItemDate-root a:hover .CommentsItemDate-icon, .CommentsItemDate-root a:active .CommentsItemDate-icon {
  color: rgba(0,0,0,0.3) !important;
}
.CommentsItemDate-date {
  color: rgba(0,0,0,0.5);
}
.CommentsItemDate-postTitle {
  margin-right: 5px;
}
.CommentsItemDate-icon {
  top: -2px;
  color: rgba(0,0,0,0.5);
  margin: 0 2px;
  position: relative;
  font-size: 0.9rem;
  vertical-align: middle;
}
.CommentsItemDate-editedMarker {
  font-size: 12px;
  padding-left: 2px;
}</style><style data-name="LWBackgroundImage" data-priority="0">.LWBackgroundImage-root {
  right: 0;
  position: absolute;
}
.LWBackgroundImage-backgroundImage {
  top: -70px;
  width: 57vw;
  right: -334px;
  position: absolute;
  max-width: 1000px;
  -webkit-mask-image: radial-gradient(ellipse at center top, #000 55%, transparent 70%);
}
@media (min-width:2000px) {
  .LWBackgroundImage-backgroundImage {
    right: 0px;
  }
}
.LWBackgroundImage-reviewResultsImage {
  top: -70px;
  width: 57vw;
  right: -334px;
  position: absolute;
  max-width: 1000px;
  -webkit-mask-image: radial-gradient(ellipse at center top, #000 55%, transparent 70%);
}
.LWBackgroundImage-imageColumn {
  top: 0;
  right: 0;
  width: 57vw;
  height: 100vh;
  position: absolute;
}
@media(max-width: 1000px) {
  .LWBackgroundImage-imageColumn {
    display: none;
  }
}
.LWBackgroundImage-reviewVotingCanvas {
  top: -57px;
  width: 57vw;
  right: -334px;
  height: 100vh;
  position: absolute;
  max-width: 1000px;
  -webkit-mask-image: radial-gradient(ellipse at center top, #000 55%, transparent 70%);
}
.LWBackgroundImage-reviewVotingCanvas img {
  width: 100%;
  right: -40px;
  height: 100vh;
  position: relative;
  object-fit: cover;
}
@media (min-width:2000px) {
  .LWBackgroundImage-reviewVotingCanvas {
    right: 0px;
  }
}
.LWBackgroundImage-votingResultsLink {
  top: 715px;
  right: 250px;
  width: 200px;
  z-index: 1;
  opacity: 0.6;
  display: block;
  position: relative;
  text-align: center;
}
.LWBackgroundImage-votingResultsLink:hover {
  opacity: 0.4;
}
@media (max-width:1599.95px) {
  .LWBackgroundImage-votingResultsLink {
    top: 690px;
    right: 100px;
  }
}
@media (max-width:1399.95px) {
  .LWBackgroundImage-votingResultsLink {
    top: 650px;
    right: 35px;
  }
}
.LWBackgroundImage-votingResultsLink h1 {
  font-size: 2.8rem;
  margin-top: 20px;
  font-family: ETBookRoman,warnock-pro,Palatino,"Palatino Linotype","Palatino LT STD","Book Antiqua",Georgia,serif;
  line-height: 2.6rem;
  font-weight: 600;
  margin-bottom: 0;
}
.LWBackgroundImage-votingResultsLink h3 {
  opacity: 0.5;
  font-size: 1.4rem;
  margin-top: 16px;
  font-style: italic;
  font-family: GreekFallback,Calibri,gill-sans-nova,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.2;
  margin-bottom: 6px;
}
.LWBackgroundImage-votingResultsLink h3 b, .LWBackgroundImage-votingResultsLink h3 strong {
  font-weight: 600;
}</style><style data-name="PostActionsButton" data-priority="0">.PostActionsButton-root {
  cursor: pointer;
}
.PostActionsButton-icon {
  cursor: pointer;
  vertical-align: middle;
}
.PostActionsButton-popper {
  z-index: 1050;
  position: relative;
}</style><style data-name="PostsItemTrailingButtons" data-priority="0">.PostsItemTrailingButtons-actions {
  top: 0;
  right: -24px;
  width: 18px;
  height: 100%;
  opacity: 0;
  display: flex;
  position: absolute;
  align-items: center;
  justify-content: center;
}
@media (max-width:959.95px) {
  .PostsItemTrailingButtons-actions {
    display: none;
  }
}
.PostsItemTrailingButtons-archiveButton {
  top: 1px;
  right: -54px;
  width: 18px;
  height: 100%;
  cursor: pointer;
  opacity: 0;
  display: flex;
  position: absolute;
  align-items: center;
  justify-content: center;
}
@media (max-width:959.95px) {
  .PostsItemTrailingButtons-archiveButton {
    display: none;
  }
}
.PostsItemTrailingButtons-dismissButton {
  cursor: pointer;
}</style><style id="jss-insertion-end"></style><link id="main-styles" rel="stylesheet" type="text/css" onerror="window.missingMainStylesheet=true" href="eliezer_files/allStyles.css"><script async="" src="eliezer_files/wtb8z7sj"></script><style data-cke-inspector="true">.ck-inspector{--ck-inspector-color-tab-background-hover:rgba(0,0,0,0.07);--ck-inspector-color-tab-active-border:#0dacef }.ck-inspector .ck-inspector-horizontal-nav{display:flex;flex-direction:row;user-select:none;align-self:stretch}.ck-inspector .ck-inspector-horizontal-nav .ck-inspector-horizontal-nav__item{-webkit-appearance:none;background:none;border:0;border-bottom:2px solid transparent;padding:.5em 1em;align-self:stretch}.ck-inspector .ck-inspector-horizontal-nav .ck-inspector-horizontal-nav__item:hover{background:var(--ck-inspector-color-tab-background-hover)}.ck-inspector .ck-inspector-horizontal-nav .ck-inspector-horizontal-nav__item.ck-inspector-horizontal-nav__item_active{border-bottom-color:var(--ck-inspector-color-tab-active-border)}.ck-inspector{--ck-inspector-navbox-empty-background:#fafafa}.ck-inspector .ck-inspector-navbox{display:flex;flex-direction:column;height:100%;align-items:stretch}.ck-inspector .ck-inspector-navbox .ck-inspector-navbox__navigation{display:flex;flex-direction:row;flex-wrap:nowrap;align-items:stretch;min-height:30px;max-height:30px;border-bottom:1px solid var(--ck-inspector-color-border);width:100%;user-select:none;align-items:center}.ck-inspector .ck-inspector-navbox .ck-inspector-navbox__content{display:flex;flex-direction:row;height:100%;overflow:hidden}.ck-inspector{--ck-inspector-icon-size:19px;--ck-inspector-button-size:calc(4px + var(--ck-inspector-icon-size));--ck-inspector-color-button:#777;--ck-inspector-color-button-hover:#222;--ck-inspector-color-button-on:#0f79e2}.ck-inspector .ck-inspector-button{width:var(--ck-inspector-button-size);height:var(--ck-inspector-button-size);border:0;overflow:hidden;border-radius:2px;padding:2px;color:var(--ck-inspector-color-button)}.ck-inspector .ck-inspector-button.ck-inspector-button_on,.ck-inspector .ck-inspector-button.ck-inspector-button_on:hover{color:var(--ck-inspector-color-button-on);opacity:1}.ck-inspector .ck-inspector-button.ck-inspector-button_disabled{opacity:.3}.ck-inspector .ck-inspector-button>span{display:none}.ck-inspector .ck-inspector-button:hover{color:var(--ck-inspector-color-button-hover)}.ck-inspector .ck-inspector-button svg{width:var(--ck-inspector-icon-size);height:var(--ck-inspector-icon-size)}.ck-inspector .ck-inspector-button svg,.ck-inspector .ck-inspector-button svg *{fill:currentColor}.ck-inspector{--ck-inspector-explorer-width:300px}.ck-inspector .ck-inspector-pane{display:flex;width:100%}.ck-inspector .ck-inspector-pane.ck-inspector-pane_empty{align-items:center;justify-content:center;padding:1em;background:var(--ck-inspector-navbox-empty-background)}.ck-inspector .ck-inspector-pane.ck-inspector-pane_empty p{align-self:center;width:100%;text-align:center}.ck-inspector .ck-inspector-pane>.ck-inspector-navbox:last-child{min-width:var(--ck-inspector-explorer-width);width:var(--ck-inspector-explorer-width)}.ck-inspector .ck-inspector-pane.ck-inspector-pane_vsplit>.ck-inspector-navbox:first-child{border-right:1px solid var(--ck-inspector-color-border);flex:1 1 auto;overflow:hidden}.ck-inspector .ck-inspector-pane.ck-inspector-pane_vsplit>.ck-inspector-navbox:first-child .ck-inspector-navbox__navigation{align-items:center}.ck-inspector .ck-inspector-pane.ck-inspector-pane_vsplit>.ck-inspector-navbox:first-child .ck-inspector-tree__config label{margin:0 .5em}.ck-inspector .ck-inspector-pane.ck-inspector-pane_vsplit>.ck-inspector-navbox:first-child .ck-inspector-tree__config input+label{margin-right:1em}.ck-inspector-side-pane{position:relative}.ck-inspector{--ck-inspector-color-tree-node-hover:#eaf2fb;--ck-inspector-color-tree-node-name:#882680;--ck-inspector-color-tree-node-attribute-name:#8a8a8a;--ck-inspector-color-tree-node-tag:#aaa;--ck-inspector-color-tree-node-attribute:#9a4819;--ck-inspector-color-tree-node-attribute-value:#2a43ac;--ck-inspector-color-tree-text-border:#b7b7b7;--ck-inspector-color-tree-node-border-hover:#b0c6e0;--ck-inspector-color-tree-content-delimiter:#ddd;--ck-inspector-color-tree-node-active-bg:#f5faff;--ck-inspector-color-tree-node-name-active-bg:#2b98f0;--ck-inspector-color-tree-node-inactive:#8a8a8a;--ck-inspector-color-tree-selection:#ff1744;--ck-inspector-color-tree-position:#000;--ck-inspector-color-comment:green}.ck-inspector .ck-inspector-tree{background:var(--ck-inspector-color-white);padding:1em;width:100%;height:100%;overflow:auto;user-select:none}.ck-inspector-tree .ck-inspector-tree-node__attribute{font:inherit;margin-left:.4em;color:var(--ck-inspector-color-tree-node-tag)}.ck-inspector-tree .ck-inspector-tree-node__attribute .ck-inspector-tree-node__attribute__name{color:var(--ck-inspector-color-tree-node-attribute)}.ck-inspector-tree .ck-inspector-tree-node__attribute .ck-inspector-tree-node__attribute__value{color:var(--ck-inspector-color-tree-node-attribute-value)}.ck-inspector-tree .ck-inspector-tree-node__attribute .ck-inspector-tree-node__attribute__value:before{content:'="'}.ck-inspector-tree .ck-inspector-tree-node__attribute .ck-inspector-tree-node__attribute__value:after{content:'"'}.ck-inspector-tree .ck-inspector-tree-node .ck-inspector-tree-node__name{color:var(--ck-inspector-color-tree-node-name);display:inline-block;width:100%;padding:0 .1em;border-left:1px solid transparent}.ck-inspector-tree .ck-inspector-tree-node .ck-inspector-tree-node__name:hover{background:var(--ck-inspector-color-tree-node-hover)}.ck-inspector-tree .ck-inspector-tree-node .ck-inspector-tree-node__content{padding:1px .5em 1px 1.5em;border-left:1px solid var(--ck-inspector-color-tree-content-delimiter);white-space:pre-wrap}.ck-inspector-tree .ck-inspector-tree-node:not(.ck-inspector-tree-node_tagless) .ck-inspector-tree-node__name>.ck-inspector-tree-node__name__bracket_open:after{content:"<";color:var(--ck-inspector-color-tree-node-tag)}.ck-inspector-tree .ck-inspector-tree-node:not(.ck-inspector-tree-node_tagless) .ck-inspector-tree-node__name .ck-inspector-tree-node__name__bracket_close:after{content:">";color:var(--ck-inspector-color-tree-node-tag)}.ck-inspector-tree .ck-inspector-tree-node:not(.ck-inspector-tree-node_tagless).ck-inspector-tree-node_empty .ck-inspector-tree-node__name:after{content:" />"}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_tagless .ck-inspector-tree-node__content{display:none}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__name:not(.ck-inspector-tree-node__name_close),.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__name:not(.ck-inspector-tree-node__name_close) :not(.ck-inspector-tree__position),.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__name:not(.ck-inspector-tree-node__name_close)>.ck-inspector-tree-node__name__bracket:after{background:var(--ck-inspector-color-tree-node-name-active-bg);color:var(--ck-inspector-color-white)}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__content,.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__name_close{background:var(--ck-inspector-color-tree-node-active-bg)}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__content{border-left-color:var(--ck-inspector-color-tree-node-name-active-bg)}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_active>.ck-inspector-tree-node__name{border-left:1px solid var(--ck-inspector-color-tree-node-name-active-bg)}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_disabled{opacity:.8}.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_disabled .ck-inspector-tree-node__name,.ck-inspector-tree .ck-inspector-tree-node.ck-inspector-tree-node_disabled .ck-inspector-tree-node__name *{color:var(--ck-inspector-color-tree-node-inactive)}.ck-inspector-tree .ck-inspector-tree-text{display:block;margin-bottom:1px}.ck-inspector-tree .ck-inspector-tree-text .ck-inspector-tree-node__content{border:1px dotted var(--ck-inspector-color-tree-text-border);border-radius:2px;padding:0 1px;margin-right:1px;display:inline-block;word-break:break-all}.ck-inspector-tree .ck-inspector-tree-text .ck-inspector-tree-text__attributes:not(:empty){margin-right:.5em}.ck-inspector-tree .ck-inspector-tree-text .ck-inspector-tree-text__attributes .ck-inspector-tree-node__attribute{background:var(--ck-inspector-color-tree-node-attribute-name);border-radius:2px;padding:0 .5em}.ck-inspector-tree .ck-inspector-tree-text .ck-inspector-tree-text__attributes .ck-inspector-tree-node__attribute+.ck-inspector-tree-node__attribute{margin-left:.2em}.ck-inspector-tree .ck-inspector-tree-text .ck-inspector-tree-text__attributes .ck-inspector-tree-node__attribute>*{color:var(--ck-inspector-color-white)}.ck-inspector-tree .ck-inspector-tree-text .ck-inspector-tree-text__attributes .ck-inspector-tree-node__attribute:first-child{margin-left:0}.ck-inspector-tree .ck-inspector-tree-text.ck-inspector-tree-node_active .ck-inspector-tree-node__content{border-style:solid;border-color:var(--ck-inspector-color-tree-node-name-active-bg)}.ck-inspector-tree .ck-inspector-tree-text.ck-inspector-tree-node_active .ck-inspector-tree-node__attribute{background:var(--ck-inspector-color-white)}.ck-inspector-tree .ck-inspector-tree-text.ck-inspector-tree-node_active .ck-inspector-tree-node__attribute>*{color:var(--ck-inspector-color-tree-node-name-active-bg)}.ck-inspector-tree .ck-inspector-tree-text.ck-inspector-tree-node_active>.ck-inspector-tree-node__content{background:var(--ck-inspector-color-tree-node-name-active-bg);color:var(--ck-inspector-color-white)}.ck-inspector-tree .ck-inspector-tree-text:not(.ck-inspector-tree-node_active) .ck-inspector-tree-node__content:hover{background:var(--ck-inspector-color-tree-node-hover);border-style:solid;border-color:var(--ck-inspector-color-tree-node-border-hover)}.ck-inspector-tree.ck-inspector-tree_text-direction_ltr .ck-inspector-tree-node__content{direction:ltr}.ck-inspector-tree.ck-inspector-tree_text-direction_rtl .ck-inspector-tree-node__content{direction:rtl}.ck-inspector-tree.ck-inspector-tree_text-direction_rtl .ck-inspector-tree-node__content .ck-inspector-tree-node__name{direction:ltr}.ck-inspector-tree.ck-inspector-tree_text-direction_rtl .ck-inspector-tree__position{transform:rotate(180deg)}.ck-inspector-tree .ck-inspector-tree-comment{color:var(--ck-inspector-color-comment);font-style:italic}.ck-inspector-tree .ck-inspector-tree-comment a{color:inherit;text-decoration:underline}.ck-inspector-tree_compact-text .ck-inspector-tree-text,.ck-inspector-tree_compact-text .ck-inspector-tree-text .ck-inspector-tree-node__content{display:inline}.ck-inspector .ck-inspector__tree__navigation{padding:.5em 1em;border-bottom:1px solid var(--ck-inspector-color-border)}.ck-inspector .ck-inspector__tree__navigation label{margin-right:.5em}.ck-inspector-tree .ck-inspector-tree__position{display:inline-block;position:relative;cursor:default;height:100%;pointer-events:none;vertical-align:top}.ck-inspector-tree .ck-inspector-tree__position:after{content:"";position:absolute;border:1px solid var(--ck-inspector-color-tree-position);width:0;top:0;bottom:0;margin-left:-1px}.ck-inspector-tree .ck-inspector-tree__position:before{margin-left:-1px}.ck-inspector-tree .ck-inspector-tree__position.ck-inspector-tree__position_selection{z-index:2;--ck-inspector-color-tree-position:var(--ck-inspector-color-tree-selection)}.ck-inspector-tree .ck-inspector-tree__position.ck-inspector-tree__position_selection:before{content:"";position:absolute;top:-1px;bottom:-1px;left:0;border-top:2px solid var(--ck-inspector-color-tree-position);border-bottom:2px solid var(--ck-inspector-color-tree-position);width:8px}.ck-inspector-tree .ck-inspector-tree__position.ck-inspector-tree__position_selection.ck-inspector-tree__position_end:before{right:-1px;left:auto}.ck-inspector-tree .ck-inspector-tree__position.ck-inspector-tree__position_marker{z-index:1}.ck-inspector-tree .ck-inspector-tree__position.ck-inspector-tree__position_marker:before{content:"";display:block;position:absolute;left:0;top:-1px;cursor:default;width:0;height:0;border-left:0 solid transparent;border-bottom:0 solid transparent;border-right:7px solid transparent;border-top:7px solid var(--ck-inspector-color-tree-position)}.ck-inspector-tree .ck-inspector-tree__position.ck-inspector-tree__position_marker.ck-inspector-tree__position_end:before{border-width:0 7px 7px 0;border-left-color:transparent;border-bottom-color:transparent;border-right-color:var(--ck-inspector-color-tree-position);border-top-color:transparent;left:-5px}.ck-inspector .ck-inspector-checkbox{vertical-align:middle}.ck-inspector{--ck-inspector-color-property-list-property-name:#d0363f;--ck-inspector-color-property-list-property-value-true:green;--ck-inspector-color-property-list-property-value-false:red;--ck-inspector-color-property-list-property-value-unknown:#888;--ck-inspector-color-property-list-background:#f5f5f5;--ck-inspector-color-property-list-title-collapser:#727272}.ck-inspector .ck-inspector-property-list{display:grid;grid-template-columns:auto 1fr;background:var(--ck-inspector-color-white)}.ck-inspector .ck-inspector-property-list>:nth-of-type(odd){background:var(--ck-inspector-color-property-list-background)}.ck-inspector .ck-inspector-property-list>:nth-of-type(2n){background:var(--ck-inspector-color-white)}.ck-inspector .ck-inspector-property-list dt{padding:0 .7em 0 1.2em;min-width:15em}.ck-inspector .ck-inspector-property-list dt.ck-inspector-property-list__title_collapsible button{display:inline-block;overflow:hidden;vertical-align:middle;margin-left:-9px;margin-right:.3em;width:0;height:0;border-left:6px solid var(--ck-inspector-color-property-list-title-collapser);border-bottom:3.5px solid transparent;border-right:0 solid transparent;border-top:3.5px solid transparent;transition:transform .2s ease-in-out;transform:rotate(0deg)}.ck-inspector .ck-inspector-property-list dt.ck-inspector-property-list__title_expanded button{transform:rotate(90deg)}.ck-inspector .ck-inspector-property-list dt.ck-inspector-property-list__title_collapsed+dd+.ck-inspector-property-list{display:none}.ck-inspector .ck-inspector-property-list dt .ck-inspector-property-list__title__color-box{width:12px;height:12px;vertical-align:text-top;display:inline-block;margin-right:3px;border-radius:2px;border:1px solid #000}.ck-inspector .ck-inspector-property-list dt.ck-inspector-property-list__title_clickable label:hover{text-decoration:underline;cursor:pointer}.ck-inspector .ck-inspector-property-list dt label{color:var(--ck-inspector-color-property-list-property-name)}.ck-inspector .ck-inspector-property-list dd{padding-right:.7em}.ck-inspector .ck-inspector-property-list dd input{width:100%}.ck-inspector .ck-inspector-property-list dd input[value=false]{color:var(--ck-inspector-color-property-list-property-value-false)}.ck-inspector .ck-inspector-property-list dd input[value=true]{color:var(--ck-inspector-color-property-list-property-value-true)}.ck-inspector .ck-inspector-property-list dd input[value="function() {…}"],.ck-inspector .ck-inspector-property-list dd input[value=undefined]{color:var(--ck-inspector-color-property-list-property-value-unknown)}.ck-inspector .ck-inspector-property-list dd input[value="function() {…}"]{font-style:italic}.ck-inspector .ck-inspector-property-list .ck-inspector-property-list{grid-column:1/-1;margin-left:1em;background:transparent}.ck-inspector .ck-inspector-property-list .ck-inspector-property-list>:nth-of-type(2n),.ck-inspector .ck-inspector-property-list .ck-inspector-property-list>:nth-of-type(odd){background:transparent}.ck-inspector .ck-inspector__object-inspector{width:100%;background:var(--ck-inspector-color-white);overflow:auto}.ck-inspector .ck-inspector__object-inspector h2,.ck-inspector .ck-inspector__object-inspector h3{display:flex;flex-direction:row;flex-wrap:nowrap}.ck-inspector .ck-inspector__object-inspector h2{display:flex;align-items:center;padding:1em;overflow:hidden;text-overflow:ellipsis}.ck-inspector .ck-inspector__object-inspector h2>span{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;display:block;margin-right:auto}.ck-inspector .ck-inspector__object-inspector h2>.ck-inspector-button{flex-shrink:0;margin-left:.5em}.ck-inspector .ck-inspector__object-inspector h2 a{font-weight:700;color:var(--ck-inspector-color-tree-node-name)}.ck-inspector .ck-inspector__object-inspector h2 a,.ck-inspector .ck-inspector__object-inspector h2 a>*{cursor:pointer}.ck-inspector .ck-inspector__object-inspector h2 em:after,.ck-inspector .ck-inspector__object-inspector h2 em:before{content:'"'}.ck-inspector .ck-inspector__object-inspector h3{display:flex;align-items:center;font-size:12px;padding:.4em .7em}.ck-inspector .ck-inspector__object-inspector h3 a{color:inherit;font-weight:700;margin-right:auto}.ck-inspector .ck-inspector__object-inspector h3 .ck-inspector-button{visibility:hidden}.ck-inspector .ck-inspector__object-inspector h3:hover .ck-inspector-button{visibility:visible}.ck-inspector .ck-inspector__object-inspector hr{border-top:1px solid var(--ck-inspector-color-border)}.ck-inspector-model-tree__hide-markers .ck-inspector-tree__position.ck-inspector-tree__position_marker{display:none}.ck-inspector-modal{--ck-inspector-set-data-modal-overlay:rgba(0,0,0,0.5);--ck-inspector-set-data-modal-shadow:rgba(0,0,0,0.06);--ck-inspector-set-data-modal-button-background:#eee;--ck-inspector-set-data-modal-button-background-hover:#ddd;--ck-inspector-set-data-modal-save-button-background:#1976d2;--ck-inspector-set-data-modal-save-button-background-hover:#0b60b5}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal{z-index:999999;position:fixed;inset:0;background-color:var(--ck-inspector-set-data-modal-overlay)}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content{position:absolute;border:1px solid var(--ck-inspector-color-border);background:var(--ck-inspector-color-white);overflow:auto;border-radius:2px;outline:none;box-shadow:0 1px 1px var(--ck-inspector-set-data-modal-shadow),0 2px 2px var(--ck-inspector-set-data-modal-shadow),0 4px 4px var(--ck-inspector-set-data-modal-shadow),0 8px 8px var(--ck-inspector-set-data-modal-shadow),0 16px 16px var(--ck-inspector-set-data-modal-shadow);max-height:calc(100vh - 160px);max-width:calc(100vw - 160px);width:100%;height:100%;left:50%;top:50%;transform:translate(-50%,-50%);display:flex;flex-direction:column;justify-content:space-between}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content h2{font-size:14px;font-weight:700;margin:0;padding:12px 20px;background:var(--ck-inspector-color-background);border-bottom:1px solid var(--ck-inspector-color-border)}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content textarea{flex-grow:1;margin:20px;border:1px solid var(--ck-inspector-color-border);border-radius:2px;resize:none;padding:10px;font-family:monospace;font-size:14px}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content button{padding:10px 20px;border-radius:2px;font-size:14px;white-space:nowrap;border:1px solid var(--ck-inspector-color-border)}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content button:hover{background:var(--ck-inspector-set-data-modal-button-background-hover)}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content .ck-inspector-quick-actions__set-data-modal__buttons{margin:0 20px 20px;display:flex;justify-content:center}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content .ck-inspector-quick-actions__set-data-modal__buttons button+button{margin-left:20px}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content .ck-inspector-quick-actions__set-data-modal__buttons button:first-child{margin-right:auto}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content .ck-inspector-quick-actions__set-data-modal__buttons button:not(:first-child){flex-basis:20%}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content .ck-inspector-quick-actions__set-data-modal__buttons button:last-child{background:var(--ck-inspector-set-data-modal-save-button-background);border-color:var(--ck-inspector-set-data-modal-save-button-background);color:#fff;font-weight:700}.ck-inspector-modal.ck-inspector-quick-actions__set-data-modal .ck-inspector-quick-actions__set-data-modal__content .ck-inspector-quick-actions__set-data-modal__buttons button:last-child:hover{background:var(--ck-inspector-set-data-modal-save-button-background-hover)}.ck-inspector .ck-inspector-editor-quick-actions{display:flex;align-content:center;justify-content:center;align-items:center;flex-direction:row;flex-wrap:nowrap}.ck-inspector .ck-inspector-editor-quick-actions>.ck-inspector-button{margin-left:.3em}.ck-inspector .ck-inspector-editor-quick-actions>.ck-inspector-button.ck-inspector-button_data-copied{animation-duration:.5s;animation-name:ck-inspector-bounce-in;color:green}@keyframes ck-inspector-bounce-in{0%{opacity:0;transform:scale3d(.5,.5,.5)}20%{transform:scale3d(1.1,1.1,1.1)}40%{transform:scale3d(.8,.8,.8)}60%{opacity:1;transform:scale3d(1.05,1.05,1.05)}to{opacity:1;transform:scaleX(1)}}.ck-inspector,.ck-inspector-portal{--ck-inspector-color-white:#fff;--ck-inspector-color-black:#000;--ck-inspector-color-background:#f3f3f3;--ck-inspector-color-link:#005cc6;--ck-inspector-code-font-size:11px;--ck-inspector-code-font-family:monaco,Consolas,Lucida Console,monospace;--ck-inspector-color-border:#d0d0d0}.ck-inspector,.ck-inspector-portal,.ck-inspector-portal :not(select),.ck-inspector :not(select){box-sizing:border-box;width:auto;height:auto;position:static;margin:0;padding:0;border:0;background:transparent;text-decoration:none;transition:none;word-wrap:break-word;font-family:Arial,Helvetica Neue,Helvetica,sans-serif;font-size:12px;line-height:17px;font-weight:400;-webkit-font-smoothing:auto}.ck-inspector{overflow:hidden;border-collapse:collapse;color:var(--ck-inspector-color-black);text-align:left;white-space:normal;cursor:auto;float:none;background:var(--ck-inspector-color-background);border-top:1px solid var(--ck-inspector-color-border);z-index:9999}.ck-inspector.ck-inspector_collapsed>.ck-inspector-navbox>.ck-inspector-navbox__navigation .ck-inspector-horizontal-nav{display:none}.ck-inspector .ck-inspector-navbox__navigation__logo{background-size:contain;background-repeat:no-repeat;background-position:50%;display:block;overflow:hidden;text-indent:100px;align-self:center;white-space:nowrap;margin-right:1em;background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg width='68' height='64' xmlns='http://www.w3.org/2000/svg'%3E%3Cg fill='none' fill-rule='evenodd'%3E%3Cpath d='M43.71 11.025a11.508 11.508 0 00-1.213 5.159c0 6.42 5.244 11.625 11.713 11.625.083 0 .167 0 .25-.002v16.282a5.464 5.464 0 01-2.756 4.739L30.986 60.7a5.548 5.548 0 01-5.512 0L4.756 48.828A5.464 5.464 0 012 44.089V20.344c0-1.955 1.05-3.76 2.756-4.738L25.474 3.733a5.548 5.548 0 015.512 0l12.724 7.292z' fill='%23FFF'/%3E%3Cpath d='M45.684 8.79a12.604 12.604 0 00-1.329 5.65c0 7.032 5.744 12.733 12.829 12.733.091 0 .183-.001.274-.003v17.834a5.987 5.987 0 01-3.019 5.19L31.747 63.196a6.076 6.076 0 01-6.037 0L3.02 50.193A5.984 5.984 0 010 45.003V18.997c0-2.14 1.15-4.119 3.019-5.19L25.71.804a6.076 6.076 0 016.037 0L45.684 8.79zm-29.44 11.89c-.834 0-1.51.671-1.51 1.498v.715c0 .828.676 1.498 1.51 1.498h25.489c.833 0 1.51-.67 1.51-1.498v-.715c0-.827-.677-1.498-1.51-1.498h-25.49zm0 9.227c-.834 0-1.51.671-1.51 1.498v.715c0 .828.676 1.498 1.51 1.498h18.479c.833 0 1.509-.67 1.509-1.498v-.715c0-.827-.676-1.498-1.51-1.498H16.244zm0 9.227c-.834 0-1.51.671-1.51 1.498v.715c0 .828.676 1.498 1.51 1.498h25.489c.833 0 1.51-.67 1.51-1.498v-.715c0-.827-.677-1.498-1.51-1.498h-25.49zm41.191-14.459c-5.835 0-10.565-4.695-10.565-10.486 0-5.792 4.73-10.487 10.565-10.487C63.27 3.703 68 8.398 68 14.19c0 5.791-4.73 10.486-10.565 10.486zm3.422-8.68c0-.467-.084-.875-.251-1.225a2.547 2.547 0 00-.686-.88 2.888 2.888 0 00-1.026-.531 4.418 4.418 0 00-1.259-.175c-.134 0-.283.006-.447.018a2.72 2.72 0 00-.446.07l.075-1.4h3.587v-1.8h-5.462l-.214 5.06c.319-.116.682-.21 1.089-.28.406-.071.77-.107 1.088-.107.218 0 .437.021.655.063.218.041.413.114.585.218s.313.244.422.419c.109.175.163.391.163.65 0 .424-.132.745-.396.961a1.434 1.434 0 01-.938.325c-.352 0-.656-.1-.912-.3-.256-.2-.43-.453-.523-.762l-1.925.588c.1.35.258.664.472.943.214.279.47.514.767.706.298.191.63.339.995.443.365.104.749.156 1.151.156.437 0 .86-.064 1.272-.193.41-.13.778-.323 1.1-.581a2.8 2.8 0 00.775-.981c.193-.396.29-.864.29-1.405z' fill='%231EBC61' fill-rule='nonzero'/%3E%3C/g%3E%3C/svg%3E");width:1.8em;height:1.8em;margin-left:1em}.ck-inspector .ck-inspector-navbox__navigation__toggle{margin-right:1em}.ck-inspector .ck-inspector-navbox__navigation__toggle.ck-inspector-navbox__navigation__toggle_up{transform:rotate(180deg)}.ck-inspector .ck-inspector-editor-selector{margin-left:auto;margin-right:.3em}@media screen and (max-width:680px){.ck-inspector .ck-inspector-editor-selector label{display:none}}.ck-inspector .ck-inspector-editor-selector select{margin-left:.5em}.ck-inspector .ck-inspector-code,.ck-inspector .ck-inspector-code *{font-size:var(--ck-inspector-code-font-size);font-family:var(--ck-inspector-code-font-family);cursor:default}.ck-inspector a{color:var(--ck-inspector-color-link);text-decoration:none}.ck-inspector a:hover{text-decoration:underline;cursor:pointer}.ck-inspector button{outline:0}.ck-inspector .ck-inspector-separator{border-right:1px solid var(--ck-inspector-color-border);display:inline-block;width:0;height:20px;margin:0 .5em;vertical-align:middle}html body.ck-inspector-body-expanded{margin-bottom:var(--ck-inspector-height)}html body.ck-inspector-body-collapsed{margin-bottom:var(--ck-inspector-collapsed-height)}.ck-inspector-wrapper *{box-sizing:border-box}</style><script async="" src="eliezer_files/player.js" defer="true" type="module" cross-origin="anonymous"></script><meta name="twitter:image:src" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg" data-react-helmet="true"><meta property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg" data-react-helmet="true"><link rel="canonical" href="https://www.lesswrong.com/users/eliezer_yudkowsky" data-react-helmet="true"><meta property="og:url" content="https://www.lesswrong.com/users/eliezer_yudkowsky" data-react-helmet="true"><meta property="og:title" content="Eliezer Yudkowsky - LessWrong" data-react-helmet="true"><meta name="description" content="Eliezer Yudkowsky's profile on LessWrong — A community blog devoted to refining the art of rationality" data-react-helmet="true"><meta name="twitter:description" content="Eliezer Yudkowsky's profile on LessWrong — A community blog devoted to refining the art of rationality" data-react-helmet="true"><meta property="og:description" content="Eliezer Yudkowsky's profile on LessWrong — A community blog devoted to refining the art of rationality" data-react-helmet="true"><script type="application/ld+json" data-react-helmet="true">{"@context":"http://schema.org","@type":"Person","name":"Eliezer Yudkowsky","url":"https://www.lesswrong.com/users/eliezer_yudkowsky","interactionStatistic":[{"@type":"InteractionCounter","interactionType":{"@type":"http://schema.org/LikeAction"},"userInteractionCount":148674},{"@type":"InteractionCounter","interactionType":{"@type":"http://schema.org/WriteAction"},"userInteractionCount":951}],"memberSince":"2009-02-23T21:58:56.739Z"}</script></head>
<body class="welcomeBoxABTest_welcomeBox twoLineEventsSidebar_control" style="">
<script>0</script><div id="react-app"><div class="wrapper Layout-wrapper" id="wrapper"><div></div><span></span><div id="intercom-outer-frame"></div><noscript class="noscript-warning"> This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. </noscript><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TRC765W" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div class="Header-root"><div style="height:64px" class="Header-headroom headroom-wrapper"><div class="headroom headroom--unfixed headroom-disable-animation"><header class="Header-appBar"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root Header-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><h2 class="Typography-root Typography-title Header-title"><div class="Header-hideSmDown"><div class="Header-titleSubtitleContainer"><div class="Header-titleFundraiserContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LESSWRONG</a></div></div></div><div class="Header-hideMdUp Header-titleFundraiserContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LW</a></div></h2><div class="ActiveDialogues-root"></div><div class="Header-rightHeaderItems"><div class="SearchBar-root"><div class="SearchBar-rootChild"><div class="SearchBar-searchInputArea"><div><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root SearchBar-searchIconButton" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root SearchBar-searchIcon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><div></div></div></div></div><div><div class="UsersMenu-root"><a href="https://www.lesswrong.com/users/ms-haze"><button tabindex="0" class="MuiButtonBase-root MuiButton-root UsersMenu-userButtonRoot MuiButton-text MuiButton-flat" type="button" data-testid="users-menu"><span class="MuiButton-label"><span class="UsersMenu-userButtonContents">Ms. Haze</span></span><span class="MuiTouchRipple-root"></span></button></a></div></div><div class="KarmaChangeNotifier-root"><div><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root KarmaChangeNotifier-karmaNotifierButton" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root KarmaChangeNotifier-starIcon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M22 9.24l-7.19-.62L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21 12 17.27 18.18 21l-1.63-7.03L22 9.24zM12 15.4l-3.76 2.27 1-4.28-3.32-2.88 4.38-.38L12 6.1l1.71 4.04 4.38.38-3.32 2.88 1 4.28L12 15.4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div></div><span class="MuiBadge-root NotificationsMenuButton-badgeContainer"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root NotificationsMenuButton-buttonClosed" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 22c1.1 0 2-.9 2-2h-4c0 1.1.9 2 2 2zm6-6v-5c0-3.07-1.63-5.64-4.5-6.32V4c0-.83-.67-1.5-1.5-1.5s-1.5.67-1.5 1.5v.68C7.64 5.36 6 7.92 6 11v5l-2 2v1h16v-1l-2-2zm-2 1H8v-6c0-2.48 1.51-4.5 4-4.5s4 2.02 4 4.5v6z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><span class="MuiBadge-badge NotificationsMenuButton-badge NotificationsMenuButton-badgeBackground"></span></span></div></div></header><div class="jss101 jss102" style="width: 20px;"></div></div></div><div class="NotificationsMenu-root"></div></div><div class=""><div class="Layout-searchResultsArea"></div><div class="Layout-main"><div class="flash-messages FlashMessages-root"></div><div class="page users-profile UsersProfile-profilePage"><div class="SingleColumnSection-root"><div class="UsersProfile-usernameTitle">Eliezer Yudkowsky</div><aside class="Typography-root Typography-body2 UsersProfile-userInfo"><div class="UsersProfile-meta"><span class="UsersProfile-userMetaInfo" title="148674 karma"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">148674</span></span><span class="UsersProfile-userMetaInfo" title="1884 karma on alignmentforum.org"><span class="OmegaIcon-root UsersProfile-icon UsersProfile-specificalz">Ω</span><span class="Typography-root Typography-body2 MetaInfo-root">1884</span></span><span class="UsersProfile-userMetaInfo" title="951 posts"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M14 2H6c-1.1 0-1.99.9-1.99 2L4 20c0 1.1.89 2 1.99 2H18c1.1 0 2-.9 2-2V8l-6-6zm2 16H8v-2h8v2zm0-4H8v-2h8v2zm-3-5V3.5L18.5 9H13z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">951</span></span><span class="UsersProfile-userMetaInfo" title="7677 comments"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M20 2H4c-1.1 0-1.99.9-1.99 2L2 22l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-2 12H6v-2h12v2zm0-3H6V9h12v2zm0-3H6V6h12v2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">7677</span></span><span class="UsersProfile-userMetaInfo" title="3803 wikitag edits"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04c.39-.39.39-1.02 0-1.41l-2.34-2.34a.9959.9959 0 0 0-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">3803</span></span></div><div><a>Message</a></div><div class="UsersProfile-subscribeButton"><a>Dialogue</a></div><div class="UsersProfile-subscribeButton"><div><div><a>Subscribe</a></div></div></div></aside></div><div class="SingleColumnSection-root"></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 id="sequences" class="Typography-root Typography-display1 SectionTitle-title">Sequences</h1><div class="SectionTitle-children"></div></div><div><div class="SequencesGrid-grid"><div class="SequencesGrid-gridContent"><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/W2fkmatEzyrmbbrDt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/ds26mimg1uvv82k5d63v.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Metaethics</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ePDpMhJoKCff6qnvh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/e0chotk2uafu1ic9kvny.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Quantum Physics</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/d3WgHDBAPYYScp5Em"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/ncfkdhspgrfhhjpbisaj.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Fun Theory</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/AmFb5xWbPWWQyQ244"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/nczv7w6hr10v4rumtusv.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Ethical Injunctions</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/LAop879LCQWrM5YnE"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/vnyzzznenju0hzdv6pqb.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">The Bayesian Conspiracy</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/qWoFR4ytMpQ5vw3FT"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/sio9b8jw1apesuispocg.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Three Worlds Collide</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/SqFbMbtxGybdS2gRs"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/i2ogsvmipbdolntkew4a.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Highly Advanced Epistemology 101 for Beginners</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/oLGCcbnvabyibnG9d"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/vbhv0s06jdmonk6garvf.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Inadequate Equilibria</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#pvim9PZJ6qHRTMqD3"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/yd3bzuj2zhnafkh9uavf.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">The Craft and the Community</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#3szfzHZr7EYGSWt92"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/bdj5ovunbpuswk1eipt9.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Challenging the Difficult</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#SXurf2mWFw8LX2mkG"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/nggx4r2f8zoyehbcqcia.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Yudkowsky's Coming of Age</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#waF2Pomid7YHjfEDt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/f5njri3ukki9fltibb8y.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Quantified Humanism</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#9bvAELWc8y2gYjRav"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/i9c5eiacx4ldzaezqmfn.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Value Theory</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#fqh9TLuoquxpducDb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/mm0ivmd2a1eizxatc0uz.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Fake Preferences</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#fxynfGCSHpY4FmBZy"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/qynhzqukuonidzl0c0kp.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Science and Rationality</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#Kqs6GR7F5xziuSyGZ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/wncutymtkeulpld7cbrm.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Quantum Physics and Many Worlds</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#FqgKAHZAiZn9JAjDo"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/fowl7xmsw7pq08qcyvtt.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Physicalism 201</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#6BFkmEgre7uwhDxDR"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/awsd65brbw8jl3p3txx5.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Joy in the Merely Real</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#p3TndjYbdYaiWwm9x"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/tggcycp4xgcp5awosmta.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Reductionism 101</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#oFePMp9rKftEeZDDr"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/ocof6os9fv9dfgiuyr36.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Lawful Truth</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#SGB7Y5WERh4skwtnb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/bbhnqs3en78i274e5fzx.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">A Human's Guide to Words</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#3HyeNiEpvbQQaqeoH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/cl2cyyzxkous0oy9uir6.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Fragile Purposes</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#MH2b8NfWv22dBtrs8"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/zdvived9irhffc6rnz1e.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">The Simple Math of Evolution</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#5bZZZJ5psXrrD5BGb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/lzvmuizelhfnz4vflmqk.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Letting Go</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#M3TJ2fTCzoQq66NBJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/kfdosmh7m4gptzsdcl5e.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Death Spirals</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#pmHZDpak4NeRLLLCw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/a1qshk4kjvlctafdi5rw.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Seeing with Fresh Eyes</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#qqFS6Kw5fmPyzkLby"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/xl51zsusg8iahec404fm.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Against Doublethink</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#GSqFqc646rsRd2oyz"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/hltj7lnof0lzwlgbeidd.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Against Rationalization</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#3ELrPerFTSo75WnrH"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/h6vrwdypijqgsop7xwa0.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Politics and Rationality</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#FrqfoG3LJeCZs96Ym"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/khst2yhr0iyt9vaq18ee.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Overly Convenient Excuses</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#5uZQHpecjn7955faL"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/qxrtikxmqtdgdrv8laod.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Mysterious Answers</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#zpCiuR4T343j9WkcK"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/ff6hxn6crxxxzfrtnciq.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Noticing Confusion</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#7gRSERQZbqTuLX5re"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/vx5txwdtbsejuj6tbf4e.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Fake Beliefs</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/rationality#5g5TkQTe9rmPS5vvM"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/wwkkaskmbcajjogyv1hu.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Predictably Wrong</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#SyvHDEqbCmB3va7HJ"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/cbtybpfyrqqqf7jciw1u.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">4: HJG and the Phoenix's Call</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#2jyo5h7xkyPiMD3AA"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/fecn7ysevbxwo1yfkiat.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">5: HJPEV and the Last Enemy</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#fhRcCn2AcDCYW8PHB"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/xsuilhn2dwx0eoxvrzoa.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">3: HJPEV and the Shadows of Death</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#EBuZhwCrYuJGp7ax4"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/tevykiajl66u3wfuaeae.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">2: HJPEV and the Professor's Games</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#u7ciTcKteyx2hqdBh"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/r6niwnpcmu9r4ztfbl6n.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">6: HJPEV and the Philosopher's Stone</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/hpmor#PtgH6ALi5CoJnPmGS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="eliezer_files/i9dkgkhw14vwar63i4xn.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">The Methods of Rationality</div></div></div></span></div></div></div></div></div><div class="SingleColumnSection-root"><div class="UsersProfile-postsTitle"><div class="SectionTitle-root"><h1 id="posts" class="Typography-root Typography-display1 SectionTitle-title">Posts</h1><div class="SectionTitle-children"><span class="SettingsButton-iconWithLabelGroup"><svg class="MuiSvgIcon-root SettingsButton-icon SettingsButton-iconWithLabel ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path transform="scale(1.2, 1.2)" fill="none" d="M0 0h20v20H0V0z"></path><path transform="scale(1.2, 1.2)" d="M15.95 10.78c.03-.25.05-.51.05-.78s-.02-.53-.06-.78l1.69-1.32c.15-.12.19-.34.1-.51l-1.6-2.77c-.1-.18-.31-.24-.49-.18l-1.99.8c-.42-.32-.86-.58-1.35-.78L12 2.34c-.03-.2-.2-.34-.4-.34H8.4c-.2 0-.36.14-.39.34l-.3 2.12c-.49.2-.94.47-1.35.78l-1.99-.8c-.18-.07-.39 0-.49.18l-1.6 2.77c-.1.18-.06.39.1.51l1.69 1.32c-.04.25-.07.52-.07.78s.02.53.06.78L2.37 12.1c-.15.12-.19.34-.1.51l1.6 2.77c.1.18.31.24.49.18l1.99-.8c.42.32.86.58 1.35.78l.3 2.12c.04.2.2.34.4.34h3.2c.2 0 .37-.14.39-.34l.3-2.12c.49-.2.94-.47 1.35-.78l1.99.8c.18.07.39 0 .49-.18l1.6-2.77c.1-.18.06-.39-.1-.51l-1.67-1.32zM10 13c-1.65 0-3-1.35-3-3s1.35-3 3-3 3 1.35 3 3-1.35 3-3 3z"></path></svg><span class="SettingsButton-label">Sorted by New</span></span></div></div></div><div class="ProfileShortform-root"><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">14</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/KYuR2HcWPEmXZqMZs/eliezer-yudkowsky-s-shortform"><span><span class="PostsTitle-sticky"><svg class="PostsTitle-stickyIcon ForumIcon-root" fill="currentColor" height="15" viewBox="0 0 10 15" width="10" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M 0.62965 7.43734C 0.504915 7.43692 0.383097 7.40021 0.279548 7.33183C 0.175999 7.26345 0.0953529 7.16646 0.0477722 7.05309C 0.000191541 6.93972 -0.0121941 6.81504 0.0121763 6.69475C 0.0365467 6.57447 0.0965826 6.46397 0.184718 6.37719L 1.77312 4.81248L 1.77312 1.75013L 1.32819 1.75013C 1.20359 1.75073 1.08025 1.72558 0.966163 1.67633C 0.852072 1.62708 0.749771 1.55483 0.665885 1.46423C 0.581999 1.37364 0.518398 1.26674 0.479198 1.15045C 0.439999 1.03415 0.426075 0.91106 0.438329 0.789139C 0.466198 0.56792 0.576593 0.364748 0.748122 0.218993C 0.919651 0.0732386 1.1401 -0.00472087 1.36675 0.000221379L 8.00217 0.000221379C 8.12677 -0.000372526 8.25011 0.0247692 8.3642 0.0740189C 8.47829 0.123269 8.58059 0.195528 8.66448 0.286119C 8.74837 0.37671 8.81197 0.483614 8.85117 0.599907C 8.89037 0.716201 8.90429 0.839293 8.89204 0.961214C 8.86417 1.18243 8.75377 1.38561 8.58224 1.53136C 8.41071 1.67711 8.19026 1.75507 7.96361 1.75013L 7.55724 1.75013L 7.55724 4.81248L 9.14861 6.37719C 9.23675 6.46397 9.29679 6.57447 9.32116 6.69475C 9.34553 6.81504 9.33314 6.93972 9.28556 7.05309C 9.23798 7.16646 9.15733 7.26345 9.05378 7.33183C 8.95023 7.40021 8.82842 7.43692 8.70368 7.43734L 0.62965 7.43734ZM 4.16834 13.562C 4.18174 13.6824 4.23985 13.7937 4.33154 13.8745C 4.42323 13.9553 4.54204 14 4.66518 14C 4.78833 14 4.90713 13.9553 4.99882 13.8745C 5.09051 13.7937 5.14863 13.6824 5.16202 13.562L 5.73747 8.74977L 3.5929 8.74977L 4.16834 13.562Z"></path></svg></span>Eliezer Yudkowsky's Shortform</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/KYuR2HcWPEmXZqMZs/eliezer-yudkowsky-s-shortform"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-04-01T22:43:50.929Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/KYuR2HcWPEmXZqMZs/eliezer-yudkowsky-s-shortform"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">0</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div></div><div class=""><div class="PostsList2-postsBoxShadow"><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">205</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/F8sfrbPjCQj4KwJqn/the-sun-is-big-but-superintelligences-will-not-spare-earth-a"><span>The Sun is big, but superintelligences will not spare Earth a little sunlight</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2024-09-23T03:39:16.243Z">7mo</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">142</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">318</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/fPvssZk3AoDzXwfwJ/universal-basic-income-and-poverty"><span>Universal Basic Income and Poverty</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2024-07-26T07:23:50.151Z">8mo</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">139</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma LWPostsItem-karmaPredictedReviewWinner"><span class="LWTooltip-root">171</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/LvKDMWQ3yLG9R3gHw/empiricism-as-anti-epistemology"><span>'Empiricism!' as Anti-Epistemology</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2024-03-14T02:02:59.723Z">1y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">90</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">206</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/EzSH9698DhBsXAcYY/my-current-lk99-questions"><span>My current LK99 questions</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="CuratedIcon-postIcon"><span class="LWTooltip-root"><a href="https://www.lesswrong.com/recommendations"><svg class="MuiSvgIcon-root CuratedIcon-curatedIcon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-08-13T04:07:43.668Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="CuratedIcon-postIcon"><span class="LWTooltip-root"><a href="https://www.lesswrong.com/recommendations"><svg class="MuiSvgIcon-root CuratedIcon-curatedIcon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">38</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">416</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/nH4c3Q9t9F3nJ7y8W/gpts-are-predictors-not-imitators"><span>GPTs are Predictors, not Imitators</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/nH4c3Q9t9F3nJ7y8W/gpts-are-predictors-not-imitators"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-04-08T19:59:13.601Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/nH4c3Q9t9F3nJ7y8W/gpts-are-predictors-not-imitators"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">100</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">267</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/oM9pEezyCb4dCsuKq/pausing-ai-developments-isn-t-enough-we-need-to-shut-it-all-1"><span>Pausing AI Developments Isn't Enough. We Need to Shut it All Down</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-04-08T00:36:47.702Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">44</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">14</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/KYuR2HcWPEmXZqMZs/eliezer-yudkowsky-s-shortform"><span>Eliezer Yudkowsky's Shortform</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/KYuR2HcWPEmXZqMZs/eliezer-yudkowsky-s-shortform"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-04-01T22:43:50.929Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/KYuR2HcWPEmXZqMZs/eliezer-yudkowsky-s-shortform"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">0</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">120</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/uNepkB5EqETC8b9C2/manifold-if-okay-agi-why"><span>Manifold:  If okay AGI, why?</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-03-25T22:43:53.820Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://manifold.markets/EliezerYudkowsky/if-artificial-general-intelligence?r=RWxpZXplcll1ZGtvd3NreQ"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">37</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">178</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/rwkkcgSpnAyE8oNo3/alexander-and-yudkowsky-on-agi-goals"><span>Alexander and Yudkowsky on AGI goals</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/rwkkcgSpnAyE8oNo3/alexander-and-yudkowsky-on-agi-goals"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-01-24T21:09:16.938Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/rwkkcgSpnAyE8oNo3/alexander-and-yudkowsky-on-agi-goals"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">53</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">302</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/tD9zEiHfkvakpnNam/a-challenge-for-agi-organizations-and-a-challenge-for-1"><span>A challenge for AGI organizations, and a challenge for readers</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/tD9zEiHfkvakpnNam/a-challenge-for-agi-organizations-and-a-challenge-for-1"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2022-12-01T23:11:44.279Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-tertiaryRow"><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/tD9zEiHfkvakpnNam/a-challenge-for-agi-organizations-and-a-challenge-for-1"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">33</div></div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div></div></div></div><aside class="Typography-root Typography-body2 SectionFooter-root"><a class="LoadMore-root LoadMore-sectionFooterStyles" href="#">Load More</a></aside></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 id="wikitag-contributions" class="Typography-root Typography-display1 SectionTitle-title">Wikitag Contributions</h1><div class="SectionTitle-children"></div></div><div class="TagEditsByUser-root"><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/w/multiple-stage-fallacy">Multiple stage fallacy</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 1y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root"><span class="ChangeMetricsDisplay-charsAdded">(+16)</span></span></div></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/w/orthogonality-thesis">Orthogonality Thesis</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 1y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root">(<span class="ChangeMetricsDisplay-charsAdded">+28</span>/<span class="ChangeMetricsDisplay-charsRemoved">-17</span>)</span></div></div></div></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root UsersProfile-commentSorting"><h1 class="Typography-root Typography-display1 SectionTitle-title"><a href="https://www.lesswrong.com/users/eliezer_yudkowsky/replies">Comments</a></h1><div class="SectionTitle-children">Sorted by <div class="InlineSelect-root"><a class="InlineSelect-link">Newest</a></div></div></div><div class="RecentComments-root"><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="aYyrcQgBi69XCFFjH"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/?commentId=aYyrcQgBi69XCFFjH">How might we safely pass the buck to AI?</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/how-might-we-safely-pass-the-buck-to-ai?commentId=aYyrcQgBi69XCFFjH"><span class="LWTooltip-root"><time datetime="2025-02-20T07:29:53.726Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">23</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>11</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Cool.
 &nbsp;What's the actual plan and why should I expect it not to create 
machine Carissa Sevar? &nbsp;I agree that the Textbook From The Future 
Containing All The Simple Tricks That Actually Work Robustly enables the
 construction of such an AI, but also at that point you don't need it.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node af CommentFrame-answerLeafComment" id="WpfHQ7WCPvKtDZbG6"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/?commentId=WpfHQ7WCPvKtDZbG6">How might we safely pass the buck to AI?</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/how-might-we-safely-pass-the-buck-to-ai?commentId=WpfHQ7WCPvKtDZbG6"><span class="LWTooltip-root"><time datetime="2025-02-20T07:24:25.804Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="LWTooltip-root"><span class="OverallVoteAxis-secondaryScore"><span class="OverallVoteAxis-secondarySymbol">Ω</span><span class="OverallVoteAxis-secondaryScoreNumber">4</span></span></span><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">10</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>-4</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>So
 if it's difficult to get amazing trustworthy work out of a machine 
actress playing an Eliezer-level intelligence doing a thousand years 
worth of thinking, your proposal to have AIs do our AI alignment 
homework fails on the first step, it sounds like?</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node af CommentFrame-answerLeafComment" id="DmwDgi2uQf6wAFRNw"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/?commentId=DmwDgi2uQf6wAFRNw">How might we safely pass the buck to AI?</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/how-might-we-safely-pass-the-buck-to-ai?commentId=DmwDgi2uQf6wAFRNw"><span class="LWTooltip-root"><time datetime="2025-02-20T03:03:34.816Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="LWTooltip-root"><span class="OverallVoteAxis-secondaryScore"><span class="OverallVoteAxis-secondarySymbol">Ω</span><span class="OverallVoteAxis-secondaryScoreNumber">8</span></span></span><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">20</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>5</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>So
 the "IQ 60 people controlling IQ 80 people controlling IQ 100 people 
controlling IQ 120 people controlling IQ 140 people until they're 
genuinely in charge and genuinely getting honest reports and genuinely 
getting great results in their control of a government" theory of 
alignment?</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node af CommentFrame-answerLeafComment" id="LrGMuJKZztjhp6yMA"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/?commentId=LrGMuJKZztjhp6yMA">How might we safely pass the buck to AI?</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/how-might-we-safely-pass-the-buck-to-ai?commentId=LrGMuJKZztjhp6yMA"><span class="LWTooltip-root"><time datetime="2025-02-20T00:48:46.403Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="LWTooltip-root"><span class="OverallVoteAxis-secondaryScore"><span class="OverallVoteAxis-secondarySymbol">Ω</span><span class="OverallVoteAxis-secondaryScoreNumber">14</span></span></span><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">29</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>16</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>I
 don't think you can train an actress to simulate me, successfully, 
without her going dangerous. &nbsp;I think that's over the threshold for
 where a mind starts reflecting on itself and pulling itself together.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="6tbCLyALZoE58qidy"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/?commentId=6tbCLyALZoE58qidy">How might we safely pass the buck to AI?</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/how-might-we-safely-pass-the-buck-to-ai?commentId=6tbCLyALZoE58qidy"><span class="LWTooltip-root"><time datetime="2025-02-20T00:46:48.319Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">21</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>9</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>I'm
 not saying that it's against thermodynamics to get behaviors you don't 
know how to verify. &nbsp;I'm asking what's the plan for getting them.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="fxnhSv3n4aRjPQDwQ"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/DfrSZaf3JC8vJdbZL/?commentId=fxnhSv3n4aRjPQDwQ">How to Make Superbabies</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/DfrSZaf3JC8vJdbZL/how-to-make-superbabies?commentId=fxnhSv3n4aRjPQDwQ"><span class="LWTooltip-root"><time datetime="2025-02-20T00:45:46.116Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">135</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>99</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>One of the most important projects in the world. &nbsp;Somebody should fund it.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class="NamesAttachedReactionsCommentBottom-footerReactions"><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/check.svg" style="filter: opacity(0.4) saturate(0.6); transform: scale(1) translate(0px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">12</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/x.svg" style="filter: opacity(0.4) saturate(0.6); transform: scale(1) translate(0px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">3</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span></span><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node af CommentFrame-answerLeafComment" id="xYaTBEKJaLDQQL8iT"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/?commentId=xYaTBEKJaLDQQL8iT">How might we safely pass the buck to AI?</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/TTFsKxQThrqgWeXYJ/how-might-we-safely-pass-the-buck-to-ai?commentId=xYaTBEKJaLDQQL8iT"><span class="LWTooltip-root"><time datetime="2025-02-19T21:57:29.778Z">2mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="LWTooltip-root"><span class="OverallVoteAxis-secondaryScore"><span class="OverallVoteAxis-secondarySymbol">Ω</span><span class="OverallVoteAxis-secondaryScoreNumber">27</span></span></span><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">97</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>58</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Can
 you tl;dr how you go from "humans cannot tell which alignment arguments
 are good or bad" to "we justifiably trust the AI to report honest good 
alignment takes"? &nbsp;Like, not with a very large diagram full of 
complicated parts such that it's hard to spot where you've messed up. 
&nbsp;Just whatever simple principle you think lets you bypass GIGO.</p><p>Eg, suppose that in 2020 the Open Philanthropy Foundation would like to train an AI such that the AI would honestly say if <span><span class="InlineReactHoverableHighlight-highlight"><span>the OpenPhil doctrine of "AGI in 2050"</span></span></span> was based on groundless thinking ultimately driven by social conformity. &nbsp;<span><span class="InlineReactHoverableHighlight-highlight"><span>However,
 OpenPhil is not allowed to train their AI based on MIRI. &nbsp;They 
have to train their AI entirely on OpenPhil-produced content.</span></span></span>
 &nbsp;How does OpenPhil bootstrap an AI which will say, "Guys, you have
 no idea when AI shows up but it's probably not that far and you sure 
can't rely on it"? &nbsp;Assume that whenever OpenPhil tries to run an 
essay contest for saying what they're getting wrong, their panel of 
judges ends up awarding the prize to somebody reassuringly saying that 
AI risk is an even smaller deal than OpenPhil thinks. &nbsp;How does 
OpenPhil bootstrap from that pattern of thumbs-up/thumbs-down to an AI 
that actually has better-than-OpenPhil alignment takes?</p><p>Broadly 
speaking, the standard ML paradigm lets you bootstrap somewhat from "I 
can verify whether this problem was solved" to "I can train a generator 
to solve this problem". &nbsp;This applies as much to MIRI as OpenPhil. 
&nbsp;MIRI would also need some nontrivial secret amazing clever trick 
to gradient-descend an AI that gave us great alignment takes, instead of
 seeking out the flaws in our own verifier and exploiting those.</p><p>What's
 the trick? &nbsp;My basic guess, when I see some very long complicated 
paper that doesn't explain the key problem and key solution up front, is
 that you've done the equivalent of an inventor building a sufficiently 
complicated perpetual motion machine that their mental model of it no 
longer tracks how conservation laws apply. &nbsp;(As opposed to the 
simpler error of their explicitly believing that one particular step or 
motion locally violates a conservation law.) &nbsp;But if you've got a 
directly explainable trick for how you get great suggestions you can't 
verify, go for it.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class="NamesAttachedReactionsCommentBottom-footerReactions"><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction NamesAttachedReactionsCommentBottom-hasQuotes"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/noun-soldier-5069240.svg" style="filter: opacity(0.7) saturate(0.6); transform: scale(1.2) translate(0px, 1px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">1</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction NamesAttachedReactionsCommentBottom-hasQuotes"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/noun-misunderstanding-4936548-updated.svg" style="filter: opacity(0.5) saturate(0.6); transform: scale(1.3) translate(1px, 1px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">1</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span></span><span class=""><svg class="MuiSvgIcon-root NamesAttachedReactionsCommentBottom-overviewButton" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M4 10.5c-.83 0-1.5.67-1.5 1.5s.67 1.5 1.5 1.5 1.5-.67 1.5-1.5-.67-1.5-1.5-1.5zm0-6c-.83 0-1.5.67-1.5 1.5S3.17 7.5 4 7.5 5.5 6.83 5.5 6 4.83 4.5 4 4.5zm0 12c-.83 0-1.5.68-1.5 1.5s.68 1.5 1.5 1.5 1.5-.68 1.5-1.5-.67-1.5-1.5-1.5zM7 19h14v-2H7v2zm0-6h14v-2H7v2zm0-8v2h14V5H7z"></path><path fill="none" d="M0 0h24v24H0V0z"></path></svg></span><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="uuvZEHkdrMggPywuQ"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/oM9pEezyCb4dCsuKq/?commentId=uuvZEHkdrMggPywuQ">Pausing AI Developments Isn't Enough. We Need to Shut it All Down</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/oM9pEezyCb4dCsuKq/pausing-ai-developments-isn-t-enough-we-need-to-shut-it-all-1?commentId=uuvZEHkdrMggPywuQ"><span class="LWTooltip-root"><time datetime="2025-01-21T22:52:38.822Z">3mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">25</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>6</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p><span><span class="InlineReactHoverableHighlight-highlight"><span>You seem confused about my exact past position.</span></span></span> &nbsp;<span><span class="InlineReactHoverableHighlight-highlight"><span>I was arguing against EAs who were like, "We'll solve AGI with policy, therefore no doom."</span></span></span> &nbsp;<span><span class="InlineReactHoverableHighlight-highlight"><span>I am not presently a great optimist about the likelihood of policy being an easy solution.</span></span></span> &nbsp;There is just nothing else left.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class="NamesAttachedReactionsCommentBottom-footerReactions"><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction NamesAttachedReactionsCommentBottom-hasQuotes"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/check.svg" style="filter: opacity(0.4) saturate(0.6); transform: scale(1) translate(0px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">1</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction NamesAttachedReactionsCommentBottom-hasQuotes"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/x.svg" style="filter: opacity(0.4) saturate(0.6); transform: scale(1) translate(0px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">1</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction NamesAttachedReactionsCommentBottom-hasQuotes"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/noun-chat-1459491.svg" style="filter: opacity(0.4) saturate(0.6); transform: scale(1) translate(0px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">1</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span><span><span><span class="NamesAttachedReactionsCommentBottom-footerReaction"><span><span class="ReactionIcon-invertIfDarkMode"><img src="eliezer_files/lightbulb.svg" style="filter: opacity(0.4) saturate(0.6); transform: scale(1) translate(0px); width: 18px; height: 18px;" class="ReactionIcon-reactionSvg"></span></span><span class="NamesAttachedReactionsCommentBottom-reactionCount">1</span></span><span class="NamesAttachedReactionsCommentBottom-footerReactionSpacer"></span></span></span></span><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="89w5ypYLS4q8wJifr"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/nH4c3Q9t9F3nJ7y8W/?commentId=89w5ypYLS4q8wJifr">GPTs are Predictors, not Imitators</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/nH4c3Q9t9F3nJ7y8W/gpts-are-predictors-not-imitators?commentId=89w5ypYLS4q8wJifr"><span class="LWTooltip-root"><time datetime="2024-12-09T22:07:31.265Z">4mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">6</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>0</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>(I affirm this as my intended reading.)</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="wtExPJXgfo2QSq3gk"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/4ARaTpNX62uaL86j6/?commentId=wtExPJXgfo2QSq3gk">The Hidden Complexity of Wishes</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/eliezer_yudkowsky">Eliezer Yudkowsky</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/4ARaTpNX62uaL86j6/the-hidden-complexity-of-wishes?commentId=wtExPJXgfo2QSq3gk"><span class="LWTooltip-root"><time datetime="2024-12-09T22:06:03.442Z">4mo</time></span></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-verticalArrows"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-down VoteArrowIconSolid-downLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">6</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIconSolid-root VoteArrowIconSolid-up VoteArrowIconSolid-upLarge" type="button"><span class="MuiIconButton-label"><svg width="9" height="6" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" style="color: inherit; height: 14px; width: 14px;" class="VoteArrowIconSolid-smallArrowLarge"><path d="M4.11427 0.967669C4.31426 0.725192 4.68574 0.725192 4.88573 0.967669L8.15534 4.93186C8.42431 5.25798 8.19234 5.75 7.76961 5.75H1.23039C0.807659 5.75 0.575686 5.25798 0.844665 4.93186L4.11427 0.967669Z"></path></svg><svg width="9" height="9" viewBox="0 0 9 6" fill="currentColor" xmlns="http://www.w3.org/2000/svg" class="VoteArrowIconSolid-bigArrowLarge VoteArrowIconSolid-bigArrowSolidLarge"><path d="m4.499308,0.51796875 c-0.142868,0 -0.284967,0.059816 -0.384961,0.1810547 L0.84481497,4.6646484 c-0.268978,0.32612 -0.03777,0.8173828 0.38496103,0.8173828 H1.999698 L4.114347,2.9173828 c0.199989,-0.242477 0.571689,-0.242477 0.771679,0 l2.114649,2.5646484 h0.768164 c0.42273,0 0.65569,-0.4912628 0.386719,-0.8173828 L4.886026,0.69902345 C4.786031,0.57778495 4.642175,0.51796875 4.499308,0.51796875 Z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-clear ForumIcon-root" style="color: inherit;"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigClear ForumIcon-root"><path id="Union" d="M2.28033 1.21967C1.98744 0.926777 1.51256 0.926777 1.21967 1.21967C0.926777 1.51256 0.926777 1.98744 1.21967 2.28033L4.93934 6L1.21967 9.71967C0.926777 10.0126 0.926777 10.4874 1.21967 10.7803C1.51256 11.0732 1.98744 11.0732 2.28033 10.7803L6 7.06066L9.71967 10.7803C10.0126 11.0732 10.4874 11.0732 10.7803 10.7803C11.0732 10.4874 11.0732 10.0126 10.7803 9.71967L7.06066 6L10.7803 2.28033C11.0732 1.98744 11.0732 1.51256 10.7803 1.21967C10.4874 0.926777 10.0126 0.926777 9.71967 1.21967L6 4.93934L2.28033 1.21967Z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" version="1.1" id="svg1" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Union-1" d="m 4.9274384,6.5091097 1.7854422,1.7854272 c 0.140606,0.140592 0.36851,0.140592 0.509102,0 0.140592,-0.1405917 0.140592,-0.3684956 0,-0.5091025 L 5.4365554,5.9999929 7.2219826,4.2145513 c 0.140592,-0.1405872 0.140592,-0.3685296 0,-0.5091168 -0.140592,-0.1405886 -0.368496,-0.1405886 -0.509102,0 L 5.0451854,5.2744454 c 0,0 -0.772678,0.5401148 -0.117747,1.2346643 z" fill="currentColor" stroke="currentColor" stroke-width="0.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span>1</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><div class="VoteAgreementIcon-iconsContainer"><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-check ForumIcon-root" style="color: inherit;"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-bigCheck ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg width="12" height="12" viewBox="0 0 12 12" fill="none" xmlns="http://www.w3.org/2000/svg" class="VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-hideIcon ForumIcon-root"><path id="Vector (Stroke)" d="M11.5419 2.12049C11.7994 1.762 11.737 1.24987 11.3935 0.972329C11.0428 0.688906 10.5419 0.764291 10.2795 1.12957L4.54399 9.11368L1.65149 6.04587C1.34241 5.71806 0.836155 5.71806 0.52708 6.04587C0.224307 6.36699 0.224307 6.88303 0.527079 7.20416L4.06278 10.9541C4.22277 11.1238 4.44712 11.2146 4.67877 11.1981C4.91025 11.1816 5.11998 11.06 5.25616 10.8705L11.5419 2.12049Z" fill="currentColor" stroke="currentColor" stroke-width="0.4" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></span></button></span></span></span><span class="CommentsItemMeta-rightSection"><span class="CommentsItemMeta-menu"><svg class="MuiSvgIcon-root CommentsMenu-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></span></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>It
 certainly bears upon AI, but it bears that way by making a point about 
the complexity of a task rather than talking about an intelligent 
mechanism which is purportedly aligned on that task. &nbsp;It does this 
by talking about an unintelligent mechanism, which is meant to be a way 
of talking about the task itself rather than any particular machine for 
doing it.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><a class="LoadMore-root" href="#">Load More</a></div></div><div class="SingleColumnSection-root ReportUserButton-reportUserSection"><button class="ReportUserButton-reportUserBtn">Report user</button></div></div><div class="Footer-root"></div></div><div class="LWBackgroundImage-root"></div></div></div></div>

<script>window.ssrRenderedAt = "2025-04-10T03:40:41.382Z"</script>
<script>window.ssrMetadata = {"renderedAt":"2025-04-10T03:40:41.382Z","cacheFriendly":false,"timezone":"America/Toronto"}</script>
<script>window.__APOLLO_STATE__ = {"Revision:j2BCQ3AWkDhGjGst4_biography":{"_id":"j2BCQ3AWkDhGjGst4_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2025-01-24T20:20:07.307Z","userId":"j2BCQ3AWkDhGjGst4","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Revision:j2BCQ3AWkDhGjGst4_moderationGuidelines":{"_id":"j2BCQ3AWkDhGjGst4_moderationGuidelines","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2025-01-24T20:20:07.238Z","userId":"j2BCQ3AWkDhGjGst4","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"User:j2BCQ3AWkDhGjGst4":{"_id":"j2BCQ3AWkDhGjGst4","__typename":"User","beta":null,"email":"als.hate.09@gmail.com","services":{"resume":{},"password":{}},"acceptedTos":false,"pageUrl":"https://www.lesswrong.com/users/ms-haze","banned":null,"isReviewed":true,"nullifyVotes":null,"hideIntercom":false,"hideNavigationSidebar":false,"hideCommunitySection":false,"expandedFrontpageSections":null,"hidePostsRecommendations":false,"currentFrontpageFilter":null,"frontpageSelectedTab":null,"frontpageFilterSettings":{"tags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10}],"personalBlog":"Default"},"hideFrontpageFilterSettingsDesktop":false,"allPostsTimeframe":null,"allPostsSorting":null,"allPostsFilter":null,"allPostsShowLowKarma":null,"allPostsIncludeEvents":null,"allPostsHideCommunity":null,"allPostsOpenSettings":null,"draftsListSorting":null,"draftsListShowArchived":null,"draftsListShowShared":null,"lastNotificationsCheck":"2025-04-06T22:40:35.070Z","bannedUserIds":null,"bannedPersonalUserIds":null,"moderationStyle":null,"noKibitz":null,"showHideKarmaOption":null,"markDownPostEditor":true,"hideElicitPredictions":true,"hideAFNonMemberInitialWarning":false,"commentSorting":null,"location":null,"googleLocation":null,"mongoLocation":null,"mapLocation":null,"mapLocationSet":false,"mapMarkerText":null,"htmlMapMarkerText":"","nearbyEventsNotifications":false,"nearbyEventsNotificationsLocation":null,"nearbyEventsNotificationsRadius":null,"nearbyPeopleNotificationThreshold":null,"hideFrontpageMap":null,"emailSubscribedToCurated":null,"subscribedToDigest":false,"unsubscribeFromAll":null,"emails":[{"address":"als.hate.09@gmail.com","verified":true}],"whenConfirmationEmailSent":"2025-01-24T20:19:04.640Z","hideSubscribePoke":false,"hideMeetupsPoke":false,"hideHomeRHS":false,"noCollapseCommentsFrontpage":false,"noCollapseCommentsPosts":true,"noSingleLineComments":true,"showCommunityInRecentDiscussion":false,"karmaChangeNotifierSettings":{"dayOfWeekGMT":"Saturday","timeOfDayGMT":11,"updateFrequency":"daily"},"karmaChangeLastOpened":"2025-04-01T11:00:00.000Z","shortformFeedId":"uvA6dWJ4dEPoCoLzw","viewUnreviewedComments":null,"recommendationSettings":null,"theme":{"name":"default"},"bookmarkedPostsMetadata":[{"postId":"rz73eva3jv267Hy7B"},{"postId":"kcoqwHscvQTx4xgwa"}],"hiddenPostsMetadata":[],"auto_subscribe_to_my_posts":true,"auto_subscribe_to_my_comments":true,"autoSubscribeAsOrganizer":true,"noExpandUnreadCommentsReview":false,"reviewVotesQuadratic":null,"reviewVotesQuadratic2019":null,"reviewVotesQuadratic2020":null,"hideTaggingProgressBar":null,"hideFrontpageBookAd":true,"hideFrontpageBook2019Ad":null,"abTestKey":"j2BCQ3AWkDhGjGst4","abTestOverrides":null,"sortDraftsBy":null,"reactPaletteStyle":"listView","petrovPressedButtonDate":"2024-09-25T15:56:20.671Z","petrovLaunchCodeDate":null,"petrovOptOut":false,"lastUsedTimezone":"America/Toronto","acknowledgedNewUserGuidelines":null,"notificationSubforumUnread":{"email":{"enabled":false,"dayOfWeekGMT":"Monday","timeOfDayGMT":12,"batchingFrequency":"realtime"},"onsite":{"enabled":true,"dayOfWeekGMT":"Monday","timeOfDayGMT":12,"batchingFrequency":"daily"}},"subforumPreferredLayout":null,"hideJobAdUntil":null,"criticismTipsDismissed":false,"allowDatadogSessionReplay":false,"hideFrontpageBook2020Ad":null,"hideDialogueFacilitation":false,"optedInToDialogueFacilitation":false,"revealChecksToAdmins":false,"notificationNewDialogueChecks":{"email":{"enabled":false,"dayOfWeekGMT":"Monday","timeOfDayGMT":12,"batchingFrequency":"realtime"},"onsite":{"enabled":false,"dayOfWeekGMT":"Monday","timeOfDayGMT":12,"batchingFrequency":"realtime"}},"notificationYourTurnMatchForm":{"email":{"enabled":false,"dayOfWeekGMT":"Monday","timeOfDayGMT":12,"batchingFrequency":"realtime"},"onsite":{"enabled":true,"dayOfWeekGMT":"Monday","timeOfDayGMT":12,"batchingFrequency":"realtime"}},"showDialoguesList":true,"showMyDialogues":true,"showMatches":true,"showRecommendedPartners":true,"hideActiveDialogueUsers":false,"hideSunshineSidebar":false,"optedOutOfSurveys":null,"postGlossariesPinned":false,"generateJargonForDrafts":false,"generateJargonForPublishedPosts":true,"oldSlugs":["hate9"],"groups":null,"jobTitle":null,"organization":null,"careerStage":null,"biography":{"__ref":"Revision:j2BCQ3AWkDhGjGst4_biography"},"howOthersCanHelpMe":null,"howICanHelpOthers":null,"profileTagIds":[],"profileTags":[],"organizerOfGroupIds":[],"organizerOfGroups":[],"programParticipation":null,"website":null,"linkedinProfileURL":null,"facebookProfileURL":null,"blueskyProfileURL":null,"twitterProfileURL":null,"githubProfileURL":null,"frontpagePostCount":0,"afSequenceCount":0,"afSequenceDraftCount":0,"sequenceDraftCount":0,"moderationGuidelines":{"__ref":"Revision:j2BCQ3AWkDhGjGst4_moderationGuidelines"},"noindex":false,"paymentEmail":null,"paymentInfo":null,"goodHeartTokens":null,"postingDisabled":null,"allCommentingDisabled":null,"commentingOnOtherUsersDisabled":null,"conversationsDisabled":null,"walledGardenInvite":null,"hideWalledGardenUI":null,"walledGardenPortalOnboarded":null,"taggingDashboardCollapsed":null,"usernameUnset":false,"slug":"ms-haze","createdAt":"2018-05-18T19:37:27.596Z","username":"Hate9","displayName":"Ms. Haze","profileImageId":null,"previousDisplayName":"Hate9","fullName":"Mabel Emillia Schaefer","karma":37,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":1,"commentCount":12,"sequenceCount":0,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ","karmaChanges":{"__typename":"KarmaChanges","totalChange":0,"updateFrequency":"daily","startDate":"2025-04-01T11:00:00.000Z","endDate":"2025-04-09T11:00:00.000Z","nextBatchDate":"2025-04-10T11:00:00.000Z","posts":[],"comments":[],"tagRevisions":[],"todaysKarmaChanges":null,"thisWeeksKarmaChanges":null}},"ROOT_QUERY":{"__typename":"Query","currentUser":{"__ref":"User:j2BCQ3AWkDhGjGst4"},"unreadNotificationCounts":{"__typename":"NotificationCounts","unreadNotifications":0,"unreadPrivateMessages":0,"faviconBadgeNumber":0,"checkedAt":"2025-04-10T03:40:41.417Z"},"notifications({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":20,\"userId\":\"j2BCQ3AWkDhGjGst4\",\"view\":\"userNotifications\"}}})":{"__typename":"MultiNotificationOutput","results":[{"__ref":"Notification:nHcjghsdAi58DzvCG"},{"__ref":"Notification:tmbdRsdSvbYnsk7ry"},{"__ref":"Notification:L8ssetQg5EBzzpf4C"},{"__ref":"Notification:tZhxxdCZ2Xn3rEWqF"},{"__ref":"Notification:bcM88gFKmgzdwsYFG"},{"__ref":"Notification:ybv4vecuAqTbuiykv"},{"__ref":"Notification:wzrebx2txbdqA3ZnH"},{"__ref":"Notification:qxTxsC3PCjbnng9Lg"},{"__ref":"Notification:EG7wG6XPGoBjyDqLi"},{"__ref":"Notification:mEmyxkzdLQEAfestg"},{"__ref":"Notification:TbFEAr7m8TeoQeyae"},{"__ref":"Notification:7rHy9s6S7du3MeRvQ"},{"__ref":"Notification:8LBdb39y8HD5iw9p4"},{"__ref":"Notification:o5S9WswwCKbsnYjgD"},{"__ref":"Notification:gPEg4J86wyrB4Sqaz"},{"__ref":"Notification:Liee7w68tc4Yuayku"},{"__ref":"Notification:dw9eTYsBymSZowtnz"},{"__ref":"Notification:tPX4YyXkMP6fwsgCH"},{"__ref":"Notification:9RaweuBDE3obcwD86"},{"__ref":"Notification:9jbaXFdziWPT6Ziwt"}],"totalCount":null},"llmConversations({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":50,\"userId\":\"j2BCQ3AWkDhGjGst4\",\"view\":\"llmConversationsWithUser\"}}})":{"__typename":"MultiLlmConversationOutput","results":[],"totalCount":null},"user({\"input\":{\"selector\":{\"documentId\":\"j2BCQ3AWkDhGjGst4\"}}})":{"__typename":"SingleUserOutput","result":{"__ref":"User:j2BCQ3AWkDhGjGst4"}},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":12,\"view\":\"communitySequences\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:kHXfThe7cZs9qCJcD"},{"__ref":"Sequence:TtBARjJ7sjxDjgjow"},{"__ref":"Sequence:nhBeCEzWaAGFw6weu"},{"__ref":"Sequence:TEybbkyHpMEB2HTv3"},{"__ref":"Sequence:2nrd74Be7mmhkJc77"},{"__ref":"Sequence:BaozoQuaC8hYXxjbt"},{"__ref":"Sequence:sLqCreBi2EXNME57o"},{"__ref":"Sequence:29rcaHiBnxHDjHaMq"},{"__ref":"Sequence:TrPEBfTSKwSRdLgmv"},{"__ref":"Sequence:i5MgWdrk7dYMtcyA7"},{"__ref":"Sequence:btmYeavYrwfz56FEv"},{"__ref":"Sequence:jZfcWzg8cxviFqwrT"}],"totalCount":222},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":2,\"view\":\"globalEvents\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:JNL2bmDXmaG7YnRbF"},{"__ref":"Post:JxsdDs8ZfbF4dBkGe"}],"totalCount":null},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"globalEvent\":false,\"limit\":2,\"view\":\"events\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:87kEhKMAwp5M3dFGf"},{"__ref":"Post:QXcQsQyf25836Mg2w"}],"totalCount":null},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":100,\"view\":\"curatedSequences\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:5g5TkQTe9rmPS5vvM"},{"__ref":"Sequence:NBDFAKt3GbFwnwzQF"},{"__ref":"Sequence:PtgH6ALi5CoJnPmGS"},{"__ref":"Sequence:mzgtmmTKKn5MuCzFJ"},{"__ref":"Sequence:XsMTxdQ6fprAQMoKi"},{"__ref":"Sequence:Rm6oQRJJmhGCcLvxh"},{"__ref":"Sequence:v55BhXbpJuaExkpcD"},{"__ref":"Sequence:n945eovrA3oDueqtq"},{"__ref":"Sequence:ZnSMHcWjRx6yT4H92"},{"__ref":"Sequence:CmrW8fCmSLK7E25sa"},{"__ref":"Sequence:evLkoqsbi79AnM5sz"},{"__ref":"Sequence:pFatcKW3JJhTSxqAF"},{"__ref":"Sequence:n3utvGrgC2SGi9xQX"},{"__ref":"Sequence:f2YA4eGskeztcJsqT"},{"__ref":"Sequence:a6ne2ve5uturEEQK7"},{"__ref":"Sequence:dDMzozPbe4aJRkfTr"},{"__ref":"Sequence:6uDBPacS6zDipqbZ9"},{"__ref":"Sequence:BbAvHtorCZqp97X9W"},{"__ref":"Sequence:TF77XsD5PbucbJsG3"},{"__ref":"Sequence:yYxggfHYRrqnJXuRx"},{"__ref":"Sequence:EmDuGeRw749sD3GKd"},{"__ref":"Sequence:4dHMdK5TLN6xcqtyc"},{"__ref":"Sequence:KAv8z6oJCTxjR8vdR"},{"__ref":"Sequence:xEFeCwk3pdYdeG2rL"},{"__ref":"Sequence:kNANcHLNtJt5qeuSS"},{"__ref":"Sequence:hBFDRZCPLcrRDubgm"},{"__ref":"Sequence:r9tYkB2a8Fp4DN8yB"},{"__ref":"Sequence:d3WgHDBAPYYScp5Em"},{"__ref":"Sequence:qWoFR4ytMpQ5vw3FT"},{"__ref":"Sequence:HXkpm9b8o964jbQ89"},{"__ref":"Sequence:ZNNi2uNx9E6iwGKKG"},{"__ref":"Sequence:G2GDw3m4MJ5ixSM92"},{"__ref":"Sequence:qRxTKm7DAftSuTGvj"},{"__ref":"Sequence:pC6DYFLPMTCbEwH8W"},{"__ref":"Sequence:SqFbMbtxGybdS2gRs"},{"__ref":"Sequence:yFvZa9wkv5JoqhM8F"},{"__ref":"Sequence:XipJ7DMjYyriAm7fr"},{"__ref":"Sequence:oi873FWi6pHWxswSa"},{"__ref":"Sequence:bQgRsy23biR52poMf"},{"__ref":"Sequence:oLGCcbnvabyibnG9d"},{"__ref":"Sequence:2A7rrZ4ySx6R8mfoT"},{"__ref":"Sequence:ynMFrq9K5iNMfSZNg"}],"totalCount":42}},"Notification:nHcjghsdAi58DzvCG":{"_id":"nHcjghsdAi58DzvCG","__typename":"Notification","documentId":"72r66aTBwiEzunQqT","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-04-06T22:38:54.094Z","link":"/posts/72r66aTBwiEzunQqT/jenn-s-shortform","message":"jenn has created a new post: jenn's Shortform","type":"newPost","viewed":false,"extraData":null},"Notification:tmbdRsdSvbYnsk7ry":{"_id":"tmbdRsdSvbYnsk7ry","__typename":"Notification","documentId":"zhEHa9zoWTBobGdEy","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-04-06T16:59:43.590Z","link":"/events/zhEHa9zoWTBobGdEy/the-colours-of-her-coat","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:L8ssetQg5EBzzpf4C":{"_id":"L8ssetQg5EBzzpf4C","__typename":"Notification","documentId":"McuBsFJFksoo9FiQv","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-04-02T02:37:30.995Z","link":"/events/McuBsFJFksoo9FiQv/baba-is-planmaking","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:tZhxxdCZ2Xn3rEWqF":{"_id":"tZhxxdCZ2Xn3rEWqF","__typename":"Notification","documentId":"cxrwkumdrpbbC93fn","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-03-31T01:12:13.291Z","link":"/posts/cxrwkumdrpbbC93fn/scattered-thoughts","message":"jenn has created a new post: Meetups Notes (Q1 2025)","type":"newPost","viewed":false,"extraData":null},"Notification:bcM88gFKmgzdwsYFG":{"_id":"bcM88gFKmgzdwsYFG","__typename":"Notification","documentId":"nqeLhsAkEgnTwYbbE","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-03-25T23:48:51.086Z","link":"/events/nqeLhsAkEgnTwYbbE/waterloo-acx-meetups-everywhere-spring-2025","message":"jenn has created a new post: Waterloo – ACX Meetups Everywhere Spring 2025","type":"newPost","viewed":false,"extraData":null},"Notification:ybv4vecuAqTbuiykv":{"_id":"ybv4vecuAqTbuiykv","__typename":"Notification","documentId":"fTJgmjhD92ruzBj5t","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-03-25T20:49:52.432Z","link":"/events/fTJgmjhD92ruzBj5t/critically-reading-scott-alexander","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:wzrebx2txbdqA3ZnH":{"_id":"wzrebx2txbdqA3ZnH","__typename":"Notification","documentId":"XgtPQ8HNenLiTa2kx","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-03-22T04:30:29.526Z","link":"/events/XgtPQ8HNenLiTa2kx/2025-acx-spring-megameetup","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:qxTxsC3PCjbnng9Lg":{"_id":"qxTxsC3PCjbnng9Lg","__typename":"Notification","documentId":"xM5MeB6px7Bo62Z76","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-03-04T01:25:44.966Z","link":"/events/xM5MeB6px7Bo62Z76/skillshare-getting-gud-at-groceries","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:EG7wG6XPGoBjyDqLi":{"_id":"EG7wG6XPGoBjyDqLi","__typename":"Notification","documentId":"LAL7GA8tMkREpjHWJ","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-25T01:45:03.301Z","link":"/events/LAL7GA8tMkREpjHWJ/adulthood","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:mEmyxkzdLQEAfestg":{"_id":"mEmyxkzdLQEAfestg","__typename":"Notification","documentId":"DnMFzqrWGK6xKM36Q","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-24T03:30:33.467Z","link":"/events/DnMFzqrWGK6xKM36Q/hpmor-at-10","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:TbFEAr7m8TeoQeyae":{"_id":"TbFEAr7m8TeoQeyae","__typename":"Notification","documentId":"aMg3bWSjNAHD5PCXB","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-21T18:50:04.017Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"Notification:7rHy9s6S7du3MeRvQ":{"_id":"7rHy9s6S7du3MeRvQ","__typename":"Notification","documentId":"fMdfHDjjTncgREAyA","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-21T18:49:55.746Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"Notification:8LBdb39y8HD5iw9p4":{"_id":"8LBdb39y8HD5iw9p4","__typename":"Notification","documentId":"pJkSkoo5Er4xFivXC","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-21T18:46:57.327Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"Notification:o5S9WswwCKbsnYjgD":{"_id":"o5S9WswwCKbsnYjgD","__typename":"Notification","documentId":"stB3xJBT7nmXSmiBH","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-21T18:32:00.186Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"Notification:gPEg4J86wyrB4Sqaz":{"_id":"gPEg4J86wyrB4Sqaz","__typename":"Notification","documentId":"CmGMHvkmMkhTzG4Xm","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-21T06:49:20.292Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"Notification:Liee7w68tc4Yuayku":{"_id":"Liee7w68tc4Yuayku","__typename":"Notification","documentId":"MTXJqj7x5suspoXej","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-20T23:44:56.791Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"Notification:dw9eTYsBymSZowtnz":{"_id":"dw9eTYsBymSZowtnz","__typename":"Notification","documentId":"2y64FSNsXcXtBH8Bu","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-16T17:36:09.303Z","link":"/events/2y64FSNsXcXtBH8Bu/palmer-luckey-american-vulcan","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:tPX4YyXkMP6fwsgCH":{"_id":"tPX4YyXkMP6fwsgCH","__typename":"Notification","documentId":"GjbXGybzszw8eN3oB","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-15T19:08:17.032Z","link":"/posts/GjbXGybzszw8eN3oB/microplastics-much-less-than-you-wanted-to-know","message":"jenn has created a new post: Microplastics: Much Less Than You Wanted To Know","type":"newPost","viewed":false,"extraData":null},"Notification:9RaweuBDE3obcwD86":{"_id":"9RaweuBDE3obcwD86","__typename":"Notification","documentId":"Cm3mLudwDX8mSu4jC","documentType":"post","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-11T01:47:35.202Z","link":"/events/Cm3mLudwDX8mSu4jC/writer-spotlight-zvi-mowshowitz","message":"Kitchener-Waterloo Rationality posted a new event","type":"newEvent","viewed":false,"extraData":null},"Notification:9jbaXFdziWPT6Ziwt":{"_id":"9jbaXFdziWPT6Ziwt","__typename":"Notification","documentId":"DedvgNEeXDghxirLs","documentType":"message","deleted":false,"userId":"j2BCQ3AWkDhGjGst4","createdAt":"2025-02-10T20:39:30.599Z","link":"/inbox/7w5GsybsNyZZuZRvj","message":"Raemon sent you a new message!","type":"newMessage","viewed":false,"extraData":null},"User:tzER8b2F9ofG5wq5p":{"_id":"tzER8b2F9ofG5wq5p","__typename":"User","slug":"jacob-falkovich","createdAt":"2014-12-19T14:34:43.963Z","username":"Jacobian","displayName":"Jacob Falkovich","profileImageId":null,"previousDisplayName":null,"fullName":"Jacob Falkovich","karma":5806,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"<p>Writes <a href=\"http://Putanumonit.com\">Putanumonit.com<\/a> and <a href=\"https://www.secondperson.dating/\">SecondPerson.dating<\/a>. @yashkaf on Twitter.<\/p>","jobTitle":null,"organization":null,"postCount":182,"commentCount":265,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:kHXfThe7cZs9qCJcD_contents":{"_id":"kHXfThe7cZs9qCJcD_contents","__typename":"Revision","version":"1.0.0","updateType":"initial","editedAt":"2025-04-08T20:36:39.901Z","userId":"tzER8b2F9ofG5wq5p","html":"<p>Why rationalist epistemology struggles to make sense of dating.<\/p>","commitMessage":"","wordCount":9,"htmlHighlight":"<p>Why rationalist epistemology struggles to make sense of dating.<\/p>","plaintextDescription":"Why rationalist epistemology struggles to make sense of dating."},"Sequence:kHXfThe7cZs9qCJcD":{"_id":"kHXfThe7cZs9qCJcD","__typename":"Sequence","createdAt":"2025-04-08T20:36:39.645Z","userId":"tzER8b2F9ofG5wq5p","user":{"__ref":"User:tzER8b2F9ofG5wq5p"},"contents":{"__ref":"Revision:kHXfThe7cZs9qCJcD_contents"},"gridImageId":"sequencesgrid/bfx5itye2xjb0liq00zg","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":6,"readPostsCount":0,"title":"Coupling for Decouplers","canonicalCollection":null},"User:cGzLBzdypKFhFvSpd":{"_id":"cGzLBzdypKFhFvSpd","__typename":"User","slug":"ape-in-the-coat","createdAt":"2021-09-16T10:11:18.922Z","username":"Ape in the coat","displayName":"Ape in the coat","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":1260,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":23,"commentCount":535,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:TtBARjJ7sjxDjgjow_contents":{"_id":"TtBARjJ7sjxDjgjow_contents","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2025-03-26T06:41:24.894Z","userId":"cGzLBzdypKFhFvSpd","html":"<p>A deep dive into probability theory for those who already understand the basics, resolving common confusions, solving alleged paradoxes and producing a coherent framework for dealing with any type of uncertainty in a unified way.&nbsp;<\/p><p>Reading <a href=\"https://www.lesswrong.com/s/SqFbMbtxGybdS2gRs\">Highly Advanced Epistemology 101 for Beginners<\/a> first is advised.<\/p>","commitMessage":"","wordCount":45,"htmlHighlight":"<p>A deep dive into probability theory for those who already understand the basics, resolving common confusions, solving alleged paradoxes and producing a coherent framework for dealing with any type of uncertainty in a unified way.&nbsp;<\/p><p>Reading <a href=\"https://www.lesswrong.com/s/SqFbMbtxGybdS2gRs\">Highly Advanced Epistemology 101 for Beginners<\/a> first is advised.<\/p>","plaintextDescription":"A deep dive into probability theory for those who already understand the basics, resolving common confusions, solving alleged paradoxes and producing a coherent framework for dealing with any type of uncertainty in a unified way. \n\nReading Highly Advanced Epistemology 101 for Beginners first is advised."},"Sequence:TtBARjJ7sjxDjgjow":{"_id":"TtBARjJ7sjxDjgjow","__typename":"Sequence","createdAt":"2025-03-26T06:11:56.904Z","userId":"cGzLBzdypKFhFvSpd","user":{"__ref":"User:cGzLBzdypKFhFvSpd"},"contents":{"__ref":"Revision:TtBARjJ7sjxDjgjow_contents"},"gridImageId":"sequencesgrid/qunmjdhhdmyxb7qifzfc","bannerImageId":"sequences/wqezmweie3dgapfwgueu","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":2,"readPostsCount":0,"title":"Probability Theory Fundamentals 102","canonicalCollection":null},"User:jWduMJMW3s3YwqJQH":{"_id":"jWduMJMW3s3YwqJQH","__typename":"User","slug":"towards_keeperhood","createdAt":"2021-02-08T20:05:58.578Z","username":"Simon Skade","displayName":"Towards_Keeperhood","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":692,"afKarma":10,"deleted":false,"isAdmin":false,"htmlBio":"<p>I'm trying to prevent doom from AI. Currently trying to become sufficiently good at alignment research. Feel free to DM for meeting requests.<\/p>","jobTitle":null,"organization":null,"postCount":15,"commentCount":205,"sequenceCount":1,"afPostCount":0,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:nhBeCEzWaAGFw6weu_contents":{"_id":"nhBeCEzWaAGFw6weu_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2025-03-16T08:55:10.263Z","userId":"jWduMJMW3s3YwqJQH","html":"<p>Collection of my posts on orca intelligence and communication.<\/p><p>I left out my posts \"<a href=\"http://lesswrong.com/posts/vKM4CTjz5fPB7vznb/an-alternative-approach-to-superbabies\">An alternative approach to superbabies<\/a>\" and \"<a href=\"https://www.lesswrong.com/posts/dkJfuKwChxkCrnZ3w/orca-communication-project-seeking-feedback-and\">Orca communication project - seeking feedback (and collaborators)<\/a>\", as I don't recommend reading them anymore.<\/p>","commitMessage":"","wordCount":35,"htmlHighlight":"<p>Collection of my posts on orca intelligence and communication.<\/p><p>I left out my posts \"<a href=\"http://lesswrong.com/posts/vKM4CTjz5fPB7vznb/an-alternative-approach-to-superbabies\">An alternative approach to superbabies<\/a>\" and \"<a href=\"https://www.lesswrong.com/posts/dkJfuKwChxkCrnZ3w/orca-communication-project-seeking-feedback-and\">Orca communication project - seeking feedback (and collaborators)<\/a>\", as I don't recommend reading them anymore.<\/p>","plaintextDescription":"Collection of my posts on orca intelligence and communication.\n\nI left out my posts \"An alternative approach to superbabies\" and \"Orca communication project - seeking feedback (and collaborators)\", as I don't recommend reading them anymore."},"Sequence:nhBeCEzWaAGFw6weu":{"_id":"nhBeCEzWaAGFw6weu","__typename":"Sequence","createdAt":"2025-03-16T08:53:32.139Z","userId":"jWduMJMW3s3YwqJQH","user":{"__ref":"User:jWduMJMW3s3YwqJQH"},"contents":{"__ref":"Revision:nhBeCEzWaAGFw6weu_contents"},"gridImageId":"sequencesgrid/ziznojpwlotjslgx9xgw","bannerImageId":"sequences/mr7tjprcvylvyojkmlpm","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Orcas","canonicalCollection":null},"User:hdH22y8PBL4LRAS3G":{"_id":"hdH22y8PBL4LRAS3G","__typename":"User","slug":"logical_lunatic","createdAt":"2016-05-25T14:54:37.397Z","username":"Logical_Lunatic","displayName":"Joar Skalse","profileImageId":null,"previousDisplayName":null,"fullName":"Joar Skalse","karma":734,"afKarma":241,"deleted":false,"isAdmin":false,"htmlBio":"<p>My name is pronounced \"YOO-ar SKULL-se\" (the \"e\" is not silent). I'm a PhD student at Oxford University, and I was a member of the Future of Humanity Institute before it shut down. I have worked in several different areas of AI safety research. For a few highlights, see:<\/p><ol><li><a href=\"https://arxiv.org/abs/2405.06624\">Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems<\/a><\/li><li><a href=\"https://ojs.aaai.org/index.php/AAAI/article/view/26766\">Misspecification in Inverse Reinforcement Learning<\/a><\/li><li><a href=\"https://arxiv.org/abs/2309.15257\">STARC: A General Framework For Quantifying Differences Between Reward Functions<\/a><\/li><li><a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a><\/li><li><a href=\"https://www.jmlr.org/papers/v22/20-676.html\">Is SGD a Bayesian sampler? Well, almost<\/a><\/li><\/ol><p>Some of my recent research on the theoretical foundations of reward learning is also described in <a href=\"https://www.lesswrong.com/s/TEybbkyHpMEB2HTv3\">this sequence<\/a>.&nbsp;<\/p><p>For a full list of all my research, see my <a href=\"https://scholar.google.com/citations?hl=en&amp;user=GuzLUmQAAAAJ&amp;view_op=list_works\">Google Scholar<\/a>.<\/p>","jobTitle":null,"organization":null,"postCount":17,"commentCount":83,"sequenceCount":1,"afPostCount":16,"afCommentCount":32,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:TEybbkyHpMEB2HTv3_contents":{"_id":"TEybbkyHpMEB2HTv3_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2025-04-02T11:33:32.341Z","userId":"hdH22y8PBL4LRAS3G","html":"<p>In this sequence I provide an overview of the theoretical reward learning research agenda, including its motivating assumptions, several core results, and some starting points for how to contribute to it further.<\/p>","commitMessage":"","wordCount":32,"htmlHighlight":"<p>In this sequence I provide an overview of the theoretical reward learning research agenda, including its motivating assumptions, several core results, and some starting points for how to contribute to it further.<\/p>","plaintextDescription":"In this sequence I provide an overview of the theoretical reward learning research agenda, including its motivating assumptions, several core results, and some starting points for how to contribute to it further."},"Sequence:TEybbkyHpMEB2HTv3":{"_id":"TEybbkyHpMEB2HTv3","__typename":"Sequence","createdAt":"2025-02-28T13:19:10.896Z","userId":"hdH22y8PBL4LRAS3G","user":{"__ref":"User:hdH22y8PBL4LRAS3G"},"contents":{"__ref":"Revision:TEybbkyHpMEB2HTv3_contents"},"gridImageId":"sequencesgrid/qjzer8wybtd3fkmm156i","bannerImageId":"sequences/gld7osexwvzzktahrsgs","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":true,"postsCount":8,"readPostsCount":0,"title":"The Theoretical Foundations of Reward Learning","canonicalCollection":null},"User:p2N3QhmpKNGn7wkCw":{"_id":"p2N3QhmpKNGn7wkCw","__typename":"User","slug":"cole-wyeth","createdAt":"2021-07-25T00:01:54.628Z","username":"Amyr","displayName":"Cole Wyeth","profileImageId":null,"previousDisplayName":null,"fullName":"Cole Wyeth","karma":1635,"afKarma":66,"deleted":false,"isAdmin":false,"htmlBio":"<p>I am a PhD student in computer science at the University of Waterloo, supervised by Professor Ming Li and advised by Professor Marcus Hutter.<\/p><p>My current research is related to applications of algorithmic probability to sequential decision theory (universal artificial intelligence). Recently I have been trying to start a dialogue between the computational cognitive science and UAI communities. Sometimes I build robots, professionally or otherwise. Another hobby (and a personal favorite of my posts here) is the <a href=\"https://www.lesswrong.com/posts/Yz33koDN5uhSEaB6c/sherlockian-abduction-master-list\">Sherlockian abduction master list,<\/a> which is a crowdsourced project seeking to make \"Sherlock Holmes\" style inference feasible by compiling observational cues. Give it a read and see if you can contribute!<\/p><p>See my personal website <a href=\"https://colewyeth.com/\">colewyeth.com<\/a> for an overview of my interests and work.<\/p>","jobTitle":null,"organization":null,"postCount":26,"commentCount":331,"sequenceCount":3,"afPostCount":0,"afCommentCount":5,"spamRiskScore":1,"tagRevisionCount":2,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:2nrd74Be7mmhkJc77_contents":{"_id":"2nrd74Be7mmhkJc77_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2025-02-20T18:18:52.712Z","userId":"p2N3QhmpKNGn7wkCw","html":"<p>Here I speculate about questions such as:<\/p><p>What makes a theory of rationality useful or useless?<\/p><p>When is a theory of rationality useful for building agents, describing agents, or becoming a better agent, and to what extent should the answers be connected?<\/p><p>&nbsp;How elegant should we expect algorithms for intelligence to be?<\/p><p>What concepts deserve to be promoted to the root/core design of an AGI versus discovered by AGI? Perhaps relatedly, does human cognition have such a root/core algorithm, and if so, what is it?<\/p>","commitMessage":"","wordCount":85,"htmlHighlight":"<p>Here I speculate about questions such as:<\/p><p>What makes a theory of rationality useful or useless?<\/p><p>When is a theory of rationality useful for building agents, describing agents, or becoming a better agent, and to what extent should the answers be connected?<\/p><p>&nbsp;How elegant should we expect algorithms for intelligence to be?<\/p><p>What concepts deserve to be promoted to the root/core design of an AGI versus discovered by AGI? Perhaps relatedly, does human cognition have such a root/core algorithm, and if so, what is it?<\/p>","plaintextDescription":"Here I speculate about questions such as:\n\nWhat makes a theory of rationality useful or useless?\n\nWhen is a theory of rationality useful for building agents, describing agents, or becoming a better agent, and to what extent should the answers be connected?\n\n How elegant should we expect algorithms for intelligence to be?\n\nWhat concepts deserve to be promoted to the root/core design of an AGI versus discovered by AGI? Perhaps relatedly, does human cognition have such a root/core algorithm, and if so, what is it?"},"Sequence:2nrd74Be7mmhkJc77":{"_id":"2nrd74Be7mmhkJc77","__typename":"Sequence","createdAt":"2025-02-20T18:17:56.108Z","userId":"p2N3QhmpKNGn7wkCw","user":{"__ref":"User:p2N3QhmpKNGn7wkCw"},"contents":{"__ref":"Revision:2nrd74Be7mmhkJc77_contents"},"gridImageId":"sequencesgrid/xmifowdkgqnlxpeskzcj","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Meta-theory of rationality","canonicalCollection":null},"User:oezgprZbqzzq6RuqJ":{"_id":"oezgprZbqzzq6RuqJ","__typename":"User","slug":"michaelstjules","createdAt":"2019-08-31T04:59:46.433Z","username":"MichaelStJules","displayName":"MichaelStJules","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":573,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":20,"commentCount":240,"sequenceCount":2,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"XtphY3uYHwruKqDyG"},"Revision:BaozoQuaC8hYXxjbt_contents":{"_id":"BaozoQuaC8hYXxjbt_contents","__typename":"Revision","version":"1.5.0","updateType":"minor","editedAt":"2025-01-10T15:39:32.300Z","userId":"oezgprZbqzzq6RuqJ","html":"<p>It seems to me that almost every ethical view misses a lot of what we care about, projects concerns we don’t actually have onto us, or otherwise fails to care about what we care about on our behalves&nbsp;<i>as<\/i> we (would actually) care about them. In one way or the other, they fall short in empathy.<\/p><p>In this sequence, I develop consequentialist-compatible views guided primarily by empathy, to capture exactly what we (would actually) care about.<\/p><ol><li>In the <a href=\"https://www.lesswrong.com/posts/3igG3CMiBwH5XxChJ/really-radical-empatthy\">first piece<\/a>, I discuss the various ways of caring and defend all of them, and a focus on <i>what we care about&nbsp;<\/i> rather than the caring itself (e.g. pleasure, satisfaction), and in turn criticize hedonism and most desire and preference views for often missing what we care about, giving weight to things we don't actually care about, or otherwise getting the weights wrong. I motivate <i>object views<\/i>, which are concerned exactly with what we (would actually) care about.<\/li><li>In the <a href=\"https://www.lesswrong.com/posts/fDRCfKEE5S4z7i7FX/other-implications-of-really-radical-empathy\">second piece<\/a>, I discuss some ethical implications of object views: the harms of death, that suffering may not always be bad even when it's action-guiding, that chemically induced pleasures and displeasures may not matter <i>in themselves<\/i> if they aren't <i>about<\/i> anything, and other revisions to the concept of <i>welfare<\/i>.<\/li><li>In the <a href=\"https://www.lesswrong.com/posts/AqM6BJBhZ9WoFp62T/actualism-asymmetry-and-extinction\">third piece<\/a>, I motivate <i>actualist preference-affecting object views<\/i> as best capturing what we (would actually) care about, and derive from them the (Procreation) Asymmetry: we have reasons to prevent miserable lives, but not to create happy or fulfilling lives, for the sake of what those lives would actually care about. This should lead to less priority for extinction risk reduction, relative to (symmetric) total utilitarianism.<\/li><li>In the <a href=\"https://www.lesswrong.com/posts/2F5QttK5EbdCiuZqx/utilitarianism-and-the-replaceability-of-desires-and\">fourth piece<\/a>, I argue that most measures of welfare, if maximized directly on someone's behalf, can result in replacing most or all of what they care about against their wishes and for their sake. This can be avoided with <i>preference-affecting views<\/i>, which give less priority to extinction risk reduction.<\/li><li>In the fifth piece, I develop technical extensions of the views to handle changing preferences and population ethics as types of multi-player games.<\/li><\/ol>","commitMessage":"","wordCount":354,"htmlHighlight":"<p>It seems to me that almost every ethical view misses a lot of what we care about, projects concerns we don’t actually have onto us, or otherwise fails to care about what we care about on our behalves&nbsp;<i>as<\/i> we (would actually) care about them. In one way or the other, they fall short in empathy.<\/p><p>In this sequence, I develop consequentialist-compatible views guided primarily by empathy, to capture exactly what we (would actually) care about.<\/p><ol><li>In the <a href=\"https://www.lesswrong.com/posts/3igG3CMiBwH5XxChJ/really-radical-empatthy\">first piece<\/a>, I discuss the various ways of caring and defend all of them, and a focus on <i>what we care about&nbsp;<\/i> rather than the caring itself (e.g. pleasure, satisfaction), and in turn criticize hedonism and most desire and preference views for often missing what we care about, giving weight to things we don't actually care about, or otherwise getting the weights wrong. I motivate <i>object views<\/i>, which are concerned exactly with what we (would actually) care about.<\/li><li>In the <a href=\"https://www.lesswrong.com/posts/fDRCfKEE5S4z7i7FX/other-implications-of-really-radical-empathy\">second piece<\/a>, I discuss some ethical implications of object views: the harms of death, that suffering may not always be bad even when it's action-guiding, that chemically induced pleasures and displeasures may not matter <i>in themselves<\/i> if they aren't <i>about<\/i> anything, and other revisions to the concept of <i>welfare<\/i>.<\/li><li>In the <a href=\"https://www.lesswrong.com/posts/AqM6BJBhZ9WoFp62T/actualism-asymmetry-and-extinction\">third piece<\/a>, I motivate <i>actualist preference-affecting object views<\/i> as best capturing what we (would actually) care about, and derive from them the (Procreation) Asymmetry: we have reasons to prevent miserable lives, but not to create happy or fulfilling lives, for the sake of what those lives would actually care about. This should lead to less priority for extinction risk reduction, relative to (symmetric) total utilitarianism.<\/li><li>In the <a href=\"https://www.lesswrong.com/posts/2F5QttK5EbdCiuZqx/utilitarianism-and-the-replaceability-of-desires-and\">fourth piece<\/a>, I argue that most measures of welfare, if maximized directly on someone's behalf, can result in replacing most or all of what they care about against their wishes and for their sake. This can be avoided with <i>preference-affecting views<\/i>, which give less priority to extinction risk reduction.<\/li><li>In the fifth piece, I develop technical extensions of the views to handle changing preferences and population ethics as types of multi-player games.<\/li><\/ol>","plaintextDescription":"It seems to me that almost every ethical view misses a lot of what we care about, projects concerns we don’t actually have onto us, or otherwise fails to care about what we care about on our behalves as we (would actually) care about them. In one way or the other, they fall short in empathy.\n\nIn this sequence, I develop consequentialist-compatible views guided primarily by empathy, to capture exactly what we (would actually) care about.\n\n 1. In the first piece, I discuss the various ways of caring and defend all of them, and a focus on what we care about  rather than the caring itself (e.g. pleasure, satisfaction), and in turn criticize hedonism and most desire and preference views for often missing what we care about, giving weight to things we don't actually care about, or otherwise getting the weights wrong. I motivate object views, which are concerned exactly with what we (would actually) care about.\n 2. In the second piece, I discuss some ethical implications of object views: the harms of death, that suffering may not always be bad even when it's action-guiding, that chemically induced pleasures and displeasures may not matter in themselves if they aren't about anything, and other revisions to the concept of welfare.\n 3. In the third piece, I motivate actualist preference-affecting object views as best capturing what we (would actually) care about, and derive from them the (Procreation) Asymmetry: we have reasons to prevent miserable lives, but not to create happy or fulfilling lives, for the sake of what those lives would actually care about. This should lead to less priority for extinction risk reduction, relative to (symmetric) total utilitarianism.\n 4. In the fourth piece, I argue that most measures of welfare, if maximized directly on someone's behalf, can result in replacing most or all of what they care about against their wishes and for their sake. This can be avoided with preference-affecting views, which give less priority to extinction risk reduction"},"Sequence:BaozoQuaC8hYXxjbt":{"_id":"BaozoQuaC8hYXxjbt","__typename":"Sequence","createdAt":"2025-01-06T17:55:32.637Z","userId":"oezgprZbqzzq6RuqJ","user":{"__ref":"User:oezgprZbqzzq6RuqJ"},"contents":{"__ref":"Revision:BaozoQuaC8hYXxjbt_contents"},"gridImageId":"sequencesgrid/b0mni0wuw02yjhs35ho0","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Radical empathy","canonicalCollection":null},"Revision:sLqCreBi2EXNME57o_contents":{"_id":"sLqCreBi2EXNME57o_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2025-01-10T02:08:10.902Z","userId":"p2N3QhmpKNGn7wkCw","html":"<p>This sequence attempts to formulate (and resolve) the problems of agent foundations using the tools of algorithmic information theory, particularly by investigating the properties of the AIXI agent, its variants, and proposed generalizations. The central thesis is that \"universal artificial intelligence\" (~the theory of AIXI) should serve as a central paradigm for agent foundations. In particular, the informally-stated limitations attributed to AIXI (as a bounded/embedded agent) should be made rigorous <i>within the paradigm<\/i>. I expect that many can also be repaired within the paradigm, or do not arise in practice at all.<\/p><p>I probably will not get around to writing my own proper introduction to the AIXI model and its philosophical motivation until I need it for my thesis, so in the meantime this sequence requires prerequisite knowledge.<\/p><p>&nbsp;Here is a <a href=\"https://www.lesswrong.com/posts/DFdSD3iKYwFS29iQs/intuitive-explanation-of-aixi\">quick intuitive explanation<\/a> from Thomas Larsen, which I endorse except for its position on objective randomness according to AIXI.<\/p><p>The original paper:<\/p><p><a href=\"https://arxiv.org/pdf/cs/0004001\">https://arxiv.org/pdf/cs/0004001<\/a><\/p><p>&nbsp;For a longer and more complete introduction, read one of Hutter (et al.'s) books:<\/p><p><a href=\"http://www.hutter1.net/ai/uaibook.htm\">http://www.hutter1.net/ai/uaibook.htm<\/a><\/p><p><a href=\"http://www.hutter1.net/ai/uaibook2.htm\">http://www.hutter1.net/ai/uaibook2.htm<\/a> &nbsp;&nbsp;<\/p>","commitMessage":"","wordCount":170,"htmlHighlight":"<p>This sequence attempts to formulate (and resolve) the problems of agent foundations using the tools of algorithmic information theory, particularly by investigating the properties of the AIXI agent, its variants, and proposed generalizations. The central thesis is that \"universal artificial intelligence\" (~the theory of AIXI) should serve as a central paradigm for agent foundations. In particular, the informally-stated limitations attributed to AIXI (as a bounded/embedded agent) should be made rigorous <i>within the paradigm<\/i>. I expect that many can also be repaired within the paradigm, or do not arise in practice at all.<\/p><p>I probably will not get around to writing my own proper introduction to the AIXI model and its philosophical motivation until I need it for my thesis, so in the meantime this sequence requires prerequisite knowledge.<\/p><p>&nbsp;Here is a <a href=\"https://www.lesswrong.com/posts/DFdSD3iKYwFS29iQs/intuitive-explanation-of-aixi\">quick intuitive explanation<\/a> from Thomas Larsen, which I endorse except for its position on objective randomness according to AIXI.<\/p><p>The original paper:<\/p><p><a href=\"https://arxiv.org/pdf/cs/0004001\">https://arxiv.org/pdf/cs/0004001<\/a><\/p><p>&nbsp;For a longer and more complete introduction, read one of Hutter (et al.'s) books:<\/p><p><a href=\"http://www.hutter1.net/ai/uaibook.htm\">http://www.hutter1.net/ai/uaibook.htm<\/a><\/p><p><a href=\"http://www.hutter1.net/ai/uaibook2.htm\">http://www.hutter1.net/ai/uaibook2.htm<\/a> &nbsp;&nbsp;<\/p>","plaintextDescription":"This sequence attempts to formulate (and resolve) the problems of agent foundations using the tools of algorithmic information theory, particularly by investigating the properties of the AIXI agent, its variants, and proposed generalizations. The central thesis is that \"universal artificial intelligence\" (~the theory of AIXI) should serve as a central paradigm for agent foundations. In particular, the informally-stated limitations attributed to AIXI (as a bounded/embedded agent) should be made rigorous within the paradigm. I expect that many can also be repaired within the paradigm, or do not arise in practice at all.\n\nI probably will not get around to writing my own proper introduction to the AIXI model and its philosophical motivation until I need it for my thesis, so in the meantime this sequence requires prerequisite knowledge.\n\n Here is a quick intuitive explanation from Thomas Larsen, which I endorse except for its position on objective randomness according to AIXI.\n\nThe original paper:\n\nhttps://arxiv.org/pdf/cs/0004001\n\n For a longer and more complete introduction, read one of Hutter (et al.'s) books:\n\nhttp://www.hutter1.net/ai/uaibook.htm\n\nhttp://www.hutter1.net/ai/uaibook2.htm   "},"Sequence:sLqCreBi2EXNME57o":{"_id":"sLqCreBi2EXNME57o","__typename":"Sequence","createdAt":"2025-01-01T01:57:54.067Z","userId":"p2N3QhmpKNGn7wkCw","user":{"__ref":"User:p2N3QhmpKNGn7wkCw"},"contents":{"__ref":"Revision:sLqCreBi2EXNME57o_contents"},"gridImageId":"sequencesgrid/atk3kjkkvfuuwkv0mwc1","bannerImageId":"sequences/n7gfk0ahjlqeku793jp0","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":3,"readPostsCount":0,"title":"AIXI Agent foundations","canonicalCollection":null},"User:2WJYaJavgTNHoSNbC":{"_id":"2WJYaJavgTNHoSNbC","__typename":"User","slug":"willpetillo","createdAt":"2018-08-28T17:49:11.750Z","username":"WillPetillo","displayName":"WillPetillo","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":361,"afKarma":-5,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":9,"commentCount":29,"sequenceCount":1,"afPostCount":2,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:29rcaHiBnxHDjHaMq_contents":{"_id":"29rcaHiBnxHDjHaMq_contents","__typename":"Revision","version":"1.0.0","updateType":"minor","editedAt":"2025-01-02T05:01:33.267Z","userId":"2WJYaJavgTNHoSNbC","html":"<p>Substrate Needs Convergence (SNC) is the theory that Artificial General Intelligence (AGI) will gradually change under strong evolutionary pressures toward expanding itself.&nbsp; This converges over the long term on making the Earth uninhabitable for biological life. &nbsp;SNC focuses on AI systems that are comprehensive enough to form fully self-sufficient machine ecosystems that persist over time. &nbsp;The theory contends that it is impossible <i>in principle<\/i> to build such a system that is compatible with biological life. &nbsp;By implication, the only way to be safe from AGI is to not build it.<\/p><p>This sequence is an attempt to explain the underlying intuitions of SNC and bridge the inferential gap to those more accustomed to thinking about Artificial Super Intelligence (ASI) in terms of the alignment problem as described by Yudkowsky and others.<\/p><p>Recommended reading pattern: start with \"What if Alignment is not enough\" to get a high level summary. &nbsp;If the argument seems implausible, make a note of your objections, move on to the subsequent intuition-forming posts, and then return to the initial summary. &nbsp;If your objection remains, please comment regarding where you see a crux.<\/p>","commitMessage":"","wordCount":184,"htmlHighlight":"<p>Substrate Needs Convergence (SNC) is the theory that Artificial General Intelligence (AGI) will gradually change under strong evolutionary pressures toward expanding itself.&nbsp; This converges over the long term on making the Earth uninhabitable for biological life. &nbsp;SNC focuses on AI systems that are comprehensive enough to form fully self-sufficient machine ecosystems that persist over time. &nbsp;The theory contends that it is impossible <i>in principle<\/i> to build such a system that is compatible with biological life. &nbsp;By implication, the only way to be safe from AGI is to not build it.<\/p><p>This sequence is an attempt to explain the underlying intuitions of SNC and bridge the inferential gap to those more accustomed to thinking about Artificial Super Intelligence (ASI) in terms of the alignment problem as described by Yudkowsky and others.<\/p><p>Recommended reading pattern: start with \"What if Alignment is not enough\" to get a high level summary. &nbsp;If the argument seems implausible, make a note of your objections, move on to the subsequent intuition-forming posts, and then return to the initial summary. &nbsp;If your objection remains, please comment regarding where you see a crux.<\/p>","plaintextDescription":"Substrate Needs Convergence (SNC) is the theory that Artificial General Intelligence (AGI) will gradually change under strong evolutionary pressures toward expanding itself.  This converges over the long term on making the Earth uninhabitable for biological life.  SNC focuses on AI systems that are comprehensive enough to form fully self-sufficient machine ecosystems that persist over time.  The theory contends that it is impossible in principle to build such a system that is compatible with biological life.  By implication, the only way to be safe from AGI is to not build it.\n\nThis sequence is an attempt to explain the underlying intuitions of SNC and bridge the inferential gap to those more accustomed to thinking about Artificial Super Intelligence (ASI) in terms of the alignment problem as described by Yudkowsky and others.\n\nRecommended reading pattern: start with \"What if Alignment is not enough\" to get a high level summary.  If the argument seems implausible, make a note of your objections, move on to the subsequent intuition-forming posts, and then return to the initial summary.  If your objection remains, please comment regarding where you see a crux."},"Sequence:29rcaHiBnxHDjHaMq":{"_id":"29rcaHiBnxHDjHaMq","__typename":"Sequence","createdAt":"2024-12-28T22:14:23.459Z","userId":"2WJYaJavgTNHoSNbC","user":{"__ref":"User:2WJYaJavgTNHoSNbC"},"contents":{"__ref":"Revision:29rcaHiBnxHDjHaMq_contents"},"gridImageId":"sequencesgrid/ammfeotp10rmbkrwfsil","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":3,"readPostsCount":0,"title":"Substrate Needs Convergence","canonicalCollection":null},"User:wceXXk4zpvX6zNZcD":{"_id":"wceXXk4zpvX6zNZcD","__typename":"User","slug":"transhumanist_atom_understander","createdAt":"2023-09-09T03:02:58.928Z","username":"transhumanist_atom_understander","displayName":"transhumanist_atom_understander","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":366,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":5,"commentCount":52,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"nLbwLhBaQeG6tCNDN"},"Revision:TrPEBfTSKwSRdLgmv_contents":{"_id":"TrPEBfTSKwSRdLgmv_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-12-21T04:39:15.738Z","userId":"wceXXk4zpvX6zNZcD","html":"<p>Considering the future of solar power from the three fundamental perspectives of futurism: first principles considerations of ultimate bounds, the current state of business, and near-future prediction by extrapolating trends.<\/p>\n","commitMessage":"","wordCount":30,"htmlHighlight":"<p>Considering the future of solar power from the three fundamental perspectives of futurism: first principles considerations of ultimate bounds, the current state of business, and near-future prediction by extrapolating trends.<\/p>","plaintextDescription":"Considering the future of solar power from the three fundamental perspectives of futurism: first principles considerations of ultimate bounds, the current state of business, and near-future prediction by extrapolating trends."},"Sequence:TrPEBfTSKwSRdLgmv":{"_id":"TrPEBfTSKwSRdLgmv","__typename":"Sequence","createdAt":"2024-12-21T04:06:52.150Z","userId":"wceXXk4zpvX6zNZcD","user":{"__ref":"User:wceXXk4zpvX6zNZcD"},"contents":{"__ref":"Revision:TrPEBfTSKwSRdLgmv_contents"},"gridImageId":"sequencesgrid/cty0iyxr0asc6m3vbhza","bannerImageId":"sequences/jekpu8wqhduu86l2lkql","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":2,"readPostsCount":0,"title":"Prospects for Solartopia","canonicalCollection":null},"User:6G9PqE5CGbd5GMQBe":{"_id":"6G9PqE5CGbd5GMQBe","__typename":"User","slug":"jadael","createdAt":"2013-04-01T16:39:15.772Z","username":"Jadael","displayName":"Trevor Hill-Hand","profileImageId":null,"previousDisplayName":null,"fullName":"⚪","karma":100,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"<p><a href=\"http://hillhand.com\">hillhand.com<\/a><\/p>\n<p>I deeply value evidence, reason, and letting people draw their own conclusions. I dislike telling anyone what to think or do.<\/p>\n<p>I believe you, yes YOU, are capable of reading and understanding everything you want to read and understand.<\/p>\n","jobTitle":null,"organization":null,"postCount":1,"commentCount":42,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:i5MgWdrk7dYMtcyA7_contents":{"_id":"i5MgWdrk7dYMtcyA7_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-12-05T17:52:01.444Z","userId":"6G9PqE5CGbd5GMQBe","html":"<p><em><strong>Miss Macross: My Life as The Star<\/strong><\/em><\/p>\n<p><em><strong>By Lynn Minmay<\/strong><\/em><\/p>\n<ul>\n<li>First edition, 2014<\/li>\n<li>Published by Macross Historical Press<\/li>\n<li>In association with the UN Spacy Cultural Preservation Initiative<\/li>\n<\/ul>\n<p><strong>Creative Commons Declaration:<\/strong><\/p>\n<ul>\n<li>This work is protected under Article 7 of the Post-War Cultural Preservation Treaty, which recognizes the fundamental role of artistic expression in maintaining human identity.<\/li>\n<li>This memoir is released under the UN Spacy's Open Culture Initiative of 2010, ensuring free access while maintaining historical authenticity.<\/li>\n<\/ul>\n<p><strong>Authentication Notice:<\/strong><\/p>\n<ul>\n<li>Primary source verification provided by UN Spacy Historical Archives<\/li>\n<li>Zentradi cultural translations certified by the Britai-LaSalle Institute<\/li>\n<li>Personal accounts cross-referenced with SDF-1 Macross bridge logs<\/li>\n<\/ul>\n<p><strong>Cultural Heritage Statement:<\/strong><\/p>\n<ul>\n<li>\n<p>This text is designated as a Category A Cultural Asset under UN Resolution 2187, recognizing its significance in documenting the transformation of human-Zentradi relations through artistic expression.<\/p>\n<\/li>\n<li>\n<p>Commissioned by the UN Spacy Museum of Culture and Conflict<\/p>\n<\/li>\n<li>\n<p>Based on performance footage, February 11, 2010<\/p>\n<\/li>\n<li>\n<p>Holocapture processing by Macross City Technical Archives<\/p>\n<\/li>\n<\/ul>\n<hr>\n","commitMessage":"","wordCount":171,"htmlHighlight":"<p><em><strong>Miss Macross: My Life as The Star<\/strong><\/em><\/p>\n<p><em><strong>By Lynn Minmay<\/strong><\/em><\/p>\n<ul>\n<li>First edition, 2014<\/li>\n<li>Published by Macross Historical Press<\/li>\n<li>In association with the UN Spacy Cultural Preservation Initiative<\/li>\n<\/ul>\n<p><strong>Creative Commons Declaration:<\/strong><\/p>\n<ul>\n<li>This work is protected under Article 7 of the Post-War Cultural Preservation Treaty, which recognizes the fundamental role of artistic expression in maintaining human identity.<\/li>\n<li>This memoir is released under the UN Spacy's Open Culture Initiative of 2010, ensuring free access while maintaining historical authenticity.<\/li>\n<\/ul>\n<p><strong>Authentication Notice:<\/strong><\/p>\n<ul>\n<li>Primary source verification provided by UN Spacy Historical Archives<\/li>\n<li>Zentradi cultural translations certified by the Britai-LaSalle Institute<\/li>\n<li>Personal accounts cross-referenced with SDF-1 Macross bridge logs<\/li>\n<\/ul>\n<p><strong>Cultural Heritage Statement:<\/strong><\/p>\n<ul>\n<li>\n<p>This text is designated as a Category A Cultural Asset under UN Resolution 2187, recognizing its significance in documenting the transformation of human-Zentradi relations through artistic expression.<\/p>\n<\/li>\n<li>\n<p>Commissioned by the UN Spacy Museum of Culture and Conflict<\/p>\n<\/li>\n<li>\n<p>Based on performance footage, February 11, 2010<\/p>\n<\/li>\n<li>\n<p>Holocapture processing by Macross City Technical Archives<\/p>\n<\/li>\n<\/ul>\n<hr>","plaintextDescription":"Miss Macross: My Life as The Star\n\nBy Lynn Minmay\n\n * First edition, 2014\n * Published by Macross Historical Press\n * In association with the UN Spacy Cultural Preservation Initiative\n\nCreative Commons Declaration:\n\n * This work is protected under Article 7 of the Post-War Cultural Preservation Treaty, which recognizes the fundamental role of artistic expression in maintaining human identity.\n * This memoir is released under the UN Spacy's Open Culture Initiative of 2010, ensuring free access while maintaining historical authenticity.\n\nAuthentication Notice:\n\n * Primary source verification provided by UN Spacy Historical Archives\n * Zentradi cultural translations certified by the Britai-LaSalle Institute\n * Personal accounts cross-referenced with SDF-1 Macross bridge logs\n\nCultural Heritage Statement:\n\n * This text is designated as a Category A Cultural Asset under UN Resolution 2187, recognizing its significance in documenting the transformation of human-Zentradi relations through artistic expression.\n\n * Commissioned by the UN Spacy Museum of Culture and Conflict\n\n * Based on performance footage, February 11, 2010\n\n * Holocapture processing by Macross City Technical Archives\n\n----------------------------------------"},"Sequence:i5MgWdrk7dYMtcyA7":{"_id":"i5MgWdrk7dYMtcyA7","__typename":"Sequence","createdAt":"2024-12-04T22:39:01.436Z","userId":"6G9PqE5CGbd5GMQBe","user":{"__ref":"User:6G9PqE5CGbd5GMQBe"},"contents":{"__ref":"Revision:i5MgWdrk7dYMtcyA7_contents"},"gridImageId":"sequencesgrid/c9hx1tgf7xwueylbudcv","bannerImageId":"sequences/e0to5hzsf6v8zrqxgzfs","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":0,"readPostsCount":0,"title":"Miss Macross: My Life as the Star","canonicalCollection":null},"User:jHzwoFd2MhZt9eeqJ":{"_id":"jHzwoFd2MhZt9eeqJ","__typename":"User","slug":"joe-carlsmith","createdAt":"2017-11-08T21:40:51.838Z","username":"joekc","displayName":"Joe Carlsmith","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":4950,"afKarma":633,"deleted":false,"isAdmin":false,"htmlBio":"<p>Senior research analyst at Open Philanthropy. Doctorate in philosophy from the University of Oxford. Opinions my own.<\/p>","jobTitle":null,"organization":null,"postCount":104,"commentCount":75,"sequenceCount":3,"afPostCount":27,"afCommentCount":19,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:btmYeavYrwfz56FEv_contents":{"_id":"btmYeavYrwfz56FEv_contents","__typename":"Revision","version":"1.0.0","updateType":"initial","editedAt":"2024-10-30T17:26:36.851Z","userId":"jHzwoFd2MhZt9eeqJ","html":"<p>This is a four-part series of posts about how we might solve the alignment problem. It also builds off of my previous post, <a href=\"https://www.lesswrong.com/posts/AFdvSBNgN2EkAsZZA/what-is-it-to-solve-the-alignment-problem-1\">here<\/a>, about what it would even <i>be<\/i> to solve the alignment problem; and to some extent, off of <a href=\"https://www.lesswrong.com/posts/A9YYkbnjmfsP7Chfo/a-framework-for-thinking-about-ai-power-seeking\">this post<\/a> outlining a framework for thinking the incentives at stake in AI power-seeking.<\/p>","commitMessage":"","wordCount":55,"htmlHighlight":"<p>This is a four-part series of posts about how we might solve the alignment problem. It also builds off of my previous post, <a href=\"https://www.lesswrong.com/posts/AFdvSBNgN2EkAsZZA/what-is-it-to-solve-the-alignment-problem-1\">here<\/a>, about what it would even <i>be<\/i> to solve the alignment problem; and to some extent, off of <a href=\"https://www.lesswrong.com/posts/A9YYkbnjmfsP7Chfo/a-framework-for-thinking-about-ai-power-seeking\">this post<\/a> outlining a framework for thinking the incentives at stake in AI power-seeking.<\/p>","plaintextDescription":"This is a four-part series of posts about how we might solve the alignment problem. It also builds off of my previous post, here, about what it would even be to solve the alignment problem; and to some extent, off of this post outlining a framework for thinking the incentives at stake in AI power-seeking."},"Sequence:btmYeavYrwfz56FEv":{"_id":"btmYeavYrwfz56FEv","__typename":"Sequence","createdAt":"2024-10-30T17:26:36.682Z","userId":"jHzwoFd2MhZt9eeqJ","user":{"__ref":"User:jHzwoFd2MhZt9eeqJ"},"contents":{"__ref":"Revision:btmYeavYrwfz56FEv_contents"},"gridImageId":"sequencesgrid/vowmfifnizhdzdheneae","bannerImageId":"sequences/jrjlzgfnqwnrfzxwlgfg","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"How might we solve the alignment problem?","canonicalCollection":null},"User:YwsNPRwXrbsHhKCje":{"_id":"YwsNPRwXrbsHhKCje","__typename":"User","slug":"kristianronn","createdAt":"2013-09-18T17:52:48.650Z","username":"KristianRonn","displayName":"KristianRonn","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":167,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":5,"commentCount":10,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:jZfcWzg8cxviFqwrT_contents":{"_id":"jZfcWzg8cxviFqwrT_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2024-10-21T21:28:06.623Z","userId":"YwsNPRwXrbsHhKCje","html":"<p>Global coordination stands as arguably the most critical challenge facing humanity today, functioning both as a necessary component for solving existential risks and as a significant barrier to effective mitigation. From nuclear proliferation to artificial intelligence development and climate change, our inability to collaborate effectively on a global scale not only exacerbates these threats but also perpetuates the emergence of new systemic vulnerabilities if left unaddressed.&nbsp;<\/p><p>In this sequence, I will argue that the root of this coordination problem lies in the very mechanisms that shaped our species: natural selection. This evolutionary process, operating as a trial-and-error optimization algorithm, prioritizes immediate survival and reproduction over long-term, global outcomes. As a result, our innate tendencies often favor short-term gains and localized benefits, even when they conflict with the greater good of our species and planet.<\/p><p>The inherent limitations of natural selection in predicting future optimal states have left us ill-equipped to handle global-scale challenges. In a world of finite resources, competition rather than cooperation has often been the more adaptive trait, leading to the emergence of self-interested behaviors that arguably dominate modern societies. This evolutionary legacy manifests in the form of nationalistic tendencies, economic rivalries, dangerous arms races and a general reluctance to sacrifice immediate benefits for long-term collective gains.&nbsp;<\/p><p>This three-part series summarizes my book: <a href=\"https://www.amazon.com/Darwinian-Trap-Evolutionary-Explain-Threaten/dp/B0CR4H12JV\">The Darwinian Trap: The Hidden Evolutionary Forces That Explain Our World (and Threaten Our Future)<\/a>.&nbsp;<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/q3YmKemEzyrcphAeP/darwinian-traps-and-existential-risks\"><strong>Part 1<\/strong><\/a><strong>:&nbsp;<\/strong>This part explores how evolutionary selection pressures contribute to existential risks, particularly through global resource, power, and intelligence arms races.<\/li><li><a href=\"https://www.lesswrong.com/posts/kBG6bNckhZeamQJsQ/the-fragility-of-life-hypothesis-and-the-evolution-of\"><strong>Part 2<\/strong><\/a><strong>:<\/strong> This part delves into the evolution of cooperation and discusses how survivorship bias might mislead us into thinking cooperation is easier to achieve than it actually is. It suggests that life may be inherently fragile, potentially containing the seeds of its own destruction, which could provide an explanation for the Fermi Paradox.<\/li><li><a href=\"https://www.lesswrong.com/posts/ngogpWk4phZLwgdB4/the-great-bootstrap\"><strong>Part 3<\/strong><\/a><strong>:<\/strong> The final part examines strategies to overcome global coordination challenges, both through centralized and decentralized approaches. It introduces the concept of \"reputational markets\" (a variant of prediction markets) as a tool for supply chain governance, aimed at reshaping the evolutionary trajectory toward cooperation and long-term survival and flourishing.<\/li><\/ul>","commitMessage":"","wordCount":359,"htmlHighlight":"<p>Global coordination stands as arguably the most critical challenge facing humanity today, functioning both as a necessary component for solving existential risks and as a significant barrier to effective mitigation. From nuclear proliferation to artificial intelligence development and climate change, our inability to collaborate effectively on a global scale not only exacerbates these threats but also perpetuates the emergence of new systemic vulnerabilities if left unaddressed.&nbsp;<\/p><p>In this sequence, I will argue that the root of this coordination problem lies in the very mechanisms that shaped our species: natural selection. This evolutionary process, operating as a trial-and-error optimization algorithm, prioritizes immediate survival and reproduction over long-term, global outcomes. As a result, our innate tendencies often favor short-term gains and localized benefits, even when they conflict with the greater good of our species and planet.<\/p><p>The inherent limitations of natural selection in predicting future optimal states have left us ill-equipped to handle global-scale challenges. In a world of finite resources, competition rather than cooperation has often been the more adaptive trait, leading to the emergence of self-interested behaviors that arguably dominate modern societies. This evolutionary legacy manifests in the form of nationalistic tendencies, economic rivalries, dangerous arms races and a general reluctance to sacrifice immediate benefits for long-term collective gains.&nbsp;<\/p><p>This three-part series summarizes my book: <a href=\"https://www.amazon.com/Darwinian-Trap-Evolutionary-Explain-Threaten/dp/B0CR4H12JV\">The Darwinian Trap: The Hidden Evolutionary Forces That Explain Our World (and Threaten Our Future)<\/a>.&nbsp;<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/q3YmKemEzyrcphAeP/darwinian-traps-and-existential-risks\"><strong>Part 1<\/strong><\/a><strong>:&nbsp;<\/strong>This part explores how evolutionary selection pressures contribute to existential risks, particularly through global resource, power, and intelligence arms races.<\/li><li><a href=\"https://www.lesswrong.com/posts/kBG6bNckhZeamQJsQ/the-fragility-of-life-hypothesis-and-the-evolution-of\"><strong>Part 2<\/strong><\/a><strong>:<\/strong> This part delves into the evolution of cooperation and discusses how survivorship bias might mislead us into thinking cooperation is easier to achieve than it actually is. It suggests that life may be inherently fragile, potentially containing the seeds of its own destruction, which could provide an explanation for the Fermi Paradox.<\/li><li><a href=\"https://www.lesswrong.com/posts/ngogpWk4phZLwgdB4/the-great-bootstrap\"><strong>Part 3<\/strong><\/a><strong>:<\/strong> The final part examines strategies to overcome global coordination challenges, both through centralized and decentralized approaches. It introduces the concept of \"reputational markets\" (a variant of prediction<\/li><\/ul>... ","plaintextDescription":"Global coordination stands as arguably the most critical challenge facing humanity today, functioning both as a necessary component for solving existential risks and as a significant barrier to effective mitigation. From nuclear proliferation to artificial intelligence development and climate change, our inability to collaborate effectively on a global scale not only exacerbates these threats but also perpetuates the emergence of new systemic vulnerabilities if left unaddressed. \n\nIn this sequence, I will argue that the root of this coordination problem lies in the very mechanisms that shaped our species: natural selection. This evolutionary process, operating as a trial-and-error optimization algorithm, prioritizes immediate survival and reproduction over long-term, global outcomes. As a result, our innate tendencies often favor short-term gains and localized benefits, even when they conflict with the greater good of our species and planet.\n\nThe inherent limitations of natural selection in predicting future optimal states have left us ill-equipped to handle global-scale challenges. In a world of finite resources, competition rather than cooperation has often been the more adaptive trait, leading to the emergence of self-interested behaviors that arguably dominate modern societies. This evolutionary legacy manifests in the form of nationalistic tendencies, economic rivalries, dangerous arms races and a general reluctance to sacrifice immediate benefits for long-term collective gains. \n\nThis three-part series summarizes my book: The Darwinian Trap: The Hidden Evolutionary Forces That Explain Our World (and Threaten Our Future). \n\n * Part 1: This part explores how evolutionary selection pressures contribute to existential risks, particularly through global resource, power, and intelligence arms races.\n * Part 2: This part delves into the evolution of cooperation and discusses how survivorship bias might mislead us into thinking cooperation is easier to achieve than it"},"Sequence:jZfcWzg8cxviFqwrT":{"_id":"jZfcWzg8cxviFqwrT","__typename":"Sequence","createdAt":"2024-10-21T21:26:10.178Z","userId":"YwsNPRwXrbsHhKCje","user":{"__ref":"User:YwsNPRwXrbsHhKCje"},"contents":{"__ref":"Revision:jZfcWzg8cxviFqwrT_contents"},"gridImageId":"sequencesgrid/yzmk9grzs5lfjxl08jv8","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"The Darwinian Trap","canonicalCollection":null},"Revision:KzQ5FWYBGdg6iiNx5":{"_id":"KzQ5FWYBGdg6iiNx5","__typename":"Revision","htmlHighlight":"<p>MAISU starts with an Opening session on April 18th (Friday), but most of the sessions will happen during April 19th-21th. You’re welcome to join as much or little as you want.<\/p><p>The event is for anyone who wants to help prevent AI-driven catastrophe. Other than that, we’re open to all perspectives. However each individual session will typically have narrower scope. When attending a session please respect the specific scope of that session.<\/p><p>Because this is an Unconference, the schedule is open to anyone to add sessions. Expect the schedule to continuously expand as the event approaches.&nbsp;<\/p><h1><a href=\"https://docs.google.com/document/d/1sHnzJBu6dBiGwgdtO4W14bz5Jy7eKizEh8Vun0mVM-s/edit?tab=t.0#heading=h.h88drtev6cdv\">Official website<\/a><\/h1><p>The official website is guaranteed to have the latest information. This LessWrong event post might be updated less frequently.<\/p><h1><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScXDl8z-kTyhR8zxQsgO0V0sfKrk_H4RfZ0xELpDpD81PDVwA/viewform\"><u>Register here<\/u><\/a><\/h1><ul><li>If you register, you will receive email updates about the event.<\/li><li>You can attend without registering, but you might miss important information.<\/li><\/ul><p><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScXDl8z-kTyhR8zxQsgO0V0sfKrk_H4RfZ0xELpDpD81PDVwA/viewanalytics\"><u>Click here<\/u><\/a> to see who else has registered.<\/p><h1><a href=\"https://teamup.com/ks42i9htheq3s52i27\"><u>Schedule<\/u><\/a> &nbsp; &nbsp;&nbsp;<\/h1><p>Don’t worry if it looks sparse now. More sessions will be added (maybe by you?), this is how unconferences work.<\/p><p>You can put anything you want on the schedule, any type of session, as long as it’s safety relevant.<\/p><ul><li>If you put something on the schedule you’re responsible for hosting it.<\/li><li>When scheduling something, please make sure it’s clear how it’s relevant to AI Safety (unless it’s a purely fun/social session).<\/li><\/ul><p><strong>Some examples of things you can host<\/strong><\/p><ul><li>A talk presenting …<ul><li>… your results<\/li><li>… other peoples results that you find interesting<\/li><li>… an intro level overview of some subset of AI safety<\/li><li>… an in-progress project you want feedback on<\/li><\/ul><\/li><li>An open discussion on a topic you’re interested in<\/li><li>A fun game, or other social activity<\/li><li>Some type of exercise that you find useful for thinking about AI safety<\/li><li>Sharing your hot takes with an open invitation to debate you<\/li><\/ul><p><strong>General advice<\/strong><\/p><ul><li>If you host a talk, make sure to leave plenty of time for discussions afterwards<\/li><li>1h hour is a good length for most sessions<\/li><\/ul><h3><strong>Warning!<\/strong><br>TeamUp (the scheduling app we’re using) does not automatically update. You need to manually refresh the schedule, or you might miss things.&nbsp;<\/h3><p>Sessions will be added continuously to the schedule. There will likely be some last minute additions and/or changes even after the event has started.<\/p><h1>Discussions &amp; Networking in the&nbsp;<a href=\"https://join.slack.com/t/ai-alignment/shared_invite/zt-1d379kvgh-3vNjSOmnd_3HsoKJxjcyFg\"><u>AI Alignment Slack<\/u><\/a><\/h1><p>We don’t have an event-specific Slack or Discord, instead we’re invading the AI Alignment Slack for... <\/p>","plaintextDescription":"MAISU starts with an Opening session on April 18th (Friday), but most of the sessions will happen during April 19th-21th. You’re welcome to join as much or little as you want.\n\nThe event is for anyone who wants to help prevent AI-driven catastrophe. Other than that, we’re open to all perspectives. However each individual session will typically have narrower scope. When attending a session please respect the specific scope of that session.\n\nBecause this is an Unconference, the schedule is open to anyone to add sessions. Expect the schedule to continuously expand as the event approaches. \n\n\nOfficial website\nThe official website is guaranteed to have the latest information. This LessWrong event post might be updated less frequently.\n\n\nRegister here\n * If you register, you will receive email updates about the event.\n * You can attend without registering, but you might miss important information.\n\nClick here to see who else has registered.\n\n\nSchedule     \nDon’t worry if it looks sparse now. More sessions will be added (maybe by you?), this is how unconferences work.\n\nYou can put anything you want on the schedule, any type of session, as long as it’s safety relevant.\n\n * If you put something on the schedule you’re responsible for hosting it.\n * When scheduling something, please make sure it’s clear how it’s relevant to AI Safety (unless it’s a purely fun/social session).\n\nSome examples of things you can host\n\n * A talk presenting …\n   * … your results\n   * … other peoples results that you find interesting\n   * … an intro level overview of some subset of AI safety\n   * … an in-progress project you want feedback on\n * An open discussion on a topic you’re interested in\n * A fun game, or other social activity\n * Some type of exercise that you find useful for thinking about AI safety\n * Sharing your hot takes with an open invitation to debate you\n\nGeneral advice\n\n * If you host a talk, make sure to leave plenty of time for discussions afterwards\n * 1h hour is a good length for","wordCount":536,"version":"1.1.0"},"Tag:sYm3HiWcfZvrGu3ui":{"_id":"sYm3HiWcfZvrGu3ui","__typename":"Tag","userId":"r38pkCm7wF4M44MDQ","name":"AI","shortName":null,"slug":"ai","core":true,"postCount":11593,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T22:24:22.097Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false,"isArbitalImport":false,"isPlaceholderPage":false,"baseScore":10,"extendedScore":null,"score":10,"afBaseScore":2,"afExtendedScore":null,"voteCount":2,"currentUserVote":null,"currentUserExtendedVote":null},"SocialPreviewType:JNL2bmDXmaG7YnRbF":{"_id":"JNL2bmDXmaG7YnRbF","__typename":"SocialPreviewType","imageUrl":""},"User:TitFePXAAgwc5C7oa":{"_id":"TitFePXAAgwc5C7oa","__typename":"User","profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":false,"slug":"linda-linsefors","createdAt":"2017-09-28T18:01:14.327Z","username":"Linda Linsefors","displayName":"Linda Linsefors","previousDisplayName":null,"fullName":"Linda Linsefors","karma":2459,"afKarma":332,"deleted":false,"isAdmin":false,"htmlBio":"<p>Hi, I am a Physicist, an Effective Altruist and AI Safety student/researcher.<\/p>","jobTitle":null,"organization":null,"postCount":47,"commentCount":304,"sequenceCount":0,"afPostCount":25,"afCommentCount":110,"spamRiskScore":1,"tagRevisionCount":2,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Post:JNL2bmDXmaG7YnRbF":{"_id":"JNL2bmDXmaG7YnRbF","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:KzQ5FWYBGdg6iiNx5"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":2,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:JNL2bmDXmaG7YnRbF"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2025-02-21T11:36:25.202Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"sYm3HiWcfZvrGu3ui":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"KzQ5FWYBGdg6iiNx5","commentCount":0,"voteCount":5,"baseScore":18,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.005480051506310701,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2025-02-21T11:36:25.202Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"TitFePXAAgwc5C7oa","location":null,"googleLocation":null,"onlineEvent":true,"globalEvent":false,"startTime":"2025-04-18T17:00:00.000Z","endTime":"2025-04-21T22:00:00.000Z","localStartTime":null,"localEndTime":null,"eventRegistrationLink":"https://docs.google.com/forms/d/e/1FAIpQLScXDl8z-kTyhR8zxQsgO0V0sfKrk_H4RfZ0xELpDpD81PDVwA/viewform","joinEventLink":"https://docs.google.com/document/d/1sHnzJBu6dBiGwgdtO4W14bz5Jy7eKizEh8Vun0mVM-s/edit?tab=t.0#heading=h.h88drtev6cdv","facebookLink":null,"meetupLink":null,"website":"https://docs.google.com/document/d/1sHnzJBu6dBiGwgdtO4W14bz5Jy7eKizEh8Vun0mVM-s/edit?tab=t.0#heading=h.xqf605jotm2e","contactInfo":null,"isEvent":true,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"55XxDBpfKkkBPm9H8","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2025-02-21T11:36:25.202Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"rsvpCounts":{},"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:TitFePXAAgwc5C7oa"},"coauthors":[],"slug":"maisu-minimal-ai-safety-unconference","title":"MAISU - Minimal AI Safety Unconference ","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:cpakfyNrpBu2jfyCj":{"_id":"cpakfyNrpBu2jfyCj","__typename":"Revision","htmlHighlight":"<p><strong>Get notified when we are open for applications:<\/strong> <a href=\"https://airtable.com/app16N8kPLey1bQe1/shrPo6yVHYZknKmzV\">Email<\/a> <a href=\"https://t.me/+Cm9B-LAbITY0MTE0\">Telegram<\/a><br>We rely and trust on word of mouth - <strong>Please help spread the word.<\/strong><\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/f2vFYmwFGu3HLL9QB/mo7mzlxarv8ktsayupyi\" alt=\"\"><\/figure><p>Join the 12th Less Wrong Community Weekend (LWCW) in Berlin. This is the world’s largest rationalist social gathering which brings together 250+ aspiring rationalists from across Europe and beyond for 4 days of intellectual exploration, socialising and fun.<\/p><p>We will be taking over the whole hostel with a huge variety of spaces inside and outside to talk, relax, dance, play, learn, teach, connect, cuddle, practice, share ... - simply enjoy life together our way.<\/p><p>We invite everyone who shares a <strong>curiosity<\/strong> for new perspectives to gain a truthful understanding of the world and its inhabitants, a <strong>passion<\/strong> for developing practices and systems that achieve our personal goals and, consequently, those of humanity at large as well as a desire to nurture <strong>empathetic relationships<\/strong> that support and inspire us on our journey.<\/p><p>The <strong>content will be participant driven<\/strong> in an unconference style:&nbsp;on Friday afternoon we put up 12 wall-sized daily planners and by Saturday morning the attendees fill them up with 100+ workshops, talks and activities of their own devising. The high quality sessions that others benefit most from are prepared upfront, but when inspiration hits some are just made up on the spot.<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/ynafv4wrm8eku5xfthms\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/dhrhwe7hewq8njfipa7x 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/wad0dbewem0mylba0hfp 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/pbvq0wrys4heufonxabq 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/jzus1yi81epqrqqemu64 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/j5q8qo9ftibiswclvle1 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/lsz6wosy9yvfkjwl43r8 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/fszo0xlpvhjrbh573gdp 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/q0udaoz1cfmctq2q0cgw 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/lbmfvijylnz0fddds5op 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/fopCdoA8YqJ8Rq6qK/w6ik6tplgech9xmniexy 1200w\"><\/figure><p>Previous years’ schedules have included…<\/p><figure class=\"table\"><table><tbody><tr><td style=\"width:500px\"><ul><li>Double Cruxing<\/li><li>Hamming Circles<\/li><li>Gendlin Focusing<\/li><li>Applied Rationality workshops<\/li><li>Circling<\/li><li>Authentic Relating games<\/li><li>Improvisation theater<\/li><li>Introduction to stand up comedy<\/li><li>Writing rationalist fiction<\/li><li>Dance workshops<\/li><li>Acapella singing<\/li><li>Icebreaker games<\/li><li>Lightning talks<\/li><li>Celebrating failure groups<\/li><li>Giant outdoor chess Penultima<\/li><li>Dungeons &amp; Dragons<\/li><li>Kung Fu basics<\/li><li>Board games<\/li><\/ul><\/td><td style=\"width:500px\"><ul><li>Breathwork workshops<\/li><li>Ecstatic dancing<\/li><li>Radical Honesty workshops<\/li><li>Playfighting for adults<\/li><li>Polyamory and relationships workshops<\/li><li>Sex Q&amp;A roundtable<\/li><li>Quantified self workshops<\/li><li>Moral philosophy debates<\/li><li>AI safety Q&amp;A<\/li><li>How to handle fear of AI Doom<\/li><li>Value drift in EA<\/li><li>The neurobiology of psychedelics<\/li><li>The science of longevity<\/li><li>Morning runs and yoga<\/li><li>Meditation in the rooftop winter garden<\/li><li>Night time swimming<\/li><li>Bedtime story readings<\/li><\/ul><\/td><\/tr><\/tbody><\/table><\/figure><p><i>Personal note from <\/i><a href=\"https://www.lesswrong.com/users/henry-prowbell\"><i>Henry<\/i><\/a><i>: If things like ecstatic dancing, radical honesty and polyamory workshops sound too intense for you, rest assured everything is optional. I’m a nerd and very awkward so a lot of this stuff terrifies me.<\/i><\/p><p>The event takes place in the natural environs... <\/p>","plaintextDescription":"Get notified when we are open for applications: Email Telegram\nWe rely and trust on word of mouth - Please help spread the word.\n\nJoin the 12th Less Wrong Community Weekend (LWCW) in Berlin. This is the world’s largest rationalist social gathering which brings together 250+ aspiring rationalists from across Europe and beyond for 4 days of intellectual exploration, socialising and fun.\n\nWe will be taking over the whole hostel with a huge variety of spaces inside and outside to talk, relax, dance, play, learn, teach, connect, cuddle, practice, share ... - simply enjoy life together our way.\n\nWe invite everyone who shares a curiosity for new perspectives to gain a truthful understanding of the world and its inhabitants, a passion for developing practices and systems that achieve our personal goals and, consequently, those of humanity at large as well as a desire to nurture empathetic relationships that support and inspire us on our journey.\n\nThe content will be participant driven in an unconference style: on Friday afternoon we put up 12 wall-sized daily planners and by Saturday morning the attendees fill them up with 100+ workshops, talks and activities of their own devising. The high quality sessions that others benefit most from are prepared upfront, but when inspiration hits some are just made up on the spot.\n\nPrevious years’ schedules have included…\n\n * Double Cruxing\n * Hamming Circles\n * Gendlin Focusing\n * Applied Rationality workshops\n * Circling\n * Authentic Relating games\n * Improvisation theater\n * Introduction to stand up comedy\n * Writing rationalist fiction\n * Dance workshops\n * Acapella singing\n * Icebreaker games\n * Lightning talks\n * Celebrating failure groups\n * Giant outdoor chess Penultima\n * Dungeons & Dragons\n * Kung Fu basics\n * Board games\n\n * Breathwork workshops\n * Ecstatic dancing\n * Radical Honesty workshops\n * Playfighting for adults\n * Polyamory and relationships workshops\n * Sex Q&A roundtable\n * Quantified self workshops\n * Moral philos","wordCount":1802,"version":"1.1.1"},"Tag:izp6eeJJEg9v5zcur":{"_id":"izp6eeJJEg9v5zcur","__typename":"Tag","userId":"XtphY3uYHwruKqDyG","name":"Community","shortName":null,"slug":"community","core":true,"postCount":2370,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":15,"createdAt":"2020-06-14T03:38:34.631Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false,"isArbitalImport":false,"isPlaceholderPage":false,"baseScore":0,"extendedScore":null,"score":0,"afBaseScore":null,"afExtendedScore":null,"voteCount":0,"currentUserVote":null,"currentUserExtendedVote":null},"SocialPreviewType:JxsdDs8ZfbF4dBkGe":{"_id":"JxsdDs8ZfbF4dBkGe","__typename":"SocialPreviewType","imageUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/f2vFYmwFGu3HLL9QB/mo7mzlxarv8ktsayupyi"},"Localgroup:MGAtkuYmX3hZ6eeaw":{"_id":"MGAtkuYmX3hZ6eeaw","__typename":"Localgroup","name":"LessWrong Berlin","organizerIds":["vbDMpDA5A35329Ju5","AeqmHjYoZ4gvvvjHN","DntTEDBpz74waPc8Z","xn6q3M2HvfBAmcTmc","9QxLZvSHM63kYdWkz","xnuFrMz8Hx2TJE5ti"]},"User:2DC5Z74RysBRi7HwK":{"_id":"2DC5Z74RysBRi7HwK","__typename":"User","profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"jt-1","createdAt":"2023-04-18T11:45:54.012Z","username":"jt","displayName":"jt","previousDisplayName":null,"fullName":"JT","karma":201,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":3,"commentCount":5,"sequenceCount":0,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Post:JxsdDs8ZfbF4dBkGe":{"_id":"JxsdDs8ZfbF4dBkGe","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:cpakfyNrpBu2jfyCj"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"socialPreviewData":{"__ref":"SocialPreviewType:JxsdDs8ZfbF4dBkGe"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2024-12-27T15:50:22.918Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"izp6eeJJEg9v5zcur":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"cpakfyNrpBu2jfyCj","commentCount":0,"voteCount":32,"baseScore":68,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":32,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.008481147699058056,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2024-12-27T15:50:22.918Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"2DC5Z74RysBRi7HwK","location":"DJH Jugendherberge Berlin - Am Wannsee, Badeweg, Berlin, Germany","googleLocation":{"url":"https://maps.google.com/?cid=8587459843782966624","icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/lodging-71.png","name":"Jugendherberge Berlin - Am Wannsee","types":["lodging","point_of_interest","establishment"],"photos":[{"width":4000,"height":3000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/103852221225290988494\">Dorota Pirga<\/a>"]},{"width":4032,"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/117539867409261883160\">Mike Federhenn-Fett<\/a>"]},{"width":4160,"height":3120,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108191693132357058122\">Gabriel Fonseca<\/a>"]},{"width":3024,"height":4032,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/104359235866694930756\">Oliver Bierhaus<\/a>"]},{"width":4032,"height":2268,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/110694942147990270203\">Fathi El-Khatib<\/a>"]},{"width":4032,"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/112491686055719851120\">Ke No<\/a>"]},{"width":4032,"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/117539867409261883160\">Mike Federhenn-Fett<\/a>"]},{"width":4032,"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/104928247261543099728\">Michal Tušl<\/a>"]},{"width":4032,"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/104997856249407701644\">Wolfgang Krause-Riedel<\/a>"]},{"width":4608,"height":2592,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/113494224842505259459\">Heiko H.<\/a>"]}],"rating":3.2,"reviews":[{"text":"We knew it's going to be a youth hostel, so overall you get the youth hostel value for your money. But they don't speak English at the reception, one day my friends simply asked the receptionist about the type of food they have for dinner, the receptionist misunderstood and ordered our whole group dinner... Obviously we didn't pay for that but since they spoke very-very limited English, they couldn't even explain anything or argue properly. It's a pity because otherwise the food is nice for example. It's shocking to me that they don't allow people to use the elevator, only in very exceptional circumstances. It's also quite far from any station or bus stop, and taxi is a ripoff and they tried to cheat, and also didn't speak English almost at all.","time":1710713729,"rating":3,"language":"en","author_url":"https://www.google.com/maps/contrib/115557717346684405980/reviews","author_name":"Veronika Németh-Városi","profile_photo_url":"https://lh3.googleusercontent.com/a-/ALV-UjXygkRTllmtqWQo0CZZhdCDm0daeqwCdRCQ7BgtoOfepoPKzZZ74A=s128-c0x00000000-cc-rp-mo-ba6","relative_time_description":"a month ago"},{"text":"The condition of the room is bad, bare concrete, splintered wood and worn out furniture. The shower is shared between two rooms and you need to lock your door to the shower in order to prevent people from going into your room. My bedsheets were dirty and when I went to replace them they gave me dirty sheets again. They promise high speed WiFi but it's barely enough to send a text message","time":1698909813,"rating":1,"language":"en","author_url":"https://www.google.com/maps/contrib/108437153998963115739/reviews","author_name":"Volen Conev","profile_photo_url":"https://lh3.googleusercontent.com/a-/ALV-UjWdhXRNd_BsEzeza_Y9kEbGnIku1nOHTgPObfwKIaSBz2xHlEMz=s128-c0x00000000-cc-rp-mo","relative_time_description":"6 months ago"},{"text":"Insane good Jugendherberge! I stayed there from Friday evening to Sunday lunch. Never had such a big variety of things. First of all the breakfast & dinner ALSO VEGAN ","time":1698587523,"rating":5,"language":"en","author_url":"https://www.google.com/maps/contrib/112383602919287169530/reviews","author_name":"TheTake","profile_photo_url":"https://lh3.googleusercontent.com/a/ACg8ocIA0maPb6BglEjxrojyVfi6ReDx-AYKQ79BTHVaJM6_zwvERw=s128-c0x00000000-cc-rp-mo","relative_time_description":"6 months ago"},{"text":"Great place for youth. Clean, well kept rooms, good service. Peaceful lakeside location, absolute quiet, and in close proximity to the center of berlin.","time":1707204827,"rating":5,"language":"en","author_url":"https://www.google.com/maps/contrib/115220160254237585640/reviews","author_name":"Thomas Andersen","profile_photo_url":"https://lh3.googleusercontent.com/a-/ALV-UjUO3nav-PqSrVLVF3DjgFYQntU_OYnDh1pACGnOfPNbgfqdAvNc=s128-c0x00000000-cc-rp-mo-ba2","relative_time_description":"2 months ago"},{"text":"It was good but there wasn't a toilet in the bedroom.. ohh that was too stressful.\nOhhh, and there wasn't also the lift.   Our room was on the 4th floor...😐","time":1699307919,"rating":3,"language":"en","author_url":"https://www.google.com/maps/contrib/112760164859712817850/reviews","author_name":"Mrs Khan","profile_photo_url":"https://lh3.googleusercontent.com/a-/ALV-UjXd-VQi7384j6wSr0QViwBotOQfoKa9qKG3uj3dZkxtpwvn4GpkAw=s128-c0x00000000-cc-rp-mo","relative_time_description":"5 months ago"}],"website":"http://www.jh-wannsee.de/","geometry":{"location":{"lat":52.43265950000001,"lng":13.1852799},"viewport":{"east":13.1868176802915,"west":13.1841197197085,"north":52.43405093029151,"south":52.43135296970851}},"place_id":"ChIJGZQB8gFZqEcRYH2dxzrJLHc","vicinity":"Badeweg 1, Berlin","plus_code":{"global_code":"9F4MC5MP+34","compound_code":"C5MP+34 Berlin, Germany"},"reference":"ChIJGZQB8gFZqEcRYH2dxzrJLHc","utc_offset":120,"adr_address":"<span class=\"street-address\">Badeweg 1<\/span>, <span class=\"postal-code\">14129<\/span> <span class=\"locality\">Berlin<\/span>, <span class=\"country-name\">Germany<\/span>","opening_hours":{"periods":[{"open":{"day":0,"time":"0000","hours":0,"minutes":0,"nextDate":1714860000000}}],"open_now":true,"weekday_text":["Monday: Open 24 hours","Tuesday: Open 24 hours","Wednesday: Open 24 hours","Thursday: Open 24 hours","Friday: Open 24 hours","Saturday: Open 24 hours","Sunday: Open 24 hours"]},"business_status":"OPERATIONAL","formatted_address":"Badeweg 1, 14129 Berlin, Germany","html_attributions":[],"address_components":[{"types":["street_number"],"long_name":"1","short_name":"1"},{"types":["route"],"long_name":"Badeweg","short_name":"Badeweg"},{"types":["sublocality_level_1","sublocality","political"],"long_name":"Bezirk Steglitz-Zehlendorf","short_name":"Bezirk Steglitz-Zehlendorf"},{"types":["locality","political"],"long_name":"Berlin","short_name":"Berlin"},{"types":["administrative_area_level_3","political"],"long_name":"Kreisfreie Stadt Berlin","short_name":"Kreisfreie Stadt Berlin"},{"types":["administrative_area_level_1","political"],"long_name":"Berlin","short_name":"BE"},{"types":["country","political"],"long_name":"Germany","short_name":"DE"},{"types":["postal_code"],"long_name":"14129","short_name":"14129"}],"icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/hotel_pinlet","user_ratings_total":1015,"utc_offset_minutes":120,"current_opening_hours":{"periods":[{"open":{"day":3,"date":"2024-05-01","time":"0000","truncated":true},"close":{"day":2,"date":"2024-05-07","time":"2359","truncated":true}}],"open_now":true,"weekday_text":["Monday: Open 24 hours","Tuesday: Open 24 hours","Wednesday: Open 24 hours","Thursday: Open 24 hours","Friday: Open 24 hours","Saturday: Open 24 hours","Sunday: Open 24 hours"]},"icon_background_color":"#909CE1","formatted_phone_number":"030 8032034","international_phone_number":"+49 30 8032034"},"onlineEvent":false,"globalEvent":true,"startTime":"2025-08-29T10:00:00.000Z","endTime":"2025-09-01T09:00:00.000Z","localStartTime":"2025-08-29T12:00:00.000Z","localEndTime":"2025-09-01T11:00:00.000Z","eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":"lwcw.europe[at]gmail.com","isEvent":true,"eventImageId":null,"eventType":"conference","types":["SSC","EA","MIRIx","LW"],"groupId":"MGAtkuYmX3hZ6eeaw","reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":13,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":8,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2024-12-27T15:50:23.085Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":{"__ref":"Localgroup:MGAtkuYmX3hZ6eeaw"},"rsvpCounts":{},"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:2DC5Z74RysBRi7HwK"},"coauthors":[{"__ref":"User:2DC5Z74RysBRi7HwK"}],"slug":"lesswrong-community-weekend-2025","title":"LessWrong Community Weekend 2025","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":[{"userId":"2DC5Z74RysBRi7HwK","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:BxdpR67bwpHwj3nYL":{"_id":"BxdpR67bwpHwj3nYL","__typename":"Revision","htmlHighlight":"<p>This year's Spring ACX Meetup everywhere in Eugene.<\/p>\n                <p>Location: Beergarden. – <a href=\"https://plus.codes/https://plus.codes/84PR3V3W+C6G\">https://plus.codes/84PR3V3W+C6G<\/a><\/p>\n                <p>Group Link: https://discord.gg/WmJpAbkR<\/p>\n                <p>Hosted by the ACX/EAs of Willamette Valley Meetup (see our Discord!)<\/p>\n                <p>Contact: michael.bacarella@gmail.com <\/p>","plaintextDescription":"This year's Spring ACX Meetup everywhere in Eugene.\n\nLocation: Beergarden. – https://plus.codes/84PR3V3W+C6G\n\nGroup Link: https://discord.gg/WmJpAbkR\n\nHosted by the ACX/EAs of Willamette Valley Meetup (see our Discord!)\n\nContact: michael.bacarella@gmail.com","wordCount":28,"version":"1.0.0"},"SocialPreviewType:87kEhKMAwp5M3dFGf":{"_id":"87kEhKMAwp5M3dFGf","__typename":"SocialPreviewType","imageUrl":""},"User:ycf7uRXCkvwHJ2PSS":{"_id":"ycf7uRXCkvwHJ2PSS","__typename":"User","profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"michael_b","createdAt":"2015-01-29T11:41:15.734Z","username":"michael_b","displayName":"michael_b","previousDisplayName":null,"fullName":null,"karma":78,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":5,"commentCount":40,"sequenceCount":0,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Post:87kEhKMAwp5M3dFGf":{"_id":"87kEhKMAwp5M3dFGf","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:BxdpR67bwpHwj3nYL"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:87kEhKMAwp5M3dFGf"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2025-03-25T23:50:00.404Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":null,"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"BxdpR67bwpHwj3nYL","commentCount":0,"voteCount":1,"baseScore":2,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":1,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.003073277184739709,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2025-03-25T23:50:00.404Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"ycf7uRXCkvwHJ2PSS","location":"Eugene","googleLocation":{"types":["bar","establishment","food","point_of_interest","restaurant"],"geometry":{"location":{"lat":44.0536063,"lng":-123.1044298},"viewport":{"northeast":{"lat":44.05495528029149,"lng":-123.1030808197085},"southwest":{"lat":44.0522573197085,"lng":-123.1057787802915}},"location_type":"ROOFTOP"},"place_id":"ChIJP_VdQHIewVQRaw1pZyYbdQM","plus_code":{"global_code":"84PR3V3W+C6","compound_code":"3V3W+C6 Eugene, OR, USA"},"formatted_address":"777 W 6th Ave, Eugene, OR 97402, USA","navigation_points":[{"location":{"latitude":44.0535211,"longitude":-123.1043158}}],"address_components":[{"types":["street_number"],"long_name":"777","short_name":"777"},{"types":["route"],"long_name":"West 6th Avenue","short_name":"W 6th Ave"},{"types":["neighborhood","political"],"long_name":"Whiteaker","short_name":"Whiteaker"},{"types":["locality","political"],"long_name":"Eugene","short_name":"Eugene"},{"types":["administrative_area_level_2","political"],"long_name":"Lane County","short_name":"Lane County"},{"types":["administrative_area_level_1","political"],"long_name":"Oregon","short_name":"OR"},{"types":["country","political"],"long_name":"United States","short_name":"US"},{"types":["postal_code"],"long_name":"97402","short_name":"97402"},{"types":["postal_code_suffix"],"long_name":"5109","short_name":"5109"}]},"onlineEvent":false,"globalEvent":false,"startTime":"2025-04-10T01:00:00.000Z","endTime":null,"localStartTime":"2025-04-09T18:00:00.000Z","localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":"michael.bacarella@gmail.com","isEvent":true,"eventImageId":null,"eventType":null,"types":["SSC"],"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":0,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2025-03-25T23:50:00.433Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","ignoreRateLimits":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"rsvpCounts":{"yes":3},"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:ycf7uRXCkvwHJ2PSS"},"coauthors":[],"slug":"eugene-acx-meetups-everywhere-spring-2025","title":"Eugene – ACX Meetups Everywhere Spring 2025","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:9WzPxg7HS8ALLQ2Pm":{"_id":"9WzPxg7HS8ALLQ2Pm","__typename":"Revision","htmlHighlight":"<p>This year's Spring ACX Meetup everywhere in Munich.<\/p>\n                <p>Location: Müllerstraße 35, 80469 München; TeamWork Konferenzraum; walk past the courtyard to find the actual apartment building we'll be meeting in – <a href=\"https://plus.codes/https://plus.codes/8FWH4HJ9+7P\">https://plus.codes/8FWH4HJ9+7P<\/a><\/p>\n                <p>Group Link: https://chat.whatsapp.com/JekHeDBFokxLlmceXsYhLv<\/p>\n                <p>Bring snacks if you like<\/p>\n                <p>Contact: acx.organizer.munich@gmail.com <\/p>","plaintextDescription":"This year's Spring ACX Meetup everywhere in Munich.\n\nLocation: Müllerstraße 35, 80469 München; TeamWork Konferenzraum; walk past the courtyard to find the actual apartment building we'll be meeting in – https://plus.codes/8FWH4HJ9+7P\n\nGroup Link: https://chat.whatsapp.com/JekHeDBFokxLlmceXsYhLv\n\nBring snacks if you like\n\nContact: acx.organizer.munich@gmail.com","wordCount":41,"version":"1.0.0"},"SocialPreviewType:QXcQsQyf25836Mg2w":{"_id":"QXcQsQyf25836Mg2w","__typename":"SocialPreviewType","imageUrl":""},"User:n4jmKKGNFbtkMLxLd":{"_id":"n4jmKKGNFbtkMLxLd","__typename":"User","profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"organizer","createdAt":"2024-08-29T18:14:18.071Z","username":"organizer","displayName":"Organizer","previousDisplayName":null,"fullName":null,"karma":0,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":1,"commentCount":0,"sequenceCount":0,"afPostCount":0,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Post:QXcQsQyf25836Mg2w":{"_id":"QXcQsQyf25836Mg2w","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:9WzPxg7HS8ALLQ2Pm"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"socialPreviewData":{"__ref":"SocialPreviewType:QXcQsQyf25836Mg2w"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2025-03-26T00:11:53.202Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":null,"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"9WzPxg7HS8ALLQ2Pm","commentCount":0,"voteCount":1,"baseScore":1,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":1,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0017532709753140807,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2025-03-26T00:11:53.202Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"n4jmKKGNFbtkMLxLd","location":"Munich","googleLocation":{"types":["establishment","point_of_interest"],"geometry":{"location":{"lat":48.1306723,"lng":11.5693182},"viewport":{"northeast":{"lat":48.1320212802915,"lng":11.5706671802915},"southwest":{"lat":48.1293233197085,"lng":11.5679692197085}},"location_type":"ROOFTOP"},"place_id":"ChIJ5Z38IQDfnUcRHHc_ZeeNdr0","plus_code":{"global_code":"8FWH4HJ9+7P","compound_code":"4HJ9+7P Munich, Germany"},"formatted_address":"Müllerstraße 35, 80469 München, Germany","navigation_points":[{"location":{"latitude":48.1309818,"longitude":11.5695186}}],"address_components":[{"types":["street_number"],"long_name":"35","short_name":"35"},{"types":["route"],"long_name":"Müllerstraße","short_name":"Müllerstraße"},{"types":["political","sublocality","sublocality_level_1"],"long_name":"Ludwigsvorstadt-Isarvorstadt","short_name":"Ludwigsvorstadt-Isarvorstadt"},{"types":["locality","political"],"long_name":"München","short_name":"München"},{"types":["administrative_area_level_3","political"],"long_name":"Kreisfreie Stadt München","short_name":"Kreisfreie Stadt München"},{"types":["administrative_area_level_2","political"],"long_name":"Oberbayern","short_name":"Oberbayern"},{"types":["administrative_area_level_1","political"],"long_name":"Bayern","short_name":"BY"},{"types":["country","political"],"long_name":"Germany","short_name":"DE"},{"types":["postal_code"],"long_name":"80469","short_name":"80469"}]},"onlineEvent":false,"globalEvent":false,"startTime":"2025-04-10T14:00:00.000Z","endTime":null,"localStartTime":"2025-04-10T16:00:00.000Z","localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":"acx.organizer.munich@gmail.com","isEvent":true,"eventImageId":null,"eventType":null,"types":["SSC"],"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":0,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2025-03-25T23:50:29.534Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","ignoreRateLimits":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"rsvpCounts":{"yes":1,"maybe":1},"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:n4jmKKGNFbtkMLxLd"},"coauthors":[],"slug":"munich-acx-meetups-everywhere-spring-2025","title":"Munich – ACX Meetups Everywhere Spring 2025","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"User:nmk3nLpQE89dMRzzN":{"_id":"nmk3nLpQE89dMRzzN","__typename":"User","slug":"eliezer_yudkowsky","createdAt":"2009-02-23T21:58:56.739Z","username":"Eliezer_Yudkowsky","displayName":"Eliezer Yudkowsky","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":148674,"afKarma":1884,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":951,"commentCount":7677,"sequenceCount":40,"afPostCount":18,"afCommentCount":120,"spamRiskScore":1,"tagRevisionCount":3803,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:5g5TkQTe9rmPS5vvM_contents":{"_id":"5g5TkQTe9rmPS5vvM_contents","__typename":"Revision","version":"1.9.0","updateType":"minor","editedAt":"2020-07-01T21:50:13.355Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.<\/p><p>It is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin.<\/p><\/body><\/html>","commitMessage":"","wordCount":87,"htmlHighlight":"<html><head><\/head><body><p>This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.<\/p><p>It is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin.<\/p><\/body><\/html>","plaintextDescription":"This, the first book of \"Rationality: AI to Zombies\" (also known as \"The Sequences\"), begins with cognitive bias. The rest of the book won’t stick to just this topic; bad habits and bad ideas matter, even when they arise from our minds’ contents as opposed to our minds’ structure.\n\nIt is cognitive bias, however, that provides the clearest and most direct glimpse into the stuff of our psychology, into the shape of our heuristics and the logic of our limitations. It is with bias that we will begin."},"Collection:oneQyj4pw77ynzwAF":{"_id":"oneQyj4pw77ynzwAF","__typename":"Collection","title":"Rationality: A-Z"},"Sequence:5g5TkQTe9rmPS5vvM":{"_id":"5g5TkQTe9rmPS5vvM","__typename":"Sequence","createdAt":"2017-08-24T01:49:39.814Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:5g5TkQTe9rmPS5vvM_contents"},"gridImageId":"sequencesgrid/wwkkaskmbcajjogyv1hu","bannerImageId":"sequences/bkywjoighcyelqiphpom","canonicalCollectionSlug":"rationality","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":504,"userProfileOrder":null,"af":false,"postsCount":12,"readPostsCount":2,"title":"Predictably Wrong","canonicalCollection":{"__ref":"Collection:oneQyj4pw77ynzwAF"}},"User:qgdGA4ZEyW7zNdK84":{"_id":"qgdGA4ZEyW7zNdK84","__typename":"User","slug":"ruby","createdAt":"2014-04-03T03:38:23.914Z","username":"Ruby","displayName":"Ruby","profileImageId":null,"previousDisplayName":null,"fullName":"Ruben Bloom","karma":14168,"afKarma":137,"deleted":false,"isAdmin":true,"htmlBio":"<p>LessWrong Team<\/p><p>&nbsp;<\/p><p>I have signed no contracts or agreements whose existence I cannot mention.<\/p>","jobTitle":null,"organization":null,"postCount":171,"commentCount":1647,"sequenceCount":11,"afPostCount":3,"afCommentCount":33,"spamRiskScore":1,"tagRevisionCount":1003,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:NBDFAKt3GbFwnwzQF_contents":{"_id":"NBDFAKt3GbFwnwzQF_contents","__typename":"Revision","version":"1.14.0","updateType":"minor","editedAt":"2022-07-14T00:23:22.928Z","userId":"qgdGA4ZEyW7zNdK84","html":"<p><i>Part 1 of 6 from the <\/i><a href=\"https://www.lesswrong.com/highlights\"><i>Sequence Highlights<\/i><\/a><i>.&nbsp;<\/i><\/p><p>Humans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality.&nbsp;<\/p>","commitMessage":"","wordCount":43,"htmlHighlight":"<p><i>Part 1 of 6 from the <\/i><a href=\"https://www.lesswrong.com/highlights\"><i>Sequence Highlights<\/i><\/a><i>.&nbsp;<\/i><\/p><p>Humans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality.&nbsp;<\/p>","plaintextDescription":"Part 1 of 6 from the Sequence Highlights. \n\nHumans can not only think, but think about our own thinking. This makes it possible for us to recognize the shortcomings of our default reasoning and work to improve it – the project of human rationality. "},"Collection:62bf5f5dc581cd211cc67d49":{"_id":"62bf5f5dc581cd211cc67d49","__typename":"Collection","title":"Highlights from the Sequences"},"Sequence:NBDFAKt3GbFwnwzQF":{"_id":"NBDFAKt3GbFwnwzQF","__typename":"Sequence","createdAt":"2022-07-01T22:07:11.265Z","userId":"qgdGA4ZEyW7zNdK84","user":{"__ref":"User:qgdGA4ZEyW7zNdK84"},"contents":{"__ref":"Revision:NBDFAKt3GbFwnwzQF_contents"},"gridImageId":"sequencesgrid/vuzt0hjdrboxywfd4wbt","bannerImageId":"sequences/rdl8pwokejuqyxipg6vx","canonicalCollectionSlug":"highlights","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":true,"noindex":false,"curatedOrder":502,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":2,"title":"Thinking Better on Purpose","canonicalCollection":{"__ref":"Collection:62bf5f5dc581cd211cc67d49"}},"Revision:PtgH6ALi5CoJnPmGS_contents":{"_id":"PtgH6ALi5CoJnPmGS_contents","__typename":"Revision","version":"1.8.0","updateType":"minor","editedAt":"2022-10-14T21:21:45.337Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Harry: You can't DO that!<\/p><p>Minerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—<\/p><p>Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?<\/p><p>Minerva: Magic.<\/p><p>Harry: Magic isn't enough to do that! You'd have to be a god!<\/p><p>—Harry's first encounter with magic<\/p>","commitMessage":"","wordCount":82,"htmlHighlight":"<p>Harry: You can't DO that!<\/p><p>Minerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—<\/p><p>Harry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?<\/p><p>Minerva: Magic.<\/p><p>Harry: Magic isn't enough to do that! You'd have to be a god!<\/p><p>—Harry's first encounter with magic<\/p>","plaintextDescription":"Harry: You can't DO that!\n\nMinerva McGonagall: It's only a transfiguration; an animagus transformation, to be exact—\n\nHarry: You turned into a cat! A SMALL cat! You violated Conservation of Energy! That's not just an arbitrary rule – rejecting it destroys unitarity and then you get FTL signaling! And cats are COMPLICATED! How can you go on thinking using a cat-sized brain?\n\nMinerva: Magic.\n\nHarry: Magic isn't enough to do that! You'd have to be a god!\n\n—Harry's first encounter with magic"},"Collection:ywQvGBSojSQZTMpLh":{"_id":"ywQvGBSojSQZTMpLh","__typename":"Collection","title":"Harry Potter and the Methods of Rationality"},"Sequence:PtgH6ALi5CoJnPmGS":{"_id":"PtgH6ALi5CoJnPmGS","__typename":"Sequence","createdAt":"2017-08-23T21:44:40.795Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:PtgH6ALi5CoJnPmGS_contents"},"gridImageId":"sequences/i9dkgkhw14vwar63i4xn","bannerImageId":"sequences/cjcnbiwocxsxp1qnoywt","canonicalCollectionSlug":"hpmor","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":502,"userProfileOrder":null,"af":false,"postsCount":21,"readPostsCount":0,"title":"The Methods of Rationality","canonicalCollection":{"__ref":"Collection:ywQvGBSojSQZTMpLh"}},"User:BCmzFRdQhqLPREvat":{"_id":"BCmzFRdQhqLPREvat","__typename":"User","slug":"ricraz","createdAt":"2013-07-14T15:42:06.397Z","username":"ricraz","displayName":"Richard_Ngo","profileImageId":null,"previousDisplayName":null,"fullName":"Richard Ngo","karma":18378,"afKarma":2768,"deleted":false,"isAdmin":false,"htmlBio":"<p>Formerly alignment and governance researcher at DeepMind and OpenAI. Now independent.<\/p>","jobTitle":null,"organization":null,"postCount":166,"commentCount":1051,"sequenceCount":7,"afPostCount":54,"afCommentCount":364,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:mzgtmmTKKn5MuCzFJ_contents":{"_id":"mzgtmmTKKn5MuCzFJ_contents","__typename":"Revision","version":"1.4.0","updateType":"minor","editedAt":"2022-12-24T07:52:34.985Z","userId":"grecHJcgkb3KW5wnM","html":"<p>In this report (also <a href=\"https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing\">available here as a PDF<\/a>) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles.<\/p>","commitMessage":"","wordCount":138,"htmlHighlight":"<p>In this report (also <a href=\"https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view?usp=sharing\">available here as a PDF<\/a>) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles.<\/p>","plaintextDescription":"In this report (also available here as a PDF) I have attempted to put together the most compelling case for why the development of artificial general intelligence (AGI) might pose an existential threat. It stems from my dissatisfaction with existing arguments about the potential risks from AGI. Early work tends to be less relevant in the context of modern machine learning; more recent work is scattered and brief. I originally intended to just summarise other people's arguments, but as this report has grown, it's become more representative of my own views and less representative of anyone else's. So while it covers the standard ideas, I also think that it provides a new perspective on how to think about AGI - one which doesn't take any previous claims for granted, but attempts to work them out from first principles."},"Sequence:mzgtmmTKKn5MuCzFJ":{"_id":"mzgtmmTKKn5MuCzFJ","__typename":"Sequence","createdAt":"2020-09-28T13:58:47.550Z","userId":"BCmzFRdQhqLPREvat","user":{"__ref":"User:BCmzFRdQhqLPREvat"},"contents":{"__ref":"Revision:mzgtmmTKKn5MuCzFJ_contents"},"gridImageId":"sequencesgrid/r68kkaexxymt3ckkc6pp","bannerImageId":"sequences/zxck6do8omxqiussiz5k","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":499,"userProfileOrder":1,"af":true,"postsCount":7,"readPostsCount":0,"title":"AGI safety from first principles","canonicalCollection":null},"User:XgYW5s8njaYrtyP7q":{"_id":"XgYW5s8njaYrtyP7q","__typename":"User","slug":"scottalexander","createdAt":"2009-02-28T15:53:46.032Z","username":"Yvain","displayName":"Scott Alexander","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":43998,"afKarma":93,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":217,"commentCount":1582,"sequenceCount":15,"afPostCount":1,"afCommentCount":2,"spamRiskScore":1,"tagRevisionCount":19,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:XsMTxdQ6fprAQMoKi_contents":{"_id":"XsMTxdQ6fprAQMoKi_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-07-01T21:46:04.937Z","userId":"XtphY3uYHwruKqDyG","html":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","commitMessage":"","wordCount":20,"htmlHighlight":"<html><head><\/head><body><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.<\/p><\/body><\/html>","plaintextDescription":"A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them."},"Collection:2izXHCrmJ684AnZ5X":{"_id":"2izXHCrmJ684AnZ5X","__typename":"Collection","title":"The Codex"},"Sequence:XsMTxdQ6fprAQMoKi":{"_id":"XsMTxdQ6fprAQMoKi","__typename":"Sequence","createdAt":"2017-08-24T01:21:12.377Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:XsMTxdQ6fprAQMoKi_contents"},"gridImageId":"sequencesgrid/rfpef83ejiwbsi1pmroz","bannerImageId":"sequences/i345prxcdiiwgczlrsya","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":499,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":1,"title":"Argument and Analysis","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"User:Q7NW4XaWQmfPfdcFj":{"_id":"Q7NW4XaWQmfPfdcFj","__typename":"User","slug":"abramdemski","createdAt":"2009-03-12T06:07:25.510Z","username":"abramdemski","displayName":"abramdemski","profileImageId":null,"previousDisplayName":null,"fullName":"Abram Demski","karma":19298,"afKarma":3719,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":223,"commentCount":2060,"sequenceCount":9,"afPostCount":101,"afCommentCount":656,"spamRiskScore":1,"tagRevisionCount":90,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:Rm6oQRJJmhGCcLvxh_contents":{"_id":"Rm6oQRJJmhGCcLvxh_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2019-11-28T08:22:39.871Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency.<\/p>","commitMessage":null,"wordCount":20,"htmlHighlight":"<p>This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency.<\/p>","plaintextDescription":"This is a sequence by Scott Garrabrant and Abram Demski on one current way of thinking about alignment: Embedded Agency."},"Sequence:Rm6oQRJJmhGCcLvxh":{"_id":"Rm6oQRJJmhGCcLvxh","__typename":"Sequence","createdAt":"2018-10-29T13:26:42.043Z","userId":"Q7NW4XaWQmfPfdcFj","user":{"__ref":"User:Q7NW4XaWQmfPfdcFj"},"contents":{"__ref":"Revision:Rm6oQRJJmhGCcLvxh_contents"},"gridImageId":"sequencesgrid/mxpqfzoorr921qviypmq","bannerImageId":"sequences/eoxmiqgdxndzkbhsws1z","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":495,"userProfileOrder":null,"af":true,"postsCount":7,"readPostsCount":0,"title":"Embedded Agency","canonicalCollection":null},"User:2aoRX3ookcCozcb3m":{"_id":"2aoRX3ookcCozcb3m","__typename":"User","slug":"robbbb","createdAt":"2012-08-10T00:50:11.669Z","username":"RobbBB","displayName":"Rob Bensinger","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":22015,"afKarma":1379,"deleted":false,"isAdmin":true,"htmlBio":"<p>Communications @ MIRI. Unless otherwise indicated, my posts and comments here reflect my own views, and not necessarily my employer's. (Though we agree about an awful lot.)<\/p>","jobTitle":null,"organization":null,"postCount":124,"commentCount":2215,"sequenceCount":5,"afPostCount":12,"afCommentCount":189,"spamRiskScore":1,"tagRevisionCount":144,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:v55BhXbpJuaExkpcD_contents":{"_id":"v55BhXbpJuaExkpcD_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-06-16T04:35:35.951Z","userId":"2aoRX3ookcCozcb3m","html":"<p>A collection of MIRI write-ups and conversations about alignment released in 2022, following the <a href=\"https://www.lesswrong.com/s/n945eovrA3oDueqtq\">Late 2021 MIRI Conversations<\/a>.<\/p>","commitMessage":"","wordCount":18,"htmlHighlight":"<p>A collection of MIRI write-ups and conversations about alignment released in 2022, following the <a href=\"https://www.lesswrong.com/s/n945eovrA3oDueqtq\">Late 2021 MIRI Conversations<\/a>.<\/p>","plaintextDescription":"A collection of MIRI write-ups and conversations about alignment released in 2022, following the Late 2021 MIRI Conversations."},"Sequence:v55BhXbpJuaExkpcD":{"_id":"v55BhXbpJuaExkpcD","__typename":"Sequence","createdAt":"2022-06-15T13:22:48.792Z","userId":"2aoRX3ookcCozcb3m","user":{"__ref":"User:2aoRX3ookcCozcb3m"},"contents":{"__ref":"Revision:v55BhXbpJuaExkpcD_contents"},"gridImageId":"sequencesgrid/hxbqvswdmhyoomidbpyu","bannerImageId":"sequences/bnagpl4ipkzivsuvj8di","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":494,"userProfileOrder":null,"af":true,"postsCount":23,"readPostsCount":0,"title":"2022 MIRI Alignment Discussion","canonicalCollection":null},"Revision:n945eovrA3oDueqtq_contents":{"_id":"n945eovrA3oDueqtq_contents","__typename":"Revision","version":"1.7.0","updateType":"minor","editedAt":"2022-07-06T23:27:31.966Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.<\/p><p>Short summaries of each post, and links to audio versions, are available <a href=\"https://intelligence.org/late-2021-miri-conversations/\">here<\/a>. There are also two related posts released shortly before this sequence:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/CpvyhFy9WvCNsifkY/discussion-with-eliezer-yudkowsky-on-agi-interventions\">Discussion with Eliezer Yudkowsky on AGI Interventions<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/cCMihiwtZx7kdcKgt/comments-on-carlsmith-s-is-power-seeking-ai-an-existential\">Comments [by Nate Soares] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"<\/a><\/li><\/ul><p>Rob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.<\/p><p>⠀<\/p>","commitMessage":"","wordCount":90,"htmlHighlight":"<p>This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.<\/p><p>Short summaries of each post, and links to audio versions, are available <a href=\"https://intelligence.org/late-2021-miri-conversations/\">here<\/a>. There are also two related posts released shortly before this sequence:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/CpvyhFy9WvCNsifkY/discussion-with-eliezer-yudkowsky-on-agi-interventions\">Discussion with Eliezer Yudkowsky on AGI Interventions<\/a><\/li><li><a href=\"https://www.lesswrong.com/posts/cCMihiwtZx7kdcKgt/comments-on-carlsmith-s-is-power-seeking-ai-an-existential\">Comments [by Nate Soares] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"<\/a><\/li><\/ul><p>Rob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.<\/p><p>⠀<\/p>","plaintextDescription":"This sequence is a (chronological) series of chatroom conversation logs about artificial general intelligence. A large number of topics are covered, beginning with conversations related to alignment difficulty.\n\nShort summaries of each post, and links to audio versions, are available here. There are also two related posts released shortly before this sequence:\n\n * Discussion with Eliezer Yudkowsky on AGI Interventions\n * Comments [by Nate Soares] on Joe Carlsmith's \"Is power-seeking AI an existential risk?\"\n\nRob Bensinger edited and posted this sequence, and Matthew Graves helped with much of the formatting.\n\n⠀"},"Sequence:n945eovrA3oDueqtq":{"_id":"n945eovrA3oDueqtq","__typename":"Sequence","createdAt":"2021-11-15T21:08:28.070Z","userId":"2aoRX3ookcCozcb3m","user":{"__ref":"User:2aoRX3ookcCozcb3m"},"contents":{"__ref":"Revision:n945eovrA3oDueqtq_contents"},"gridImageId":"sequencesgrid/gpk2pxurl1yymecllfoo","bannerImageId":"sequences/zenshq6ta1cmqiaisfka","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":400,"userProfileOrder":null,"af":true,"postsCount":15,"readPostsCount":0,"title":"2021 MIRI Conversations","canonicalCollection":null},"User:r38pkCm7wF4M44MDQ":{"_id":"r38pkCm7wF4M44MDQ","__typename":"User","slug":"raemon","createdAt":"2010-09-09T02:09:20.629Z","username":"Raemon","displayName":"Raemon","profileImageId":null,"previousDisplayName":null,"fullName":"Raymond Arnold","karma":55921,"afKarma":718,"deleted":false,"isAdmin":true,"htmlBio":"<p>LessWrong team member / moderator. I've been a LessWrong organizer since 2011, with roughly equal focus on the cultural, practical and intellectual aspects of the community. My first project was creating the Secular Solstice and helping groups across the world run their own version of it. More recently I've been interested in improving my own epistemic standards and helping others to do so as well.<\/p>","jobTitle":null,"organization":null,"postCount":475,"commentCount":8285,"sequenceCount":28,"afPostCount":3,"afCommentCount":214,"spamRiskScore":1,"tagRevisionCount":304,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:ZnSMHcWjRx6yT4H92_contents":{"_id":"ZnSMHcWjRx6yT4H92_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2023-05-07T17:41:30.975Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:<\/p><ul><li>Read this sequence of posts before discussing politics on LessWrong.<\/li><li>Generally, be extra careful and charitable when discussing politics.<\/li><li>Recent \"news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.<\/li><li>If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture.<\/li><\/ul>","commitMessage":"","wordCount":136,"htmlHighlight":"<p>Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:<\/p><ul><li>Read this sequence of posts before discussing politics on LessWrong.<\/li><li>Generally, be extra careful and charitable when discussing politics.<\/li><li>Recent \"news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.<\/li><li>If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture.<\/li><\/ul>","plaintextDescription":"Politics is a hard subject to discuss rationally. Correspondingly, LessWrong has a developed a unique set of norms and habits around discussions politics that still allow for dialog while hopefully avoiding many pitfalls. The exact norms are hard to summarize, but approximately they are:\n\n * Read this sequence of posts before discussing politics on LessWrong.\n * Generally, be extra careful and charitable when discussing politics.\n * Recent \"news-driven\" posts (which includes much mainstream politics) will generally not be given much visibility. Moderators don't promote them to the Frontpage, so only longtime LessWrong readers are likely to see them when browsing the site.\n * If you're a new user who came specifically to weigh in on some recent political discourse, I recommend instead focusing on other topics until you've gotten a better feel for LessWrong discussion culture."},"Sequence:ZnSMHcWjRx6yT4H92":{"_id":"ZnSMHcWjRx6yT4H92","__typename":"Sequence","createdAt":"2021-08-27T19:12:38.957Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:ZnSMHcWjRx6yT4H92_contents"},"gridImageId":"sequencesgrid/qu5jdoyzz4jov7siczag","bannerImageId":"sequences/vt1dmuiohcsfxdvsfear","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":true,"noindex":false,"curatedOrder":101,"userProfileOrder":null,"af":false,"postsCount":13,"readPostsCount":0,"title":"LessWrong Political Prerequisites","canonicalCollection":null},"User:ZQefXso7Pp4nnGPmi":{"_id":"ZQefXso7Pp4nnGPmi","__typename":"User","slug":"diffractor","createdAt":"2017-09-21T23:07:36.656Z","username":"Diffractor","displayName":"Diffractor","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":2282,"afKarma":691,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":68,"commentCount":116,"sequenceCount":2,"afPostCount":69,"afCommentCount":76,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"3oopbgcjYfvN8B2fp"},"Revision:CmrW8fCmSLK7E25sa_contents":{"_id":"CmrW8fCmSLK7E25sa_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2023-03-20T18:26:31.579Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning.&nbsp;<\/p><p>Infra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach.<\/p>","commitMessage":"","wordCount":70,"htmlHighlight":"<p>Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning.&nbsp;<\/p><p>Infra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach.<\/p>","plaintextDescription":"Infra-Bayesianism is a new approach to epistemology / decision theory / reinforcement learning theory, which builds on \"imprecise probability\" to solve the problem of prior misspecification / grain-of-truth / nonrealizability which plagues Bayesianism and Bayesian reinforcement learning. \n\nInfra-Bayesianism also naturally leads to an implementation of UDT, and (more speculatively at this stage) has applications to multi-agent theory, embedded agency and reflection. This sequence lays down the foundations of the approach."},"Sequence:CmrW8fCmSLK7E25sa":{"_id":"CmrW8fCmSLK7E25sa","__typename":"Sequence","createdAt":"2020-08-27T18:48:07.743Z","userId":"ZQefXso7Pp4nnGPmi","user":{"__ref":"User:ZQefXso7Pp4nnGPmi"},"contents":{"__ref":"Revision:CmrW8fCmSLK7E25sa_contents"},"gridImageId":"sequencesgrid/ek5uoqxjn8zl6l9unirr","bannerImageId":"sequences/ttxnyvceytmd5iigtc7z","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":101,"userProfileOrder":null,"af":true,"postsCount":16,"readPostsCount":0,"title":"Infra-Bayesianism","canonicalCollection":null},"User:uuYBzWLiixkbN3s7C":{"_id":"uuYBzWLiixkbN3s7C","__typename":"User","slug":"brienneyudkowsky","createdAt":"2013-05-13T00:07:08.935Z","username":"BrienneYudkowsky","displayName":"LoganStrohl","profileImageId":null,"previousDisplayName":null,"fullName":"Logan Strohl","karma":6453,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":60,"commentCount":304,"sequenceCount":3,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"EQNTWXLKMeWMp2FQS"},"Revision:evLkoqsbi79AnM5sz_contents":{"_id":"evLkoqsbi79AnM5sz_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2022-10-12T18:06:39.660Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”<\/p>","commitMessage":"","wordCount":66,"htmlHighlight":"<p>Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”<\/p>","plaintextDescription":"Here is what will happen in this sequence: I will pick out the concepts that seem central to my understanding of naturalism; I will name them with words; and I will do my best to tell you what I mean by those words. My only goal in this sequence is to communicate what I mean by the sentence, “Knowing the territory takes patient and direct observation.”"},"Sequence:evLkoqsbi79AnM5sz":{"_id":"evLkoqsbi79AnM5sz","__typename":"Sequence","createdAt":"2022-02-13T00:38:57.581Z","userId":"uuYBzWLiixkbN3s7C","user":{"__ref":"User:uuYBzWLiixkbN3s7C"},"contents":{"__ref":"Revision:evLkoqsbi79AnM5sz_contents"},"gridImageId":"sequencesgrid/xhjq89g5vufbwx0df0uf","bannerImageId":"sequences/doefofloenqkxfx0j1px","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":100,"userProfileOrder":null,"af":false,"postsCount":8,"readPostsCount":0,"title":"Intro to Naturalism","canonicalCollection":null},"User:xSfc2APSi8WzFxp7i":{"_id":"xSfc2APSi8WzFxp7i","__typename":"User","slug":"so8res","createdAt":"2012-01-10T05:50:18.713Z","username":"So8res","displayName":"So8res","profileImageId":null,"previousDisplayName":null,"fullName":"Nate Soares","karma":16442,"afKarma":1945,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":148,"commentCount":529,"sequenceCount":2,"afPostCount":32,"afCommentCount":28,"spamRiskScore":1,"tagRevisionCount":1331,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:pFatcKW3JJhTSxqAF_contents":{"_id":"pFatcKW3JJhTSxqAF_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-03-03T23:50:46.013Z","userId":"qgdGA4ZEyW7zNdK84","html":"<blockquote><p>My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges <i>and<\/i> reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.<\/p><\/blockquote><p>A sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.<\/p><blockquote><p>When all is said and done, Nature will not judge us by our actions; we will be measured only by what <i>actually happens.<\/i> Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.<\/p><\/blockquote><p>Originally posted on <a href=\"https://mindingourway.com/guilt/\">Minding Our Way<\/a>. There's also an <a href=\"https://pod.link/1498321446\">official audio version<\/a>.<\/p>","commitMessage":"","wordCount":208,"htmlHighlight":"<blockquote><p>My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges <i>and<\/i> reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.<\/p><\/blockquote><p>A sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.<\/p><blockquote><p>When all is said and done, Nature will not judge us by our actions; we will be measured only by what <i>actually happens.<\/i> Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.<\/p><\/blockquote><p>Originally posted on <a href=\"https://mindingourway.com/guilt/\">Minding Our Way<\/a>. There's also an <a href=\"https://pod.link/1498321446\">official audio version<\/a>.<\/p>","plaintextDescription":"> My goal is to help people remove guilt-based motivation entirely, and replace it with intrinsic motivation. I'm aiming to both reduce the frequency of Netflix binges and reduce the bad feelings that follow. I'm aiming to help people feel like they're still worthwhile human beings if they stop working before they literally drop.\n\nA sequence about replacing guilt with other feelings and finding better ways to self-motivate, so that you can build a better future without falling apart in the process.\n\n> When all is said and done, Nature will not judge us by our actions; we will be measured only by what actually happens. Our goal, in the end, is to ensure that the timeless history of our universe is one that is filled with whatever it is we're fighting for. For me, at least, this is the underlying driver that takes the place of guilt: Once we have learned our lessons from the past, there is no reason to wrack ourselves with guilt. All we need to do, in any given moment, is look upon the actions available to us, consider, and take whichever one seems most likely to lead to a future full of light.\n\nOriginally posted on Minding Our Way. There's also an official audio version."},"Sequence:pFatcKW3JJhTSxqAF":{"_id":"pFatcKW3JJhTSxqAF","__typename":"Sequence","createdAt":"2022-03-02T07:22:26.188Z","userId":"xSfc2APSi8WzFxp7i","user":{"__ref":"User:xSfc2APSi8WzFxp7i"},"contents":{"__ref":"Revision:pFatcKW3JJhTSxqAF_contents"},"gridImageId":"sequencesgrid/m0lpxsua2jmtwbmwlttp","bannerImageId":"sequences/ojux53txivllnxot2xok","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":50,"userProfileOrder":null,"af":false,"postsCount":46,"readPostsCount":0,"title":"Replacing Guilt","canonicalCollection":null},"User:AThTtkDufXp3rmMDa":{"_id":"AThTtkDufXp3rmMDa","__typename":"User","slug":"evhub","createdAt":"2017-01-17T06:05:22.405Z","username":"evhub","displayName":"evhub","profileImageId":null,"previousDisplayName":null,"fullName":"Evan Hubinger","karma":14057,"afKarma":4529,"deleted":false,"isAdmin":false,"htmlBio":"<p>Evan Hubinger (he/him/his) (<a href=\"mailto:evanjhub@gmail.com\">evanjhub@gmail.com<\/a>)<\/p><p>Head of <a href=\"https://www.alignmentforum.org/posts/EPDSdXr8YbsDkgsDG/introducing-alignment-stress-testing-at-anthropic\">Alignment Stress-Testing<\/a> at <a href=\"https://www.anthropic.com/\">Anthropic<\/a>. My posts and comments are my own and do not represent Anthropic's positions, policies, strategies, or opinions.<\/p><p>Previously: <a href=\"https://intelligence.org/\">MIRI<\/a>, OpenAI<\/p><p>See: “<a href=\"https://www.lesswrong.com/posts/7jn5aDadcMH6sFeJe/why-i-m-joining-anthropic\">Why I'm joining Anthropic<\/a>”<\/p><p>Selected work:<\/p><ul><li>“<a href=\"https://www.alignmentforum.org/posts/wSKPuBfgkkqfTpmWJ/auditing-language-models-for-hidden-objectives\">Auditing language models for hidden objectives<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/posts/njAZwT8nkHnjipJku/alignment-faking-in-large-language-models\">Alignment faking in large language models<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/posts/ZAsJv7xijKTfZkMtr/sleeper-agents-training-deceptive-llms-that-persist-through\">Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training<\/a>”<\/li><li>“<a href=\"https://www.lesswrong.com/s/n3utvGrgC2SGi9xQX\">Conditioning Predictive Models<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/posts/fRsjBseRuvRhMPPE5/an-overview-of-11-proposals-for-building-safe-advanced-ai\">An overview of 11 proposals for building safe advanced AI<\/a>”<\/li><li>“<a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB\">Risks from Learned Optimization<\/a>”<\/li><\/ul>","jobTitle":null,"organization":null,"postCount":72,"commentCount":776,"sequenceCount":1,"afPostCount":67,"afCommentCount":545,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Revision:n3utvGrgC2SGi9xQX_contents":{"_id":"n3utvGrgC2SGi9xQX_contents","__typename":"Revision","version":"0.4.0","updateType":"minor","editedAt":"2024-01-19T06:56:12.155Z","userId":"XtphY3uYHwruKqDyG","html":"<p><em>This is the Conditioning Predictive Models Sequence based on the paper “<a href=\"https://arxiv.org/abs/2302.00805\">Conditioning Predictive Models: Risks and Strategies<\/a>” by Evan Hubinger, Adam Jermyn, Johannes Treutlein, Rubi Hudson, and Kate Woolverton. Each post in the sequence corresponds to a different section of the paper.<\/em><\/p>\n<h1>Abstract<\/h1>\n<p>Our intention is to provide a definitive reference on what it would take to safely make use of generative/predictive models in the absence of a solution to the <a href=\"https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\">Eliciting Latent Knowledge<\/a> problem.<\/p>\n<p>Furthermore, we believe that large language models can be understood as such predictive models of the world, and that such a conceptualization raises significant opportunities for their safe yet powerful use via carefully conditioning them to predict desirable outputs.<\/p>\n<p>Unfortunately, such approaches also raise a variety of potentially fatal safety problems, particularly surrounding situations where predictive models predict the output of other AI systems, potentially unbeknownst to us. There are numerous potential solutions to such problems, however, primarily via carefully conditioning models to predict the things we want—e.g. humans—rather than the things we don’t—e.g. malign AIs.<\/p>\n<p>Furthermore, due to the simplicity of the prediction objective, we believe that predictive models present the easiest <a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/pL56xPoniLvtMDQ4J\">inner alignment<\/a> problem that we are aware of.<\/p>\n<p>As a result, we think that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models.<\/p>\n","commitMessage":"","wordCount":229,"htmlHighlight":"<p><em>This is the Conditioning Predictive Models Sequence based on the paper “<a href=\"https://arxiv.org/abs/2302.00805\">Conditioning Predictive Models: Risks and Strategies<\/a>” by Evan Hubinger, Adam Jermyn, Johannes Treutlein, Rubi Hudson, and Kate Woolverton. Each post in the sequence corresponds to a different section of the paper.<\/em><\/p>\n<h1>Abstract<\/h1>\n<p>Our intention is to provide a definitive reference on what it would take to safely make use of generative/predictive models in the absence of a solution to the <a href=\"https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge\">Eliciting Latent Knowledge<\/a> problem.<\/p>\n<p>Furthermore, we believe that large language models can be understood as such predictive models of the world, and that such a conceptualization raises significant opportunities for their safe yet powerful use via carefully conditioning them to predict desirable outputs.<\/p>\n<p>Unfortunately, such approaches also raise a variety of potentially fatal safety problems, particularly surrounding situations where predictive models predict the output of other AI systems, potentially unbeknownst to us. There are numerous potential solutions to such problems, however, primarily via carefully conditioning models to predict the things we want—e.g. humans—rather than the things we don’t—e.g. malign AIs.<\/p>\n<p>Furthermore, due to the simplicity of the prediction objective, we believe that predictive models present the easiest <a href=\"https://www.alignmentforum.org/s/r9tYkB2a8Fp4DN8yB/p/pL56xPoniLvtMDQ4J\">inner alignment<\/a> problem that we are aware of.<\/p>\n<p>As a result, we think that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models.<\/p>","plaintextDescription":"This is the Conditioning Predictive Models Sequence based on the paper “Conditioning Predictive Models: Risks and Strategies” by Evan Hubinger, Adam Jermyn, Johannes Treutlein, Rubi Hudson, and Kate Woolverton. Each post in the sequence corresponds to a different section of the paper.\n\n\nAbstract\nOur intention is to provide a definitive reference on what it would take to safely make use of generative/predictive models in the absence of a solution to the Eliciting Latent Knowledge problem.\n\nFurthermore, we believe that large language models can be understood as such predictive models of the world, and that such a conceptualization raises significant opportunities for their safe yet powerful use via carefully conditioning them to predict desirable outputs.\n\nUnfortunately, such approaches also raise a variety of potentially fatal safety problems, particularly surrounding situations where predictive models predict the output of other AI systems, potentially unbeknownst to us. There are numerous potential solutions to such problems, however, primarily via carefully conditioning models to predict the things we want—e.g. humans—rather than the things we don’t—e.g. malign AIs.\n\nFurthermore, due to the simplicity of the prediction objective, we believe that predictive models present the easiest inner alignment problem that we are aware of.\n\nAs a result, we think that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models."},"Sequence:n3utvGrgC2SGi9xQX":{"_id":"n3utvGrgC2SGi9xQX","__typename":"Sequence","createdAt":"2023-02-01T20:45:11.592Z","userId":"AThTtkDufXp3rmMDa","user":{"__ref":"User:AThTtkDufXp3rmMDa"},"contents":{"__ref":"Revision:n3utvGrgC2SGi9xQX_contents"},"gridImageId":"sequencesgrid/gdwaqd3wg9zngxrbwbqm","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":30,"userProfileOrder":null,"af":true,"postsCount":7,"readPostsCount":0,"title":"Conditioning Predictive Models","canonicalCollection":null},"User:pWHLps2yEJTSNNBLk":{"_id":"pWHLps2yEJTSNNBLk","__typename":"User","slug":"janus-1","createdAt":"2021-09-25T11:56:33.908Z","username":"janus","displayName":"janus","profileImageId":null,"previousDisplayName":null,"fullName":"janus","karma":3390,"afKarma":535,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":8,"commentCount":152,"sequenceCount":2,"afPostCount":6,"afCommentCount":51,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:f2YA4eGskeztcJsqT_contents":{"_id":"f2YA4eGskeztcJsqT_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2024-01-19T06:55:25.277Z","userId":"XtphY3uYHwruKqDyG","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:f2YA4eGskeztcJsqT":{"_id":"f2YA4eGskeztcJsqT","__typename":"Sequence","createdAt":"2023-05-19T13:51:20.142Z","userId":"pWHLps2yEJTSNNBLk","user":{"__ref":"User:pWHLps2yEJTSNNBLk"},"contents":{"__ref":"Revision:f2YA4eGskeztcJsqT_contents"},"gridImageId":"sequencesgrid/iwls9nubn9dkangx3q5t","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":25,"userProfileOrder":null,"af":true,"postsCount":6,"readPostsCount":0,"title":"Cyborgism","canonicalCollection":null},"User:wsicf4AeB4yhMyHej":{"_id":"wsicf4AeB4yhMyHej","__typename":"User","slug":"scasper","createdAt":"2019-12-01T05:50:05.417Z","username":"scasper","displayName":"scasper","profileImageId":null,"previousDisplayName":null,"fullName":"Stephen Casper","karma":2005,"afKarma":595,"deleted":false,"isAdmin":false,"htmlBio":"<p><a href=\"https://stephencasper.com/\">https://stephencasper.com/<\/a><\/p>","jobTitle":null,"organization":null,"postCount":40,"commentCount":121,"sequenceCount":1,"afPostCount":27,"afCommentCount":53,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:a6ne2ve5uturEEQK7_contents":{"_id":"a6ne2ve5uturEEQK7_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2024-01-19T06:55:55.626Z","userId":"XtphY3uYHwruKqDyG","html":"<p>Interpretability research is popular, and interpretability tools play a role in almost every agenda for making AI safe. However, for all the interpretability work that exists, there is a significant gap between the research and engineering applications. If one of our main goals for interpretability research is to help us with aligning highly intelligent AI systems in high stakes settings, shouldn’t we be seeing tools that are more helpful on real world problems?<\/p><p>This 12-post sequence argues for taking an engineering approach to interpretability research. And from this lens, it analyzes existing work and proposes directions for moving forward.&nbsp;<\/p>","commitMessage":"","wordCount":99,"htmlHighlight":"<p>Interpretability research is popular, and interpretability tools play a role in almost every agenda for making AI safe. However, for all the interpretability work that exists, there is a significant gap between the research and engineering applications. If one of our main goals for interpretability research is to help us with aligning highly intelligent AI systems in high stakes settings, shouldn’t we be seeing tools that are more helpful on real world problems?<\/p><p>This 12-post sequence argues for taking an engineering approach to interpretability research. And from this lens, it analyzes existing work and proposes directions for moving forward.&nbsp;<\/p>","plaintextDescription":"Interpretability research is popular, and interpretability tools play a role in almost every agenda for making AI safe. However, for all the interpretability work that exists, there is a significant gap between the research and engineering applications. If one of our main goals for interpretability research is to help us with aligning highly intelligent AI systems in high stakes settings, shouldn’t we be seeing tools that are more helpful on real world problems?\n\nThis 12-post sequence argues for taking an engineering approach to interpretability research. And from this lens, it analyzes existing work and proposes directions for moving forward. "},"Sequence:a6ne2ve5uturEEQK7":{"_id":"a6ne2ve5uturEEQK7","__typename":"Sequence","createdAt":"2023-02-09T16:19:47.632Z","userId":"wsicf4AeB4yhMyHej","user":{"__ref":"User:wsicf4AeB4yhMyHej"},"contents":{"__ref":"Revision:a6ne2ve5uturEEQK7_contents"},"gridImageId":"sequencesgrid/o6bsfz6il5u2kep6vksv","bannerImageId":null,"canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":25,"userProfileOrder":null,"af":true,"postsCount":15,"readPostsCount":0,"title":"The Engineer’s Interpretability Sequence","canonicalCollection":null},"Revision:dDMzozPbe4aJRkfTr_contents":{"_id":"dDMzozPbe4aJRkfTr_contents","__typename":"Revision","version":"1.4.0","updateType":"minor","editedAt":"2024-04-19T21:59:04.883Z","userId":"BCmzFRdQhqLPREvat","html":"<p>This sequence collects a number of stories I've written, starting in mid-2023, with a unifying theme of exploring different aspects of possible futures. I find fiction a valuable format for exploring these ideas because it forces concreteness, not only about the future itself, but also about how people (or AIs) experience that future. My fiction is broadly divided into three categories:<\/p><ol><li><a href=\"https://narrativeark.substack.com/t/short-stories\"><u>Traditional short stories<\/u><\/a>, mostly focusing on the human element of the future. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-witness\"><i><u>The Witness<\/u><\/i><\/a>.<\/li><li><a href=\"https://narrativeark.substack.com/t/vignettes-and-fables\"><u>Vignettes and fables<\/u><\/a> in which I explore interesting ideas more directly. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-ants-and-grasshopperhtml\"><i><u>The Ants and the Grasshopper<\/u><\/i><\/a>.<\/li><li>“<a href=\"https://narrativeark.substack.com/t/ai-autofiction\"><u>AI autofiction<\/u><\/a>” in which I describe how the world might look from the perspective of future AIs; these typically assume more technical knowledge. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/succession\"><i><u>Succession<\/u><\/i><\/a><i><u>.<\/u><\/i><\/li><\/ol><p>You can browse each category on my substack using the links above.<\/p>","commitMessage":"","wordCount":142,"htmlHighlight":"<p>This sequence collects a number of stories I've written, starting in mid-2023, with a unifying theme of exploring different aspects of possible futures. I find fiction a valuable format for exploring these ideas because it forces concreteness, not only about the future itself, but also about how people (or AIs) experience that future. My fiction is broadly divided into three categories:<\/p><ol><li><a href=\"https://narrativeark.substack.com/t/short-stories\"><u>Traditional short stories<\/u><\/a>, mostly focusing on the human element of the future. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-witness\"><i><u>The Witness<\/u><\/i><\/a>.<\/li><li><a href=\"https://narrativeark.substack.com/t/vignettes-and-fables\"><u>Vignettes and fables<\/u><\/a> in which I explore interesting ideas more directly. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/the-ants-and-grasshopperhtml\"><i><u>The Ants and the Grasshopper<\/u><\/i><\/a>.<\/li><li>“<a href=\"https://narrativeark.substack.com/t/ai-autofiction\"><u>AI autofiction<\/u><\/a>” in which I describe how the world might look from the perspective of future AIs; these typically assume more technical knowledge. I recommend starting with <a href=\"https://www.narrativeark.xyz/p/succession\"><i><u>Succession<\/u><\/i><\/a><i><u>.<\/u><\/i><\/li><\/ol><p>You can browse each category on my substack using the links above.<\/p>","plaintextDescription":"This sequence collects a number of stories I've written, starting in mid-2023, with a unifying theme of exploring different aspects of possible futures. I find fiction a valuable format for exploring these ideas because it forces concreteness, not only about the future itself, but also about how people (or AIs) experience that future. My fiction is broadly divided into three categories:\n\n 1. Traditional short stories, mostly focusing on the human element of the future. I recommend starting with The Witness.\n 2. Vignettes and fables in which I explore interesting ideas more directly. I recommend starting with The Ants and the Grasshopper.\n 3. “AI autofiction” in which I describe how the world might look from the perspective of future AIs; these typically assume more technical knowledge. I recommend starting with Succession.\n\nYou can browse each category on my substack using the links above."},"Sequence:dDMzozPbe4aJRkfTr":{"_id":"dDMzozPbe4aJRkfTr","__typename":"Sequence","createdAt":"2023-07-06T02:23:42.313Z","userId":"BCmzFRdQhqLPREvat","user":{"__ref":"User:BCmzFRdQhqLPREvat"},"contents":{"__ref":"Revision:dDMzozPbe4aJRkfTr_contents"},"gridImageId":"sequencesgrid/v2gocvypckw2doyt5aex","bannerImageId":"sequences/fetzeibutgxnex2mtn49","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":20,"userProfileOrder":null,"af":false,"postsCount":26,"readPostsCount":3,"title":"Stories","canonicalCollection":null},"User:vRcer5FTqagjMkcDz":{"_id":"vRcer5FTqagjMkcDz","__typename":"User","slug":"steve2152","createdAt":"2018-08-13T02:14:22.599Z","username":"steve2152","displayName":"Steven Byrnes","profileImageId":null,"previousDisplayName":null,"fullName":"Steve Byrnes","karma":21524,"afKarma":3429,"deleted":false,"isAdmin":false,"htmlBio":"<p>I'm an AGI safety / AI alignment researcher in Boston with a particular focus on brain algorithms. Research Fellow at <a href=\"https://astera.org/\">Astera<\/a>. See <a href=\"https://sjbyrnes.com/agi.html\">https://sjbyrnes.com/agi.html<\/a> for a summary of my research and sorted list of writing. Physicist by training. Email: <a href=\"mailto:steven.byrnes@gmail.com\">steven.byrnes@gmail.com<\/a>. <a href=\"https://www.admonymous.co/steve47285\">Leave me anonymous feedback here<\/a><u>. I’m also at:<\/u> <a href=\"https://www.greaterwrong.com/users/steve2152?show=posts&amp;format=rss\"><u>RSS feed<\/u><\/a>, <a href=\"https://x.com/steve47285\"><u>X/Twitter<\/u><\/a>, <a href=\"https://bsky.app/profile/stevebyrnes.bsky.social\"><u>Bluesky<\/u><\/a>, <a href=\"https://www.linkedin.com/in/steven-byrnes-005a304/\"><u>LinkedIn<\/u><\/a>, and more at <a href=\"https://sjbyrnes.com/\">my website<\/a>.<\/p>","jobTitle":null,"organization":null,"postCount":158,"commentCount":2325,"sequenceCount":3,"afPostCount":64,"afCommentCount":573,"spamRiskScore":1,"tagRevisionCount":4,"reviewedByUserId":"3oopbgcjYfvN8B2fp"},"Revision:6uDBPacS6zDipqbZ9_contents":{"_id":"6uDBPacS6zDipqbZ9_contents","__typename":"Revision","version":"0.17.0","updateType":"minor","editedAt":"2024-12-06T14:30:43.955Z","userId":"vRcer5FTqagjMkcDz","html":"<p>Let’s say a thought pops into your mind: “I could open the window right now”. Maybe you then immediately stand up and go open the window. Or maybe you don’t. (“Nah, I’ll keep it closed,” you might say to yourself.) I claim that there’s a final-common-pathway signal in your brain that cleaves those two possibilities: when this special signal is positive, then the current “thought” will stick around, and potentially lead to actions and/or direct-follow-up thoughts; and when this signal is negative, then the current “thought” will get thrown out, and your brain will go fishing (partly randomly) for a new thought to replace it. I call this final-common-pathway signal by the name&nbsp;<strong>“valence”<\/strong>. Thus, the “valence” of a “thought” is roughly the extent to which the thought feels demotivating / aversive (negative valence) versus motivating / appealing (positive valence).<\/p><p>I claim that valence plays an absolutely central role in the brain—I think it’s one of the most important ingredients in the brain’s Model-Based Reinforcement Learning system, which in turn is one of the most important algorithms in your brain.<\/p><p>Thus, unsurprisingly, I see valence as a shining light that illuminates many aspects of psychology and everyday mental life. This series explores that idea. Here’s the outline:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction\"><strong>Post 1 (<\/strong><i><strong>Introduction<\/strong><\/i><strong>)<\/strong><\/a> will give some background on how I’m thinking about valence from the perspective of brain algorithms, including exactly what I’m talking about, and how it relates to the “wanting versus liking” dichotomy. (The thing I’m talking about is closer to “motivational valence” than “hedonic valence”, although neither term is&nbsp;<i>great<\/i>.)<\/li><li><a href=\"https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity\"><strong>Post 2 (<\/strong><i><strong>Valence &amp; Normativity<\/strong><\/i><strong>)<\/strong><\/a> will talk about the intimate relationship between valence and the universe of desires, preferences, values, goals, etc.—i.e. the “normative” side of the “positive-versus-normative” dichotomy, or equivalently the “ought” side of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem\"><u>Hume’s<\/u><\/a> “is-versus-ought”. I’ll start with simple cases: for example, if the idea of doing a certain thing right now feels unappealing (negative valence), then we’re less likely to do it. Then I’ll move on to more interesting cases, including what it means to like or dislike a broad concept like “religion”, and ego-syntonic versus ego-dystonic desires, and a descriptive account of moral reasoning and value formation.<\/li><li><a href=\"https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs\"><strong>Post 3 (<\/strong><i><strong>Valence &amp; Beliefs<\/strong><\/i><strong>)<\/strong><\/a> is the complement of Post 2, in that it covers the relationship between valence and the universe of beliefs, expectations, concepts, etc.—i.e. the “positive” side of the “positive-versus-normative” dichotomy, or equivalently the “is” side of “is-versus-ought”. The role of valence here is less foundational than it is on the normative side, but it’s still quite important. I’ll talk specifically about motivated reasoning, the halo effect (a.k.a. affect heuristic), and some related phenomena.<\/li><li><a href=\"https://www.lesswrong.com/posts/LaeP39jJpfPyoiSZm/valence-series-4-valence-and-liking-admiring\"><strong>Post 4 (<\/strong><i><strong>Valence &amp; Liking / Admiring<\/strong><\/i><strong>)<\/strong><\/a> argues that when my brain assigns a positive valence to a person I know, that corresponds to a familiar everyday phenomenon that I call “liking / admiring”. I argue that this has close ties to social status, mirroring, deference, self-esteem, self-concepts, and more. I also argue that there’s an “innate drive to feel liked / admired” which is critically important in human affairs, and I speculate a bit on how it works in the brain.<\/li><li><a href=\"https://www.lesswrong.com/posts/txj4wigyjLNbcoZ9o/valence-series-5-valence-disorders-in-mental-health-and\"><strong>Post 5 (<\/strong><i><strong>‘Valence Disorders’ in Mental Health &amp; Personality<\/strong><\/i><strong>)<\/strong><\/a> notes that, given the central role of valence in brain algorithms, it follows that if something creates&nbsp;<i>systematic&nbsp;<\/i>impacts on valence, it should lead to a characteristic suite of major downstream effects on mental life. I’ll propose three specific hypotheses along these lines:<ul><li>(A) If the valence of every thought is shifted negative, that leads to a suite of symptoms strongly overlapping with depression;<\/li><li>(B) If the valence of every thought is shifted positive, that leads to a suite of symptoms strongly overlapping with mania;<\/li><li>(C) If the valence of every thought is “extremized”—very positive or very negative, but rarely in between—that leads to a suite of symptoms similar to narcissistic personality disorder.<\/li><\/ul><\/li><li><a href=\"https://www.lesswrong.com/posts/xLmzMjxgZDaLyxZKb/valence-series-appendix-a-hedonic-tone-dis-pleasure-dis\"><strong>Appendix A <\/strong><i><strong>(Hedonic tone / (dis)pleasure / (dis)liking)<\/strong><\/i><\/a> has some more details about the hedonic tone (i.e., the “liking” side of the “wanting-versus-liking” dichotomy, in contrast to valence which is more about “wanting”). This appendix thus elaborates on the very brief discussion in &nbsp;<a href=\"https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction#1_5_2_Valence__as_I_m_using_the_term__is_different_from__hedonic_valence____pleasantness\"><u>§1.5.2<\/u><\/a>. I suggest that “hedonic tone” is a different brain signal from “valence”, but centrally involved in the valence-calculation algorithm.<\/li><li><i><strong>Valence and AI alignment<\/strong><\/i><strong> deserves a post too, but actually I already wrote that one a while ago: see&nbsp;<\/strong><a href=\"https://www.lesswrong.com/posts/Hi7zurzkCog336EC2/plan-for-mediocre-alignment-of-brain-like-model-based-rl-agi\"><strong><u>Plan for mediocre alignment of brain-like [model-based RL] AGI<\/u><\/strong><\/a><strong>.<\/strong> Check it out if you’re interested. I won’t discuss AI further in this series, with some minor exceptions, including a section at the very end of the Post 5.<\/li><\/ul><p><i>Thanks to Tsvi Benson-Tilsen,&nbsp;Seth Herd, Aysja Johnson, Justis Mills,&nbsp;Charlie Steiner, Adele Lopez, and Garrett Baker for critical comments on earlier drafts. Banner image by DALL-E 3.<\/i><\/p>","commitMessage":"","wordCount":799,"htmlHighlight":"<p>Let’s say a thought pops into your mind: “I could open the window right now”. Maybe you then immediately stand up and go open the window. Or maybe you don’t. (“Nah, I’ll keep it closed,” you might say to yourself.) I claim that there’s a final-common-pathway signal in your brain that cleaves those two possibilities: when this special signal is positive, then the current “thought” will stick around, and potentially lead to actions and/or direct-follow-up thoughts; and when this signal is negative, then the current “thought” will get thrown out, and your brain will go fishing (partly randomly) for a new thought to replace it. I call this final-common-pathway signal by the name&nbsp;<strong>“valence”<\/strong>. Thus, the “valence” of a “thought” is roughly the extent to which the thought feels demotivating / aversive (negative valence) versus motivating / appealing (positive valence).<\/p><p>I claim that valence plays an absolutely central role in the brain—I think it’s one of the most important ingredients in the brain’s Model-Based Reinforcement Learning system, which in turn is one of the most important algorithms in your brain.<\/p><p>Thus, unsurprisingly, I see valence as a shining light that illuminates many aspects of psychology and everyday mental life. This series explores that idea. Here’s the outline:<\/p><ul><li><a href=\"https://www.lesswrong.com/posts/As7bjEAbNpidKx6LR/valence-series-1-introduction\"><strong>Post 1 (<\/strong><i><strong>Introduction<\/strong><\/i><strong>)<\/strong><\/a> will give some background on how I’m thinking about valence from the perspective of brain algorithms, including exactly what I’m talking about, and how it relates to the “wanting versus liking” dichotomy. (The thing I’m talking about is closer to “motivational valence” than “hedonic valence”, although neither term is&nbsp;<i>great<\/i>.)<\/li><li><a href=\"https://www.lesswrong.com/posts/SqgRtCwueovvwxpDQ/valence-series-2-valence-and-normativity\"><strong>Post 2 (<\/strong><i><strong>Valence &amp; Normativity<\/strong><\/i><strong>)<\/strong><\/a> will talk about the intimate relationship between valence and the universe of desires, preferences, values, goals, etc.—i.e. the “normative” side of the “positive-versus-normative” dichotomy, or equivalently the “ought” side of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem\"><u>Hume’s<\/u><\/a> “is-versus-ought”. I’ll start with simple cases: for example, if the idea of doing a certain thing right now feels unappealing (negative valence), then we’re less likely to do it. Then I’ll move on to more interesting cases, including what it means to like or dislike a broad concept like “religion”, and ego-syntonic versus ego-dystonic desires, and a descriptive account of moral reasoning and value formation.<\/li><li><a href=\"https://www.lesswrong.com/posts/rM8DwFKZM4eB7i2p8/valence-series-3-valence-and-beliefs\"><strong>Post 3 (<\/strong><i><strong>Valence &amp; Beliefs<\/strong><\/i><strong>)<\/strong><\/a> is the complement of Post 2, in t<\/li><\/ul>... ","plaintextDescription":"Let’s say a thought pops into your mind: “I could open the window right now”. Maybe you then immediately stand up and go open the window. Or maybe you don’t. (“Nah, I’ll keep it closed,” you might say to yourself.) I claim that there’s a final-common-pathway signal in your brain that cleaves those two possibilities: when this special signal is positive, then the current “thought” will stick around, and potentially lead to actions and/or direct-follow-up thoughts; and when this signal is negative, then the current “thought” will get thrown out, and your brain will go fishing (partly randomly) for a new thought to replace it. I call this final-common-pathway signal by the name “valence”. Thus, the “valence” of a “thought” is roughly the extent to which the thought feels demotivating / aversive (negative valence) versus motivating / appealing (positive valence).\n\nI claim that valence plays an absolutely central role in the brain—I think it’s one of the most important ingredients in the brain’s Model-Based Reinforcement Learning system, which in turn is one of the most important algorithms in your brain.\n\nThus, unsurprisingly, I see valence as a shining light that illuminates many aspects of psychology and everyday mental life. This series explores that idea. Here’s the outline:\n\n * Post 1 (Introduction) will give some background on how I’m thinking about valence from the perspective of brain algorithms, including exactly what I’m talking about, and how it relates to the “wanting versus liking” dichotomy. (The thing I’m talking about is closer to “motivational valence” than “hedonic valence”, although neither term is great.)\n * Post 2 (Valence & Normativity) will talk about the intimate relationship between valence and the universe of desires, preferences, values, goals, etc.—i.e. the “normative” side of the “positive-versus-normative” dichotomy, or equivalently the “ought” side of Hume’s “is-versus-ought”. I’ll start with simple cases: for example, if the idea of doing"},"Sequence:6uDBPacS6zDipqbZ9":{"_id":"6uDBPacS6zDipqbZ9","__typename":"Sequence","createdAt":"2023-12-04T13:57:10.054Z","userId":"vRcer5FTqagjMkcDz","user":{"__ref":"User:vRcer5FTqagjMkcDz"},"contents":{"__ref":"Revision:6uDBPacS6zDipqbZ9_contents"},"gridImageId":"sequencesgrid/lalel10qzujyi47rqiww","bannerImageId":"sequences/o0ucggb2f6dfdntl8aut","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":15,"userProfileOrder":null,"af":false,"postsCount":6,"readPostsCount":0,"title":"Valence","canonicalCollection":null},"Revision:BbAvHtorCZqp97X9W_contents":{"_id":"BbAvHtorCZqp97X9W_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2024-10-11T21:43:31.606Z","userId":"jHzwoFd2MhZt9eeqJ","html":"<p>This series examines a set of interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power. They’re old questions – but I think that we will have to grapple with them in new ways as increasingly powerful AI systems come online.<\/p><p>The series covers a lot of ground, but I’m hoping the individual essays can be read fairly well on their own. The first essay includes a brief summary of the essays released thus far. There's also a full PDF of the series <a href=\"https://jc.gatspress.com/pdf/otherness_full.pdf\">here<\/a>, full audio <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/15266490-first-half-of-full-audio-for-otherness-and-control-in-the-age-of-agi\">here<\/a>, and video/transcript of a lecture summary <a href=\"https://www.lesswrong.com/posts/84vnGai2E3eQsyAuA/video-and-transcript-of-presentation-on-otherness-and-1\">here<\/a>.<\/p>","commitMessage":"","wordCount":106,"htmlHighlight":"<p>This series examines a set of interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power. They’re old questions – but I think that we will have to grapple with them in new ways as increasingly powerful AI systems come online.<\/p><p>The series covers a lot of ground, but I’m hoping the individual essays can be read fairly well on their own. The first essay includes a brief summary of the essays released thus far. There's also a full PDF of the series <a href=\"https://jc.gatspress.com/pdf/otherness_full.pdf\">here<\/a>, full audio <a href=\"https://joecarlsmithaudio.buzzsprout.com/2034731/15266490-first-half-of-full-audio-for-otherness-and-control-in-the-age-of-agi\">here<\/a>, and video/transcript of a lecture summary <a href=\"https://www.lesswrong.com/posts/84vnGai2E3eQsyAuA/video-and-transcript-of-presentation-on-otherness-and-1\">here<\/a>.<\/p>","plaintextDescription":"This series examines a set of interconnected questions about how agents with different values should relate to one another, and about the ethics of seeking and sharing power. They’re old questions – but I think that we will have to grapple with them in new ways as increasingly powerful AI systems come online.\n\nThe series covers a lot of ground, but I’m hoping the individual essays can be read fairly well on their own. The first essay includes a brief summary of the essays released thus far. There's also a full PDF of the series here, full audio here, and video/transcript of a lecture summary here."},"Sequence:BbAvHtorCZqp97X9W":{"_id":"BbAvHtorCZqp97X9W","__typename":"Sequence","createdAt":"2024-01-02T22:38:25.534Z","userId":"jHzwoFd2MhZt9eeqJ","user":{"__ref":"User:jHzwoFd2MhZt9eeqJ"},"contents":{"__ref":"Revision:BbAvHtorCZqp97X9W_contents"},"gridImageId":"sequencesgrid/sqq40tz8m2jsvyrj8s4r","bannerImageId":"sequences/k02fhen4orb3kodl36nv","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":10,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":1,"title":"Otherness and control in the age of AGI","canonicalCollection":null},"User:n6LYNw2uGfYnD4pX2":{"_id":"n6LYNw2uGfYnD4pX2","__typename":"User","slug":"lsusr","createdAt":"2019-08-03T22:27:09.960Z","username":"lsusr","displayName":"lsusr","profileImageId":null,"previousDisplayName":null,"fullName":"Lsusr","karma":18257,"afKarma":25,"deleted":false,"isAdmin":false,"htmlBio":"<p>Here is a <a href=\"https://www.lsusr.com/\">list of all my public writings and videos (from before February 2025).<\/a><\/p>\n<p>If you want to do a dialogue with me, but I didn't check your name, just send me a message instead. Ask for what you want!<\/p>\n","jobTitle":null,"organization":null,"postCount":289,"commentCount":1677,"sequenceCount":15,"afPostCount":0,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":2,"reviewedByUserId":"3oopbgcjYfvN8B2fp"},"Revision:TF77XsD5PbucbJsG3_contents":{"_id":"TF77XsD5PbucbJsG3_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-03-09T22:15:49.216Z","userId":"n6LYNw2uGfYnD4pX2","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:TF77XsD5PbucbJsG3":{"_id":"TF77XsD5PbucbJsG3","__typename":"Sequence","createdAt":"2020-11-30T08:12:20.977Z","userId":"n6LYNw2uGfYnD4pX2","user":{"__ref":"User:n6LYNw2uGfYnD4pX2"},"contents":{"__ref":"Revision:TF77XsD5PbucbJsG3_contents"},"gridImageId":"sequencesgrid/whqbkvzjopvlh7paq73r","bannerImageId":"sequences/wt6zrk3cpnvpdv7pxnar","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":10,"userProfileOrder":null,"af":false,"postsCount":13,"readPostsCount":0,"title":"Luna Lovegood","canonicalCollection":null},"User:kdeMdATaSc2MZKmdH":{"_id":"kdeMdATaSc2MZKmdH","__typename":"User","slug":"holdenkarnofsky","createdAt":"2009-12-30T00:19:32.818Z","username":"HoldenKarnofsky","displayName":"HoldenKarnofsky","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":7105,"afKarma":478,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":48,"commentCount":98,"sequenceCount":1,"afPostCount":8,"afCommentCount":34,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:yYxggfHYRrqnJXuRx_contents":{"_id":"yYxggfHYRrqnJXuRx_contents","__typename":"Revision","version":"0.2.0","updateType":"minor","editedAt":"2024-05-29T19:05:52.787Z","userId":"XtphY3uYHwruKqDyG","html":"<p>I think we have good reason to believe that the <strong>21st century could be the most important century ever for humanity.<\/strong> I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.<\/p><p>A bit more specifically,<a href=\"https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP\"><strong><sup><u>1<\/u><\/sup><\/strong><\/a> I think there is a good chance that:<\/p><ol><li>During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.<\/li><li>Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.<\/li><\/ol><p>I think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.<\/p><p>I believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind.<\/p>","commitMessage":"","wordCount":242,"htmlHighlight":"<p>I think we have good reason to believe that the <strong>21st century could be the most important century ever for humanity.<\/strong> I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.<\/p><p>A bit more specifically,<a href=\"https://www.lesswrong.com/posts/yHzDrTCum4rdNRDJJ/the-most-important-century-sequence-introduction?commentId=k7Fy2PF5z7kGxbxSP\"><strong><sup><u>1<\/u><\/sup><\/strong><\/a> I think there is a good chance that:<\/p><ol><li>During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.<\/li><li>Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.<\/li><\/ol><p>I think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.<\/p><p>I believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind.<\/p>","plaintextDescription":"I think we have good reason to believe that the 21st century could be the most important century ever for humanity. I think the most likely way this would happen would be via the development of advanced AI systems that lead to explosive growth and scientific advancement, getting us more quickly than most people imagine to a deeply unfamiliar future.\n\nA bit more specifically,1 I think there is a good chance that:\n\n 1. During the century we're in right now, we will develop technologies that cause us to transition to a state in which humans as we know them are no longer the main force in world events. This is our last chance to shape how that transition happens.\n 2. Whatever the main force in world events is (perhaps digital people, misaligned AI, or something else) will create highly stable civilizations that populate our entire galaxy for billions of years to come. The transition taking place this century could shape all of that.\n\nI think it's very unclear whether this would be a good or bad thing. What matters is that it could go a lot of different ways, and we have a chance to affect that.\n\nI believe the above possibility doesn't get enough attention, discussion, or investment, particularly from people whose goal is to make the world better. By writing about it, I'd like to either help change that, or gain more opportunities to get criticized and change my mind."},"Sequence:yYxggfHYRrqnJXuRx":{"_id":"yYxggfHYRrqnJXuRx","__typename":"Sequence","createdAt":"2021-08-30T21:41:37.485Z","userId":"kdeMdATaSc2MZKmdH","user":{"__ref":"User:kdeMdATaSc2MZKmdH"},"contents":{"__ref":"Revision:yYxggfHYRrqnJXuRx_contents"},"gridImageId":"sequencesgrid/nsphhanrutzgofgj5xvu","bannerImageId":"sequences/vb9fvlizrpmm56tajkmk","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":4,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"The Most Important Century","canonicalCollection":null},"User:gb44edJjXhte8DA3A":{"_id":"gb44edJjXhte8DA3A","__typename":"User","slug":"paulfchristiano","createdAt":"2010-07-28T17:04:08.586Z","username":"paulfchristiano","displayName":"paulfchristiano","profileImageId":null,"previousDisplayName":null,"fullName":"Paul Christiano","karma":27852,"afKarma":6136,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":157,"commentCount":2345,"sequenceCount":1,"afPostCount":78,"afCommentCount":825,"spamRiskScore":1,"tagRevisionCount":592,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:EmDuGeRw749sD3GKd_contents":{"_id":"EmDuGeRw749sD3GKd_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-05-26T04:28:48.055Z","userId":"EQNTWXLKMeWMp2FQS","html":"<p>This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification.<\/p>","commitMessage":null,"wordCount":16,"htmlHighlight":"<p>This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification.<\/p>","plaintextDescription":"This is a sequence curated by Paul Christiano on one current approach to alignment: Iterated Amplification."},"Sequence:EmDuGeRw749sD3GKd":{"_id":"EmDuGeRw749sD3GKd","__typename":"Sequence","createdAt":"2018-10-29T13:26:36.619Z","userId":"gb44edJjXhte8DA3A","user":{"__ref":"User:gb44edJjXhte8DA3A"},"contents":{"__ref":"Revision:EmDuGeRw749sD3GKd_contents"},"gridImageId":"sequencesgrid/prcccqtc5w7ytolilruu","bannerImageId":"sequences/bamysbymxal5tqccjawg","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":3,"userProfileOrder":null,"af":true,"postsCount":23,"readPostsCount":0,"title":"Iterated Amplification","canonicalCollection":null},"User:du6SPHKnnPrPmxWNT":{"_id":"du6SPHKnnPrPmxWNT","__typename":"User","slug":"rohinmshah","createdAt":"2015-05-26T23:46:04.336Z","username":"rohinmshah","displayName":"Rohin Shah","profileImageId":null,"previousDisplayName":null,"fullName":"Rohin Shah","karma":15546,"afKarma":5543,"deleted":false,"isAdmin":false,"htmlBio":"<p>Research Scientist at Google DeepMind. Creator of the Alignment Newsletter. <a href=\"http://rohinshah.com/\">http://rohinshah.com/<\/a><\/p>","jobTitle":null,"organization":null,"postCount":207,"commentCount":2232,"sequenceCount":2,"afPostCount":107,"afCommentCount":1384,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:4dHMdK5TLN6xcqtyc_contents":{"_id":"4dHMdK5TLN6xcqtyc_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-09-23T04:25:25.157Z","userId":"XtphY3uYHwruKqDyG","html":"<p>This is a sequence investigating the feasibility of one approach to AI alignment: value learning.<\/p>","commitMessage":"","wordCount":15,"htmlHighlight":"<p>This is a sequence investigating the feasibility of one approach to AI alignment: value learning.<\/p>","plaintextDescription":"This is a sequence investigating the feasibility of one approach to AI alignment: value learning."},"Sequence:4dHMdK5TLN6xcqtyc":{"_id":"4dHMdK5TLN6xcqtyc","__typename":"Sequence","createdAt":"2018-10-29T18:23:24.873Z","userId":"du6SPHKnnPrPmxWNT","user":{"__ref":"User:du6SPHKnnPrPmxWNT"},"contents":{"__ref":"Revision:4dHMdK5TLN6xcqtyc_contents"},"gridImageId":"sequencesgrid/x0pxuhnauzakdnrqijhe","bannerImageId":"sequences/x4nn0v3suj8bbf0tr9b3","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":2,"userProfileOrder":null,"af":true,"postsCount":19,"readPostsCount":0,"title":"Value Learning","canonicalCollection":null},"User:vAyu6PoTQHg8fzFNJ":{"_id":"vAyu6PoTQHg8fzFNJ","__typename":"User","slug":"cfar-2017","createdAt":"2022-06-24T17:44:49.041Z","username":"CFAR 2017","displayName":"CFAR!Duncan","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":1655,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":27,"commentCount":7,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:KAv8z6oJCTxjR8vdR_contents":{"_id":"KAv8z6oJCTxjR8vdR_contents","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2022-09-23T22:16:10.468Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.&nbsp;&nbsp;<\/p><p>This is the result of the first five years or so of that research and development.<\/p>","commitMessage":"","wordCount":49,"htmlHighlight":"<p>The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.&nbsp;&nbsp;<\/p><p>This is the result of the first five years or so of that research and development.<\/p>","plaintextDescription":"The Center for Applied Rationality set out to develop simple, concrete concepts and techniques that could be straightforwardly applied to anyone's problems and goals, (hopefully) resulting in clearer thinking, better decision-making, and better follow-through.  \n\nThis is the result of the first five years or so of that research and development."},"Sequence:KAv8z6oJCTxjR8vdR":{"_id":"KAv8z6oJCTxjR8vdR","__typename":"Sequence","createdAt":"2022-06-28T20:53:06.291Z","userId":"vAyu6PoTQHg8fzFNJ","user":{"__ref":"User:vAyu6PoTQHg8fzFNJ"},"contents":{"__ref":"Revision:KAv8z6oJCTxjR8vdR_contents"},"gridImageId":"sequencesgrid/prnzteddh56bhbv5nmae","bannerImageId":"sequences/vq4k8iz6x7kdwrk41xo1","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":28,"readPostsCount":2,"title":"CFAR Handbook","canonicalCollection":null},"User:MEu8MdhruX5jfGsFQ":{"_id":"MEu8MdhruX5jfGsFQ","__typename":"User","slug":"johnswentworth","createdAt":"2011-02-19T16:54:09.598Z","username":"johnswentworth","displayName":"johnswentworth","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":53277,"afKarma":6642,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":352,"commentCount":3266,"sequenceCount":8,"afPostCount":120,"afCommentCount":700,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"EQNTWXLKMeWMp2FQS"},"Revision:xEFeCwk3pdYdeG2rL_contents":{"_id":"xEFeCwk3pdYdeG2rL_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-23T22:15:25.152Z","userId":"r38pkCm7wF4M44MDQ","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:xEFeCwk3pdYdeG2rL":{"_id":"xEFeCwk3pdYdeG2rL","__typename":"Sequence","createdAt":"2020-01-25T23:15:50.589Z","userId":"MEu8MdhruX5jfGsFQ","user":{"__ref":"User:MEu8MdhruX5jfGsFQ"},"contents":{"__ref":"Revision:xEFeCwk3pdYdeG2rL_contents"},"gridImageId":"sequencesgrid/mrcucooleoeaj8ybccb3","bannerImageId":"sequences/cwsk9pkbwwvfzhkvvgrk","canonicalCollectionSlug":"","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":0,"title":"Gears Which Turn The World","canonicalCollection":null},"User:N9zj5qpTfqmbn9dro":{"_id":"N9zj5qpTfqmbn9dro","__typename":"User","slug":"zvi","createdAt":"2009-03-31T20:54:54.077Z","username":"Zvi","displayName":"Zvi","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":49471,"afKarma":146,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":880,"commentCount":1458,"sequenceCount":3,"afPostCount":2,"afCommentCount":7,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:kNANcHLNtJt5qeuSS_contents":{"_id":"kNANcHLNtJt5qeuSS_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-23T22:15:04.353Z","userId":"r38pkCm7wF4M44MDQ","html":"","commitMessage":"","wordCount":1,"htmlHighlight":"","plaintextDescription":""},"Sequence:kNANcHLNtJt5qeuSS":{"_id":"kNANcHLNtJt5qeuSS","__typename":"Sequence","createdAt":"2019-12-31T20:35:02.123Z","userId":"N9zj5qpTfqmbn9dro","user":{"__ref":"User:N9zj5qpTfqmbn9dro"},"contents":{"__ref":"Revision:kNANcHLNtJt5qeuSS_contents"},"gridImageId":"sequencesgrid/y7bhrihn26iisjvhu61y","bannerImageId":"sequences/pu8r1gxicerwcbjlfg6i","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":20,"readPostsCount":0,"title":"Immoral Mazes","canonicalCollection":null},"Revision:hBFDRZCPLcrRDubgm_contents":{"_id":"hBFDRZCPLcrRDubgm_contents","__typename":"Revision","version":"1.5.0","updateType":"minor","editedAt":"2022-10-22T22:02:09.456Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions. <\/p><p>Unfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.<\/p><p>But the core skill of doublecrux –&nbsp;noticing what would actually change your mind –&nbsp;is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share. <\/p><p>This sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating.<\/p>","commitMessage":"","wordCount":131,"htmlHighlight":"<p>Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions. <\/p><p>Unfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.<\/p><p>But the core skill of doublecrux –&nbsp;noticing what would actually change your mind –&nbsp;is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share. <\/p><p>This sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating.<\/p>","plaintextDescription":"Doublecrux is a valuable tool – it can help groups come to decisions, and it can enable individual thinkers to help each other form more accurate conclusions.\n\nUnfortunately it's often a time consuming tool. Some disagreements can take hours to resolve. Others take years. By default, most of our belief networks are a messy, impenetrable morass, and disentangling that takes time.\n\nBut the core skill of doublecrux – noticing what would actually change your mind – is something you can develop. And as you develop it, I've found it easier to a) figure out what I actually believe and why, b) develop belief structures that are easier for me to understand, update, and share.\n\nThis sequence explores when doublecrux is useful, what are some important subskills, and why they're worth cultivating."},"Sequence:hBFDRZCPLcrRDubgm":{"_id":"hBFDRZCPLcrRDubgm","__typename":"Sequence","createdAt":"2019-07-28T01:26:44.221Z","userId":"r38pkCm7wF4M44MDQ","user":{"__ref":"User:r38pkCm7wF4M44MDQ"},"contents":{"__ref":"Revision:hBFDRZCPLcrRDubgm_contents"},"gridImageId":"sequencesgrid/sbiiwhliynfuouklvwph","bannerImageId":"sequences/mfjwxg5bqke2ooeq3eiz","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Keep your beliefs cruxy and your frames explicit","canonicalCollection":null},"Revision:r9tYkB2a8Fp4DN8yB_contents":{"_id":"r9tYkB2a8Fp4DN8yB_contents","__typename":"Revision","version":"1.8.0","updateType":"minor","editedAt":"2021-07-23T06:12:38.425Z","userId":"AThTtkDufXp3rmMDa","html":"<p><em>This is a sequence version of the paper “<a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.<\/em><\/p>\n<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,<\/em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?<\/p>\n","commitMessage":"","wordCount":163,"htmlHighlight":"<p><em>This is a sequence version of the paper “<a href=\"https://arxiv.org/abs/1906.01820\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.<\/em><\/p>\n<p>The goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as <em>mesa-optimization,<\/em> a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?<\/p>","plaintextDescription":"This is a sequence version of the paper “Risks from Learned Optimization in Advanced Machine Learning Systems” by Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant. Each post in the sequence corresponds to a different section of the paper. Evan Hubinger, Chris van Merwijk, Vladimir Mikulik, and Joar Skalse contributed equally to this sequence.\n\nThe goal of this sequence is to analyze the type of learned optimization that occurs when a learned model (such as a neural network) is itself an optimizer—a situation we refer to as mesa-optimization, a neologism we introduce in this sequence. We believe that the possibility of mesa-optimization raises two important questions for the safety and transparency of advanced machine learning systems. First, under what circumstances will learned models be optimizers, including when they should not be? Second, when a learned model is an optimizer, what will its objective be—how will it differ from the loss function it was trained under—and how can it be aligned?"},"Sequence:r9tYkB2a8Fp4DN8yB":{"_id":"r9tYkB2a8Fp4DN8yB","__typename":"Sequence","createdAt":"2019-05-31T02:18:02.737Z","userId":"AThTtkDufXp3rmMDa","user":{"__ref":"User:AThTtkDufXp3rmMDa"},"contents":{"__ref":"Revision:r9tYkB2a8Fp4DN8yB_contents"},"gridImageId":"sequencesgrid/rzdw9faewnetbmumls9y","bannerImageId":"sequences/ahlmdailzfoxjcczzbub","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":true,"postsCount":5,"readPostsCount":0,"title":"Risks from Learned Optimization","canonicalCollection":null},"Revision:d3WgHDBAPYYScp5Em_contents":{"_id":"d3WgHDBAPYYScp5Em_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-10-13T07:26:27.113Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the <a href=\"https://wiki.lesswrong.com/wiki/Complexity_of_value\">complexity of value<\/a> thesis.<\/p><p>Also forms part of the fully general answer to religious theodicy.<\/p><p>Sequence by <a href=\"https://www.lesswrong.com/users/eliezer_yudkowsky\">Eliezer Yudkowsky<\/a>, imported from <a href=\"https://wiki.lesswrong.com/wiki/The_Fun_Theory_Sequence\">the wiki<\/a>. Overlaps with <a href=\"https://www.lesswrong.com/s/9bvAELWc8y2gYjRav\">Value Theory<\/a>.<\/p>","commitMessage":"","wordCount":62,"htmlHighlight":"<p>A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the <a href=\"https://wiki.lesswrong.com/wiki/Complexity_of_value\">complexity of value<\/a> thesis.<\/p><p>Also forms part of the fully general answer to religious theodicy.<\/p><p>Sequence by <a href=\"https://www.lesswrong.com/users/eliezer_yudkowsky\">Eliezer Yudkowsky<\/a>, imported from <a href=\"https://wiki.lesswrong.com/wiki/The_Fun_Theory_Sequence\">the wiki<\/a>. Overlaps with <a href=\"https://www.lesswrong.com/s/9bvAELWc8y2gYjRav\">Value Theory<\/a>.<\/p>","plaintextDescription":"A concrete theory of transhuman values. How much fun is there in the universe? Will we ever run out of fun? Are we having fun yet? Could we be having more fun? Part of the complexity of value thesis.\n\nAlso forms part of the fully general answer to religious theodicy.\n\nSequence by Eliezer Yudkowsky, imported from the wiki. Overlaps with Value Theory."},"Sequence:d3WgHDBAPYYScp5Em":{"_id":"d3WgHDBAPYYScp5Em","__typename":"Sequence","createdAt":"2018-09-22T01:17:01.044Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:d3WgHDBAPYYScp5Em_contents"},"gridImageId":"sequencesgrid/ncfkdhspgrfhhjpbisaj","bannerImageId":"sequences/kusdtqumjqf6bymmhaso","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":29,"readPostsCount":2,"title":"Fun Theory","canonicalCollection":null},"Revision:qWoFR4ytMpQ5vw3FT_contents":{"_id":"qWoFR4ytMpQ5vw3FT_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-07-06T20:02:30.941Z","userId":"nmk3nLpQE89dMRzzN","html":"<blockquote>&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.&quot;<br/>      -- (Hugo nominee) Peter Watts, &quot;<a href=\"http://www.rifters.com/crawl/?p=266\">In Praise of Baby-Eating<\/a>&quot;<\/blockquote><p><\/p><p><em>Three Worlds Collide<\/em> is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.<\/p><p>(PDF is <a href=\"http://robinhanson.typepad.com/files/three-worlds-collide.pdf\">here<\/a>. Old contents post with comments is <a href=\"https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8\">here<\/a>.)<\/p>","commitMessage":null,"wordCount":102,"htmlHighlight":"<blockquote>&quot;The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.&quot;<br/>      -- (Hugo nominee) Peter Watts, &quot;<a href=\"http://www.rifters.com/crawl/?p=266\">In Praise of Baby-Eating<\/a>&quot;<\/blockquote><p><\/p><p><em>Three Worlds Collide<\/em> is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.<\/p><p>(PDF is <a href=\"http://robinhanson.typepad.com/files/three-worlds-collide.pdf\">here<\/a>. Old contents post with comments is <a href=\"https://www.lesswrong.com/posts/HawFh7RvDM4RyoJ2d/three-worlds-collide-0-8\">here<\/a>.)<\/p>","plaintextDescription":"> \"The kind of classic fifties-era first-contact story that Jonathan Swift might have written, if Jonathan Swift had had a background in game theory.\"\n>       -- (Hugo nominee) Peter Watts, \"In Praise of Baby-Eating\"\n\n\n\nThree Worlds Collide is a story I wrote to illustrate some points on naturalistic metaethics and diverse other issues of rational conduct.  It grew, as such things do, into a small novella.  On publication, it proved widely popular and widely criticized.  Be warned that the story, as it wrote itself, ended up containing some profanity and PG-13 content.\n\n(PDF is here. Old contents post with comments is here.)"},"Sequence:qWoFR4ytMpQ5vw3FT":{"_id":"qWoFR4ytMpQ5vw3FT","__typename":"Sequence","createdAt":"2018-07-06T20:02:30.941Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:qWoFR4ytMpQ5vw3FT_contents"},"gridImageId":"sequencesgrid/sio9b8jw1apesuispocg","bannerImageId":"sequences/evlaa0fe6nysqqhhqwyd","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":8,"readPostsCount":0,"title":"Three Worlds Collide","canonicalCollection":null},"Revision:HXkpm9b8o964jbQ89_contents":{"_id":"HXkpm9b8o964jbQ89_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-09T22:33:08.727Z","userId":"N9zj5qpTfqmbn9dro","html":"<p>A series of meditations on freedom to do the things you care about.<\/p><blockquote>Some things are fundamentally Out to Get You.<\/blockquote><blockquote>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.<\/blockquote><blockquote>When something is out to get you, if you aren&#x27;t careful, it can take all your resources - your time, you money, your attention.<\/blockquote><blockquote>This matters, more deeply than you might realize. It&#x27;s not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you. <\/blockquote><blockquote>Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.<\/blockquote><p><\/p>","commitMessage":null,"wordCount":146,"htmlHighlight":"<p>A series of meditations on freedom to do the things you care about.<\/p><blockquote>Some things are fundamentally Out to Get You.<\/blockquote><blockquote>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.<\/blockquote><blockquote>When something is out to get you, if you aren&#x27;t careful, it can take all your resources - your time, you money, your attention.<\/blockquote><blockquote>This matters, more deeply than you might realize. It&#x27;s not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you. <\/blockquote><blockquote>Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.<\/blockquote><p><\/p>","plaintextDescription":"A series of meditations on freedom to do the things you care about.\n\n> Some things are fundamentally Out to Get You.\n\n> They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Everything is data to sell you something, rather than an opportunity to help you.\n\n> When something is out to get you, if you aren't careful, it can take all your resources - your time, you money, your attention.\n\n> This matters, more deeply than you might realize. It's not just that you need your resources. You need enough resources to have slack: freedom from constraints that might bind you.\n\n> Slack means margin of error. You can relax. You can explore and pursue opportunities. You can plan for the long term. You can stick to principles and do the right thing.\n\n"},"Sequence:HXkpm9b8o964jbQ89":{"_id":"HXkpm9b8o964jbQ89","__typename":"Sequence","createdAt":"2018-04-09T22:33:08.727Z","userId":"N9zj5qpTfqmbn9dro","user":{"__ref":"User:N9zj5qpTfqmbn9dro"},"contents":{"__ref":"Revision:HXkpm9b8o964jbQ89_contents"},"gridImageId":"sequencesgrid/rqnuxewffasun6tvdkng","bannerImageId":"sequences/ecwup5jjh2nq00uf0mi0","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":15,"readPostsCount":2,"title":"Slack and the Sabbath ","canonicalCollection":null},"Revision:ZNNi2uNx9E6iwGKKG_contents":{"_id":"ZNNi2uNx9E6iwGKKG_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","commitMessage":null,"wordCount":156,"htmlHighlight":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","plaintextDescription":"This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.\n\nParts of this sequence draw heavily upon material from The Art of Strategy by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it's probably a bad idea to pick a legal fight with people who write books called The Art of Strategy.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.\n\nSpecial thanks to Luke for his book recommendation and his strong encouragement to write this."},"Sequence:ZNNi2uNx9E6iwGKKG":{"_id":"ZNNi2uNx9E6iwGKKG","__typename":"Sequence","createdAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:ZNNi2uNx9E6iwGKKG_contents"},"gridImageId":"sequencesgrid/vitugifyyh2upm9ucjzh","bannerImageId":"sequences/zvybkycf2vyasr4zwptr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":0,"title":"Introduction to Game Theory","canonicalCollection":null},"Revision:G2GDw3m4MJ5ixSM92_contents":{"_id":"G2GDw3m4MJ5ixSM92_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-09-21T21:34:27.910Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","commitMessage":"","wordCount":19,"htmlHighlight":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","plaintextDescription":"A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour."},"Sequence:G2GDw3m4MJ5ixSM92":{"_id":"G2GDw3m4MJ5ixSM92","__typename":"Sequence","createdAt":"2018-02-22T18:10:39.949Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:G2GDw3m4MJ5ixSM92_contents"},"gridImageId":"sequencesgrid/djfksyoldrjt4ef5jts3","bannerImageId":"sequences/ad7shnab6qq5v6cqxpme","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"The Blue-Minimizing Robot","canonicalCollection":null},"User:c8gC5wARE3fPwu94u":{"_id":"c8gC5wARE3fPwu94u","__typename":"User","slug":"alkjash","createdAt":"2017-10-06T20:42:59.929Z","username":"alkjash","displayName":"alkjash","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":5057,"afKarma":4,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":83,"commentCount":280,"sequenceCount":4,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"qgdGA4ZEyW7zNdK84"},"Revision:qRxTKm7DAftSuTGvj_contents":{"_id":"qRxTKm7DAftSuTGvj_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-23T22:17:16.410Z","userId":"r38pkCm7wF4M44MDQ","html":"<p><em>If all you have is a hammer, everything looks like a nail.<\/em><\/p><p>Thirty days of instrumental rationality practice.<\/p><p>Key word: systematic.<\/p>","commitMessage":"","wordCount":19,"htmlHighlight":"<p><em>If all you have is a hammer, everything looks like a nail.<\/em><\/p><p>Thirty days of instrumental rationality practice.<\/p><p>Key word: systematic.<\/p>","plaintextDescription":"If all you have is a hammer, everything looks like a nail.\n\nThirty days of instrumental rationality practice.\n\nKey word: systematic."},"Sequence:qRxTKm7DAftSuTGvj":{"_id":"qRxTKm7DAftSuTGvj","__typename":"Sequence","createdAt":"2018-02-22T16:29:33.789Z","userId":"c8gC5wARE3fPwu94u","user":{"__ref":"User:c8gC5wARE3fPwu94u"},"contents":{"__ref":"Revision:qRxTKm7DAftSuTGvj_contents"},"gridImageId":"sequencesgrid/chv9ct9cisa2fne7htnk","bannerImageId":"sequences/ihwuzf8j8n5xfqdiften","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":34,"readPostsCount":2,"title":"Hammertime","canonicalCollection":null},"Revision:pC6DYFLPMTCbEwH8W_contents":{"_id":"pC6DYFLPMTCbEwH8W_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-02-22T16:02:57.918Z","userId":"c8gC5wARE3fPwu94u","html":"<p>How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write <em>Hamlet<\/em>?<\/p><p>Babble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.<\/p><p>Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.<\/p><p>It is time to reclaim your birthright, hero: go forth and babble!<\/p>","commitMessage":null,"wordCount":113,"htmlHighlight":"<p>How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write <em>Hamlet<\/em>?<\/p><p>Babble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.<\/p><p>Two Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.<\/p><p>It is time to reclaim your birthright, hero: go forth and babble!<\/p>","plaintextDescription":"How do babies learn language? How did Moses compute the ten Commandments? How did Shakespeare write Hamlet?\n\nBabble and Prune is an ancient mythological story, a psychological model, a new religion for a post-religion age, that answers all these questions and more.\n\nTwo Gods - Babble and Prune, Artist and Critic, Generator and Discriminator - are locked in eternal conflict over your mind. Babble creates a constant stream of coarse material, while Prune cuts these ideas harshly without the slightest hint of remorse. Only you, chosen hero, can restore the balance between these two ancient deities, and in doing so maximize your creative output.\n\nIt is time to reclaim your birthright, hero: go forth and babble!"},"Sequence:pC6DYFLPMTCbEwH8W":{"_id":"pC6DYFLPMTCbEwH8W","__typename":"Sequence","createdAt":"2018-02-22T16:02:57.918Z","userId":"c8gC5wARE3fPwu94u","user":{"__ref":"User:c8gC5wARE3fPwu94u"},"contents":{"__ref":"Revision:pC6DYFLPMTCbEwH8W_contents"},"gridImageId":"sequencesgrid/nhvoi5fvxxzthqhu2ctt","bannerImageId":"sequences/dncaedgak01s1ssja5nf","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":5,"readPostsCount":2,"title":"Babble and Prune","canonicalCollection":null},"Revision:SqFbMbtxGybdS2gRs_contents":{"_id":"SqFbMbtxGybdS2gRs_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2020-04-19T19:13:02.750Z","userId":"XtphY3uYHwruKqDyG","html":"<p>These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.<\/p>","commitMessage":null,"wordCount":27,"htmlHighlight":"<p>These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed.<\/p>","plaintextDescription":"These essays include a discussion of truth, formal logic, causality, and metaethics, and are a good way for more ambitious readers to quickly get up to speed."},"Sequence:SqFbMbtxGybdS2gRs":{"_id":"SqFbMbtxGybdS2gRs","__typename":"Sequence","createdAt":"2018-01-22T08:55:37.700Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:SqFbMbtxGybdS2gRs_contents"},"gridImageId":"sequencesgrid/i2ogsvmipbdolntkew4a","bannerImageId":"sequences/kx9ydblgnzt7f16remz3","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"Highly Advanced Epistemology 101 for Beginners","canonicalCollection":null},"User:SdZmP36R37riQrHAw":{"_id":"SdZmP36R37riQrHAw","__typename":"User","slug":"lukeprog","createdAt":"2009-03-19T08:07:34.230Z","username":"lukeprog","displayName":"lukeprog","profileImageId":null,"previousDisplayName":null,"fullName":"Luke Muehlhauser","karma":36768,"afKarma":3,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":458,"commentCount":4087,"sequenceCount":3,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":58,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:yFvZa9wkv5JoqhM8F_contents":{"_id":"yFvZa9wkv5JoqhM8F_contents","__typename":"Revision","version":null,"updateType":"minor","editedAt":"2025-04-10T03:40:41.453Z","userId":null,"html":null,"commitMessage":"","wordCount":null,"htmlHighlight":"","plaintextDescription":""},"Sequence:yFvZa9wkv5JoqhM8F":{"_id":"yFvZa9wkv5JoqhM8F","__typename":"Sequence","createdAt":"2017-11-25T22:42:52.100Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:yFvZa9wkv5JoqhM8F_contents"},"gridImageId":"sequencesgrid/yxlirutmux2fjqnnjhoc","bannerImageId":"sequences/q1spaabxeuy2wkgpafwa","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":1,"title":"Rationality and Philosophy","canonicalCollection":null},"User:pnFbJAtNHGDK8PHQx":{"_id":"pnFbJAtNHGDK8PHQx","__typename":"User","slug":"annasalamon","createdAt":"2009-02-27T04:25:14.013Z","username":"AnnaSalamon","displayName":"AnnaSalamon","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":18364,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":91,"commentCount":992,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":27,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:XipJ7DMjYyriAm7fr_contents":{"_id":"XipJ7DMjYyriAm7fr_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-25T21:06:47.500Z","userId":"pnFbJAtNHGDK8PHQx","html":"<p>Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply &quot;intuiting&quot; the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. <\/p><p>For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb&#x27;s problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.<\/p>","commitMessage":null,"wordCount":66,"htmlHighlight":"<p>Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply &quot;intuiting&quot; the answers to decision problems by ad-hoc methods is not conducive to thorough analysis. <\/p><p>For this, we formulate decision theories. This sequence, themed with an analysis of Newcomb&#x27;s problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing.<\/p>","plaintextDescription":"Decisions need to be modeled with some structure in order to be scrutinized and systematically improved; simply \"intuiting\" the answers to decision problems by ad-hoc methods is not conducive to thorough analysis.\n\nFor this, we formulate decision theories. This sequence, themed with an analysis of Newcomb's problem, is a consolidated summary and context for the many decision theory discussions found on LessWrong at the time of writing."},"Sequence:XipJ7DMjYyriAm7fr":{"_id":"XipJ7DMjYyriAm7fr","__typename":"Sequence","createdAt":"2017-11-25T21:06:47.500Z","userId":"pnFbJAtNHGDK8PHQx","user":{"__ref":"User:pnFbJAtNHGDK8PHQx"},"contents":{"__ref":"Revision:XipJ7DMjYyriAm7fr_contents"},"gridImageId":"sequencesgrid/qpreo6bc9vxwyf2l1dzo","bannerImageId":"sequences/nrxkrnabxv7q0szgjjcr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Decision Theory: Newcomb's Problem","canonicalCollection":null},"Revision:oi873FWi6pHWxswSa_contents":{"_id":"oi873FWi6pHWxswSa_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-24T03:37:56.045Z","userId":"SdZmP36R37riQrHAw","html":"<p>A <u><a href=\"https://wiki.lesswrong.com/wiki/Sequence\">sequence<\/a><\/u> summarizing scientifically-backed advice for &quot;<u><a href=\"https://wiki.lesswrong.com/wiki/Winning\">winning<\/a><\/u>&quot; at everyday life: in one&#x27;s productivity, in one&#x27;s relationships, in one&#x27;s emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.<\/p>","commitMessage":null,"wordCount":35,"htmlHighlight":"<p>A <u><a href=\"https://wiki.lesswrong.com/wiki/Sequence\">sequence<\/a><\/u> summarizing scientifically-backed advice for &quot;<u><a href=\"https://wiki.lesswrong.com/wiki/Winning\">winning<\/a><\/u>&quot; at everyday life: in one&#x27;s productivity, in one&#x27;s relationships, in one&#x27;s emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature.<\/p>","plaintextDescription":"A sequence summarizing scientifically-backed advice for \"winning\" at everyday life: in one's productivity, in one's relationships, in one's emotions, etc. Each post concludes with footnotes and a long list of references from the academic literature."},"Sequence:oi873FWi6pHWxswSa":{"_id":"oi873FWi6pHWxswSa","__typename":"Sequence","createdAt":"2017-11-24T03:37:56.045Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:oi873FWi6pHWxswSa_contents"},"gridImageId":"sequencesgrid/yp01lueog8rjaybsizux","bannerImageId":"sequences/l6y9o00lif4qenrdel5w","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"The Science of Winning at Life","canonicalCollection":null},"Revision:bQgRsy23biR52poMf_contents":{"_id":"bQgRsy23biR52poMf_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-22T02:58:02.903Z","userId":"SdZmP36R37riQrHAw","html":"<p>Years ago, I wrote an unfinished sequence of posts called &quot;<a href=\"https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics<\/a>.&quot; My last post, <a href=\"https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">Pluralistic Moral Reductionism<\/a>, said I would next explore &quot;empathic metaethics,&quot; but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic metaethics&quot; in <a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort\">section 6.1.2<\/a> of a report prepared for my employer, the <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy Project<\/a>. With my employer&#x27;s permission, I&#x27;ve adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics.<\/p>","commitMessage":null,"wordCount":87,"htmlHighlight":"<p>Years ago, I wrote an unfinished sequence of posts called &quot;<a href=\"https://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics\">No-Nonsense Metaethics<\/a>.&quot; My last post, <a href=\"https://www.lesserwrong.com/posts/3zDX3f3QTepNeZHGc/pluralistic-moral-reductionism\">Pluralistic Moral Reductionism<\/a>, said I would next explore &quot;empathic metaethics,&quot; but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on &quot;empathic metaethics&quot; in <a href=\"https://www.openphilanthropy.org/2017-report-consciousness-and-moral-patienthood#ExtremeEffort\">section 6.1.2<\/a> of a report prepared for my employer, the <a href=\"https://www.openphilanthropy.org/\">Open Philanthropy Project<\/a>. With my employer&#x27;s permission, I&#x27;ve adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics.<\/p>","plaintextDescription":"Years ago, I wrote an unfinished sequence of posts called \"No-Nonsense Metaethics.\" My last post, Pluralistic Moral Reductionism, said I would next explore \"empathic metaethics,\" but I never got around to writing those posts. Recently, I wrote a high-level summary of some initial thoughts on \"empathic metaethics\" in section 6.1.2 of a report prepared for my employer, the Open Philanthropy Project. With my employer's permission, I've adapted that section for publication here, so that it can serve as the long-overdue concluding post in my sequence on metaethics."},"Sequence:bQgRsy23biR52poMf":{"_id":"bQgRsy23biR52poMf","__typename":"Sequence","createdAt":"2017-11-22T02:58:02.903Z","userId":"SdZmP36R37riQrHAw","user":{"__ref":"User:SdZmP36R37riQrHAw"},"contents":{"__ref":"Revision:bQgRsy23biR52poMf_contents"},"gridImageId":"sequencesgrid/kvoeqrfluqd0jv5fvwez","bannerImageId":"sequences/p5ywbc6j8355jbcptyrz","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":5,"readPostsCount":0,"title":"No-Nonsense Metaethics","canonicalCollection":null},"Revision:oLGCcbnvabyibnG9d_contents":{"_id":"oLGCcbnvabyibnG9d_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-11-07T03:42:59.852Z","userId":"nmk3nLpQE89dMRzzN","html":"<p>Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal.<\/p>","commitMessage":null,"wordCount":34,"htmlHighlight":"<p>Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal.<\/p>","plaintextDescription":"Inadequate Equilibria is a book about a generalized notion of efficient markets, and how we can use this notion to guess where society will or won’t be effective at pursuing some widely desired goal."},"Sequence:oLGCcbnvabyibnG9d":{"_id":"oLGCcbnvabyibnG9d","__typename":"Sequence","createdAt":"2017-11-07T03:42:59.852Z","userId":"nmk3nLpQE89dMRzzN","user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"contents":{"__ref":"Revision:oLGCcbnvabyibnG9d_contents"},"gridImageId":"sequencesgrid/vbhv0s06jdmonk6garvf","bannerImageId":"sequences/gl1xzufmu65v6cn66wrm","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":0,"title":"Inadequate Equilibria","canonicalCollection":null},"User:hbQoLoK5tpmFAJGr4":{"_id":"hbQoLoK5tpmFAJGr4","__typename":"User","slug":"scott-garrabrant","createdAt":"2017-09-22T02:21:16.385Z","username":"Scott Garrabrant","displayName":"Scott Garrabrant","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":8387,"afKarma":1575,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":74,"commentCount":416,"sequenceCount":4,"afPostCount":99,"afCommentCount":192,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"grecHJcgkb3KW5wnM"},"Revision:2A7rrZ4ySx6R8mfoT_contents":{"_id":"2A7rrZ4ySx6R8mfoT_contents","__typename":"Revision","version":"0.3.0","updateType":"minor","editedAt":"2021-01-19T23:18:25.404Z","userId":"XtphY3uYHwruKqDyG","html":"<p>Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames.<\/p>","commitMessage":"","wordCount":34,"htmlHighlight":"<p>Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames.<\/p>","plaintextDescription":"Cartesian frames are a way to add a first-person perspective (with choices, uncertainty, and so on) on top of a set of possible worlds. This sequence introduces Cartesian frames and basic operations on frames."},"Sequence:2A7rrZ4ySx6R8mfoT":{"_id":"2A7rrZ4ySx6R8mfoT","__typename":"Sequence","createdAt":"2020-10-22T13:42:07.868Z","userId":"hbQoLoK5tpmFAJGr4","user":{"__ref":"User:hbQoLoK5tpmFAJGr4"},"contents":{"__ref":"Revision:2A7rrZ4ySx6R8mfoT_contents"},"gridImageId":"sequencesgrid/a9iwqgsxkqznfrtskanw","bannerImageId":"sequences/jtgjfl0vc1igtmdwambt","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":0,"userProfileOrder":null,"af":true,"postsCount":13,"readPostsCount":1,"title":"Cartesian Frames","canonicalCollection":null},"User:iPdmf2tiNRtfJbvdQ":{"_id":"iPdmf2tiNRtfJbvdQ","__typename":"User","slug":"alicorn","createdAt":"2009-03-17T18:52:42.458Z","username":"Alicorn","displayName":"Alicorn","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":30845,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":82,"commentCount":5201,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Revision:ynMFrq9K5iNMfSZNg_contents":{"_id":"ynMFrq9K5iNMfSZNg_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2019-05-02T19:07:37.622Z","userId":"XtphY3uYHwruKqDyG","html":"<p><u><a href=\"https://wiki.lesswrong.com/wiki/Luminosity\">Luminosity<\/a><\/u>, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an <u><a href=\"https://wiki.lesswrong.com/wiki/Emotion\">emotion<\/a><\/u>, a <u><a href=\"https://wiki.lesswrong.com/wiki/Belief\">belief<\/a><\/u> or <u><a href=\"https://wiki.lesswrong.com/wiki/Alief\">alief<\/a><\/u>, a disposition, a <u><a href=\"https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1\">quale<\/a><\/u>, a memory - anything that might happen or be stored in your brain. What&#x27;s going on in your head?<\/p>","commitMessage":null,"wordCount":52,"htmlHighlight":"<p><u><a href=\"https://wiki.lesswrong.com/wiki/Luminosity\">Luminosity<\/a><\/u>, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an <u><a href=\"https://wiki.lesswrong.com/wiki/Emotion\">emotion<\/a><\/u>, a <u><a href=\"https://wiki.lesswrong.com/wiki/Belief\">belief<\/a><\/u> or <u><a href=\"https://wiki.lesswrong.com/wiki/Alief\">alief<\/a><\/u>, a disposition, a <u><a href=\"https://wiki.lesswrong.com/index.php?title=Qualia&action=edit&redlink=1\">quale<\/a><\/u>, a memory - anything that might happen or be stored in your brain. What&#x27;s going on in your head?<\/p>","plaintextDescription":"Luminosity, as used here, is self-awareness. A luminous mental state is one that you have and know that you have. It could be an emotion, a belief or alief, a disposition, a quale, a memory - anything that might happen or be stored in your brain. What's going on in your head?"},"Sequence:ynMFrq9K5iNMfSZNg":{"_id":"ynMFrq9K5iNMfSZNg","__typename":"Sequence","createdAt":"2018-02-22T18:50:08.321Z","userId":"iPdmf2tiNRtfJbvdQ","user":{"__ref":"User:iPdmf2tiNRtfJbvdQ"},"contents":{"__ref":"Revision:ynMFrq9K5iNMfSZNg_contents"},"gridImageId":"sequencesgrid/ozdf0thhtehmpmbf9dys","bannerImageId":"sequences/pkhcwvrxma1bl0g4cuto","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":0,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"Living Luminously","canonicalCollection":null}}</script>
<script>window.__APOLLO_FOREIGN_STATE__ = {}</script>

<script src="eliezer_files/api.js"></script><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" tabindex="-1" title="Intercom"></iframe><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-e33nogc02uw1" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="eliezer_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M18.601 8.39897C18.269 8.06702 17.7309 8.06702 17.3989 8.39897L12 13.7979L6.60099 8.39897C6.26904 8.06702 5.73086 8.06702 5.39891 8.39897C5.06696 8.73091 5.06696 9.2691 5.39891 9.60105L11.3989 15.601C11.7309 15.933 12.269 15.933 12.601 15.601L18.601 9.60105C18.9329 9.2691 18.9329 8.73091 18.601 8.39897Z" fill="white"></path>
</svg>
</div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    0% {
      opacity: 0;
      transform: scale(0);
    }
    40% {
      opacity: 1;
    }
    100% {
      transform: scale(1);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #f5f5f5;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }


  .intercom-lightweight-app-launcher:hover {
    transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    transform: scale(1.1)
  }

  .intercom-lightweight-app-launcher:active {
    transform: scale(0.85);
    transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
  }


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1, 1, 1);
    transform-origin: bottom right;

    
        width: 400px;
        height: calc(100% - 104px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 84px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 16px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    border-bottom: none;
    background: white
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    height: 80px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div></body></html>