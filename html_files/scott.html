<!DOCTYPE html>
<html lang="en"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<link rel="preload" as="style" href="scott_files/allStyles.css"><link rel="stylesheet" type="text/css" href="scott_files/icon.css"><link rel="stylesheet" type="text/css" href="scott_files/reset-min.css"><link rel="stylesheet" type="text/css" href="scott_files/css.css"><link rel="stylesheet" type="text/css" href="scott_files/jvr1gjm.css"><link rel="stylesheet" type="text/css" href="scott_files/tqv5rhd.css"><script type="text/javascript" async="" charset="utf-8" src="scott_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-C0eb2CrhokW3SgZMDSrT/ioPvOCBoj1s7JouJ8IrLFB+j5cW9qY3JDWtShxtCryz"></script><script async="" src="scott_files/google-analytics_analytics.js"></script><script>window.publicInstanceSettings = {"forumType":"LessWrong","title":"LessWrong","siteNameWithArticle":"LessWrong","sentry":{"url":"https://1ab1949fc8d04608b43132f37bb2a1b0@sentry.io/1301611","environment":"production","release":"69f0f3c5d57b596e8249571383f8a280eff9bb23"},"debug":false,"aboutPostId":"bJ2haLkcGeLtTWaD5","faqPostId":"2rWKkWuPrgTMpLRbp","contactPostId":"ehcYkvyz7dh9L7Wt8","expectedDatabaseId":"production","tagline":"A community blog devoted to refining the art of rationality","faviconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","faviconWithBadge":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_with_badge.ico","forumSettings":{"headerTitle":"LESSWRONG","shortForumTitle":"LW","tabTitle":"LessWrong"},"analytics":{"environment":"lesswrong.com"},"cluster":{"enabled":true,"numWorkers":2},"testServer":false,"fmCrosspost":{"siteName":"the EA Forum","baseUrl":"https://forum.effectivealtruism.org/"},"allowTypeIIIPlayer":true,"hasRejectedContentSection":true,"hasCuratedPosts":true,"performanceMetricLogging":{"enabled":true,"batchSize":100},"reviewBotId":"tBchiz3RM7rPwujrJ","recombee":{"databaseId":"lightcone-infrastructure-lesswrong-prod-2","publicApiToken":"sb95OJbQ7mKLQAm1abPog2m5vCPj7XqZlVYdHGyANcjzqaHT5fX6HEgB0vCfiLav"},"homepagePosts":{"feeds":[{"name":"forum-classic","label":"Latest","description":"The classic LessWrong frontpage algorithm that combines karma with time discounting, plus any tag-based weighting if applied.","showToLoggedOut":true},{"name":"recombee-hybrid","label":"Enriched","description":"An equal mix of Latest and Recommended.","showSparkleIcon":true,"defaultTab":true,"showToLoggedOut":true},{"name":"recombee-lesswrong-custom","label":"Recommended","description":"Personalized recommendations from the history of LessWrong, using a machine learning model that takes into account posts you've read and/or voted on.","showSparkleIcon":true,"showToLoggedOut":true},{"name":"forum-subscribed-authors","label":"Subscribed","description":"Posts and comments by people you've explicitly subscribed to.","isInfiniteScroll":true},{"name":"vertex-default","label":"Vertex","description":"Experimental feed for Google Vertex recommendations.","showLabsIcon":true,"adminOnly":true},{"name":"forum-bookmarks","label":"Bookmarks","description":"A list of posts you saved because you wanted to have them findable later."},{"name":"forum-continue-reading","label":"Resume Reading","description":"Further posts in post sequences that you started reading.","disabled":true}]}}</script><link rel="shortcut icon" href="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico"><script>window.publicSettings = {"forum":{"numberOfDays":10,"postInterval":30,"numberOfWeeks":4,"numberOfYears":4,"maxPostsPerDay":5,"numberOfMonths":4},"type3":{"cutoffDate":"2023-07-01","explicitlyAllowedPostIds":["SvKSwT6xYfYahH4XN","2weRdcvqANDq3zdPH","Zm7WAJMTaFvuh2Wc7","HcjL8ydHxPezj6wrt","pgGiqLQg2KWsaz5RE","jFzovY2CERF5bd2EW","sm6npdgZArSn4afeZ","CfX6pGepdjQYELSpK","NyFuuKQ8uCEDtd2du","LCjtqsQWapoSfDHqK","MxyRNd6qJsYAcXKuw","reG3g4wwzwJcKnFfh","zfeWGvTrS6wKQeeoF","oHsMeXehPy4jHcmwy","ofL22R6KZsfrvdmwg","655TmdcwAgryPGPWS","hhrv8aAcmkzJxvP58","iqQJiKcephtMgzJgN","mnpkM57R6ZbjnwrYw","6mRv7Cr57AJAtRFHv","ak9wY2t9K3K4GxCXv","Ay6GBGNcCgP55dRQ7","aH4mjhgqNPyYvJT85","JpoLCHytYiCm7fwNA","efMgZujzfjP9B9H4R","BjLxPLsev54LFCS3A","HTGCGASf9xfB6edAh","H6LnGwjKiGvDyR5yo","qL8Z9TBCNWQyN6yLq","F4xwRTrFQyazHufjD","LY7Nca846X8kcT8Jk","K9aLcuxAPyf5jGyFX","2AuvBPw6Rb7yxkvKc","muhtBvbh4etjkKXd9","ALEYMFAuFSCz8v5YE","CJxSgaqG6y7z6Rbij","k5TpDCEHeK4qwnJt8","4Y2J7NtuweW2B8JvB","BpYDqQNZ2NZNCqPp6","oMiogKLkK8L59WzDe","TyQSMmoJpRG3HBv5S","8KHR3tfa4SJjMSkXd","g4pi2jfQHFF6mPdjw","znEhB9hJtwXica5s3","Sd2r7H8bCmd9ChGbX","P2nYKqwmHdYKARTG8","FW3DEYbKPZJh5A8Bj","K3hFLRn7MvYacL466","ouSpHCCPgsXkwxAGb","w9SuQtRJLbDpeir6L","yPQGYn9rSme9RRpiQ","BD6WYC4GT6dnWaJRN","c8khnHoRTSGjmHLLf","TaPr4YSBbiakeKdwX","pyNPXST7feDX45ygt","ERPL3v2Y976W7XG3j","XpXQ4KNzLa9ZHYw8p","PBhrHw5X8sDmHDWkX","8KhThQXzsAEZ59iko","iYJo382hY28K7eCrP","KrEwDMN4YXp5YWD45","rNJ39yQmzTnseh8nL","hMQPyLDbg3bA7P6aN","3Jqz6JE8K6vyQ9hJ5","SQAfPKZBAAKYMjx25","Y345zuBetHqGnotwm","pZerSnxv6FPqvgoYu","3bPH2az479gzxDMbf","QXShCBvPydkwafekn","iLMkKDKmfbMkDuQBm","iNCg6mjw584r9BWZK","9oqF382ASmjaGBo7z","DdNB42JgBzbbvmAum","JP7eZYHB7aY6fA4TR","snwX7hXgLFikqDBr6","CsKrQdQJJCFPjfKjF","vhxywjnBH6ioRnnt3","A4MK9RQqSAJZjanQD","PCpzG9NJeviXM5YSq","KCcdhZK7omEMwBdju","kdmCm5NQTpqhJmGm6","2p8BWvcJvKkXGMsch","FLnDFnXyWrKr6eiT6","2gWs8SScqeDFidqyv","2HafkDSNdtMzptzcN","cTQRGJTQ2eGKm5G9g","qaHHJ3kkCQS4nsoGJ","gS8Jmcfoa9FAh92YK","eRhFaibbTeGbjdaaf","xij43oLTBRnEQv2bT","BZMc9Xzqw5WcCMHrr","2jZykdLg9fBGqKd46","gBChm3THPGFcrq5eH","9HSwh2mE3tX6xvZ2W","tEHJXNhw6t87foqJL","T5McDuWDeCvDZKeSj","PeTL97v92LxRJBsrM","Cq45AuedYnzekp3LX","pfmZ5cYQCahABGZzi","3wBj8BPquskZAbXu9","xPJKZyPCvap4Fven8","BPKvZuLRyiJBjfNbg","um7w5RogAHhxGy8Ti","CcyGR3pp3FCDuW6Pf","BfaAADSQ88cuxLQoD","ckuuDa8DmJ4pdFeD8","pczHfyxmnFhtKthqR","dymK5c7BkpgXH4acw","B4AyJXYPpGbBmxQzd","xNBRkPNHAGQ6EQaLS","88TN6y9M5xxAHHNwW","Lt8Rn4rkYwqiTXGPy","QdXrkWoK2Pp6XhNuQ","NjzBrtvDS4jXi5Krp","ZWC3n9c6v4s35rrZ3","Fy2b55mLtghd4fQpx","eaczwARbFnrisFx8E","KLjQedNYNEP4tW73W","DSnamjnW7Ad8vEEKd","7iDtkfyn322nPzTP4","eaSJtg8Kvc56bFBdt","AmaWMMWPzuQ62Ernf","jkf2YjuH8Z2E7hKBA","BroeiXGh9PrKZEkJ5","9Tw5RqnEzqEtaoEkq","EMJ3egz48BtZS8Pws","MkKcnPdTZ3pQ9F5yC","kjArXFinD3deRZNRu","Q8zqoBWBBHD2RjDuS","ePA4NDzZkunz98tLx","4xKeNKFXFB458f5N8","irbREZtZzPi7WEYex","QxZs5Za4qXBegXCgu","ZmQv4DFx6y4jFbhLy","M7rwT264CSYY6EdR3","z3cTkXbA7jgwGWPcv","9thqSN8HDLM3LTxK5","MtNnFg4uN32YPoKNa","Ep2Z42hYqj68QZz6w","ibk7q8msSYxZXmfCf","EgDpZS4HHeh5vqJPe","5dhWhjfxn4tPfFQdi","Wh8HAK6LR5CAoPCCC","Yy7mgec8tsbTAuTqb","azoP7WeKYYfgCozoh","Zh9AiXNjQaYXjmNaC","bJiyYJeCyh4HcKHub","aPrCzeFfbBmRsvzby","vXCK3kptLLggEfojX","M2LWXsJxKS626QNEA","LQp9cZPzJncFKh5c8","CZnBQtvDw33rmWpBD","miHttwTgajY2sjY3L","K2JBqDeETX2yEgyyZ","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","mja6jZ6k9gAwki9Nu","qjSHfbjmSyMnGR9DS","Sx26Aj3xuMzmnKE4A","P3uavjFmZD5RopJKk","pJJdcZgB6mPNWoSWr","oGezscrQvPDgGvrbt","AYbhqi65SWzHzy7Xx","E4cKD9iTWHaE7f3AJ","x9FNKTEt68Rz6wQ6P","HAEPbGaMygJq8L59k","znBJwbuT3f5eWgM4E","yJfBzcDL9fBHJfZ6P","YAkpzvjC768Jm2TYb","LTtNXM9shNM9AC2mp","9hR2RmpJmxT8dyPo4","WQWhXzALcrzrJtqRh","p7WXmG6Fbo3eaSwm3","KheBaeW8Pi7LwewoF","A2Qam9Bd9xpbb2wLQ","asmZvCPHcB4SkSCMW","euJm4RwkAptZnP89i","r8stxYL29NF9w53am","6yTShbTdtATxKonY5","yDRX2fdkm3HqfTpav","EhEZoTFzys9EDmEXn","YSWa8rYeD3aDaofSP","rwkkcgSpnAyE8oNo3","HmfxSWnqnK265GEFM","Ltey8BS83qSkd9M3u","atcJqdhCxTZiJSxo2","pC47ZTsPNAkjavkXs","wJnm5cBiZGmKn595f","GrtbTAPfkJa4D6jjH","LgavAYtzFQZKg95WC","reitXJgJXFzKpdKyd","ZiQqsgGX6a42Sfpii","neQ7eXuaXpiYw7SBy","hQHuXuRGZxxWXaPgg","9kcTNWopvXFncXgPy","baTWMegR42PAsH9qJ","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","R6M4vmShiowDn56of","6Fpvch8RR29qLEWNH","N6WM6hs7RQMKDhYjB","pdaGN6pQyQarFHXF4","SA9hDewwsYgnuscae","i9xyZBS3qzA8nFXNQ","bx3gkHJehRCYZAF3r","Jk9yMXpBLMWNTFLzh","JvZhhzycHu2Yd57RN","vzfz4AS6wbooaTeQk","gHefoxiznGfsbiAu9","sbcmACvB6DqYXYidL","kipMvuaK3NALvFHc9","xdwbX9pFEr7Pomaxv","XvN2QQpKTuEzgkZHY","uFNgRumrDTpBfQGrs","ii4xtogen7AyYmN6B","kpPnReyBC54KESiSn","FRv7ryoqtvSuqBxuT","u8GMcpEN9Z6aQiCvp","B2CfMNfay2P8f2yyc","JD7fwtRQ27yc8NoqS","mRwJce3npmzbKfxws","3rxMBRCYEmHCNDLhu","FWvzwCDRgcjb9sigb","KrJfoZzpSDpnrv9va","LpM3EAakwYdS6aRKf","Cf2xxC3Yx9g6w7yXN","qHCDysDnvhteW7kRd","mELQFMi9egPn5EAjK","qDmnyEMtJkE9Wrpau","4ZvJab25tDebB8FGE","4QemtxDFaGXyGSrGD","Psr9tnQFuEXiuqGcR","qmXqHKpgRfg83Nif9","ximou2kyQorm6MPjX","eccTPEonRe4BAvNpD","2cYebKxNp47PapHTL","pv7Qpu8WSge8NRbpB","PqMT9zGrNsGJNfiFR","B9kP6x5rpmuCzpfWb","zB4f7QqKhBHa5b37a","qc7P2NwfxQMC3hdgm","RcifQCKkRc9XTjxC2","YABJKJ3v97k9sbxwg","bNXdnRTpSXk9p4zmi","fRsjBseRuvRhMPPE5","MzKKi7niyEqkBPnyu","NQgWL7tvAPgN2LTLn","cujpciCqNbawBihhQ","wEebEiPpEwjYvnyqq","AqbWna2S85pFTsHH4","Nwgdq6kHke5LY692J","8xLtE3BwgegJ7WBbf","SWxnP5LZeJzuT3ccd","Tr7tAyt5zZpdTwTQK","ax695frGJEzGxFBK4","FkgsxrGf3QxhfLWHG","vJ7ggyjuP4u2yHNcP","X5RyaEDHNq5qutSHK","xhD6SHAAE9ghKZ9HS","AyNHoTWWAJ5eb99ji","F5ktR95qqpmGXXmLq","znfkdCoHMANwqc2WE","jbE85wCkRr9z7tqmD","4K5pJnKBGkqqTbyxx","yeADMcScw8EW9yxpH","9QxnfMYccz9QRgZ5z","X2i9dQQK3gETCyqh2","4XRjPocTprL4L8tmB","D6trAzh6DApKPhbv4","BcYfsi7vmhDvzQGiF","i42Dfoh4HtsCAfXxL","zp5AEENssb8ZDnoZR","KwdcMts8P8hacqwrX","RQpNHSiWaXTvDxt6R","nSjavaKcBrtNktzGa","hNqte2p48nqKux3wS","7im8at9PmhbT4JHsW","SwcyMEgLyd4C3Dern","AHhCrJ2KpTjsCSwbt","rz73eva3jv267Hy7B","E4zGWYzh6ZiG85b2z","hvGoYXi2kgnS3vxqb","D4hHASaZuLCW92gMy","v7c47vjta3mavY3QC","G5TwJ9BGxcgh5DsmQ","YRgMCXMbkKBZgMz4M","ham9i5wf4JCexXnkN","a4jRN9nbD79PAhWTB","xJyY5QkQvNJpZLJRo","ivpKSjM4D6FbqF4pZ","p7x32SEt43ZMC9r7r","f886riNJcArmpFahm","xhE4TriBSPywGuhqi","ThvvCE2HsLohJYd7b","diruo47z32eprenTg","JJFphYfMsdFMuprBy","ZDZmopKquzHYPRNxq","KkwtLtroaNToWs2H6","vKErZy7TFhjxtyBuG","3L46WGauGpr7nYubu","CSZnj2YNMKGfsMbZA","G2Lne2Fi7Qra5Lbuf","x6hpkYyzMG6Bf8T3W","aFaKhG86tTrKvtAnT","PrCmeuBPC4XLDQz8C","dYspinGtiba5oDCcv","9cbEPEuCa9E7uHMXT","N5Jm6Nj4HkNKySA5Z","asmZvCPHcB4SkSCMW","duxy4Hby5qMsv42i8","Djs38EWYZG8o7JMWY","A8iGaZ3uHNNGgJeaD","XYYyzgyuRH5rFN64K","2jfiMgKkh7qw9z8Do","JPan54R525D68NoEt","o4cgvYmNZnfS4xhxL","CeZXDmp8Z363XaM6b","DQKgYhEYP86PLW7tZ","niQ3heWwF6SydhS7R","gvK5QWRLk3H8iqcNy","fnkbdwckdfHS2H22Q","YicoiQurNBxSp7a65","JBFHzfPkXHB2XfDGj","tj8QP2EFdP8p54z6i","9fB4gvoooNYa4t56S","zTfSXQracE7TW8x4w","YcdArE79SDxwWAuyF","8xRSjC76HasLnMGSf","CvKnhXTu9BPcdKE4W","DtcbfwSrcewFubjxp","NxF5G6CJiof6cemTw","4ZwGqkMTyAvANYEDw","EF5M6CmKRd6qZk27Z","cCMihiwtZx7kdcKgt","Qz6w4GYZpgeDp6ATB","TPjbTXntR54XSZ3F2","x3fNwSe5aWZb5yXEG","bnY3L48TtDrKTzGRb","ZFtesgbY9XwtqqyZ5","S7csET9CgBtpi7sCh","tTWL6rkfEuQN9ivxj","L6Ktf952cwdMJnzWm","P6fSj3t4oApQQTB7E","4s2gbwMHSdh2SByyZ","sTwW3QLptTQKuyRXx","EYd63hYSzadcNnZTD","tF8z9HBoBn783Cirz","hyShz2ABiKX56j5tJ","YN6daWakNnkXEeznB","6DuJxY8X45Sco4bS2","TMFNQoRZxM4CuRCY6","q3JY4iRzjq56FyjGF","diutNaWF669WgEt3v","5okDRahtDewnWfFmz","r3NHPD3dLFNk9QE2Y","ALkH4o53ofm862vxc","N9oKuQKuf7yvCCtfq","WjsyEBHgSstgfXTvm","2G8j8D5auZKKAjSfY","rBkZvbGDQZhEymReM","nNqXfnjiezYukiMJi","36Dhz325MZNq3Cs6B","f2GF3q6fgyx8TqZcn","byewoxJiAfwE6zpep","nEBbw2Bc2CnN2RMxy","w4aeAFzSAguvqA5qu","xFotXGEotcKouifky","rzqACeBGycZtqCfaX","DoPo4PDjgSySquHX8","o3RLHYviTE4zMb9T9","5gfqG3Xcopscta3st","GNhMPAWcfBCASy8e6","uXH4r6MmKPedk8rMA","Gg9a4y8reWKtLe3Tn","bBdfbWfWxHN9Chjcq","sT6NxFxso6Z9xjS7o","k9dsbn8LZ6tTesDS3","exa5kmvopeRyfJgCy","YTJp5WBcktBimdxBG","X79Rc5cA5mSWBexnd","SvKpaPbZ2tibeDpgh","rQKstXH8ZMAdN5iqD","vQKbgEKjGZcpbCqDs","Z9cbwuevS9cqaR96h","pHHaNkG8xDcaq5DJF","sjRG35aq5fosJ6mdG","pPWiLGsWCtN92vLwu","D5BP9CxKHkcjA7gLv","57sq9qA3wurjres4K","t2LGSDwT7zSnAGybG","7Pq9KwZhG6vejmYpo","g3PwPgcdcWiP33pYn","zcriHTKgKNehSSdyG","kvLPC5YWgSujcHSkY","HnC29723hm6kJT7KP","CRiJuJxgArjBMJLvK","dyJfGeWo5GX2u6NGi","QLmSFeFexgTLsNeeA","kmT47aLQmqzcw329Y","givHhuPu6G43g8kWN","83DimRqppcaoyYAsy","vvzfFcbmKgEsDBRHh","FfNEt8mpi6qanNmXg","MrAfiomDNWCzxjei5","73kwTFKgi4AagxFHJ","iBBK4j6RWC7znEiDv","W8vSrHAM9qoWdzFoP","Rx9GLepCxctXDqCPc","4X9JLr2SpB6v68twG","yxTP9FckrwoMjxPc4","FuZ7MoR3dJEJuoRbN","xRyLxfytmLFZ6qz5s","mwGAyWmsSqzMz4WMd","xxC3Ka7axphW8kJ9E","KT8Mf3ey6uwQAkWek","GDT6tKH5ajphXHGny","ZXaRHHLsxaTTQQsZb","CHdsSaQGAvtkXBzmJ","HAEPbGaMygJq8L59k","SmDziGM9hBjW9DKmf","8NKu9WES7KeKRWEKK","NfdHG6oHBJ8Qxc26s","LTtNXM9shNM9AC2mp","uKp6tBFStnsvrot5t","baTWMegR42PAsH9qJ","Xqcorq5EyJBpZcCrN","7cAsBPGh98pGyrhz9","ZbgCx2ntD5eu8Cno9","9kcTNWopvXFncXgPy","HxWdXMqoQtjDhhNGA","xwBuoE9p8GE7RAuhd","inedT6KkbLSDwZvfd","sWLLdG6DWJEy3CH7n","dhj9dhiwhq3DX6W8z","yLLkWMDbC9ZNKbjDG","P3Yt66Wh5g7SbkKuT","brXr7PJ2W4Na2EW2q","45mNHCMaZgsvfDXbw","7izSBpNJSEXSAbaFh","pfoZSkZ389gnz5nZm","jfG6vdJZCwTQmG7kb","sGnPTfjE5JthAStqg","gvA4j8pGYG4xtaTkw","PZtsoaoSLpKjjbMqM","jnDibtfvWNHLucf4D","GrtbTAPfkJa4D6jjH","zEWJBFFMvQ835nq6h","64FdKLwmea8MCLWkE","Dx9LoqsEh3gHNJMDk","FMkQtPvzsriQAow5q","XuLG6M7sHuenYWbfC","PGv9THs68ArPur7yP","NcGBmDEe5qXB7dFBF","tEDXpFgsHsm5T8sWz","7gsehrZnvXo2YGiT7","x4n4jcoDP7xh5LWLq","boBZkTqPdboX5u7g9","CJw2tNHaEimx6nwNy","CcC8MocynqKPmMPwL","Rrt7uPJ8r3sYuLrXo","rwjv8bZfSuE9ZAigH","khYYedgupgrHonWNc","wrkEnGrTTrM2mnmGa","f9s7pHub6hbsX7YKT","YduZEfz8usGbJXN4x","55SHk8kh9dDvaDTCC","SFG9Cm7mf5eP4juKs","eLRSCC7r4KinuxqZX","oW6mbA3XHzcfJTwNq","kWMkDoy3izRTobZFe","LtsJLfnP4YwhGdaCf","w9kwayt5SWqBQe8Nx","h5CGM5qwivGk2f5T9","iPGpENE4ARKbzzQmt","PQ3nutgxfTgvq69Xt","3zZjF3YKJ257x79mu","9Qwignbzu4ddXLTsT","aiCtrN9EF2FjKz5sv","JcpwEKbmNHdwhpq5n","idipkijjz5PoxAwju","F7RgpHHDpZYBjZGia","xWTSHJASRaLABgHWc","Fg8dtE8HHkDoiGcwt","zPJE7MDtL25RpN7Cc","qqhdj3W3vSfB5E9ss","9SE67uz98kh6x2CxR","gR6H3egpRPNYnoTrA","qPoaA5ZSedivA4xJa","H6L7fuEN9qXDanQ6W","gfexKxsBDM6v2sCMo","7uJnA3XDpTgemRH2c","stb3Jjumzhv49zCEb","XjMkPyaPYTf7LrKiT","XuyRMxky6G8gq7a69","huRxRzwcvwTzvtEPY","8bWbNwiSGbGi9jXPS","sq3WkpyqGANT7hGRP","AyfDnnAdjG7HHeD3d","WmfapdnpFfHWzkdXY","8rYxw9xZfwy86jkpG","zFhhDCxz87yKwqYQf","doiMq8aH2yiZaCJsT","MQzbaHoiQutiHkx2M","ra9Pt2JkEDnKW4jsc","9YDk52NPrfq7nqLvd","KTEciTeFwL2tTujZk","6bSjRezJDxR2omHKE","r5H6YCmnn8DMtBtxt","JbcWQCxKWn3y49bNB","R4FX6wDmppvZ2JqpB","9vnWFwng8QzEnBT8z","XCtFBWoMeFwG8myYh","6uwLq8kofo4Tzxfe2","G993PFTwqqdQv4eTg","DWgWbXRfXLGHPgZJM","K7wtTqTEoKXC9Kb24","hmai5Lru5kWXpH7Ju","w4jjwDPa853m9P4ag","xvAkpCSdqgtYhEceo","6vMBpZtoRw4ia2JrK","Wzjjynmp8gMmdX6dt","CsN6WxwDnPzxAFhps","CLXkgEerPi9MpJCem","BKjJJH2cRpJcAnP7T","qXtbBAxmFkAQLQEJE","jES7mcPvKpfmzMTgC","D7epkkJb3CqDTYgX9","FpcgSoJDNNEZ4BQfj","mF8dkhZF9hAuLHXaD","camG6t6SxzfasF42i","HALKHS4pMbfghxsjD","HDXLTFnSndhpLj2XZ","fgYQjTktBmNZvMqce","fwNskn4dosKng9BCB","B5auLtDfQrvwEkw4Q","z7YvA5osMotdL5F4w","Hoh6umyMWSqzPGMJZ","vHSrtmr3EBohcw6t8","nsCwdYJEpmW5Hw5Xm","LKAXgTen4Xbqb8eZY","22GrdspteQc8EonMn","TSaJ9Zcvc3KWh3bjX","sJK6HN5vTPPnuuNgQ","mh3xapTix6fFtd3xM","JBnaLpsrYXLXjFocu","uR8c2NPp4bWHQ5u45","d4YGxMpzmvxknHfbe","wcNEXDHowiWkRxDNv","scNCmwaduCgJmCBYh","LsXtcLyzyfGg3gT5R","McN9BNtNcbYNfdCB5","4tzEAgdbNTwB6nKyL","sCFGEhwcB8MX3FQf5","G4uMdBzgDsxMsTNmr","34Gkqus9vusXRevR8","7MCqRnZzvszsxgtJi","HXxHcRCxR4oHrAsEr","cmrtpfG7hGEL9Zh9f","oHk9T3jbx2J5zJ39P","sYt3ZCrBq2QAf3rak","r8stxYL29NF9w53am","zymnWfGwf6BdDt64c","yyDrMYBfvYtKbmPmm","4gevjbK77NQS6hybY","jnjjzkH8Fdzg4D6EK","XKfQF73YnyMRiRf9a","gYfgWSxCpFdk2cZfE","CQsEwAyJP6NYvKZw6","JiLcxpWzCrnwkndsT","gpk8dARHBi7Mkmzt9","GrbeyZzp6NwzSWpds","9MZdwQ7u53oaRiBYX","gFyJgnu5vAbzELBM8","ouQNu3hhfKLBRuwR7","m5AH78nscsGjMbBwv","oKYWbXioKaANATxKY","cq5x4XDnLcBrYbb66","KjdP2WjWng6skwbY7","wfpdejMWog4vEDLDg","7F5jo5LD9FD7DpxCX","kDjKF2yFhFEWe4hgC","pWi5WmvDcN4Hn7Bo6","NGc3Yjecg9pDMznWq","xxvKhjpcTAJwvtbWM","DJnvFsZ2maKxPi7v7","zo9zKcz47JxDErFzQ","fyZBtNB3Ki3fM4a6Y","H4kadKrC2xLK24udn","BxersHYN2qcFoonwg","Ck5cgNS2Eozc8mBeJ","wr9dH2GjztvCz6pYX","EzAt4SbtQcXtDNhHK","syeBtmGoKvjJTH6sH","eWqFy8wESHbxNod7i","8cWMX6L8St8k9pPRC","jP583FwKepjiWbeoQ","rMfpnorsMoRwyn4iP","TKk7rShf9d5ePN7vR","fNJvYD6XqnX82i4jA","r8aAqSBeeeMNRtiYK","Gh2qQHrCg3teQen3c","3GAnfeG9KmsbsWeTj","JKgGvJCzNoBQss2bq","JjGs6mDZxeCWkg3ii","AzKx6EjaoaMuk595v","duAkuSqJhGDcfMaTA","pXLqpguHJzxSjDdx7","FbJYEn6eWA5JnGeGP","8GiTowD6XqTNzgCz7","qfDgEreMoSEtmLTws","96N8BT9tJvybLbn5z","SCs4KpcShb23hcTni","bDMoMvw2PYgijqZCC","nqwzrpkPvviLHWXaE","YuZXRxWSqaCoZHEXr","6YYmkpumigAmh3efu","SgszmZwrDHwG3qurr","9EyzaH3jzH3PyQtM5","eR7Su77N2nK3e5YRZ","GSBCw94DsxLgDat6r","cpdsMuAHSWhWnKdog","avvXAvGhhGgkJDDso","KnPN7ett8RszE79PH","ptmmK9PWgYTuWToaZ","XNhfw5Bqsi4SGNNBk","PKy8NuNPknenkDY74","3yqf6zJSwBF34Zbys","YpyW97jRbtvBAncAr","LwcKYR8bykM6vDHyo","H6hMugfY3tDQGfqYL","iyRpsScBa6y4rduEt","mLuQfS7gmfr4nwTdv","TrvkWBwYvvJjSqSCj","yXHcqrCpiHC5tDuEc","HKfBeWN8ufNdFgzG6","P8yeoeJ2bwmnD93mZ","kxW6q5YdTGWh5sWby","ksatPnddyZjHwZWwG","st7DiQP23YQSxumCt","tE7y8FZe7wSSzoRaS","L4HQ3gnSrBETRdcGu","eqxqgFxymP8hXDTt5","uKWXktrR7KpbgZAs4","h4vWsBBjASgiQ2pn6","DXBziiT2RFLcmLY9J","k42G2aaNhRNB7hdCJ","XSKQLeQnBupFo7GGC","BnDF5kejzQLqd5cjH","AMmqk74zWmvP8tXEJ","NQQzXpahhkb6f6ZCe","Tk5ovpucaqweCu4tu","9WX59u7g2sdKqnjDm","Xht9swezkGZLAxBrd","8c8AZq5hgifmnHKSN","nMNi86hgNjaNnh8iu","s3rAKTkdSHb6Hwwoz","rqnbrJhDKCoZvNGEZ","Ea8pt2dsrS6D4P54F","uN3wjp2K6TEQ2oAML","DAc4iuy4D3EiNBt9B","jqCz2X49FRn5Bgb5b","8hxvfZiqH24oqyr6y","puYfAEJJomeodeSsi","S54HKhxQyttNLATKu","igSPcmvTigCHxWt8x","4esQ684vtR9zcjHgW","yGaw4NqRha8hgx5ny","eHnupDgggBqDqT5eg","k7oxdbNaGATZbtEg3","bbGEiSmNiTpPrFhcQ","Z6dmoLyfBdmo6HEss","QcXuwQvvPkqcKZmXS","7FJRnxbRtT7Sbzizs","oBTkthd7h8sDpkiu2","cmiRk9XtT9Psnd3Yr","G6npMHwgRGSQDKavX","hwxj4gieR7FWNwYfa","yGycR8tFA3JJbvApp","jxy7rBcQink8a7C9b","vQNJrJqebXEWjJfnz","kjmpq33kHg7YpeRYW","FwYMuD2sNcaEpE5on","4rwABGAd9kZG8nf2P","GkXKvkLAcTm5ackCq","TrmMcujGZt5JAtMGg","gBpYo7mt2zNBmtBJd","aNRYQFnMQbA7uu99u","YMokuZdoY9tEDHjzv","MG8Yhsxqu9JY4xRPr","zEvqFtT4AtTztfYC4","fzeoYhKoYPR3tDYFT","8npC4KRcAJtGdErTq","AYbhqi65SWzHzy7Xx","N99KgncSXewWqkzMA","2KacvW34BbXFmDBtQ","tSgcorrgBnrCH8nL3","NHuLAS3oKZWr2X9hP","9hR2RmpJmxT8dyPo4","fwSDKTZvraSdmwFsj","Cf2zBkoocqcjnrNFD","MPj7t2w3nk4s9EYYh","TTPux7QFBpKxZtMKE","shcSdHGPhnLQkpSbX","M4w2rdYgCKctbADMn","hMjFMSQZb4swKugfv","mkrvsNi8cYGSjGqkh","DXcezGmnBcAYL2Y2u","Aq8BQMXRZX3BoFd4c","FoJSa8mgLPT83g9e8","Xt85tj6GQJCuuXT68","JAAHjm4iZ2j5Exfo2","sAiHxHkQrsYsRpKFP","6phFYpNQH9SmWL9Jt","Rkxj7TFxhbm59AKJh","rNFzvii8LtCL5joJo","Hw26MrLuhGWH7kBLm","Zvu6ZP47dMLHXMiG3","HByDKLLdaWEcA2QQD","7qhtuQLCCvmwCPfXK","FgjcHiWvADgsocE34","Lp4Q9kSGsJHLfoHX3","3xF66BNSC5caZuKyC","BseaxjsiDPKvGtDrm","Q924oPJzK92FifuFg","oJwJzeZ6ar2Hr7KAX","H7Rs8HqrwBDque8Ru","gEKHX8WKrXGM4roRC","FKB7iEergZaC7PvQf","suxvE2ddnYMPJN9HD","iETtCZcfmRyHp69w4","mz3hwS4c9bc9EHAm9","KFLdfuw35qkgjzWer","RApxEu3A4GnvGoEe2","XLbDQL2qYi9FDozvL","p4XpZWcQksSiCPG72","mB95aqTSJLNR9YyjH","2NaAhMPGub8F2Pbr7","BbM47qBPzdSRruY4z","dYnHLWMXCYdm9xu5j","qHpazCw3ryvBojGSa","wyYubb3eC5FS365nk","wmjPGE8TZKNLSKzm4","CBWSDdzjqfnexBurB","gBnSRErajRtvhMnDr","BfBF6T6HA82zBxPrv","dbDHEQyKqnMDDqq2G","doPejjd84w8BmERqj","PT8vSxsusqWuN7JXp","dKxX76SCfCvceJXHv","DSzpr8Y9299jdDLc9","hnLutdvjC8kPScPAj","vit9oWGj6WgXpRhce","CsKboswS3z5iaiutC","kjQXzkTGuixoJtQnq","RgJicDmXHDxcJ9Fsw","L6iFpR9ZyTmzHvYci","Z5ZBPEgufmDsm7LAv","PRAyQaiMWg2La7XQy","x6Kv7nxKHfLGtPJej","3pjv6uDvY9sqmsnvY","Aet2mbnK7GDDfrEQu","scL68JtnSr3iakuc6","3SG4WbNPoP8fsuZgs","XfpJ6WQBDcEcC8Mu4","iprqfLaDLCGoJFeiZ","frApEhpyKQAcFvbXJ","znBJwbuT3f5eWgM4E","cR7Zfrc4BtnFes46y","hbmsW2k9DxED5Z4eJ","SzecSPYxqRa5GCaSF","hxaq9MCaSrwWPmooZ","FSmPtu7foXwNYpWiB","WQWhXzALcrzrJtqRh","jYNT3Qihn2aAYaaPb","gebzzEwn2TaA6rGkc","WhHFvzFsYfMxgYCdo","tjxgbovwc5Ft7wrtc","2brqzQWfmNx5Agdrx","QaDwBio8MLqRvTREH","Jko7pt7MwwTBrfG3A","A9tJFJY7DsGTFKKkh","Wnqua6eQkewL3bqsF","DJB82jKwgJE5NsWgT","5b6YcFbEBCZbX6YSK","zk6RK3xFaDeJHsoym","FQqcejhNWGG8vHDch","srge9MCLHSiwzaX6r","DJRe5obJd7kqCkvRr","D8ds9idKWbwzCseCh","hTMFt3h7QqA2qecn7","9LXxgXySTFsnookkw","CHtwDXy63BsLkQx4n","u5RLu5F3zKTB3Qjnu","4tke3ibK9zfnvh9sE","2WngsveoLhFubuLMH","ADwayvunaJqBLzawa","NG6FrXgmqPd5Wn3mh","Ww5xKq5brC4xAJY7o","HL6x8zHo9BkuK3tic","PKBXczqhry7iK3Ruw","oBBzqkZwkxDvsKBGB","HuFZJkGptWDtRbkWs","iQWk5jYeDg5ACCmpx","RdpqsQ6xbHzyckW9m","sizjfDgCgAsuLJQmm","X3p8mxE5dHYDZNxCm","wZGpoZgDANdkwTrwt","uAc7bWgpEhrGwFcv7","3nDR23ksSQJ98WNDm","sMsvcdxbK2Xqx8EHr","evYFijNMdjfbPaCho","Psp8ZpYLCDJjshpRb","Zupr296Zy74wpihXT","68dHanLWsS6SEyZp9","x9FNKTEt68Rz6wQ6P","DWHkxqX4t79aThDkg","xLm9mgJRPvmPGpo7Q","6LzKRP88mhL9NKNrS","XYDsYSbBjqgPAgcoQ","eRohP4gbxuBuhqTbe","Wpf3Gsa8A89mmjkk8","PfcQguFpT8CDHcozj","XPwEptSSFRCnfHqFk","pohTfSGsNQZYbGpCy","zcPLNNw4wgBX5k8kQ","2meuc3kPRkBcRpj3R","bzhGBHrGrFfQss4Df","2269iGRnWruLHsZ5r","kj37Hzb2MsALwLqWt","Qz9GvoPbnFwGrHHQB","pJJdcZgB6mPNWoSWr","dtmmP4YdJEfK9y4Rc","QPqm5aj2meRmE7kR8","2oybbEw697CQgcRE5","TYTEJxzeK3jBMq2TZ","K4eDzqS2rbcBDsCLZ","FcRt3xAF4ynojfj6G","gMXsyhPiEJbGerF6F","9sguwESkteCgqFMbj","mvPfao35Moah8py46","kuDKtwwbsksAW4BG2","pL56xPoniLvtMDQ4J","ENBzEkoyvdakz4w5d","wM4bcDxEh75NDkhjo","YAkpzvjC768Jm2TYb","ExssKjAaXEEYcnzPd","n3LAgnHg6ashQK3fF","GMCs73dCPTL8dWYGq","8gapy2nLy4wysXSGL","dgFcJtHaYfaoByAK9","HhWhaSzQr6xmBki8F","CpvyhFy9WvCNsifkY","aan3jPEEwPhrcGZjj","mhA4vkeaRn9cpxkag","iA25AvZqAr6G8mAXR","C4tR3BEpuWviT7Sje","FghubkDy6Dp6mnxk7","RKz7pc6snBttndxXz","jiJquD34sa9Lyo5wc","c8EeJtqnsKyXdLtc5","ZGGGBR9sDgtLgMDaA","uM6mENiJi2pNPpdnC","o9dnstYoc7cwpgdhg","YSWa8rYeD3aDaofSP","pC47ZTsPNAkjavkXs","QtyKq4BDyuJ3tysoK","bYrF8rXFYwPqnfxTp","KbyRPCAsWv5GtfrbG","c2RzFadrxkzyRAFXa","9ZodFr54FtpLThHZh","xmoYza9vgcRvWD5PA","sbb9bZgojmEa7Yjrc","6yTShbTdtATxKonY5","BHYBdijDcAKQ6e45Z","qGEqpy7J78bZh3awf","KJbQyFbXiiYDDWbaS","PYtus925Gcg7cqTEq","yTvBSFrXhZfL8vr5a","Aud7CL7uhz55KL8jG","bXTNKjsD4y3fabhwR","AmNjHo8xXMKnZEWRS","CHD5m9fnosr7L3dto","MN4NRkMw7ggt9587K","CDXDnruBJe23rpdfC","y5GftLezdozEHdXkL","d6yNW5T6J9rtnGizc","pT48swb8LoPowiAzR","27AWRKbKyXuzQoaSk","vNHf7dx5QZA4SLSZb","KwbJFexa4MEdhJbs4","mja6jZ6k9gAwki9Nu","fW9n8bEuMpLwkxCx6","muXfZr5EYCfZqLmsb","5PBWgHiCiiJHjPRSn","PAYMMgPi2L3MPP967","RaxaXBNmStYe289gC","DMxe4XKXnjyMEAAGw","xF7gBJYsy6qenmmCS","gMszBSAX23uqYhytR","HbXXd2givHBBLxr3d","Z5wF8mdonsM2AuGgt","utySCY9nJt9xGYGGQ","gCz7cB6JG66EhweSS","krHDNc7cDvfEL8z9a","aNAFrGbzXddQBMDqh","sksP9Lkv9wqaAhXsA","p3s8RvkcyTwzu27ps","8ccTZ9ZxpJrvnxt4F","p7WXmG6Fbo3eaSwm3","CPBmbgYZpsGqkiz2R","yDRX2fdkm3HqfTpav","WbLAA8qZQNdbRgKte","75dnjiD8kv2khe9eQ","JZZENevaLzLLeC3zn","MgFDzAfCku9MSDLuw","PQtEqmyqHWDa2vf5H","zbqLuTgTCu365MNu9","P3uavjFmZD5RopJKk","8gqrbnW758qjHFTrH","pZaPhGg2hmmPwByHc","4hLcbXaqudM9wSeor","WxW6Gc6f2z3mzmqKs","j9HoG56Y6KuopSzdn","GhFoAxG49RXFzze5Y","rD57ysqawarsbry6v","LCfaLXcWnk8pujnX4","tAXrD8Y6hcJ8dt6Nt","af9MjBqF2hgu3EN6r","FRRb6Gqem8k69ocbi","LbyxFk8JmPKPAQBvL","PHmYhE4sKnwzYgvkh","fZJRxYLtNNzpbWZAA","kgmkdf3C7EkDX7dnT","Gs29k3beHiqWFZqnn","MMAK6eeMCH3JGuqeZ","cdB5f2adKoLGW8Ytc","5e49dHLDJoDpeXGnh","Ccsx339LE9Jhoii9K","PHnMDhfiadQt6Gj23","Jo89KvfAs9z7owoZp","fri4HdDkwhayCYFaE","tD9zEiHfkvakpnNam","xggxWfyzZmnz7hydm","JgBBuDf5uZHmpEMDs","vbcjYg6h3XzuqaaN8","hRohhttbtpY3SHmmD","6KzFwcDy7hsCkzJKY","F2DZXsMdhGyX4FPAd","esRZaPXSHgWzyB2NL","AqsjZwxHNqH64C2b6","4psQW7vRwt7PE5Pnj","voLHQgNncnjjgAPH7","aaHDA4X6cTzFrvuSX","LHtMNz7ua8zu4rSZr","zjMKpSB2Xccn9qi5t","BAzCGCys4BkzGDCWR","goC9qv4PWf2cjfnbm","Z2CuyKtkCmWGQtAEh","c3iQryHA4tnAvPZEv","vwLxd6hhFvPbvKmBH","Js34Ez9nrDeJCTYQL","fJvjin8ETkzhFdadC","W59Nb72sYJhMJKGB8","xiPMaYGTm2xfsB8WF","oPEWyxJjRo4oKHzMu","PjfsbKrK5MnJDDoFr","sBBGxdvhKcppQWZZE","vwM7hnT9ysE3suwfk","BzYmJYECAc3xyCTt6","uiyWHaTrz3ML7JqDX","vZssZr2wq7YrG3FMa","73QyjLymEak4L8RDC","6vcxuRHzeM99jYcYd","bG4PR9uSsZqHg2gYY","HoQ5Rp7Gs6rebusNP","9iA87EfNKnREgdTJN","QEYWkRoCn4fZxXQAY","kAgJJa3HLSZxsuSrf","FZaDFYbnRoHmde7F6","BNfL58ijGawgpkh9b","4gDbqL3Tods8kHDqs","DwqgLXn5qYC7GqExF","atcJqdhCxTZiJSxo2","zRn6cLtxyNodudzhw","P32AuYu9MqM2ejKKY","K2JBqDeETX2yEgyyZ","3FoMuCLqZggTxoC3S","LcEzxX2FNTKbB6KXS","o5F2p3krzT4JgzqQc","cy3BhHrGinZCp3LXE","zsG9yKcriht2doRhM","WYmmC3W6ZNhEgAmWG","EL4HNa92Z95FKL9R2","EKu66pFKDHFYPaZ6q","Pa5NqtxHBkGuCh98G","JKj5Krff5oKMb8TjT","vwt3wKXWaCvqZyF74","4basF9w9jaPZpoC8R","Bfq6ncLfYdtCb6sat","jDQm7YJxLnMnSNHFu","FDJnZt8Ks2djouQTZ","f3o9ydY7iPjFF2fyk","KnQs55tjxWopCzKsk","Ww2dxwWpSfkQB4NZb","ZawRiFR8ytvpqfBPX","ZGzDNfNCXzfx6hYAH","rFjhz5Ks685xHbMXW","Mrz2srZWc7EzbADSo","B4DuwmtqF3HhNwvua","zQKgKjecvR4W7oJw5","BSpdshJWGAW6TuNzZ","JHcTP4Ad8QAmRTCZm","GGn8MBiY8Xz6NdNdH","hQysqfSEzciRazx8k","AtfQFj8umeyBBkkxa","r99tazGiLgzqFX7ka","uFYQaGCRwt3wKtyZP","BFamedwSgRdGGKXQQ","teaxCFgtmCQ3E9fy8","ka8eveZpT7hXLhRTM","euJm4RwkAptZnP89i","LLRtjkvh9AackwuNB","yPLr2tnXbiFXkMWvk","ervaGwJ2ZcwqfCcLx","4AHXDwcGab5PhKhHT","NuueGqPZdotjMQKLu","qjSHfbjmSyMnGR9DS","xtzvtJBNofk4FPAtt","SkcM4hwgH3AP6iqjs","Br4xDbYu4Frwrb64a","HvcZmKS43SLCbJvRb","BEtzRE2M5m9YEAQpX","EhEZoTFzys9EDmEXn","bmoQ2wy7Nd7EiJdpg","pYcFPMBtQveAjcSfH","zb3hWt99i9Fm93KPq","W9rJv26sxs4g2B9bL","Dod9AWz8Rp4Svdpof","hQHuXuRGZxxWXaPgg","zB3ukZJqt3pQDw9jz","KheBaeW8Pi7LwewoF","Ek7M3xGAoXDdQkPZQ","guDcrPqLsnhEjrPZj","7XbcDaeigMaxW43EB","ttGbpJQ8shBi8hDhh","wJnm5cBiZGmKn595f","puhPJimawPuNZ5wAR","eoHbneGvqDu25Hasc","gHgs2e2J5azvGFatb","x5ASTMPKPowLKpLpZ","EhAbh2pQoAXkm9yor","jfq2BH5kfQqu2vYv3","Mf2MCkYgSZSJRz5nM","mXgsd5o9uuYaQKHMz","YM6Qgiz9RT7EmeFpp","PcfHSSAMNFMgdqFyB","uX3HjXo6BWos3Zgy5","nzmCvRvPm4xJuqztv","CMt3ijXYuCynhPWXa","Ndtb22KYBxpBsagpj","yFJ7vCjefBxnTchmG","SQ9cZtfrzDJmw9A2m","PJLABqQ962hZEqhdB","HmfxSWnqnK265GEFM","i3BTagvt3HbPMx6PN","ZEgQGAjQm5rTAnGuM","ctpkTaqTKbmm6uRgC","qEweugBipR5P2cMyK","xnPFYBuaGhpq869mY","YtvZxRpZjcFNwJecS","ido3qfidfDJbigTEQ","85J8hjEn48FicYfvp","N6vZEnCn6A95Xn39p","tJQsxD34maYw2g5E4","96TBXaHwLbFyeAxrg","ixZLTmFfnKRbaStA5","2x7fwbwb35sG8QmEt","oaqKjHbgsoqEXBMZ2","t2NN6JwMFaqANuLqH","J9pNx22bj5RuiRjAj","AN2cBr6xKWCB8dRQG","G5eMM3Wp3hbCuKKPE","y5jAuKqkShdjMNZab","vADtvr9iDeYsCDfxd","x4GmqcwjFTnWeRiud","5ntgky9ShzKKWu7us","z8usYeKX7dtTWsEnk","3S4nyoNEEuvNsbXt8","EEv9JeuY5xfuDDSgF","ASpGaS3HGEQCbJbjS","AXXaXJvf7WcTessog","QL7J9wmS6W2fWpofd","osYFcQtxnRKB4F4HA","MajyZJrsf8fAywWgY","bvqC4Ci7rXq4sN9df","GctJD5oCDRxCspEaZ","A9NxPTwbw6r6Awuwt","dKTh9Td3KaJ8QW6gw","oTX2LXHqXqYg2u4g6","LuXb6CZG4x7pDRBP8","hamma4XgeNrsvAJv5","BfTW9jmDzujYkhjAb","DoHcgTvyxdorAMquE","EbFABnst8LsidYs5Y","Sdx6A6yLByRRs8iLY","qbHLGo5vu8HD3JqEM","48WeP7oTec3kBEada","LgavAYtzFQZKg95WC","5QpufhoH2ASnppsjs","Kz9zMgWB5C27Pmdkh","qy5dF7bQcFjSKaW58","wkuDgmpxwbu2M2k3w","JcpzFpPBSmzuksmWM","zMxrkFrB6ka4Lb7fM","PX7AdEkpuChKqrNoj","ui6mDLdqXkaXiDMJ5","uXn3LyA8eNqpvdoZw","FwiPfF8Woe5JrzqEu","hzuSDMx7pd2uxFc5w","mHqQxwKuzZS69CXX5","yKXKcyoBzWtECzXrE","zHS4FJhByRjqsuH4o","a5JAiTdytou3Jg749","HEn2qiMxk5BggN83J","tYAvXXgSwHCzNTK8f","WXvt8bxYnwBYpy9oT","kLR5H4pbaBjzZxLv6","CtXaFo3hikGMWW4C9","4DBBQkEQvNEWafkek","qwdupkFd6kmeZHYXy","EHbJ69JDs4suovpLw","w5F4w8tNZc6LcBKRP","xqkGmfikqapbJ2YMj","yRAo2KEGWenKYZG9K","scwoBEju75C45W5n3","qJgz2YapqpFEDTLKn","aSQy7yHj6nPD44RNo","Ltey8BS83qSkd9M3u","9Yc7Pp7szcjPgPsjf","hN2aRnu798yas5b2k","ERWeEA8op6s6tYCKy","yJfBzcDL9fBHJfZ6P","BZ6XaCwN4QGgH9CxF","3nMpdmt8LrzxQnkGp","TNHQLZK5pHbxdnz4e","F6ZTtBXn2cFLmWPdM","neQ7eXuaXpiYw7SBy","k2SNji3jXaLGhBeYP","WsSybGTqpBoHpXJyQ","jtMXj24Masrnq3SpS","jqTeghCJ2anMHPPjG","B7P97C27rvHPz3s9B","uK6sQCNMw8WKzJeCQ","hurF9uFGkJYXzpHEE","xEHy9oivifjgFbnvc","33KewgYhNSxFpbpXg","c5GHf2kMGhA4Tsj4g","dC7mP5nSwvpL65Qu5","hpjou9ZnLZkSJR7sd","bshZiaLefDejvPKuS","AvjbBjAAbKBk73v5F","XqvnWFtRD2keJdwjX","KJ9MFBPwXGwNpadf2","37sHjeisS9uJufi4u","5iZTwGHv2tNfFmeDa","gziZACDg6EBpGZbJe","RYcoJdvmoBbi5Nax7","9o3QBg2xJXcRCxGjS","vs3kzjLhbdKsndnBy","bZ2w99pEAeAbKnKqo","bjjbp5i5G8bekJuxv","vwqLfDfsHmiavFAGP","Yp2vYb4zHXEeoTkJc","z6QQJbtpkEAX3Aojj","ubPAo3zGeJNqtZDqT","pfibDHFZ3waBo6pAc","cumc876woKaZLmQs5","Ty2tjPwv8uyPK9vrz","ZiQqsgGX6a42Sfpii","ybYBCK9D7MZCcdArB","pNcFYZnPdXyL2RfgA","rEBXN3x6kXgD4pLxs","no5jDTut5Byjqb4j5","qCsxiojX7BSLuuBgQ","uyBeAN5jPEATMqKkX","aHaqgTNnFzD7NGLMx","bQ6zpf6buWgP939ov","mkbGjzxD8d8XqKHzA","CKpByWmsZ8WmpHtYa","midXmMb2Xg37F2Kgn","reitXJgJXFzKpdKyd","LFNXiQuGrar3duBzJ","KcvJXhKqx4itFNWty","RWu8eZqbwgB9zaerh","EFQ3F6kmt4WHXRqik","FfPukic3Qskd9ZAkk","A2Qam9Bd9xpbb2wLQ","t9svvNPNmFf5Qa3TA","n5TqCuizyJDfAPjkr","Kbm6QnJv9dgWsPHQP","gFMH3Cqw4XxwL69iy","Kyc5dFDzBg4WccrbK","RWo4LwFzpHNQCTcYt","vbWBJGWyWyKyoxLBe","PsEppdvgRisz5xAHG","tscc3e5eujrsEeFN4","GG2rtBReAm6o3mrtn","E4cKD9iTWHaE7f3AJ","yCWPkLi8wJvewPbEp","AcKRB8wDpdaN6v6ru","LbrPTJ4fmABEdEnLf","rtM3jFaoQn3eoAiPh","eDicGjD9yte6FLSie","xg3hXCYQPJkwHyik2","bJ2haLkcGeLtTWaD5","PBRWb2Em5SNeWYwwB","7hFeMWC6Y5eaSixbD","aMHq4mA2PHSM2TMoH","wpZJvgQ4HvJE2bysy","2brqzQWfmNx5Agdrx","GLMFmFvXGyAcG25ni","NLBbCQeNLFvBJJkrt","bYrF8rXFYwPqnfxTp","v7c47vjta3mavY3QC","3MvaoZbGPxtRFCijw","TappK5n3kZmQzWEWD","tSemJckYr29Gnxod2","WdkLDpBGMCWhfByAY","EctieqKwDQcQHhqZy","hNqte2p48nqKux3wS","qw3Z79HELMsmLkL9F","zwDz9pgT43fRczkB4","Fafzj3wMvoCW4WjeF","kxW6q5YdTGWh5sWby","G5eMM3Wp3hbCuKKPE","kSiT2XjfTnDHKx44W","DSzpr8Y9299jdDLc9","wZGpoZgDANdkwTrwt","qajfiXo5qRThZQG7s","rRzZzBBQ36CrqhZTY","aP36QcAsxyuEispq6","TxcRbCYHaeL59aY7E","MFNJ7kQttCuCXHp8P","PQ3nutgxfTgvq69Xt","JJFphYfMsdFMuprBy","ythFNoiAotjvuEGkg","GZSzMqr8hAB2dR8pk","BBQ5HEnL3ShefQxEj","fzeoYhKoYPR3tDYFT","bXuAXCbzw9hsJSuEN","mbCccXJuuRBZdXdpH","m7THsgXyxxiEXgyHv","xtHd6sfdr2bZHa6Pb","pfaTqpWFghfrbvzaD","u8GMcpEN9Z6aQiCvp","gBpYo7mt2zNBmtBJd","rkpDX7j7va6c8Q7cZ","NGkBfd8LTqcpbQn5Z","GEPX7jgLMB8vR2qaK"]},"locale":"en-US","mapbox":{"apiKey":"pk.eyJ1IjoiaGFicnlrYSIsImEiOiJjaWxvcnhidzgwOGlodHJrbmJ2bmVmdjRtIn0.inr-_5rWOOslGQxY8iDFOA"},"petrov":{"afterTime":1727400080403,"beforeTime":1727376805595,"petrovPostId":"6LJ6xcHEjKF9zWKzs","petrovServerUrl":"https://forum.effectivealtruism.org/graphql","petrovGamePostId":"KTEciTeFwL2tTujZk"},"reacts":{"addNewReactKarmaThreshold":10,"downvoteExistingReactKarmaThreshold":20,"addNameToExistingReactKarmaThreshold":5},"stripe":{"publicKey":"pk_live_51HtKAwA2QvoATZCZiy9f2nc6hA52YS1BE81cFu9FEV1IKar0Bwx6hIpxxxYHnhaxO9KM7kRYofZId3sUUI7Q0NeO00tGni3Wza"},"algolia":{"appId":"fakeAppId","searchKey":"fakeSearchKey","indexPrefix":"test_"},"llmChat":{"userIds":["McgHKH6MMYSnPwQcm","6Fx2vQtkYSZkaCvAg","MEu8MdhruX5jfGsFQ","YaNNYeR5HjKLDBefQ","hBEAsEpoNHaZfefxR","NFmcwmaFeTWfgrvBN","ZnpELPxzzD2CiigNy","Q7NW4XaWQmfPfdcFj","NXeHNNSFHGESrYkPv","QDNJ93vrjoaRBesk2","iMBN2523tmh4Yicc3","5iPRfSnjako6iM6LG","aBHfQ4C5fSM4TPyTn","n4M37rPXGyL6p8ivK","e9ToWWzhwWp5GSE7P","TCjNiBLBPyhZq5BuM","XLwKyCK7JmC292ZCC","S3ydcLKdejjkodNut","ENgxBL95Sc7MRwYty","KCExMGwS2ETzN3Ksr","XGEcH5rmq4yGvD82A","YFiFbXgjBpDKZT93g","dZMo8p7fGCgPMfdfD","Pdca6FNZBrXj9z28n","LHbu27FubhwFv8ZJt","gYxdDBQ3AZbde8HgZ","5JqkvjdNcxwN8D86a","6c2KCEXTGogBZ9KoE","haTrhurXNmNN8EiXc"]},"logoUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1498011194/LessWrong_Logo_skglnw.svg","ckEditor":{"uploadUrl":"https://39669.cke-cs.com/easyimage/upload/","webSocketUrl":"39669.cke-cs.com/ws"},"recombee":{"enabled":true},"hasEvents":true,"logRocket":{"apiKey":"mtnxzn/lesswrong","sampleDensity":5},"reCaptcha":{"apiKey":"6LfFgqEUAAAAAHKdMgzGO-1BRBhHw1x6_8Ly1cXc"},"siteImage":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg","cloudinary":{"cloudName":"lesswrong-2-0","uploadPresetBanner":"navcjwf7","uploadPresetGridImage":"tz0mgw2s","uploadPresetSocialPreview":"nn5tppry"},"googleMaps":{"apiKey":"AIzaSyA3C48rl26gynG3qIuNuS-3Bh_Zz9jFXkY"},"adminAccount":{"email":"team@lesswrong.com","username":"LessWrong"},"annualReview":{"end":"2024-02-01T08:00:00Z","start":"2023-12-04T00:10:00Z","reviewPhaseEnd":"2024-01-15T08:00:00Z","votingPhaseEnd":"2024-02-01T08:00:00Z","nominationPhaseEnd":"2023-12-17T08:00:00Z","votingResultsPostId":"TSaJ9Zcvc3KWh3bjX","announcementPostPath":"/posts/B6CxEApaatATzown6/the-lesswrong-2022-review","reviewWinnerSectionsInfo":{"modeling":{"tag":"World Modeling","order":2,"title":"World","coords":{"leftXPct":0.05,"leftYPct":0,"rightXPct":0.57,"rightYPct":0,"middleXPct":0.31,"middleYPct":0,"leftFlipped":true,"leftWidthPct":0.26,"rightWidthPct":0.26,"middleWidthPct":0.26},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753450/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_15ba02c3-b268-45f1-a780-322bbaa6fc22_eu9l0l.png"},"ai safety":{"tag":"AI","order":5,"title":"Technical AI Safety","coords":{"leftXPct":0.2,"leftYPct":0.3,"rightXPct":0.554,"rightYPct":0.3,"middleXPct":0.467,"middleYPct":0.3,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,fl_progressive,q_auto/v1708570131/lwbot_topographic_watercolor_artwork_of_a_giant_robot_hand_gent_e4e9f305-9611-4787-8768-d7af3d702ed4_ta2ii9.png"},"practical":{"tag":"Practical","order":3,"title":"Practical","coords":{"leftXPct":0.2,"leftYPct":0.05,"rightXPct":0.634,"rightYPct":0.05,"middleXPct":0.417,"middleYPct":0.05,"leftFlipped":false,"leftWidthPct":0.217,"rightWidthPct":0.217,"middleWidthPct":0.217},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708974564/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_4f6449e2-569b-48a3-b878-a400315b3ef0_hqutxe.png"},"ai strategy":{"tag":"AI","order":4,"title":"AI Strategy","coords":{"leftXPct":0,"leftYPct":0,"rightXPct":0.66,"rightYPct":0,"middleXPct":0.33,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753570/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_8dda30ee-71d6-4b24-80c7-a8499a5b25c6_uacvgk.png"},"rationality":{"tag":"Rationality","order":0,"title":"Rationality","coords":{"leftXPct":0.12,"leftYPct":0,"rightXPct":0.72,"rightYPct":0,"middleXPct":0.42,"middleYPct":0,"leftFlipped":false,"leftWidthPct":0.3,"rightFlipped":true,"rightWidthPct":0.3,"middleWidthPct":0.3},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753260/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_09275054-eb84-43c4-9cfa-4a05e1818c9e_rmov5i.png"},"optimization":{"tag":"World Optimization","order":1,"title":"Optimization","coords":{"leftXPct":0.1,"leftYPct":0.2,"rightXPct":0.7,"rightYPct":0.2,"middleXPct":0.4,"middleYPct":0.2,"leftWidthPct":0.33,"rightFlipped":true,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1708753382/ohabryka_Aquarelle_sketch_by_Thomas_W._Schaller_inspired_by_top_242eda7f-95a9-4c3b-8090-991a1b11286f_xcjhxq.png"}},"reviewWinnerYearGroupsInfo":{"2018":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008323/ruby37_green_on_white_aquarelle_sketch_by_thomas_schaller_of_ri_7a3fa89a-ac7a-466f-929f-b396cb4d9bd5_p8rh9t.png"},"2019":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.72,"rightYPct":0.1,"middleXPct":0.34,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008331/ruby37_blue_on_white_aquarelle_sketch_by_thomas_schaller_of_gre_f421cc99-2bb5-4357-b164-d05c2f4fe84e_aib1co.png"},"2020":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.01,"rightXPct":0.72,"rightYPct":0.01,"middleXPct":0.34,"middleYPct":0.01,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008346/ruby37_aquarelle_sketch_of_futuristic_landscape_by_thomas_schal_f07d5805-9fb0-4dcc-9295-7f063624e28c_slcokh.png"},"2021":{"tag":null,"coords":{"leftXPct":0.01,"leftYPct":0.1,"rightXPct":0.545,"rightYPct":0.1,"middleXPct":0.278,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.267,"rightFlipped":false,"middleFlipped":false,"rightWidthPct":0.267,"middleWidthPct":0.267},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/a_270/q_auto,f_auto/ohabryka_Topographic_aquarelle_book_cover_by_Thomas_W._Schaller_f9c9dbbe-4880-4f12-8ebb-b8f0b900abc1_m4k6dy_734413"},"2022":{"tag":null,"coords":{"leftXPct":0,"leftYPct":0.1,"rightXPct":0.79,"rightYPct":0.1,"middleXPct":0.43,"middleYPct":0.1,"leftFlipped":false,"leftWidthPct":0.33,"rightFlipped":true,"rightWidthPct":0.33,"middleWidthPct":0.33},"imgUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1709008351/ruby37_aquarelle_sketch_of_a_woman_focusing_hard_studying_in_an_2ac568ef-408e-4561-acc8-84c76bb42fba_gwt8uq.png"}},"showReviewOnFrontPageIfActive":true},"googleVertex":{"enabled":true},"intercomAppId":"wtb8z7sj","commentInterval":15,"googleDocImport":{"enabled":true},"moderationEmail":"team@lesswrong.com","timeDecayFactor":1.15,"googleTagManager":{"apiKey":"GTM-TRC765W"},"textReplacements":{"Less Wrong":"Down Bad","Alignment Forum":"Standards Committee","Artificial Intelligence":"Fake News"},"alternateHomePage":false,"gatherTownMessage":"Schelling social hours on Tues 1pm and Thurs 6pm PT","bookDisplaySetting":false,"gardenOpenToPublic":false,"karmaRewarderId100":"iqWr6C3oEB4yWpzn5","legacyRouteAcronym":"lw","maxRenderQueueSize":3,"recommendationsTab":{"manuallyStickiedPostIds":[]},"frontpageScoreBonus":0,"karmaRewarderId1000":"mBBmKWkmw8bgJmGiG","defaultVisibilityTags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10}],"enableGoodHeartProject":false,"maxDocumentsPerRequest":5000,"defaultSequenceBannerId":"sequences/vnyzzznenju0hzdv6pqb.jpg","defaultModeratorComments":[{"id":"FfMok764BCY6ScqWm","label":"Option A"},{"id":"yMHoNoYZdk5cKa3wQ","label":"Option B"}],"newUserIconKarmaThreshold":50,"dialogueMatchmakingEnabled":true,"hideUnreviewedAuthorComments":"2023-04-04T18:54:35.895Z","gatherTownUserTrackingIsBroken":true,"postModerationWarningCommentId":"sLay9Tv65zeXaQzR4","commentModerationWarningCommentId":"LbGNE5Ssnvs6MYnLu","performanceMetricLoggingEnax5bled":true,"firstCommentAcknowledgeMessageCommentId":"QgwD7PkQHFp3nfhjj"}</script><script>window.tabId = "nmdtdS7apdkrfbPfF"</script><script>window.isReturningVisitor = false</script><script async="" src="scott_files/bundle.js"></script><title>Scott Alexander - LessWrong</title><meta data-react-helmet="true" name="twitter:image:src" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"><meta data-react-helmet="true" property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"><meta data-react-helmet="true" http-equiv="Accept-CH" content="DPR, Viewport-Width, Width"><meta data-react-helmet="true" charset="utf-8"><meta data-react-helmet="true" name="description" content="Scott Alexander's profile on LessWrong — A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"><meta data-react-helmet="true" name="twitter:description" content="Scott Alexander's profile on LessWrong — A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:url" content="https://www.lesswrong.com/users/scottalexander"><meta data-react-helmet="true" property="og:description" content="Scott Alexander's profile on LessWrong — A community blog devoted to refining the art of rationality"><meta data-react-helmet="true" http-equiv="delegate-ch" content="sec-ch-dpr https://res.cloudinary.com;"><link data-react-helmet="true" rel="canonical" href="scott_files/scottalexander.html"><link data-react-helmet="true" rel="alternate" type="application/rss+xml" href="https://www.lesswrong.com/feed.xml"><script data-react-helmet="true" type="application/ld+json">{"@context":"http://schema.org","@type":"Person","name":"Scott Alexander","url":"https://www.lesswrong.com/users/scottalexander","interactionStatistic":[{"@type":"InteractionCounter","interactionType":{"@type":"http://schema.org/LikeAction"},"userInteractionCount":42640},{"@type":"InteractionCounter","interactionType":{"@type":"http://schema.org/WriteAction"},"userInteractionCount":217}],"memberSince":"2009-02-28T15:53:46.032Z"}</script><meta name="twitter:card" content="summary"><script>window.themeOptions = {"name":"default"}</script><style id="jss-insertion-point"></style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: rgba(0, 0, 0, 0.54);
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(0, 0, 0, 0.26);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: rgba(0, 0, 0, 0.54);
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(0, 0, 0, 0.26);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-moz-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-moz-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-moz-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-moz-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-moz-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-moz-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(0,0,0,0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(0, 0, 0, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-contained {
  color: rgba(0, 0, 0, 0.87);
  box-shadow: 0px 1px 5px 0px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 3px 1px -2px rgba(0,0,0,0.12);
  background-color: #e0e0e0;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
  box-shadow: none;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:hover {
  background-color: #d5d5d5;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #e0e0e0;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-containedPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(0,0,0,0.2),0px 12px 17px 2px rgba(0,0,0,0.14),0px 5px 22px 4px rgba(0,0,0,0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(0,0,0,0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(0, 0, 0, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(0, 0, 0, 0.26);
}
.MuiButton-contained {
  color: rgba(0, 0, 0, 0.87);
  box-shadow: 0px 1px 5px 0px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 3px 1px -2px rgba(0,0,0,0.12);
  background-color: #e0e0e0;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(0, 0, 0, 0.26);
  box-shadow: none;
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-contained:hover {
  background-color: #d5d5d5;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #e0e0e0;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(0, 0, 0, 0.12);
}
.MuiButton-containedPrimary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #fff;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(0,0,0,0.2),0px 12px 17px 2px rgba(0,0,0,0.14),0px 5px 22px 4px rgba(0,0,0,0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: rgba(0, 0, 0, 0.54);
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: rgba(0, 0, 0, 0.54);
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(0, 0, 0, 0.08);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(0, 0, 0, 0.26);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.08);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiPopover">
.MuiPopover-paper {
  outline: none;
  position: absolute;
  min-width: 16px;
  max-width: calc(100% - 32px);
  overflow-y: auto;
  overflow-x: hidden;
  min-height: 16px;
  max-height: calc(100% - 32px);
}
</style><style data-jss="" data-meta="MuiPopover">
.MuiPopover-paper {
  outline: none;
  position: absolute;
  min-width: 16px;
  max-width: calc(100% - 32px);
  overflow-y: auto;
  overflow-x: hidden;
  min-height: 16px;
  max-height: calc(100% - 32px);
}
</style><style data-jss="" data-meta="MuiMenu">
.MuiMenu-paper {
  max-height: calc(100% - 96px);
  -webkit-overflow-scrolling: touch;
}
</style><style data-jss="" data-meta="MuiTooltip">
.MuiTooltip-popper {
  z-index: 1500;
  opacity: 0.9;
}
.MuiTooltip-tooltip {
  color: #fff;
  padding: 9.1px;
  z-index: 10000000;
  font-size: 13px;
  max-width: 300px;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  background-color: rgba(75,75,75,.94);
}
.MuiTooltip-touch {
  padding: 8px 16px;
  font-size: 0.875rem;
  line-height: 1.14286em;
}
.MuiTooltip-tooltipPlacementLeft {
  margin: 0 24px ;
  transform-origin: right center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementLeft {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementRight {
  margin: 0 24px;
  transform-origin: left center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementRight {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementTop {
  margin: 24px 0;
  transform-origin: center bottom;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementTop {
    margin: 14px 0;
  }
}
.MuiTooltip-tooltipPlacementBottom {
  margin: 24px 0;
  transform-origin: center top;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementBottom {
    margin: 14px 0;
  }
}
</style><style data-jss="" data-meta="MuiTooltip">
.MuiTooltip-popper {
  z-index: 1500;
  opacity: 0.9;
}
.MuiTooltip-tooltip {
  color: #fff;
  padding: 9.1px;
  z-index: 10000000;
  font-size: 13px;
  max-width: 300px;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  background-color: rgba(75,75,75,.94);
}
.MuiTooltip-touch {
  padding: 8px 16px;
  font-size: 0.875rem;
  line-height: 1.14286em;
}
.MuiTooltip-tooltipPlacementLeft {
  margin: 0 24px ;
  transform-origin: right center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementLeft {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementRight {
  margin: 0 24px;
  transform-origin: left center;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementRight {
    margin: 0 14px;
  }
}
.MuiTooltip-tooltipPlacementTop {
  margin: 24px 0;
  transform-origin: center bottom;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementTop {
    margin: 14px 0;
  }
}
.MuiTooltip-tooltipPlacementBottom {
  margin: 24px 0;
  transform-origin: center top;
}
@media (min-width:600px) {
  .MuiTooltip-tooltipPlacementBottom {
    margin: 14px 0;
  }
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(0, 0, 0, 0.12);
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(0, 0, 0, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(0, 0, 0, 0.12);
}
</style><style data-jss="">
.jss85 {
  top: 0;
  left: 0;
  bottom: 0;
  z-index: 1199;
  position: fixed;
}
.jss86 {
  right: auto;
}
.jss87 {
  left: auto;
  right: 0;
}
.jss88 {
  right: 0;
  bottom: auto;
}
.jss89 {
  top: auto;
  right: 0;
  bottom: 0;
}
</style><link id="main-styles" rel="stylesheet" type="text/css" onerror="window.missingMainStylesheet=true" href="scott_files/allStyles.css"><script async="" src="scott_files/wtb8z7sj"></script><meta property="og:title" content="Scott Alexander - LessWrong" data-react-helmet="true"></head>
<body class="abTestNoEffect_group2 collectionsPageABTest_originalLayoutGroup booksProgressBarABTest_control welcomeBoxABTest_welcomeBox twoLineEventsSidebar_expanded dialogueFacilitationMessages_optIn frontpageDialogueReciprocityRecommendations_noShow showOpinionsInReciprocity_show showRecommendedContentInMatchForm_show checkNotificationMessageContent_v4 newFrontpagePostFeedsWithRecommendationsOptIn_classicFrontpage">
<script>0</script><div id="react-app"><div class="wrapper Layout-wrapper" id="wrapper"><div></div><span></span><div class="IntercomWrapper-intercomFrame" id="intercom-outer-frame"></div><noscript class="noscript-warning"> This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. </noscript><noscript></noscript><div class="Header-root"><div style="height: 64px;" class="Header-headroom headroom-wrapper"><div class="headroom headroom--unfixed headroom-disable-animation"><header class="Header-appBar"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><h2 class="Typography-root Typography-title Header-title"><div class="Header-hideSmDown"><div class="Header-titleSubtitleContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LESSWRONG</a></div></div><div class="Header-hideMdUp"><a class="Header-titleLink" href="https://www.lesswrong.com/">LW</a></div></h2><div class="Header-rightHeaderItems"><div class="SearchBar-root"><div class="SearchBar-rootChild"><div class="SearchBar-searchInputArea SearchBar-searchInputAreaSmall"><div><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root SearchBar-searchIcon SearchBar-searchIconSmall" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><div></div></div></div></div><div class="UsersAccountMenu-root"><button tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat" type="button"><span class="MuiButton-label"><span class="UsersAccountMenu-userButton">Login</span></span><span class="MuiTouchRipple-root"></span></button></div></div></div></header><div class="jss85 jss86" style="width: 20px;"></div></div></div></div><div class="Layout-standaloneNavFlex"><div class="Layout-searchResultsArea"></div><div class="Layout-main"><div class="flash-messages FlashMessages-root"></div><div class="page users-profile UsersProfile-profilePage"><div class="SingleColumnSection-root"><div class="UsersProfile-usernameTitle">Scott Alexander</div><aside class="Typography-root Typography-body2 UsersProfile-userInfo"><div class="UsersProfile-meta"><span class="UsersProfile-userMetaInfo" title="42640 karma"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">42640</span></span><span class="UsersProfile-userMetaInfo" title="73 karma on alignmentforum.org"><span class="OmegaIcon-root UsersProfile-icon UsersProfile-specificalz">Ω</span><span class="Typography-root Typography-body2 MetaInfo-root">73</span></span><span class="UsersProfile-userMetaInfo" title="217 posts"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M14 2H6c-1.1 0-1.99.9-1.99 2L4 20c0 1.1.89 2 1.99 2H18c1.1 0 2-.9 2-2V8l-6-6zm2 16H8v-2h8v2zm0-4H8v-2h8v2zm-3-5V3.5L18.5 9H13z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">217</span></span><span class="UsersProfile-userMetaInfo" title="1577 comments"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M20 2H4c-1.1 0-1.99.9-1.99 2L2 22l4-4h14c1.1 0 2-.9 2-2V4c0-1.1-.9-2-2-2zm-2 12H6v-2h12v2zm0-3H6V9h12v2zm0-3H6V6h12v2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">1577</span></span><span class="UsersProfile-userMetaInfo" title="19 wiki edits"><svg class="MuiSvgIcon-root UsersProfile-icon UsersProfile-specificalz" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04c.39-.39.39-1.02 0-1.41l-2.34-2.34a.9959.9959 0 0 0-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><span class="Typography-root Typography-body2 MetaInfo-root">19</span></span></div><div><a>Message</a></div><div class="UsersProfile-subscribeButton"><div><div><a>Subscribe</a></div></div></div></aside></div><div class="SingleColumnSection-root"></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 id="sequences" class="Typography-root Typography-display1 SectionTitle-title">Sequences</h1><div class="SectionTitle-children"></div></div><div class="SequencesGridWrapper-gridWrapper"><div class="SequencesGrid-grid"><div class="SequencesGrid-gridContent"><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/hs42Xd4joLcTP6uTb"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/r8usyus20ivlpuj8np6i.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Priming</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/sdTckKmNM6zb7yGRt"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/mjogxcwbbaclxmmckeiw.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Positivism and Self Deception</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/ZNNi2uNx9E6iwGKKG"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/vitugifyyh2upm9ucjzh.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Introduction to Game Theory</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/s/G2GDw3m4MJ5ixSM92"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/djfksyoldrjt4ef5jts3.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">The Blue-Minimizing Robot</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#k5MPpr72eiGknaS7F"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/byzxi4zdrlvodk0ph46r.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Hypotheses and Hunches</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#TQW9brvXJ5Fajorr4"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/dyq1iu03mw0qo54n6byk.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Probability and Predictions</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#WnTvZdXz2q9ySfr4o"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/opwbi6lh0ud7r7dlyghc.png"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Parables and Prayers</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#TKDT2Mt6dDMH8AsZW"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/lel3jdh48of1dhtwfo4i.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Futurism and Forecasting</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#xmDeR64CivZiTAcLx"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/u0ackeoho1tquuiozpt4.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Community and Cooperation</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#zfXAcwLnGocsCsriG"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/hxgrnxobgf692eqpd8mz.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Economics and Efficiency</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#B384FrQNrxSq4hZoS"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/ggdn92agzidnk0voif2z.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Research and Reviews</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#BQBqPowfxjvoee8jw"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/zukiyrvljrwfe5bql7ek.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Studies and Statistics</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#NHXY86jBahi968uW4"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/bgpjay2m1labmbqdtjmi.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Categorisation and Concepts</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#XsMTxdQ6fprAQMoKi"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/rfpef83ejiwbsi1pmroz.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Argument and Analysis</div></div></div></span></div><div class="SequencesGridItem-root"><span class="LinkCard-root"><div class="LinkCard-root"><div class="LinkCard-background"><a href="https://www.lesswrong.com/codex#rNuPrZvabXe2MaZv8"></a></div><div class="SequencesGridItem-image"><img width="315" height="124" src="scott_files/acfvxltz0mnyd7jqdq76.jpg"></div><div class="SequencesGridItem-meta SequencesGridItem-hiddenAuthor"><div class="SequencesGridItem-title">Politics and Pragmatics</div></div></div></span></div></div></div></div></div><div class="SingleColumnSection-root"><div class="UsersProfile-postsTitle"><div class="SectionTitle-root"><h1 id="posts" class="Typography-root Typography-display1 SectionTitle-title">Posts</h1><div class="SectionTitle-children"><span class="SettingsButton-iconWithLabelGroup"><svg class="MuiSvgIcon-root SettingsButton-icon SettingsButton-iconWithLabel ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path transform="scale(1.2, 1.2)" fill="none" d="M0 0h20v20H0V0z"></path><path transform="scale(1.2, 1.2)" d="M15.95 10.78c.03-.25.05-.51.05-.78s-.02-.53-.06-.78l1.69-1.32c.15-.12.19-.34.1-.51l-1.6-2.77c-.1-.18-.31-.24-.49-.18l-1.99.8c-.42-.32-.86-.58-1.35-.78L12 2.34c-.03-.2-.2-.34-.4-.34H8.4c-.2 0-.36.14-.39.34l-.3 2.12c-.49.2-.94.47-1.35.78l-1.99-.8c-.18-.07-.39 0-.49.18l-1.6 2.77c-.1.18-.06.39.1.51l1.69 1.32c-.04.25-.07.52-.07.78s.02.53.06.78L2.37 12.1c-.15.12-.19.34-.1.51l1.6 2.77c.1.18.31.24.49.18l1.99-.8c.42.32.86.58 1.35.78l.3 2.12c.04.2.2.34.4.34h3.2c.2 0 .37-.14.39-.34l.3-2.12c.49-.2.94-.47 1.35-.78l1.99.8c.18.07.39 0 .49-.18l1.6-2.77c.1-.18.06-.39-.1-.51l-1.67-1.32zM10 13c-1.65 0-3-1.35-3-3s1.35-3 3-3 3 1.35 3 3-1.35 3-3 3z"></path></svg><span class="SettingsButton-label">Sorted by New</span></span></div></div></div><div class=""><div class="PostsList2-postsBoxShadow"><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">33</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/ynpC7oXhXxGPNuCgH/acx-meetups-everywhere-2023-times-and-places"><span>ACX Meetups Everywhere 2023: Times &amp; Places</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://astralcodexten.substack.com/p/meetups-everywhere-2023-times-and"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-08-25T23:59:07.941Z">1y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://astralcodexten.substack.com/p/meetups-everywhere-2023-times-and"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">5</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">91</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/NGkBfd8LTqcpbQn5Z/biological-anchors-the-trick-that-might-or-might-not-work"><span>Biological Anchors: The Trick that Might or Might Not Work</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://astralcodexten.substack.com/p/biological-anchors-a-trick-that-might"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-08-12T00:53:30.159Z">1y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://astralcodexten.substack.com/p/biological-anchors-a-trick-that-might"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">3</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">35</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/55aoSeDTDKbw9dgza/spring-meetups-everywhere-2023"><span>Spring Meetups Everywhere 2023</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://astralcodexten.substack.com/p/spring-meetups-everywhere-2023"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-04-11T00:59:20.265Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://astralcodexten.substack.com/p/spring-meetups-everywhere-2023"><svg class="MuiSvgIcon-root PostsItemIcons-linkIcon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">0</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">174</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/rwkkcgSpnAyE8oNo3/alexander-and-yudkowsky-on-agi-goals"><span>Alexander and Yudkowsky on AGI goals</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/rwkkcgSpnAyE8oNo3/alexander-and-yudkowsky-on-agi-goals"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-01-24T21:09:16.938Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><a href="https://alignmentforum.org/posts/rwkkcgSpnAyE8oNo3/alexander-and-yudkowsky-on-agi-goals"><span class="OmegaIcon-root PostsItemIcons-icon PostsItemIcons-alignmentIcon">Ω</span></a></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">52</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">46</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/gS8Jmcfoa9FAh92YK/crosspost-acx-2022-prediction-contest-results"><span>[Crosspost] ACX 2022 Prediction Contest Results</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2023-01-24T06:56:33.101Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">6</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">43</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/KCcdhZK7omEMwBdju/bay-solstice-2022-call-for-volunteers"><span>Bay Solstice 2022 Call For Volunteers</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2022-09-04T06:44:19.043Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"><span class="PostsItemIcons-postIcon"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostsItemIcons-icon ForumIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">2</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">63</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/fLdADsBLAMuGvky2M/acx-meetups-everywhere-list"><span>ACX Meetups Everywhere List</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2022-08-26T18:12:04.083Z">2y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">1</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">106</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/gBpYo7mt2zNBmtBJd/crosspost-on-hreha-on-behavioral-economics"><span>[Crosspost] On Hreha On Behavioral Economics</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2021-08-31T18:14:39.075Z">3y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">6</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background LWPostsItem-bottomBorder"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">110</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/kxW6q5YdTGWh5sWby/eight-hundred-slightly-poisoned-word-games"><span>Eight Hundred Slightly Poisoned Word Games</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2021-08-09T20:17:17.814Z">3y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">5</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div><div class="LWPostsItem-row"><div class="LWPostsItem-root LWPostsItem-background"><div><div class="LWPostsItem-postsItem LWPostsItem-withGrayHover"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo LWPostsItem-karma"><span class="LWTooltip-root">103</span></span><span class="LWPostsItem-title"><span><span class="PostsTitle-root"><span class="PostsTitle-eaTitleDesktopEllipsis"><a href="https://www.lesswrong.com/posts/wZGpoZgDANdkwTrwt/toward-a-bayesian-theory-of-willpower"><span>Toward A Bayesian Theory Of Willpower</span></a></span><span class="PostsTitle-hideXsDown"><div class="PostsTitle-interactionWrapper"><span class="PostsItemIcons-iconSet"></span></div></span></span></span></span><span class="LWPostsItem-spacer"></span><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo PostsItemDate-postedAt"><time datetime="2021-03-26T02:33:55.056Z">4y</time></span></span><div class="LWPostsItem-mobileSecondRowSpacer"></div><div class="LWPostsItem-mobileIcons"><span class="PostsItemIcons-iconSet"></span></div><div class="LWPostsItem-mobileActions"><div class="PostActionsButton-root"><div><svg class="MuiSvgIcon-root PostActionsButton-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M6 10c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm12 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm-6 0c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"></path></svg></div></div></div><div class="LWPostsItem-commentsIcon"><div class="PostsItemComments-commentsIconLarge"><svg class="MuiSvgIcon-root PostsItemComments-commentCountIcon PostsItemComments-noUnreadComments" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M21.99 4c0-1.1-.89-2-1.99-2H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h14l4 4-.01-18z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><div class="PostsItemComments-commentCount">28</div></div></div><div class="LWPostsItem-mobileDismissButton"></div></div></div><div class="PostsItemTrailingButtons-actions"></div></div></div></div><aside class="Typography-root Typography-body2 SectionFooter-root"><a class="LoadMore-root LoadMore-sectionFooterStyles" href="#">Load More</a></aside></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root"><h1 id="wiki-contributions" class="Typography-root Typography-display1 SectionTitle-title">Wiki Contributions</h1><div class="SectionTitle-children"></div></div><div class="TagEditsByUser-root"><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root">(<span class="ChangeMetricsDisplay-charsAdded">+52</span>/<span class="ChangeMetricsDisplay-charsRemoved">-52</span>)</span></div></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root">(<span class="ChangeMetricsDisplay-charsAdded">+11</span>/<span class="ChangeMetricsDisplay-charsRemoved">-11</span>)</span></div></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root">(<span class="ChangeMetricsDisplay-charsAdded">+13</span>/<span class="ChangeMetricsDisplay-charsRemoved">-9</span>)</span></div></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root">(<span class="ChangeMetricsDisplay-charsAdded">+8</span>/<span class="ChangeMetricsDisplay-charsRemoved">-7</span>)</span></div></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root">(<span class="ChangeMetricsDisplay-charsAdded">+8</span>/<span class="ChangeMetricsDisplay-charsRemoved">-46</span>)</span></div></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span></div></div><div class="SingleLineTagUpdates-root"><div class="SingleLineTagUpdates-metadata"><div class="SingleLineTagUpdates-title"><a href="https://www.lesswrong.com/tag/list-of-blogs">List of Blogs</a></div><span class="LWTooltip-root"><span class="Typography-root Typography-body2 PostsItem2MetaInfo-metaInfo SingleLineTagUpdates-postedAt"> 11y </span></span><div class="SingleLineTagUpdates-changeMetrics"><span class="ChangeMetricsDisplay-root"><span class="ChangeMetricsDisplay-charsAdded">(+2537)</span></span></div></div></div><a class="LoadMore-root" href="#">Load More</a></div></div><div class="SingleColumnSection-root"><div class="SectionTitle-root UsersProfile-commentSorting"><h1 class="Typography-root Typography-display1 SectionTitle-title"><a href="https://www.lesswrong.com/users/scottalexander/replies">Comments</a></h1><div class="SectionTitle-children">Sorted by <div class="InlineSelect-root"><a class="InlineSelect-link">Newest</a></div></div></div><div class="RecentComments-root"><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="CK6s9yxineHH22Aeh"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/WE65pBLQvNk3h3Dnr/?commentId=CK6s9yxineHH22Aeh">Cryonics is free</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/WE65pBLQvNk3h3Dnr/cryonics-is-free?commentId=CK6s9yxineHH22Aeh"><span class="LWTooltip-root"><time datetime="2024-10-01T00:50:11.197Z">10d</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">23</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">3</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Who is the wealthy person?</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="FzrPrCdanWqWRyCGt"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/F8sfrbPjCQj4KwJqn/?commentId=FzrPrCdanWqWRyCGt">The Sun is big, but superintelligences will not spare Earth a little sunlight</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/F8sfrbPjCQj4KwJqn/the-sun-is-big-but-superintelligences-will-not-spare-earth-a?commentId=FzrPrCdanWqWRyCGt"><span class="LWTooltip-root"><time datetime="2024-09-29T12:58:26.477Z">11d</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">17</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">4</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>But
 it's also relevant that we're not asking the superintelligence to grant
 a random wish, we're asking it for the right to keep something we 
already have. This seems more easily granted than the random wish, since
 it doesn't imply he has to give random amounts of money to everyone.</p><p>My preferred analogy would be:</p><blockquote><p>You
 founded a company that was making $77/year. Bernard launched a hostile 
takeover, took over the company, then expanded it to make $170 
billion/year. You ask him to keep paying you the $77/year as a pension, 
so that you don't starve to death.</p></blockquote><p>This seems like a 
very sympathetic request, such that I expect the real, human Bernard 
would grant it. I agree this doesn't necessarily generalize to 
superintelligences, but that's Zack's point - Eliezer should choose a 
different example.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="KoKSYrPKhGFv7K2ja"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/jGu4nLgQYwfsoxddu/?commentId=KoKSYrPKhGFv7K2ja">Reconsider the anti-cavity bacteria if you are Asian</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/jGu4nLgQYwfsoxddu/reconsider-the-anti-cavity-bacteria-if-you-are-asian?commentId=KoKSYrPKhGFv7K2ja"><span class="LWTooltip-root"><time datetime="2024-04-16T11:26:38.021Z">6mo</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">9</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">0</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Thanks, this is interesting.</p><p>My
 understanding is that cavities are formed because the very local pH on 
that particular sub-part of the tooth is below 5.5. IIUC teeth can't get
 cancer. Are you imagining Lumina colonies on the gums having this 
effect there, the Lumina colonies on the teeth affecting the general 
oral environment (which I think would require more calculation than just
 comparing to the hyper-local cavity environment) or am I 
misunderstanding something?</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="p2RhoBoPGkL6mN6z3"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/JEhW3HDMKzekDShva/?commentId=p2RhoBoPGkL6mN6z3">Significantly Enhancing Adult Intelligence With Gene Editing May Be Possible</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/JEhW3HDMKzekDShva/significantly-enhancing-adult-intelligence-with-gene-editing?commentId=p2RhoBoPGkL6mN6z3"><span class="LWTooltip-root"><time datetime="2023-12-12T19:27:54.074Z">10mo</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">16</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">0</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Thanks, this is very interesting.</p><p>One thing I don't understand: you write that a major problem with viruses is:</p><blockquote><p>As
 one might expect, the immune system is not a big fan of viruses. So 
when you deliver DNA for a gene editor with an AAV, the viral proteins 
often trigger an adaptive immune response. This means that when you next
 try to deliver a payload with the same AAV, antibodies created during 
the first dose will bind to and destroy most of them.</p></blockquote><p>Is this a problem for people who expect to only want one genetic modification during their lifetime?</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="hGJZeHiupJGxa2hdD"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/mSeesg7i4d9scWAet/?commentId=hGJZeHiupJGxa2hdD">Apocalypse insurance, and the hardline libertarian take on AI risk</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/mSeesg7i4d9scWAet/apocalypse-insurance-and-the-hardline-libertarian-take-on-ai?commentId=hGJZeHiupJGxa2hdD"><span class="LWTooltip-root"><time datetime="2023-11-28T06:59:34.348Z">10mo</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">33</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">14</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>I
 agree with everyone else pointing out that centrally-planned guaranteed
 payments regardless of final outcome doesn't sound like a good price 
discovery mechanism for insurance. You might be able to hack together a 
better one using <span><span class=""><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/dLzZWNGD23zqNLvt3/the-apocalypse-bet"><span>https://www.lesswrong.com/posts/dLzZWNGD23zqNLvt3/the-apocalypse-bet</span></a></span></span> , although I can't figure out an exact mechanism.</p><p>Superforecasters say <span><span><span><a href="https://www.astralcodexten.com/p/the-extinction-tournament"><span>the risk of AI apocalypse before 2100 is 0.38%</span></a></span></span></span>.
 If we assume whatever price mechanism we come up with tracks that, and 
value the world at GWP x 20 (this ignores the value of human life, so 
it's a vast underestimate), and that AI companies pay it in 77 equal 
yearly installments from now until 2100, that's about $100 billion/year.
 But this seems so Pascalian as to be almost cheating. Anybody whose 
actions have a &gt;1/25 million chance of destroying the world would owe
 $1 million a year in insurance (maybe this is fair and I just have bad 
intuitions about how <i>high</i> 1/25 million really is)</p><blockquote><p>An
 AI company should be able to make some of its payments (to the people 
whose lives it risks, in exchange for the ability to risk those lives) 
by way of fractions of the value that their technology manages to 
capture. Except, that's complicated by the fact that anyone doing the 
job properly shouldn't be leaving their fingerprints on the future. The 
cosmic endowment is not quite theirs to give (perhaps they should be 
loaning against their share of it?).</p></blockquote><p>This seems like 
such a big loophole as to make the plan almost worthless. Suppose OpenAI
 said "If we create superintelligence, we're going to keep 10% of the 
universe for ourselves and give humanity the other 90%" (this doesn't 
seem too unfair to me, and the exact numbers don't matter for the 
argument). It seems like instead of paying insurance, they can say 
"Okay, fine, we get 9% and you get 91%" and this would be in some sense a
 fair trade (one percent of the cosmic endowment is worth much more than
 $100 billion!) But this also feels like OpenAI moving some numbers 
around on an extremely hypothetical ledger, not changing anything in 
real life, and continuing to threaten the world just as much as before.</p><p>But if you <i>don't</i>
 allow a maneuver like this, it seems like you might ban (through 
impossible-to-afford insurance) some action that has an 0.38% chance of 
destroying the world and a 99% chance of creating a perfect utopia 
forever.</p><p>There are probably economic mechanisms that solve all these problems, but this insurance proposal seems underspecified.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="KoSESirrNNEkoahCo"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/KXHMCH7wCxrvKsJyn/?commentId=KoSESirrNNEkoahCo">OpenAI: Facts from a Weekend</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/KXHMCH7wCxrvKsJyn/openai-facts-from-a-weekend?commentId=KoSESirrNNEkoahCo"><span class="LWTooltip-root"><time datetime="2023-11-28T06:03:55.522Z">10mo</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">20</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">0</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Thanks, this makes more sense than anything else I've seen, but one thing I'm still confused about:</p><p>If
 the factions were Altman-Brockman-Sutskever vs. 
Toner-McCauley-D'Angelo, then even assuming Sutskever was an Altman 
loyalist, any vote to remove Toner would have been tied 3-3. I can't 
find anything about tied votes in the bylaws - do they fail? If so, 
Toner should be safe. And in fact, Toner knew she (secretly) had 
Sutskever on her side, and it would have been 4-2. If Altman 
manufactured some scandal, the board could have just voted to ignore it.</p><p>So
 I still don't understand "why so abruptly?" or why they felt like they 
had to take such a drastic move when they held all the cards (and were 
pretty stable even if Ilya flipped).</p><p>Other loose ends:</p><ul><li>Toner got on the board because of OpenPhil's donation. But how did McCauley get on the board?</li><li>Is D'Angelo a safetyist?</li><li>Why wouldn't they tell anyone, including Emmett Shear, the full story?</li></ul></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="JEh3qAkmhtKkCEMgG"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/AskPyNg6hHP6SrmEy/?commentId=JEh3qAkmhtKkCEMgG">Redirecting one’s own taxes as an effective altruism method</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/AskPyNg6hHP6SrmEy/redirecting-one-s-own-taxes-as-an-effective-altruism-method?commentId=JEh3qAkmhtKkCEMgG"><span class="LWTooltip-root"><time datetime="2023-11-14T07:05:06.373Z">11mo</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">11</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">5</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Thanks for this, consider me another strong disagreement + strong upvote.</p><p>I
 know a nonprofit which had a tax issue - they were financially able and
 willing to pay, but for complicated reasons paying would have caused 
them legal damage in other ways and they keep kicking the can down the 
road until some hypothetical future when these are solved. I can't 
remember if the nonprofit is now formally dissolved or just effectively 
defunct, but the IRS keeps sending nasty letters to the former board 
members and officers.</p><p>Do you know anything about a situation like 
this? Does the IRS ever pursue board members / founders / officers for a
 charity's nonpayment? Assuming the nonprofit has no money and never 
will have money again, are there any repercussions for the people 
involved if they don't figure out a legal solution and just put off 
paying the taxes until the ten year deadline?</p><p>(it would be 
convenient if yes, but this would feel surprising - otherwise you could 
just start a corporation, not pay your taxes the first year, dissolve 
it, start an identical corporation the second year, and so on.)</p><p>Also,
 does the IRS acknowledge the ten-year deadline enough that they will 
stop threatening you after ten years, or would the board members have to
 take them to court to make the letters stop?</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="EvcpLfyYZEqDmfuQk"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/yT22RcWrxZcXyGjsA/?commentId=EvcpLfyYZEqDmfuQk">How to have Polygenically Screened Children</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="LWTooltip-root"><span class="ShowParentComment-root"><svg class="MuiSvgIcon-root ShowParentComment-icon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M11 9l1.42 1.42L8.83 14H18V4h2v12H8.83l3.59 3.58L11 21l-6-6 6-6z"></path></svg></span></span><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/yT22RcWrxZcXyGjsA/how-to-have-polygenically-screened-children?commentId=EvcpLfyYZEqDmfuQk"><span class="LWTooltip-root"><time datetime="2023-05-11T06:21:18.777Z">1y</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">5</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">1</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Thanks!</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="TEp3k6kyanFakcNLj"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/yT22RcWrxZcXyGjsA/?commentId=TEp3k6kyanFakcNLj">How to have Polygenically Screened Children</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/yT22RcWrxZcXyGjsA/how-to-have-polygenically-screened-children?commentId=TEp3k6kyanFakcNLj"><span class="LWTooltip-root"><time datetime="2023-05-09T19:02:38.555Z">1y</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">16</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">4</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>Thank you, this is a great post. A few questions:</p><ul><li>You
 say "see below for how to get access to these predictors". Am I 
understanding right that the advice you're referring to is to contact 
Jonathan and see if he knows?</li><li>I heard a rumor that you can get 
IQ out of standard predictors like LifeView by looking at "risk of 
cognitive disability"; since cognitive disability is just IQ under a 
certain bar, this is covertly predicting IQ. Do you know anything about 
whether this is true?</li><li>I can't find any of these services listing cost clearly, but this older article <span><span><span><a href="https://www.genomeweb.com/sequencing/genomic-prediction-raises-45m#.ZFqXprDMJaR"><span>https://www.genomeweb.com/sequencing/genomic-prediction-raises-45m#.ZFqXprDMJaR</span></a></span></span></span> suggests a cost of $1,000 + 400*embryo for screening. Where did you get the $20,000 estimate?</li></ul></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><div><div><div class="comments-node CommentFrame-commentsNodeRoot comments-node-root comments-node-odd CommentFrame-node CommentFrame-answerLeafComment" id="aJ4FdzNhHNFjv5Lvj"><div><div class="CommentsItem-root recent-comments-node"><div class="CommentsItem-postTitleRow"><span class="LWTooltip-root"><a class="CommentsItem-postTitle" href="https://www.lesswrong.com/posts/eJq7xWcASjMkvikkD/?commentId=aJ4FdzNhHNFjv5Lvj">On Investigating Conspiracy Theories</a></span></div><div class="CommentsItem-body"><div class="CommentsItemMeta-root"><span class="CommentsItemMeta-username CommentUserName-author"><span><span class=""><a class="UsersNameDisplay-noColor" href="https://www.lesswrong.com/users/scottalexander">Scott Alexander</a></span></span></span><span class="CommentsItemDate-root CommentsItemDate-date"><a rel="nofollow" href="https://www.lesswrong.com/posts/eJq7xWcASjMkvikkD/on-investigating-conspiracy-theories?commentId=aJ4FdzNhHNFjv5Lvj"><span class="LWTooltip-root"><time datetime="2023-02-21T02:32:59.921Z">2y</time></span><svg class="MuiSvgIcon-root CommentsItemDate-icon ForumIcon-root ForumIcon-linkRotation" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a></span><span class="NamesAttachedReactionsVoteOnComment-root"><span class="OverallVoteAxis-vote"><span class="OverallVoteAxis-overallSection OverallVoteAxis-overallSectionBox"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-left" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span><span class="LWTooltip-root"><span class="OverallVoteAxis-voteScore">41</span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteArrowIcon-root VoteArrowIcon-right" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root VoteArrowIcon-smallArrow" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteArrowIcon-bigArrow VoteArrowIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></button></span></span></span><span class="AgreementVoteAxis-agreementSection"><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-clear VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallArrowBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigClear VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span></button></span><span class="AgreementVoteAxis-agreementScore"><span class="LWTooltip-root"><span class="AgreementVoteAxis-voteScore">20</span></span></span><span class="LWTooltip-root"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root VoteAgreementIcon-root" type="button"><span class="MuiIconButton-label"><span class="VoteAgreementIcon-iconsContainer"><svg class="MuiSvgIcon-root VoteAgreementIcon-check VoteAgreementIcon-noClickCatch" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation" style="color: inherit;"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-smallCheckBigVoted VoteAgreementIcon-noClickCatch VoteAgreementIcon-hideIcon" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg><svg class="MuiSvgIcon-root VoteAgreementIcon-bigCheck VoteAgreementIcon-noClickCatch VoteAgreementIcon-exited" focusable="false" viewBox="6 6 12 12" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"></path></svg></span></span></button></span></span></span><span class="CommentsItemMeta-rightSection"></span></div><div class="InlineReactSelectionWrapper-root"><div class="CommentBody-root ContentStyles-base content ContentStyles-commentBody"><div class="CommentBody-commentStyling"><p>A
 key point underpinning my thoughts, which I don't think this really 
responds to, is that scientific consensus actually is really good, so 
good I have trouble finding anecdotes of things in the reference class 
of ivermectin turning out to be true (reference class: things that 
almost all the relevant experts think are false and denounce 
full-throatedly as a conspiracy theory after spending a lot of time 
looking at the evidence).</p><p>There are some, maybe many, examples of 
weaker problems. For example, there are frequent examples of things that
 journalists/the government/professional associations want to *pretend* 
is scientific consensus, getting proven wrong - I claim if you really 
look carefully, the scientists weren't really saying those things, at 
least not as intensely as they were saying ivermectin didn't work. There
 are frequent examples of scientists being sloppy and firing off an 
opinion on something they weren't really thinking hard about and being 
wrong. There are frequent examples of scientists having dumb political 
opinions and trying to dress them up as science. I can't give a perfect 
necessary-and-sufficient definition of the relevant reference class. But
 I think it's there and recognizable.</p><p>I stick to my advice that 
people who know they're not sophisticated should avoid trying to 
second-guess the mainstream, and people who think they might be 
sophisticated should sometimes second-guess the mainstream when there 
isn't the exact type of scientific consensus which has a really good 
track record (and hopefully they're sophisticated enough to know when 
that is).</p><p>I'm not sure how you're using "free riding" here. I 
agree that someone needs to do the work of forming/testing/challenging 
opinions, but I think if there's basically no chance you're right (eg 
you're a 15 year old with no scientific background who thinks they've 
discovered a flaw in E=mc^2), that person is not you, and your input is 
not necessary to move science forward. I agree that person shouldn't 
cravenly quash their own doubt and pretend to believe, they should 
continue believing whatever rationality compels them to believe, which 
should probably be something like "This thing about relativity doesn't 
seem quite right, but given that I'm 15 and know nothing, on the Outside
 View I'm probably wrong." Then they can either try to learn more 
(including asking people what they think of their objection) and 
eventually reach a point where maybe they do think they're right, or 
they can ignore it and go on with their lives.</p></div></div></div><div class="CommentBottom-bottom CommentBottom-bottomWithReacts"><a class="comments-item-reply-link CommentsItem-replyLink">Reply</a><span class="NamesAttachedReactionsCommentBottom-footerReactionsRow"><span class=""><span class="NamesAttachedReactionsCommentBottom-addReactionButton react-hover-style"><svg fill="none" height="16" viewBox="0 0 16 16" width="16" xmlns="http://www.w3.org/2000/svg"><g fill="currentColor"><path d="m13 7c0-3.31371-2.6863-6-6-6-3.31371 0-6 2.68629-6 6 0 3.3137 2.68629 6 6 6 .08516 0 .1699-.0018.25419-.0053-.11154-.3168-.18862-.6499-.22673-.9948l-.02746.0001c-2.76142 0-5-2.23858-5-5s2.23858-5 5-5 5 2.23858 5 5l-.0001.02746c.3449.03811.678.11519.9948.22673.0035-.08429.0053-.16903.0053-.25419z"></path><path d="m7.11191 10.4982c.08367-.368.21246-.71893.38025-1.04657-.15911.03174-.32368.04837-.49216.04837-.74037 0-1.40506-.3212-1.86354-.83346-.18417-.20576-.50026-.22327-.70603-.03911-.20576.18417-.22327.50026-.03911.70603.64016.71524 1.57205 1.16654 2.60868 1.16654.03744 0 .07475-.0006.11191-.0018z"></path><path d="m6 6c0 .41421-.33579.75-.75.75s-.75-.33579-.75-.75.33579-.75.75-.75.75.33579.75.75z"></path><path d="m8.75 6.75c.41421 0 .75-.33579.75-.75s-.33579-.75-.75-.75-.75.33579-.75.75.33579.75.75.75z"></path><path d="m15 11.5c0 1.933-1.567 3.5-3.5 3.5s-3.5-1.567-3.5-3.5 1.567-3.5 3.5-3.5 3.5 1.567 3.5 3.5zm-3-2c0-.27614-.2239-.5-.5-.5s-.5.22386-.5.5v1.5h-1.5c-.27614 0-.5.2239-.5.5s.22386.5.5.5h1.5v1.5c0 .2761.2239.5.5.5s.5-.2239.5-.5v-1.5h1.5c.2761 0 .5-.2239.5-.5s-.2239-.5-.5-.5h-1.5z"></path></g></svg></span></span></span></div></div></div></div></div></div></div><a class="LoadMore-root" href="#">Load More</a></div></div></div><div class="Footer-root"></div></div></div></div></div>

<script>window.ssrRenderedAt = "2024-10-10T21:04:50.788Z"</script>
<script>window.ssrMetadata = {"renderedAt":"2024-10-10T21:04:50.788Z","cacheFriendly":false,"timezone":"Atlantic/Reykjavik"}</script>
<script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","currentUser":null,"unreadNotificationCounts":{"__typename":"NotificationCounts","unreadNotifications":0,"unreadPrivateMessages":0,"faviconBadgeNumber":0,"checkedAt":"2024-10-10T21:04:50.800Z"},"users({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":10,\"slug\":\"scottalexander\",\"view\":\"usersProfile\"}}})":{"__typename":"MultiUserOutput","results":[{"__ref":"User:XgYW5s8njaYrtyP7q"}],"totalCount":null},"revisions({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":10,\"userId\":\"XgYW5s8njaYrtyP7q\",\"view\":\"revisionsByUser\"}}})":{"__typename":"MultiRevisionOutput","results":[{"__ref":"Revision:5f5c37ee1b5cdee568cfd5f1"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5f0"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5e9"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5d1"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5d0"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5cf"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5ce"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5cd"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5cc"},{"__ref":"Revision:5f5c37ee1b5cdee568cfd5cb"}],"totalCount":null},"sequences({\"input\":{\"enableCache\":false,\"enableTotal\":true,\"terms\":{\"limit\":9,\"userId\":\"XgYW5s8njaYrtyP7q\",\"view\":\"userProfile\"}}})":{"__typename":"MultiSequenceOutput","results":[{"__ref":"Sequence:hs42Xd4joLcTP6uTb"},{"__ref":"Sequence:sdTckKmNM6zb7yGRt"},{"__ref":"Sequence:ZNNi2uNx9E6iwGKKG"},{"__ref":"Sequence:G2GDw3m4MJ5ixSM92"},{"__ref":"Sequence:k5MPpr72eiGknaS7F"},{"__ref":"Sequence:TQW9brvXJ5Fajorr4"},{"__ref":"Sequence:WnTvZdXz2q9ySfr4o"},{"__ref":"Sequence:TKDT2Mt6dDMH8AsZW"},{"__ref":"Sequence:xmDeR64CivZiTAcLx"}],"totalCount":15},"user({\"input\":{\"selector\":{\"documentId\":\"XgYW5s8njaYrtyP7q\"}}})":{"__typename":"SingleUserOutput","result":{"__ref":"User:XgYW5s8njaYrtyP7q"}},"comments({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"authorIsUnreviewed\":null,\"limit\":10,\"userId\":\"XgYW5s8njaYrtyP7q\",\"view\":\"profileComments\"}}})":{"__typename":"MultiCommentOutput","results":[{"__ref":"Comment:CK6s9yxineHH22Aeh"},{"__ref":"Comment:FzrPrCdanWqWRyCGt"},{"__ref":"Comment:KoKSYrPKhGFv7K2ja"},{"__ref":"Comment:p2RhoBoPGkL6mN6z3"},{"__ref":"Comment:hGJZeHiupJGxa2hdD"},{"__ref":"Comment:KoSESirrNNEkoahCo"},{"__ref":"Comment:JEh3qAkmhtKkCEMgG"},{"__ref":"Comment:EvcpLfyYZEqDmfuQk"},{"__ref":"Comment:TEp3k6kyanFakcNLj"},{"__ref":"Comment:aJ4FdzNhHNFjv5Lvj"}],"totalCount":null},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"authorIsUnreviewed\":null,\"excludeEvents\":true,\"limit\":10,\"userId\":\"XgYW5s8njaYrtyP7q\",\"view\":\"userPosts\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:ynpC7oXhXxGPNuCgH"},{"__ref":"Post:NGkBfd8LTqcpbQn5Z"},{"__ref":"Post:55aoSeDTDKbw9dgza"},{"__ref":"Post:rwkkcgSpnAyE8oNo3"},{"__ref":"Post:gS8Jmcfoa9FAh92YK"},{"__ref":"Post:KCcdhZK7omEMwBdju"},{"__ref":"Post:fLdADsBLAMuGvky2M"},{"__ref":"Post:gBpYo7mt2zNBmtBJd"},{"__ref":"Post:kxW6q5YdTGWh5sWby"},{"__ref":"Post:wZGpoZgDANdkwTrwt"}],"totalCount":null}},"User:XgYW5s8njaYrtyP7q":{"_id":"XgYW5s8njaYrtyP7q","__typename":"User","oldSlugs":["yvain"],"groups":["trustLevel1","canModeratePersonal","alignmentVoters","alignmentForum"],"jobTitle":null,"organization":null,"careerStage":null,"biography":null,"howOthersCanHelpMe":null,"howICanHelpOthers":null,"profileTagIds":[],"profileTags":[],"organizerOfGroupIds":[],"organizerOfGroups":[],"programParticipation":null,"website":null,"linkedinProfileURL":null,"facebookProfileURL":null,"twitterProfileURL":null,"githubProfileURL":null,"frontpagePostCount":121,"afSequenceCount":0,"afSequenceDraftCount":0,"sequenceDraftCount":1,"moderationStyle":null,"moderationGuidelines":null,"bannedUserIds":null,"location":null,"googleLocation":null,"mapLocation":null,"mapLocationSet":false,"mapMarkerText":null,"htmlMapMarkerText":"","mongoLocation":null,"shortformFeedId":null,"viewUnreviewedComments":null,"auto_subscribe_to_my_posts":true,"auto_subscribe_to_my_comments":true,"autoSubscribeAsOrganizer":true,"petrovPressedButtonDate":null,"petrovOptOut":false,"sortDraftsBy":null,"email":null,"emails":null,"banned":null,"noindex":false,"paymentEmail":null,"paymentInfo":null,"goodHeartTokens":null,"postingDisabled":null,"allCommentingDisabled":null,"commentingOnOtherUsersDisabled":null,"conversationsDisabled":null,"slug":"scottalexander","createdAt":"2009-02-28T15:53:46.032Z","username":"Yvain","displayName":"Scott Alexander","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":42640,"afKarma":73,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":217,"commentCount":1577,"sequenceCount":15,"afPostCount":1,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":19,"reviewedByUserId":"r38pkCm7wF4M44MDQ","walledGardenInvite":true,"hideWalledGardenUI":null,"walledGardenPortalOnboarded":null,"taggingDashboardCollapsed":null,"usernameUnset":null,"maxCommentCount":1577,"maxPostCount":996,"voteCount":null,"smallUpvoteCount":null,"bigUpvoteCount":null,"smallDownvoteCount":null,"bigDownvoteCount":null,"reviewedAt":null,"signUpReCaptchaRating":null,"needsReview":null,"sunshineNotes":null,"sunshineFlagged":null,"snoozedUntilContentCount":null,"nullifyVotes":null,"deleteContent":null,"moderatorActions":null,"usersContactedBeforeReview":null,"associatedClientIds":null,"altAccountsDetected":null,"voteReceivedCount":null,"smallUpvoteReceivedCount":null,"bigUpvoteReceivedCount":null,"smallDownvoteReceivedCount":null,"bigDownvoteReceivedCount":null,"recentKarmaInfo":{"last20Karma":734,"lastMonthKarma":36,"last20PostKarma":1429,"last20CommentKarma":581,"downvoterCount":0,"postDownvoterCount":0,"commentDownvoterCount":0,"lastMonthDownvoterCount":0},"lastNotificationsCheck":null,"moderatorAssistance":null},"Tag:5f5c37ee1b5cdee568cfb2f2":{"_id":"5f5c37ee1b5cdee568cfb2f2","__typename":"Tag","userId":"XgYW5s8njaYrtyP7q","name":"List of Blogs","shortName":null,"slug":"list-of-blogs","core":false,"postCount":2,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.728Z","wikiOnly":true,"deleted":false,"isSubforum":false,"noindex":false},"Revision:5f5c37ee1b5cdee568cfd5f1":{"_id":"5f5c37ee1b5cdee568cfd5f1","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":0,"removed":0},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.38.0","editedAt":"2013-08-02T03:53:32.000Z","commitMessage":"/* Gone But Not Forgotten */","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5f0":{"_id":"5f5c37ee1b5cdee568cfd5f0","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":0,"removed":0},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.37.0","editedAt":"2013-08-02T03:53:11.000Z","commitMessage":"","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5e9":{"_id":"5f5c37ee1b5cdee568cfd5e9","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":52,"removed":52},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.30.0","editedAt":"2013-06-03T04:01:21.000Z","commitMessage":"/* Generic Rationality and Philosophy */","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5d1":{"_id":"5f5c37ee1b5cdee568cfd5d1","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":11,"removed":11},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.6.0","editedAt":"2013-05-10T09:27:01.000Z","commitMessage":"/* Gender and Politics */","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5d0":{"_id":"5f5c37ee1b5cdee568cfd5d0","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":13,"removed":9},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.5.0","editedAt":"2013-05-10T08:36:57.000Z","commitMessage":"/* Economics and Social Science */","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5cf":{"_id":"5f5c37ee1b5cdee568cfd5cf","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":0,"removed":0},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.4.0","editedAt":"2013-05-10T08:02:07.000Z","commitMessage":"","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5ce":{"_id":"5f5c37ee1b5cdee568cfd5ce","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":8,"removed":7},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.3.0","editedAt":"2013-05-10T07:56:47.000Z","commitMessage":"","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5cd":{"_id":"5f5c37ee1b5cdee568cfd5cd","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":8,"removed":46},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.2.0","editedAt":"2013-05-10T07:56:05.000Z","commitMessage":"","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5cc":{"_id":"5f5c37ee1b5cdee568cfd5cc","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":0,"removed":0},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.1.0","editedAt":"2013-05-10T07:55:18.000Z","commitMessage":"","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:5f5c37ee1b5cdee568cfd5cb":{"_id":"5f5c37ee1b5cdee568cfd5cb","__typename":"Revision","tag":{"__ref":"Tag:5f5c37ee1b5cdee568cfb2f2"},"documentId":"5f5c37ee1b5cdee568cfb2f2","changeMetrics":{"added":2537,"removed":0},"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"version":"1.0.0","editedAt":"2013-05-10T07:54:18.000Z","commitMessage":"Created page with \"==Generic Rationality and Philosophy==  ciphergoth: [http://mindsarentmagic.wordpress.com/ Minds Aren't Magic] ''(focus on cryonics)''  DavidGerard: [http://rationalblogs.org/...\"","userId":"XgYW5s8njaYrtyP7q","score":2,"baseScore":2,"extendedScore":null,"voteCount":1,"currentUserVote":null,"currentUserExtendedVote":null},"Revision:hs42Xd4joLcTP6uTb_contents":{"_id":"hs42Xd4joLcTP6uTb_contents","__typename":"Revision","version":"0.6.0","updateType":"minor","editedAt":"2023-02-26T07:35:17.381Z","userId":"r38pkCm7wF4M44MDQ","html":"<p><strong>Priming<\/strong> is a psychological phenomenon that consists in early stimulus influencing later thoughts and behavior.<\/p><p>Background:<\/p><ul><li><a href=\"http://lesswrong.com/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment<\/a> <\/li><li><a href=\"http://lesswrong.com/lw/k3/priming_and_contamination/\">Priming and Contamination<\/a> <\/li><\/ul><p>See also: <a href=\"https://www.lesswrong.com/s/pmHZDpak4NeRLLLCw\">Seeing with Fresh Eyes<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Affect_heuristic\">Affect Heuristic<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Ugh_field\">Ugh Fields<\/a>, <a href=\"https://www.lesswrong.com/posts/kjArXFinD3deRZNRu/blue-and-yellow-tinted-choices\">Blue- and Yellow-Tinted Choices<\/a>.<\/p>","commitMessage":"","wordCount":38,"htmlHighlight":"<p><strong>Priming<\/strong> is a psychological phenomenon that consists in early stimulus influencing later thoughts and behavior.<\/p><p>Background:<\/p><ul><li><a href=\"http://lesswrong.com/lw/j7/anchoring_and_adjustment/\">Anchoring and Adjustment<\/a> <\/li><li><a href=\"http://lesswrong.com/lw/k3/priming_and_contamination/\">Priming and Contamination<\/a> <\/li><\/ul><p>See also: <a href=\"https://www.lesswrong.com/s/pmHZDpak4NeRLLLCw\">Seeing with Fresh Eyes<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Affect_heuristic\">Affect Heuristic<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Ugh_field\">Ugh Fields<\/a>, <a href=\"https://www.lesswrong.com/posts/kjArXFinD3deRZNRu/blue-and-yellow-tinted-choices\">Blue- and Yellow-Tinted Choices<\/a>.<\/p>","plaintextDescription":"Priming is a psychological phenomenon that consists in early stimulus influencing later thoughts and behavior.\n\nBackground:\n\n * Anchoring and Adjustment\n * Priming and Contamination\n\nSee also: Seeing with Fresh Eyes, Affect Heuristic, Ugh Fields, Blue- and Yellow-Tinted Choices."},"Sequence:hs42Xd4joLcTP6uTb":{"_id":"hs42Xd4joLcTP6uTb","__typename":"Sequence","createdAt":"2019-03-09T12:37:16.671Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:hs42Xd4joLcTP6uTb_contents"},"gridImageId":"sequencesgrid/r8usyus20ivlpuj8np6i","bannerImageId":"sequences/hkngff3tlodso1wkxlri","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Priming","canonicalCollection":null},"Revision:sdTckKmNM6zb7yGRt_contents":{"_id":"sdTckKmNM6zb7yGRt_contents","__typename":"Revision","version":"0.7.0","updateType":"minor","editedAt":"2023-02-26T07:35:34.905Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>See also: <a href=\"https://wiki.lesswrong.com/wiki/Priming\">Priming<\/a>, <a href=\"https://www.lesswrong.com/s/oi873FWi6pHWxswSa\">The Science of Winning at Life<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Alief\">Alief<\/a>, and <a href=\"https://wiki.lesswrong.com/wiki/Connotation\">Connotation<\/a>. <\/p>","commitMessage":"","wordCount":12,"htmlHighlight":"<p>See also: <a href=\"https://wiki.lesswrong.com/wiki/Priming\">Priming<\/a>, <a href=\"https://www.lesswrong.com/s/oi873FWi6pHWxswSa\">The Science of Winning at Life<\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Alief\">Alief<\/a>, and <a href=\"https://wiki.lesswrong.com/wiki/Connotation\">Connotation<\/a>. <\/p>","plaintextDescription":"See also: Priming, The Science of Winning at Life, Alief, and Connotation."},"Sequence:sdTckKmNM6zb7yGRt":{"_id":"sdTckKmNM6zb7yGRt","__typename":"Sequence","createdAt":"2019-03-09T12:27:12.156Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:sdTckKmNM6zb7yGRt_contents"},"gridImageId":"sequencesgrid/mjogxcwbbaclxmmckeiw","bannerImageId":"sequences/jjogjbpl8an845dbbqwy","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":11,"readPostsCount":0,"title":"Positivism and Self Deception","canonicalCollection":null},"Revision:ZNNi2uNx9E6iwGKKG_contents":{"_id":"ZNNi2uNx9E6iwGKKG_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","commitMessage":null,"wordCount":156,"htmlHighlight":"<p>This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.<\/p><p>Parts of this sequence draw heavily upon material from <em><u><a href=\"http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430\">The Art of Strategy<\/a><\/u><\/em> by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it&#x27;s probably a bad idea to pick a legal fight with people who write books called <em>The Art of Strategy<\/em>.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.<\/p><p>Special thanks to Luke for his book recommendation and his strong encouragement to write this.<\/p>","plaintextDescription":"This sequence of posts is a primer on game theory intended at an introductory level. Because it is introductory, Less Wrong veterans may find some parts boring, obvious, or simplistic - although hopefully nothing is so simplistic as to be outright wrong.\n\nParts of this sequence draw heavily upon material from The Art of Strategy by Avinash Dixit and Barry Nalebuff, and it may in part be considered a (very favorable) review of the book accompanied by an exploration of its content. I have tried to include enough material to be useful, but not so much material that it becomes a plagiarism rather than a review (it's probably a bad idea to pick a legal fight with people who write books called The Art of Strategy.) Therefore, for the most complete and engaging presentation of this material, I highly recommend the original book.\n\nSpecial thanks to Luke for his book recommendation and his strong encouragement to write this."},"Sequence:ZNNi2uNx9E6iwGKKG":{"_id":"ZNNi2uNx9E6iwGKKG","__typename":"Sequence","createdAt":"2018-04-08T21:50:10.329Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:ZNNi2uNx9E6iwGKKG_contents"},"gridImageId":"sequencesgrid/vitugifyyh2upm9ucjzh","bannerImageId":"sequences/zvybkycf2vyasr4zwptr","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":9,"readPostsCount":0,"title":"Introduction to Game Theory","canonicalCollection":null},"Revision:G2GDw3m4MJ5ixSM92_contents":{"_id":"G2GDw3m4MJ5ixSM92_contents","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-09-21T21:34:27.910Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","commitMessage":"","wordCount":19,"htmlHighlight":"<p>A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour.<\/p>","plaintextDescription":"A sequence on models of the human mind, drawing on psychology and neuroscience to discuss motivation, learning and behaviour."},"Sequence:G2GDw3m4MJ5ixSM92":{"_id":"G2GDw3m4MJ5ixSM92","__typename":"Sequence","createdAt":"2018-02-22T18:10:39.949Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:G2GDw3m4MJ5ixSM92_contents"},"gridImageId":"sequencesgrid/djfksyoldrjt4ef5jts3","bannerImageId":"sequences/ad7shnab6qq5v6cqxpme","canonicalCollectionSlug":null,"draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":1,"userProfileOrder":null,"af":false,"postsCount":16,"readPostsCount":0,"title":"The Blue-Minimizing Robot","canonicalCollection":null},"Revision:k5MPpr72eiGknaS7F_contents":{"_id":"k5MPpr72eiGknaS7F_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-09-05T02:19:15.940Z","userId":"XgYW5s8njaYrtyP7q","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Collection:2izXHCrmJ684AnZ5X":{"_id":"2izXHCrmJ684AnZ5X","__typename":"Collection","title":"The Codex"},"Sequence:k5MPpr72eiGknaS7F":{"_id":"k5MPpr72eiGknaS7F","__typename":"Sequence","createdAt":"2017-09-05T02:19:15.940Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:k5MPpr72eiGknaS7F_contents"},"gridImageId":"sequencesgrid/byzxi4zdrlvodk0ph46r","bannerImageId":"sequences/ysr4l3sqb6vfszn49p1u","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":4,"readPostsCount":0,"title":"Hypotheses and Hunches","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:TQW9brvXJ5Fajorr4_contents":{"_id":"TQW9brvXJ5Fajorr4_contents","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-06-23T22:40:56.142Z","userId":"r38pkCm7wF4M44MDQ","html":"<p>Nearly everyone is very very very overconfident. We know this from <a href=\"http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf\">experiments<\/a> where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.<\/p><p>It gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are <i>fifty thousand times<\/i> as confident as they should be.<\/p>","commitMessage":"","wordCount":119,"htmlHighlight":"<p>Nearly everyone is very very very overconfident. We know this from <a href=\"http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf\">experiments<\/a> where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.<\/p><p>It gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are <i>fifty thousand times<\/i> as confident as they should be.<\/p>","plaintextDescription":"Nearly everyone is very very very overconfident. We know this from experiments where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If people’s confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance they’re wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.\n\nIt gets worse. People who say there’s only a 1 in 100,000 chance they’re wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. They’re not just overconfident, they are fifty thousand times as confident as they should be."},"Sequence:TQW9brvXJ5Fajorr4":{"_id":"TQW9brvXJ5Fajorr4","__typename":"Sequence","createdAt":"2017-09-05T01:01:05.221Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:TQW9brvXJ5Fajorr4_contents"},"gridImageId":"sequencesgrid/dyq1iu03mw0qo54n6byk","bannerImageId":"sequences/s7io2gbfmdhk7lyn0flk","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Probability and Predictions","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:WnTvZdXz2q9ySfr4o_contents":{"_id":"WnTvZdXz2q9ySfr4o_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:44:23.722Z","userId":"XgYW5s8njaYrtyP7q","html":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","commitMessage":null,"wordCount":1,"htmlHighlight":"<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p><\/p><\/div><\/div><\/div><\/div>","plaintextDescription":""},"Sequence:WnTvZdXz2q9ySfr4o":{"_id":"WnTvZdXz2q9ySfr4o","__typename":"Sequence","createdAt":"2017-08-24T01:44:23.722Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:WnTvZdXz2q9ySfr4o_contents"},"gridImageId":"sequencesgrid/opwbi6lh0ud7r7dlyghc","bannerImageId":"sequences/r6u4ghtv3smv1zeh6rvv","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":6,"readPostsCount":0,"title":"Parables and Prayers","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Revision:TKDT2Mt6dDMH8AsZW_contents":{"_id":"TKDT2Mt6dDMH8AsZW_contents","__typename":"Revision","version":"1.0.0","updateType":null,"editedAt":"2017-08-24T01:41:22.191Z","userId":"XgYW5s8njaYrtyP7q","html":"<p>A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox.<\/p>","commitMessage":null,"wordCount":14,"htmlHighlight":"<p>A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox.<\/p>","plaintextDescription":"A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox."},"Sequence:TKDT2Mt6dDMH8AsZW":{"_id":"TKDT2Mt6dDMH8AsZW","__typename":"Sequence","createdAt":"2017-08-24T01:41:22.191Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":{"__ref":"Revision:TKDT2Mt6dDMH8AsZW_contents"},"gridImageId":"sequencesgrid/lel3jdh48of1dhtwfo4i","bannerImageId":"sequences/bj5eolzptpnu9fi9gi1a","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":10,"readPostsCount":0,"title":"Futurism and Forecasting","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Sequence:xmDeR64CivZiTAcLx":{"_id":"xmDeR64CivZiTAcLx","__typename":"Sequence","createdAt":"2017-08-24T01:39:54.799Z","userId":"XgYW5s8njaYrtyP7q","user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"contents":null,"gridImageId":"sequencesgrid/u0ackeoho1tquuiozpt4","bannerImageId":"sequences/c1h4gtqbcw3v04ikuprj","canonicalCollectionSlug":"codex","draft":false,"isDeleted":false,"hidden":false,"hideFromAuthorPage":false,"noindex":false,"curatedOrder":null,"userProfileOrder":null,"af":false,"postsCount":7,"readPostsCount":0,"title":"Community and Cooperation","canonicalCollection":{"__ref":"Collection:2izXHCrmJ684AnZ5X"}},"Post:WE65pBLQvNk3h3Dnr":{"_id":"WE65pBLQvNk3h3Dnr","__typename":"Post","isRead":null,"slug":"cryonics-is-free","title":"Cryonics is free","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"Tw9etd8rMnHLeSQ9q","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:CK6s9yxineHH22Aeh_contents":{"_id":"CK6s9yxineHH22Aeh_contents","__typename":"Revision","html":"<p>Who is the wealthy person?<\/p>","plaintextMainText":"Who is the wealthy person?","wordCount":5},"Comment:CK6s9yxineHH22Aeh":{"_id":"CK6s9yxineHH22Aeh","__typename":"Comment","post":{"__ref":"Post:WE65pBLQvNk3h3Dnr"},"tag":null,"postId":"WE65pBLQvNk3h3Dnr","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":"XBK2zAmxS6J6ZavCD","topLevelCommentId":"jwyDvkaYFscZxd5Pk","descendentCount":0,"title":null,"contents":{"__ref":"Revision:CK6s9yxineHH22Aeh_contents"},"postedAt":"2024-10-01T00:50:11.197Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":23,"extendedScore":{"reacts":{},"agreement":3,"approvalVoteCount":11,"agreementVoteCount":2},"score":0.044117290526628494,"voteCount":11,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":11,"afExtendedScore":{"reacts":{},"agreement":2,"approvalVoteCount":6,"agreementVoteCount":1},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.4.0","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2024-10-01T00:50:11.202Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":0,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:F8sfrbPjCQj4KwJqn":{"_id":"F8sfrbPjCQj4KwJqn","__typename":"Post","isRead":null,"slug":"the-sun-is-big-but-superintelligences-will-not-spare-earth-a","title":"The Sun is big, but superintelligences will not spare Earth a little sunlight","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"nmk3nLpQE89dMRzzN","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:FzrPrCdanWqWRyCGt_contents":{"_id":"FzrPrCdanWqWRyCGt_contents","__typename":"Revision","html":"<p>But it's also relevant that we're not asking the superintelligence to grant a random wish, we're asking it for the right to keep something we already have. This seems more easily granted than the random wish, since it doesn't imply he has to give random amounts of money to everyone.<\/p><p>My preferred analogy would be:<\/p><blockquote><p>You founded a company that was making $77/year. Bernard launched a hostile takeover, took over the company, then expanded it to make $170 billion/year. You ask him to keep paying you the $77/year as a pension, so that you don't starve to death.<\/p><\/blockquote><p>This seems like a very sympathetic request, such that I expect the real, human Bernard would grant it. I agree this doesn't necessarily generalize to superintelligences, but that's Zack's point - Eliezer should choose a different example.<\/p>","plaintextMainText":"But it's also relevant that we're not asking the superintelligence to grant a random wish, we're asking it for the right to keep something we already have. This seems more easily granted than the random wish, since it doesn't imply he has to give random amounts of money to everyone.\n\nMy preferred analogy would be:\n\nThis seems like a very sympathetic request, such that I expect the real, human Bernard would grant it. I agree this doesn't necessarily generalize to superintelligences, but that's Zack's point - Eliezer should choose a different example.","wordCount":136},"Comment:FzrPrCdanWqWRyCGt":{"_id":"FzrPrCdanWqWRyCGt","__typename":"Comment","post":{"__ref":"Post:F8sfrbPjCQj4KwJqn"},"tag":null,"postId":"F8sfrbPjCQj4KwJqn","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":"9qTmDDrehCHAMDtRH","topLevelCommentId":"BTiebqvn8W2ujJfmN","descendentCount":1,"title":null,"contents":{"__ref":"Revision:FzrPrCdanWqWRyCGt_contents"},"postedAt":"2024-09-29T12:58:26.477Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":17,"extendedScore":{"reacts":{},"agreement":4,"approvalVoteCount":10,"agreementVoteCount":5},"score":0.026745250448584557,"voteCount":11,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":3,"approvalVoteCount":5,"agreementVoteCount":2},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.0","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2024-10-05T11:35:36.959Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":1,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:jGu4nLgQYwfsoxddu":{"_id":"jGu4nLgQYwfsoxddu","__typename":"Post","isRead":null,"slug":"reconsider-the-anti-cavity-bacteria-if-you-are-asian","title":"Reconsider the anti-cavity bacteria if you are Asian","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"Cqk9Wwmj27cEJZJPj","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:KoKSYrPKhGFv7K2ja_contents":{"_id":"KoKSYrPKhGFv7K2ja_contents","__typename":"Revision","html":"<p>Thanks, this is interesting.<\/p><p>My understanding is that cavities are formed because the very local pH on that particular sub-part of the tooth is below 5.5. IIUC teeth can't get cancer. Are you imagining Lumina colonies on the gums having this effect there, the Lumina colonies on the teeth affecting the general oral environment (which I think would require more calculation than just comparing to the hyper-local cavity environment) or am I misunderstanding something?<\/p>","plaintextMainText":"Thanks, this is interesting.\n\nMy understanding is that cavities are formed because the very local pH on that particular sub-part of the tooth is below 5.5. IIUC teeth can't get cancer. Are you imagining Lumina colonies on the gums having this effect there, the Lumina colonies on the teeth affecting the general oral environment (which I think would require more calculation than just comparing to the hyper-local cavity environment) or am I misunderstanding something?","wordCount":74},"Comment:KoKSYrPKhGFv7K2ja":{"_id":"KoKSYrPKhGFv7K2ja","__typename":"Comment","post":{"__ref":"Post:jGu4nLgQYwfsoxddu"},"tag":null,"postId":"jGu4nLgQYwfsoxddu","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":"8T3ijHNAKuiBtSLi3","topLevelCommentId":"5KCcyymGd6CpNKrEo","descendentCount":1,"title":null,"contents":{"__ref":"Revision:KoKSYrPKhGFv7K2ja_contents"},"postedAt":"2024-04-16T11:26:38.021Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":9,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":6,"agreementVoteCount":0},"score":0.0006106296787038445,"voteCount":6,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":4,"agreementVoteCount":0},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.7.1","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2024-04-16T13:45:12.164Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":1,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:JEhW3HDMKzekDShva":{"_id":"JEhW3HDMKzekDShva","__typename":"Post","isRead":null,"slug":"significantly-enhancing-adult-intelligence-with-gene-editing","title":"Significantly Enhancing Adult Intelligence With Gene Editing May Be Possible","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"gsdEYz9qKx2zcMPcW","coauthorStatuses":[{"userId":"nCKrhFEZkCswos65o","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:p2RhoBoPGkL6mN6z3_contents":{"_id":"p2RhoBoPGkL6mN6z3_contents","__typename":"Revision","html":"<p>Thanks, this is very interesting.<\/p><p>One thing I don't understand: you write that a major problem with viruses is:<\/p><blockquote><p>As one might expect, the immune system is not a big fan of viruses. So when you deliver DNA for a gene editor with an AAV, the viral proteins often trigger an adaptive immune response. This means that when you next try to deliver a payload with the same AAV, antibodies created during the first dose will bind to and destroy most of them.<\/p><\/blockquote><p>Is this a problem for people who expect to only want one genetic modification during their lifetime?<\/p>","plaintextMainText":"Thanks, this is very interesting.\n\nOne thing I don't understand: you write that a major problem with viruses is:\n\nIs this a problem for people who expect to only want one genetic modification during their lifetime?","wordCount":101},"Comment:p2RhoBoPGkL6mN6z3":{"_id":"p2RhoBoPGkL6mN6z3","__typename":"Comment","post":{"__ref":"Post:JEhW3HDMKzekDShva"},"tag":null,"postId":"JEhW3HDMKzekDShva","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":2,"title":null,"contents":{"__ref":"Revision:p2RhoBoPGkL6mN6z3_contents"},"postedAt":"2023-12-12T19:27:54.074Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":16,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":18,"agreementVoteCount":0},"score":0.000597201578784734,"voteCount":18,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":5,"agreementVoteCount":0},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.1","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-12-12T20:18:38.008Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":2,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:mSeesg7i4d9scWAet":{"_id":"mSeesg7i4d9scWAet","__typename":"Post","isRead":null,"slug":"apocalypse-insurance-and-the-hardline-libertarian-take-on-ai","title":"Apocalypse insurance, and the hardline libertarian take on AI risk","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"xSfc2APSi8WzFxp7i","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:hGJZeHiupJGxa2hdD_contents":{"_id":"hGJZeHiupJGxa2hdD_contents","__typename":"Revision","html":"<p>I agree with everyone else pointing out that centrally-planned guaranteed payments regardless of final outcome doesn't sound like a good price discovery mechanism for insurance. You might be able to hack together a better one using <a href=\"https://www.lesswrong.com/posts/dLzZWNGD23zqNLvt3/the-apocalypse-bet\">https://www.lesswrong.com/posts/dLzZWNGD23zqNLvt3/the-apocalypse-bet<\/a> , although I can't figure out an exact mechanism.<\/p><p>Superforecasters say <a href=\"https://www.astralcodexten.com/p/the-extinction-tournament\">the risk of AI apocalypse before 2100 is 0.38%<\/a>. If we assume whatever price mechanism we come up with tracks that, and value the world at GWP x 20 (this ignores the value of human life, so it's a vast underestimate), and that AI companies pay it in 77 equal yearly installments from now until 2100, that's about $100 billion/year. But this seems so Pascalian as to be almost cheating. Anybody whose actions have a &gt;1/25 million chance of destroying the world would owe $1 million a year in insurance (maybe this is fair and I just have bad intuitions about how <i>high<\/i> 1/25 million really is)<\/p><blockquote><p>An AI company should be able to make some of its payments (to the people whose lives it risks, in exchange for the ability to risk those lives) by way of fractions of the value that their technology manages to capture. Except, that's complicated by the fact that anyone doing the job properly shouldn't be leaving their fingerprints on the future. The cosmic endowment is not quite theirs to give (perhaps they should be loaning against their share of it?).<\/p><\/blockquote><p>This seems like such a big loophole as to make the plan almost worthless. Suppose OpenAI said \"If we create superintelligence, we're going to keep 10% of the universe for ourselves and give humanity the other 90%\" (this doesn't seem too unfair to me, and the exact numbers don't matter for the argument). It seems like instead of paying insurance, they can say \"Okay, fine, we get 9% and you get 91%\" and this would be in some sense a fair trade (one percent of the cosmic endowment is worth much more than $100 billion!) But this also feels like OpenAI moving some numbers around on an extremely hypothetical ledger, not changing anything in real life, and continuing to threaten the world just as much as before.<\/p><p>But if you <i>don't<\/i> allow a maneuver like this, it seems like you might ban (through impossible-to-afford insurance) some action that has an 0.38% chance of destroying the world and a 99% chance of creating a perfect utopia forever.<\/p><p>There are probably economic mechanisms that solve all these problems, but this insurance proposal seems underspecified.<\/p>","plaintextMainText":"I agree with everyone else pointing out that centrally-planned guaranteed payments regardless of final outcome doesn't sound like a good price discovery mechanism for insurance. You might be able to hack together a better one using https://www.lesswrong.com/posts/dLzZWNGD23zqNLvt3/the-apocalypse-bet , although I can't figure out an exact mechanism.\n\nSuperforecasters say the risk of AI apocalypse before 2100 is 0.38%. If we assume whatever price mechanism we come up with tracks that, and value the world at GWP x 20 (this ignores the value of human life, so it's a vast underestimate), and that AI companies pay it in 77 equal yearly installments from now until 2100, that's about $100 billion/year. But this seems so Pascalian as to be almost cheating. Anybody whose actions have a >1/25 million chance of destroying the world would owe $1 million a year in insurance (maybe this is fair and I just have bad intuitions about how high 1/25 million really is)\n\nThis seems like such a big loophole as to make the plan almost worthless. Suppose OpenAI said \"If we create superintelligence, we're going to keep 10% of the universe for ourselves and give humanity the other 90%\" (this doesn't seem too unfair to me, and the exact numbers don't matter for the argument). It seems like instead of paying insurance, they can say \"Okay, fine, we get 9% and you get 91%\" and this would be in some sense a fair trade (one percent of the cosmic endowment is worth much more than $100 billion!) But this also feels like OpenAI moving some numbers around on an extremely hypothetical ledger, not changing anything in real life, and continuing to threaten the world just as much as before.\n\nBut if you don't allow a maneuver like this, it seems like you might ban (through impossible-to-afford insurance) some action that has an 0.38% chance of destroying the world and a 99% chance of creating a perfect utopia forever.\n\nThere are probably economic mechanisms that solve all these problems, but this insurance ","wordCount":418},"Comment:hGJZeHiupJGxa2hdD":{"_id":"hGJZeHiupJGxa2hdD","__typename":"Comment","post":{"__ref":"Post:mSeesg7i4d9scWAet"},"tag":null,"postId":"mSeesg7i4d9scWAet","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":3,"title":null,"contents":{"__ref":"Revision:hGJZeHiupJGxa2hdD_contents"},"postedAt":"2023-11-28T06:59:34.348Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":33,"extendedScore":{"reacts":{},"agreement":14,"approvalVoteCount":19,"agreementVoteCount":8},"score":0.0011360063217580318,"voteCount":19,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":15,"afExtendedScore":{"reacts":{},"agreement":8,"approvalVoteCount":12,"agreementVoteCount":4},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.0.0","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-11-30T12:15:15.794Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":3,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:KXHMCH7wCxrvKsJyn":{"_id":"KXHMCH7wCxrvKsJyn","__typename":"Post","isRead":null,"slug":"openai-facts-from-a-weekend","title":"OpenAI: Facts from a Weekend","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"N9zj5qpTfqmbn9dro","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:KoSESirrNNEkoahCo_contents":{"_id":"KoSESirrNNEkoahCo_contents","__typename":"Revision","html":"<p>Thanks, this makes more sense than anything else I've seen, but one thing I'm still confused about:<\/p><p>If the factions were Altman-Brockman-Sutskever vs. Toner-McCauley-D'Angelo, then even assuming Sutskever was an Altman loyalist, any vote to remove Toner would have been tied 3-3. I can't find anything about tied votes in the bylaws - do they fail? If so, Toner should be safe. And in fact, Toner knew she (secretly) had Sutskever on her side, and it would have been 4-2. If Altman manufactured some scandal, the board could have just voted to ignore it.<\/p><p>So I still don't understand \"why so abruptly?\" or why they felt like they had to take such a drastic move when they held all the cards (and were pretty stable even if Ilya flipped).<\/p><p>Other loose ends:<\/p><ul><li>Toner got on the board because of OpenPhil's donation. But how did McCauley get on the board?<\/li><li>Is D'Angelo a safetyist?<\/li><li>Why wouldn't they tell anyone, including Emmett Shear, the full story?<\/li><\/ul>","plaintextMainText":"Thanks, this makes more sense than anything else I've seen, but one thing I'm still confused about:\n\nIf the factions were Altman-Brockman-Sutskever vs. Toner-McCauley-D'Angelo, then even assuming Sutskever was an Altman loyalist, any vote to remove Toner would have been tied 3-3. I can't find anything about tied votes in the bylaws - do they fail? If so, Toner should be safe. And in fact, Toner knew she (secretly) had Sutskever on her side, and it would have been 4-2. If Altman manufactured some scandal, the board could have just voted to ignore it.\n\nSo I still don't understand \"why so abruptly?\" or why they felt like they had to take such a drastic move when they held all the cards (and were pretty stable even if Ilya flipped).\n\nOther loose ends:\n\n * Toner got on the board because of OpenPhil's donation. But how did McCauley get on the board?\n * Is D'Angelo a safetyist?\n * Why wouldn't they tell anyone, including Emmett Shear, the full story?","wordCount":167},"Comment:KoSESirrNNEkoahCo":{"_id":"KoSESirrNNEkoahCo","__typename":"Comment","post":{"__ref":"Post:KXHMCH7wCxrvKsJyn"},"tag":null,"postId":"KXHMCH7wCxrvKsJyn","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":"3cj6qhSRt4HoBLpC7","topLevelCommentId":"toNjz7gy4rrCFd99A","descendentCount":7,"title":null,"contents":{"__ref":"Revision:KoSESirrNNEkoahCo_contents"},"postedAt":"2023-11-28T06:03:55.522Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":20,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":10,"agreementVoteCount":0},"score":0.0007142554968595505,"voteCount":10,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":8,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":7,"agreementVoteCount":0},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.1.1","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-11-28T18:42:16.411Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":4,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:AskPyNg6hHP6SrmEy":{"_id":"AskPyNg6hHP6SrmEy","__typename":"Post","isRead":null,"slug":"redirecting-one-s-own-taxes-as-an-effective-altruism-method","title":"Redirecting one’s own taxes as an effective altruism method","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"eJdEKa8cRgmPuLNvT","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:JEh3qAkmhtKkCEMgG_contents":{"_id":"JEh3qAkmhtKkCEMgG_contents","__typename":"Revision","html":"<p>Thanks for this, consider me another strong disagreement + strong upvote.<\/p><p>I know a nonprofit which had a tax issue - they were financially able and willing to pay, but for complicated reasons paying would have caused them legal damage in other ways and they keep kicking the can down the road until some hypothetical future when these are solved. I can't remember if the nonprofit is now formally dissolved or just effectively defunct, but the IRS keeps sending nasty letters to the former board members and officers.<\/p><p>Do you know anything about a situation like this? Does the IRS ever pursue board members / founders / officers for a charity's nonpayment? Assuming the nonprofit has no money and never will have money again, are there any repercussions for the people involved if they don't figure out a legal solution and just put off paying the taxes until the ten year deadline?<\/p><p>(it would be convenient if yes, but this would feel surprising - otherwise you could just start a corporation, not pay your taxes the first year, dissolve it, start an identical corporation the second year, and so on.)<\/p><p>Also, does the IRS acknowledge the ten-year deadline enough that they will stop threatening you after ten years, or would the board members have to take them to court to make the letters stop?<\/p>","plaintextMainText":"Thanks for this, consider me another strong disagreement + strong upvote.\n\nI know a nonprofit which had a tax issue - they were financially able and willing to pay, but for complicated reasons paying would have caused them legal damage in other ways and they keep kicking the can down the road until some hypothetical future when these are solved. I can't remember if the nonprofit is now formally dissolved or just effectively defunct, but the IRS keeps sending nasty letters to the former board members and officers.\n\nDo you know anything about a situation like this? Does the IRS ever pursue board members / founders / officers for a charity's nonpayment? Assuming the nonprofit has no money and never will have money again, are there any repercussions for the people involved if they don't figure out a legal solution and just put off paying the taxes until the ten year deadline?\n\n(it would be convenient if yes, but this would feel surprising - otherwise you could just start a corporation, not pay your taxes the first year, dissolve it, start an identical corporation the second year, and so on.)\n\nAlso, does the IRS acknowledge the ten-year deadline enough that they will stop threatening you after ten years, or would the board members have to take them to court to make the letters stop?","wordCount":224},"Comment:JEh3qAkmhtKkCEMgG":{"_id":"JEh3qAkmhtKkCEMgG","__typename":"Comment","post":{"__ref":"Post:AskPyNg6hHP6SrmEy"},"tag":null,"postId":"AskPyNg6hHP6SrmEy","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":2,"title":null,"contents":{"__ref":"Revision:JEh3qAkmhtKkCEMgG_contents"},"postedAt":"2023-11-14T07:05:06.373Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":11,"extendedScore":{"reacts":{},"agreement":5,"approvalVoteCount":8,"agreementVoteCount":3},"score":0.0003603025688789785,"voteCount":8,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":5,"afExtendedScore":{"reacts":{},"agreement":4,"approvalVoteCount":4,"agreementVoteCount":2},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.20.0","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-12-03T23:20:43.311Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":2,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:yT22RcWrxZcXyGjsA":{"_id":"yT22RcWrxZcXyGjsA","__typename":"Post","isRead":null,"slug":"how-to-have-polygenically-screened-children","title":"How to have Polygenically Screened Children","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"gsdEYz9qKx2zcMPcW","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:EvcpLfyYZEqDmfuQk_contents":{"_id":"EvcpLfyYZEqDmfuQk_contents","__typename":"Revision","html":"<p>Thanks!<\/p>","plaintextMainText":"Thanks!","wordCount":1},"Comment:EvcpLfyYZEqDmfuQk":{"_id":"EvcpLfyYZEqDmfuQk","__typename":"Comment","post":{"__ref":"Post:yT22RcWrxZcXyGjsA"},"tag":null,"postId":"yT22RcWrxZcXyGjsA","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":"tXx8qp87K6GyAqJ7R","topLevelCommentId":"TEp3k6kyanFakcNLj","descendentCount":0,"title":null,"contents":{"__ref":"Revision:EvcpLfyYZEqDmfuQk_contents"},"postedAt":"2023-05-11T06:21:18.777Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":5,"extendedScore":{"agreement":1,"approvalVoteCount":3,"agreementVoteCount":1},"score":0.00010833610576810315,"voteCount":3,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":{"agreement":1,"approvalVoteCount":3,"agreementVoteCount":1},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.9.1","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-05-11T06:21:18.786Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":0,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Revision:TEp3k6kyanFakcNLj_contents":{"_id":"TEp3k6kyanFakcNLj_contents","__typename":"Revision","html":"<p>Thank you, this is a great post. A few questions:<\/p><ul><li>You say \"see below for how to get access to these predictors\". Am I understanding right that the advice you're referring to is to contact Jonathan and see if he knows?<\/li><li>I heard a rumor that you can get IQ out of standard predictors like LifeView by looking at \"risk of cognitive disability\"; since cognitive disability is just IQ under a certain bar, this is covertly predicting IQ. Do you know anything about whether this is true?<\/li><li>I can't find any of these services listing cost clearly, but this older article <a href=\"https://www.genomeweb.com/sequencing/genomic-prediction-raises-45m#.ZFqXprDMJaR\">https://www.genomeweb.com/sequencing/genomic-prediction-raises-45m#.ZFqXprDMJaR<\/a> suggests a cost of $1,000 + 400*embryo for screening. Where did you get the $20,000 estimate?<\/li><\/ul>","plaintextMainText":"Thank you, this is a great post. A few questions:\n\n * You say \"see below for how to get access to these predictors\". Am I understanding right that the advice you're referring to is to contact Jonathan and see if he knows?\n * I heard a rumor that you can get IQ out of standard predictors like LifeView by looking at \"risk of cognitive disability\"; since cognitive disability is just IQ under a certain bar, this is covertly predicting IQ. Do you know anything about whether this is true?\n * I can't find any of these services listing cost clearly, but this older article https://www.genomeweb.com/sequencing/genomic-prediction-raises-45m#.ZFqXprDMJaR suggests a cost of $1,000 + 400*embryo for screening. Where did you get the $20,000 estimate?","wordCount":121},"Comment:TEp3k6kyanFakcNLj":{"_id":"TEp3k6kyanFakcNLj","__typename":"Comment","post":{"__ref":"Post:yT22RcWrxZcXyGjsA"},"tag":null,"postId":"yT22RcWrxZcXyGjsA","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":2,"title":null,"contents":{"__ref":"Revision:TEp3k6kyanFakcNLj_contents"},"postedAt":"2023-05-09T19:02:38.555Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":16,"extendedScore":{"reacts":{},"agreement":4,"approvalVoteCount":15,"agreementVoteCount":5},"score":0.00031762145226821303,"voteCount":18,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":6,"afExtendedScore":{"reacts":{},"agreement":3,"approvalVoteCount":8,"agreementVoteCount":4},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.9.1","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-05-11T06:21:20.892Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":1,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Post:eJq7xWcASjMkvikkD":{"_id":"eJq7xWcASjMkvikkD","__typename":"Post","isRead":null,"slug":"on-investigating-conspiracy-theories","title":"On Investigating Conspiracy Theories","draft":null,"shortform":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"userId":"N9zj5qpTfqmbn9dro","coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"debate":false,"collabEditorDialogue":false},"Revision:aJ4FdzNhHNFjv5Lvj_contents":{"_id":"aJ4FdzNhHNFjv5Lvj_contents","__typename":"Revision","html":"<p>A key point underpinning my thoughts, which I don't think this really responds to, is that scientific consensus actually is really good, so good I have trouble finding anecdotes of things in the reference class of ivermectin turning out to be true (reference class: things that almost all the relevant experts think are false and denounce full-throatedly as a conspiracy theory after spending a lot of time looking at the evidence).<\/p><p>There are some, maybe many, examples of weaker problems. For example, there are frequent examples of things that journalists/the government/professional associations want to *pretend* is scientific consensus, getting proven wrong - I claim if you really look carefully, the scientists weren't really saying those things, at least not as intensely as they were saying ivermectin didn't work. There are frequent examples of scientists being sloppy and firing off an opinion on something they weren't really thinking hard about and being wrong. There are frequent examples of scientists having dumb political opinions and trying to dress them up as science. I can't give a perfect necessary-and-sufficient definition of the relevant reference class. But I think it's there and recognizable.<\/p><p>I stick to my advice that people who know they're not sophisticated should avoid trying to second-guess the mainstream, and people who think they might be sophisticated should sometimes second-guess the mainstream when there isn't the exact type of scientific consensus which has a really good track record (and hopefully they're sophisticated enough to know when that is).<\/p><p>I'm not sure how you're using \"free riding\" here. I agree that someone needs to do the work of forming/testing/challenging opinions, but I think if there's basically no chance you're right (eg you're a 15 year old with no scientific background who thinks they've discovered a flaw in E=mc^2), that person is not you, and your input is not necessary to move science forward. I agree that person shouldn't cravenly quash their own doubt and pretend to believe, they should continue believing whatever rationality compels them to believe, which should probably be something like \"This thing about relativity doesn't seem quite right, but given that I'm 15 and know nothing, on the Outside View I'm probably wrong.\" Then they can either try to learn more (including asking people what they think of their objection) and eventually reach a point where maybe they do think they're right, or they can ignore it and go on with their lives.<\/p>","plaintextMainText":"A key point underpinning my thoughts, which I don't think this really responds to, is that scientific consensus actually is really good, so good I have trouble finding anecdotes of things in the reference class of ivermectin turning out to be true (reference class: things that almost all the relevant experts think are false and denounce full-throatedly as a conspiracy theory after spending a lot of time looking at the evidence).\n\nThere are some, maybe many, examples of weaker problems. For example, there are frequent examples of things that journalists/the government/professional associations want to *pretend* is scientific consensus, getting proven wrong - I claim if you really look carefully, the scientists weren't really saying those things, at least not as intensely as they were saying ivermectin didn't work. There are frequent examples of scientists being sloppy and firing off an opinion on something they weren't really thinking hard about and being wrong. There are frequent examples of scientists having dumb political opinions and trying to dress them up as science. I can't give a perfect necessary-and-sufficient definition of the relevant reference class. But I think it's there and recognizable.\n\nI stick to my advice that people who know they're not sophisticated should avoid trying to second-guess the mainstream, and people who think they might be sophisticated should sometimes second-guess the mainstream when there isn't the exact type of scientific consensus which has a really good track record (and hopefully they're sophisticated enough to know when that is).\n\nI'm not sure how you're using \"free riding\" here. I agree that someone needs to do the work of forming/testing/challenging opinions, but I think if there's basically no chance you're right (eg you're a 15 year old with no scientific background who thinks they've discovered a flaw in E=mc^2), that person is not you, and your input is not necessary to move science forward. I agree that person shouldn'","wordCount":404},"Comment:aJ4FdzNhHNFjv5Lvj":{"_id":"aJ4FdzNhHNFjv5Lvj","__typename":"Comment","post":{"__ref":"Post:eJq7xWcASjMkvikkD"},"tag":null,"postId":"eJq7xWcASjMkvikkD","tagId":null,"relevantTagIds":[],"relevantTags":[],"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":13,"title":null,"contents":{"__ref":"Revision:aJ4FdzNhHNFjv5Lvj_contents"},"postedAt":"2023-02-21T02:32:59.921Z","repliesBlockedUntil":null,"userId":"XgYW5s8njaYrtyP7q","deleted":false,"deletedPublic":false,"deletedByUserId":null,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":41,"extendedScore":{"reacts":{},"agreement":20,"approvalVoteCount":18,"agreementVoteCount":12},"score":0.0006971580442041159,"voteCount":20,"emojiReactors":{},"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":8,"afExtendedScore":{"reacts":{},"agreement":11,"approvalVoteCount":8,"agreementVoteCount":5},"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.1.1","reviewedByUserId":null,"shortform":false,"shortformFrontpage":true,"lastSubthreadActivity":"2023-10-03T14:27:47.966Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":1,"votingSystem":"namesAttachedReactions","isPinnedOnProfile":false,"debateResponse":null,"rejected":false,"rejectedReason":null,"modGPTRecommendation":null,"originalDialogueId":null},"Revision:RP4RvpcxZb6CmYgBg":{"_id":"RP4RvpcxZb6CmYgBg","__typename":"Revision","htmlHighlight":"<p>Thanks to everyone who responded to my request for ACX meetup organizers. Volunteers have arranged meetups in 169 cities around the world, from Baghdad to Bangalore to Buenos Aires.<\/p><p>You can find the list below, in the following order:<\/p><p>Africa &amp; Middle East<\/p><p>Asia-Pacific<\/p><p>Europe<\/p><p>North America<\/p><p>South America<\/p><p>You can see a map of all the events on <a href=\"https://www.lesswrong.com/community\">the LessWrong community page<\/a>. You can also see a searchable sheet at this <a href=\"https://airtable.com/appEBNqFVvAGqyOeJ/shrU2yUQYPpjL1ZbF/tblZXwcGfvBges9Eq\">Airtable link<\/a>.<\/p><p>Within each region, it’s alphabetized first by country, then by city. For instance, the first entry in Europe is Vienna, <strong>A<\/strong>ustria, and the first entry for Germany is <strong>B<\/strong>erlin. Each region and country has its own header. The USA is the exception where it is additionally sorted by state, with states having their own subheaders. Hopefully this is clear. You can also just have your web browser search for your city by pressing ctrl+f and typing it if you’re on Windows, or command+f and typing if you’re on Mac. If you’re on Linux, I assume you can figure this out.<\/p><p>Scott will provisionally be attending the meetup in Berkeley. ACX meetups coordinator Skyler will provisionally be attending Boston, Cavendish, Burlington, Berlin, Bremen, Amsterdam, Cardiff, London, and Berkeley. Some of the biggest ones might be announced on the blog, regardless of whether or not Scott or Skyler attends.<\/p><p><strong>Extra Info For Potential Attendees<\/strong><\/p><p><strong>1. <\/strong>If you’re reading this, you’re invited. Please don’t feel like you “won’t be welcome” just because you’re new to the blog, demographically different from the average reader, don’t want to buy anything at the cafe or restaurant where it’s held, or hate ACX and everything it stands for. You’ll be fine!&nbsp;<br><strong>2<\/strong>. You don’t have to RSVP or contact the organizer to be able to attend (unless the event description says otherwise); RSVPs are mostly to give organizers a better sense of how many people might show up, and let them tell you if there are last-second changes. I’ve also given email addresses for all organizers in case you have a question.<\/p><p><strong>Extra Info For Meetup Organizers:<\/strong><br><br><strong>1.<\/strong> If you’re the host, bring a sign that says “ACX MEETUP” and prop it up somewhere (or otherwise be identifiable).<br><strong>2. <\/strong>Bring blank labels and pens for nametags.<br><strong>3. <\/strong>Have people type their name and email address in a spreadsheet or in a Google Form (accessed via a bit.ly link or QR code), so you can start a mailing list to make organizing future meetups easier.<br><strong>4.<\/strong> If it’s t... <\/p>","plaintextDescription":"Thanks to everyone who responded to my request for ACX meetup organizers. Volunteers have arranged meetups in 169 cities around the world, from Baghdad to Bangalore to Buenos Aires.\n\nYou can find the list below, in the following order:\n\nAfrica & Middle East\n\nAsia-Pacific\n\nEurope\n\nNorth America\n\nSouth America\n\nYou can see a map of all the events on the LessWrong community page. You can also see a searchable sheet at this Airtable link.\n\nWithin each region, it’s alphabetized first by country, then by city. For instance, the first entry in Europe is Vienna, Austria, and the first entry for Germany is Berlin. Each region and country has its own header. The USA is the exception where it is additionally sorted by state, with states having their own subheaders. Hopefully this is clear. You can also just have your web browser search for your city by pressing ctrl+f and typing it if you’re on Windows, or command+f and typing if you’re on Mac. If you’re on Linux, I assume you can figure this out.\n\nScott will provisionally be attending the meetup in Berkeley. ACX meetups coordinator Skyler will provisionally be attending Boston, Cavendish, Burlington, Berlin, Bremen, Amsterdam, Cardiff, London, and Berkeley. Some of the biggest ones might be announced on the blog, regardless of whether or not Scott or Skyler attends.\n\nExtra Info For Potential Attendees\n\n1. If you’re reading this, you’re invited. Please don’t feel like you “won’t be welcome” just because you’re new to the blog, demographically different from the average reader, don’t want to buy anything at the cafe or restaurant where it’s held, or hate ACX and everything it stands for. You’ll be fine! \n2. You don’t have to RSVP or contact the organizer to be able to attend (unless the event description says otherwise); RSVPs are mostly to give organizers a better sense of how many people might show up, and let them tell you if there are last-second changes. I’ve also given email addresses for all organizers in case you have a","wordCount":10093,"version":"1.0.0"},"Revision:ynpC7oXhXxGPNuCgH_customHighlight":{"_id":"ynpC7oXhXxGPNuCgH_customHighlight","__typename":"Revision","html":"","plaintextDescription":""},"Revision:T57Qd9J3AfxmwhQtY_description":{"_id":"T57Qd9J3AfxmwhQtY_description","__typename":"Revision","htmlHighlight":"<p>The rationalist community has chapters all over the world, the oldest being the NYC community, which has been around since 2009. Many of these groups are centered around regular meetups, or call themselves 'meetups'.<\/p><p>These are posts about meetups and local communities in general, not about specific communities (unless they also provide general insight).<br><br>For example - <a href=\"https://www.lesswrong.com/posts/bDnFhJBcLQvCY3vJW/what-are-meetups-actually-trying-to-accomplish\">What are meetups actually trying to accomplish?<\/a><\/p><p>For specific meetups see <a href=\"https://www.lesswrong.com/tag/events-community\">Events(community)<\/a><\/p><p>See also - <a href=\"https://www.lesswrong.com/tag/community\">Community<\/a><\/p>"},"Tag:T57Qd9J3AfxmwhQtY":{"_id":"T57Qd9J3AfxmwhQtY","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:T57Qd9J3AfxmwhQtY_description"},"canVoteOnRels":null,"userId":"sKAL2jzfkYkDbQmx9","name":"Meetups & Local Communities (topic)","shortName":null,"slug":"meetups-and-local-communities-topic","core":false,"postCount":101,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-31T06:45:58.891Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:izp6eeJJEg9v5zcur_description":{"_id":"izp6eeJJEg9v5zcur_description","__typename":"Revision","htmlHighlight":"<p>The <strong>LessWrong<\/strong> <strong>Community<\/strong> consists of the people who write on LessWrong and who contribute to its mission of refining the art of human rationality. This tag includes community events, analysis of the health, norms and direction of the community, and space to understand communities in general.<\/p><p>LessWrong also has many brothers and sisters like the Berkeley Rationality Community, <a href=\"https://www.reddit.com/r/slatestarcodex/\">SlateStarCodex<\/a>, <a href=\"https://www.reddit.com/r/rational/\">Rational Fiction<\/a>, <a href=\"https://forum.effectivealtruism.org/\">Effective Altruism<\/a>, <a href=\"https://www.alignmentforum.org/\">AI Alignment<\/a>, and more, who participate here. To see upcoming LessWrong events, go to the <a href=\"https://www.lesswrong.com/community\">community section<\/a>.<\/p><hr><h2><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Community Sub-Topics<\/strong><\/h2><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:50%\"><p><strong>All<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/bounties-active?showPostCount=true&amp;useTagName=true\">Bounties (active)<\/a><br><a href=\"https://www.lesswrong.com/tag/grants-and-fundraising-opportunities?showPostCount=true\">Grants &amp; Fundraising<\/a><br><a href=\"http://www.lesswrong.com/tag/growth-stories?showPostCount=true&amp;useTagName=true\">Growth Stories<\/a><br><a href=\"https://www.lesswrong.com/tag/online-socialization?showPostCount=true&amp;useTagName=true\">Online Socialization<\/a><br><a href=\"https://www.lesswrong.com/tag/petrov-day?showPostCount=true&amp;useTagName=true\">Petrov Day<\/a><br><a href=\"https://www.lesswrong.com/tag/public-discourse?showPostCount=true&amp;useTagName=true\">Public Discourse<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/ritual?showPostCount=true&amp;useTagName=true\">Ritual<\/a><br><a href=\"https://www.lesswrong.com/tag/solstice-celebration?showPostCount=true&amp;useTagName=true\">Solstice Celebration<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:50%\"><p><strong>LessWrong<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/events-community?showPostCount=true&amp;useTagName=true\">Events (Community)<\/a><br><a href=\"https://www.lesswrong.com/tag/site-meta?showPostCount=true&amp;useTagName=true\">Site Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/greaterwrong-meta?showPostCount=true&amp;useTagName=true\">GreaterWrong Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/lesswrong-events?showPostCount=true&amp;useTagName=true\">LessWrong Events<\/a><br><a href=\"http://www.lesswrong.com/tag/lw-moderation?showPostCount=true&amp;useTagName=true\">LW Moderation<\/a><br><a href=\"http://www.lesswrong.com/tag/meetups-topic?showPostCount=true&amp;useTagName=true\">Meetups (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/moderation-topic?showPostCount=true&amp;useTagName=true\">Moderation (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/the-sf-bay-area?showPostCount=true&amp;useTagName=true\">The SF Bay Area<\/a><br><a href=\"http://www.lesswrong.com/tag/tagging?showPostCount=true\">Tagging<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure><p><i>Not all Community posts are tagged with subtopics.<\/i><\/p><hr><p>This tag applies to any post about:<\/p><ul><li>Specific projects, orgs, and prizes [e.g. <a href=\"http://www.lesswrong.com/posts/xFGQdgJndLcthgWoE\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/cSzaxcmeYW6z7cgtc\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/nDHbgjdddG5EN6ocg\"><u>5<\/u><\/a>]<\/li><li>Requests and offers for help [<a href=\"http://www.lesswrong.com/posts/bSWavBThj6ebB62gD\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/LuL7LLqcdmM7TTYvW\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/x72ta8C3dKu2QRfPv\"><u>3<\/u><\/a>]<\/li><li>Announcements, retrospectives, funding requests, and AMAs from orgs [<a href=\"http://www.lesswrong.com/posts/XJiNtvxoiLCpBn6FH\"><u>1<\/u><\/a> <a href=\"https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama\"><u>2<\/u><\/a> <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/tCHsm5ZyAca8HfJSG\"><u>5<\/u><\/a>]<\/li><li>Discussions of the orgs in the LessWrong, Rationalist cluster [<a href=\"http://www.lesswrong.com/posts/KpnyCT7CZy4Qe6kx6\"><u>1<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/6SGqkCgHuNr7d4yJm/thoughts-on-the-singularity-institute-si\"><u>2<\/u><\/a>]<\/li><li>Discussions about the LessWrong, Rationalist, and related communities [<a href=\"http://www.lesswrong.com/posts/2Ee5DPBxowTTXZ6zf\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/yGycR8tFA3JJbvApp\"><u>2<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/zAqoj79A7QuhJKKvi\"><u>3<\/u><\/a>]<\/li><\/ul><p>While the <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a><i> <\/i>core tag is for posts discussing how to do good in general, the Community tag is for the specific, concrete efforts of our community to execute plans.<\/p>"},"Tag:izp6eeJJEg9v5zcur":{"_id":"izp6eeJJEg9v5zcur","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:izp6eeJJEg9v5zcur_description"},"canVoteOnRels":null,"userId":"XtphY3uYHwruKqDyG","name":"Community","shortName":null,"slug":"community","core":true,"postCount":2260,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":15,"createdAt":"2020-06-14T03:38:34.631Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:ynpC7oXhXxGPNuCgH":{"_id":"ynpC7oXhXxGPNuCgH","__typename":"SocialPreviewType","imageUrl":""},"User:88BHmY89XnzyJnCGH":{"_id":"88BHmY89XnzyJnCGH","__typename":"User","slug":"screwtape","createdAt":"2014-06-01T07:51:37.130Z","username":"Screwtape","displayName":"Screwtape","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":3475,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"<p>I'm Screwtape, also known as Skyler. I'm an aspiring rationalist originally introduced to the community through HPMoR, and I stayed around because the writers here kept improving how I thought. I'm fond of the Rationality As A Martial Art metaphor, new mental tools to make my life better, and meeting people who are strange in ways I find familiar and comfortable. If you're ever in the Boston area, feel free to say hi.<\/p><p>Starting early in 2023, I'm the ACX Meetups Czar. You might also know me from the New York City Rationalist Megameetup, editing the Animorphs: The Reckoning podfic, or being that guy at meetups with a bright bandanna who gets really excited when people bring up indie tabletop roleplaying games.&nbsp;<\/p><p>I recognize that last description might fit more than one person.<\/p>","jobTitle":null,"organization":null,"postCount":99,"commentCount":341,"sequenceCount":3,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Post:ynpC7oXhXxGPNuCgH":{"_id":"ynpC7oXhXxGPNuCgH","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:RP4RvpcxZb6CmYgBg"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":40,"rejectedReason":null,"customHighlight":{"__ref":"Revision:ynpC7oXhXxGPNuCgH_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:T57Qd9J3AfxmwhQtY"},{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"socialPreviewData":{"__ref":"SocialPreviewType:ynpC7oXhXxGPNuCgH"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":"https://astralcodexten.substack.com/p/meetups-everywhere-2023-times-and","postedAt":"2023-08-25T23:59:07.941Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"T57Qd9J3AfxmwhQtY":2,"izp6eeJJEg9v5zcur":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"RP4RvpcxZb6CmYgBg","commentCount":5,"voteCount":16,"baseScore":33,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0008418814395554364,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-08-28T22:32:56.039Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2023-08-25T23:58:44.192Z","afSticky":false,"hideAuthor":false,"moderationStyle":"norm-enforcing","ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[{"__ref":"User:88BHmY89XnzyJnCGH"}],"slug":"acx-meetups-everywhere-2023-times-and-places","title":"ACX Meetups Everywhere 2023: Times & Places","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":[{"userId":"88BHmY89XnzyJnCGH","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:n2ZpMJKzva2oW6gF4":{"_id":"n2ZpMJKzva2oW6gF4","__typename":"Revision","htmlHighlight":"<p><i>This post originally posted on Astral Codex Ten on Feb 23 2022.&nbsp;<\/i><\/p><p><i>It was printed in <\/i><a href=\"https://www.amazon.com/Carving-Reality-Essays-LessWrong-Community/dp/B0C95MJJBK\"><i>The Carving of Reality<\/i><\/a><i>, the third volume of the Best of LessWrong book series. It was included as a (shorter) replacement for Ajeya Cotra's <\/i><a href=\"https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines\"><i>Draft report on AI timelines<\/i><\/a><i>, and Eliezer's <\/i><a href=\"https://www.lesswrong.com/posts/ax695frGJEzGxFBK4/biology-inspired-agi-timelines-the-trick-that-never-works\"><i>Biology-Inspired AGI Timelines: The Trick That Never Works<\/i><\/a><i>, covering the topic from multiple sides.<\/i><\/p><p><i>It's crossposted here with Scott's permission for completeness (i.e. having all essays in the book appear on LessWrong).<\/i><\/p><h1>Introduction<\/h1><p>I've been trying to review and summarize Eliezer Yudkowksy's recent dialogues on AI safety. Previously in sequence:<a href=\"https://astralcodexten.substack.com/p/practically-a-book-review-yudkowsky\"> Yudkowsky Contra Ngo On Agents<\/a>. Now we’re up to Yudkowsky contra Cotra on biological anchors, but before we get there we need to figure out what Cotra's talking about and what's going on.<\/p><p>The<a href=\"https://www.openphilanthropy.org/\"> Open Philanthropy Project<\/a> (\"Open Phil\") is a big effective altruist foundation interested in funding AI safety. It's got $20 billion, probably the majority of money in the field, so its decisions matter a lot and it’s very invested in getting things right. In 2020, it asked senior researcher Ajeya Cotra to produce<a href=\"https://drive.google.com/drive/u/1/folders/15ArhEPZSTYU8f012bs6ehPS6-xmhtBPP\"> <strong>a report on when human-level AI would arrive.<\/strong><\/a><strong> <\/strong>It says the resulting document is \"informal\" - but it’s 169 pages long and likely to affect millions of dollars in funding, which some might describe as making it <i>kind<\/i> of formal. The report finds a 10% chance of “transformative AI” by 2031, a 50% chance by 2052, and an almost 80% chance by 2100.<\/p><p>Eliezer rejects their methodology and expects AI earlier (he doesn’t offer many numbers, but<a href=\"https://www.econlib.org/archives/2017/01/my_end-of-the-w.html\"> here<\/a> he gives Bryan Caplan 50-50 odds on 2030, albeit<a href=\"https://www.econlib.org/archives/2017/01/my_end-of-the-w.html#comment-166919\"> not totally seriously<\/a>). He made the case in his own very long essay,<a href=\"https://www.lesswrong.com/posts/ax695frGJEzGxFBK4/biology-inspired-agi-timelines-the-trick-that-never-works\"> <strong>Biology-Inspired AGI Timelines: The Trick That Never Works<\/strong><\/a>, sparking a bunch of arguments and counterarguments and even more long essays.<\/p><p>There's a small cottage industry of summarizing the report already, eg OpenPhil CEO Holden Karnofsky's<a href=\"https://www.cold-takes.com/forecasting-transformative-ai-the-biological-anchors-method-in-a-nutshell/\"> article<\/a> and Alignment Newsletter editor Rohin Shah's<a href=\"https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines?commentId=7d4q79ntst6ryaxWD\"> comment<\/a>. I've drawn from both for my much-inferior attempt.<\/p><h1>Part I: The Cotra Report<\/h1><p>Ajeya Cotra is a senior research analyst at OpenPhil. She's assisted by her fiancee Paul Christiano (compsci PhD, OpenAI veteran, runs an AI alignment nonprofit) and to a lesser degree by other leading lights. Although not everyone involved has formal ML training, if you care a lot about whether efforts are “establishment” or “contrarian”,... <\/p>","plaintextDescription":"This post originally posted on Astral Codex Ten on Feb 23 2022. \n\nIt was printed in The Carving of Reality, the third volume of the Best of LessWrong book series. It was included as a (shorter) replacement for Ajeya Cotra's Draft report on AI timelines, and Eliezer's Biology-Inspired AGI Timelines: The Trick That Never Works, covering the topic from multiple sides.\n\nIt's crossposted here with Scott's permission for completeness (i.e. having all essays in the book appear on LessWrong).\n\n\nIntroduction\nI've been trying to review and summarize Eliezer Yudkowksy's recent dialogues on AI safety. Previously in sequence: Yudkowsky Contra Ngo On Agents. Now we’re up to Yudkowsky contra Cotra on biological anchors, but before we get there we need to figure out what Cotra's talking about and what's going on.\n\nThe Open Philanthropy Project (\"Open Phil\") is a big effective altruist foundation interested in funding AI safety. It's got $20 billion, probably the majority of money in the field, so its decisions matter a lot and it’s very invested in getting things right. In 2020, it asked senior researcher Ajeya Cotra to produce a report on when human-level AI would arrive. It says the resulting document is \"informal\" - but it’s 169 pages long and likely to affect millions of dollars in funding, which some might describe as making it kind of formal. The report finds a 10% chance of “transformative AI” by 2031, a 50% chance by 2052, and an almost 80% chance by 2100.\n\nEliezer rejects their methodology and expects AI earlier (he doesn’t offer many numbers, but here he gives Bryan Caplan 50-50 odds on 2030, albeit not totally seriously). He made the case in his own very long essay, Biology-Inspired AGI Timelines: The Trick That Never Works, sparking a bunch of arguments and counterarguments and even more long essays.\n\nThere's a small cottage industry of summarizing the report already, eg OpenPhil CEO Holden Karnofsky's article and Alignment Newsletter editor Rohin Shah's comment. I've d","wordCount":9834,"version":"1.0.0"},"Revision:NGkBfd8LTqcpbQn5Z_customHighlight":{"_id":"NGkBfd8LTqcpbQn5Z_customHighlight","__typename":"Revision","html":"","plaintextDescription":""},"Revision:zHjC29kkPmsdo7WTr_description":{"_id":"zHjC29kkPmsdo7WTr_description","__typename":"Revision","htmlHighlight":"<p><strong>AI Timelines<\/strong> is the discussion of how long until various major milestones in AI progress are achieved, whether it's the timeline until a human-level AI is developed, the timeline until certain benchmarks are defeated, the timeline until we can simulate a mouse-level intelligence, or something else.<\/p><p>This is to be distinguished from the closely related question of <a href=\"https://www.lesswrong.com/tag/ai-takeoff\">AI takeoff<\/a> speeds, which is about the dynamics of AI progress after human-level AI is developed (e.g. will it be a single project or the whole economy that sees growth, how fast will that growth be, etc).<\/p>"},"Tag:zHjC29kkPmsdo7WTr":{"_id":"zHjC29kkPmsdo7WTr","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:zHjC29kkPmsdo7WTr_description"},"canVoteOnRels":null,"userId":"EQNTWXLKMeWMp2FQS","name":"AI Timelines","shortName":null,"slug":"ai-timelines","core":false,"postCount":340,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-16T10:16:47.235Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:sYm3HiWcfZvrGu3ui_description":{"_id":"sYm3HiWcfZvrGu3ui_description","__typename":"Revision","htmlHighlight":"<p><strong>Artificial Intelligence<\/strong> is the study of creating intelligence in algorithms. <strong>AI Alignment <\/strong>is the task of ensuring [powerful] AI system are aligned with human values and interests. The central concern is that a powerful enough AI, if not designed and implemented with sufficient understanding, would optimize something unintended by its creators and pose an existential threat to the future of humanity. This is known as the <i>AI alignment<\/i> problem.<\/p><p>Common terms in this space are <i>superintelligence, AI Alignment, AI Safety, Friendly AI, Transformative AI, human-level-intelligence, AI Governance, and Beneficial AI. <\/i>This entry and the associated tag roughly encompass all of these topics: anything part of the broad cluster of understanding AI and its future impacts on our civilization deserves this tag.<\/p><p><strong>AI Alignment<\/strong><\/p><p>There are narrow conceptions of alignment, where you’re trying to get it to do something like cure Alzheimer’s disease without destroying the rest of the world. And there’s much more ambitious notions of alignment, where you’re trying to get it to do the right thing and achieve a happy intergalactic civilization.<\/p><p>But both the narrow and the ambitious alignment have in common that you’re trying to have the AI do that thing rather than making a lot of paperclips.<\/p><p>See also <a href=\"https://www.lesswrong.com/tag/general-intelligence\">General Intelligence<\/a>.<\/p><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\" rowspan=\"2\"><p><strong>Basic Alignment Theory<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aixi?showPostCount=true&amp;useTagName=true\">AIXI<\/a><br><a href=\"http://www.lesswrong.com/tag/coherent-extrapolated-volition?showPostCount=true&amp;useTagName=true\">Coherent Extrapolated Volition<\/a><br><a href=\"https://www.lesswrong.com/tag/complexity-of-value?showPostCount=true&amp;useTagName=true\">Complexity of Value<\/a><br><a href=\"https://www.lesswrong.com/tag/corrigibility?showPostCount=true&amp;useTagName=true\">Corrigibility<\/a><br><a href=\"https://www.lesswrong.com/tag/deceptive-alignment?showPostCount=true&amp;useTagName=true\">Deceptive Alignment<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/embedded-agency?showPostCount=true&amp;useTagName=true\">Embedded Agency<\/a><br><a href=\"https://www.lesswrong.com/tag/fixed-point-theorems?showPostCount=true&amp;useTagName=true\">Fixed Point Theorems<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodhart's Law<\/a><br><a href=\"https://www.lesswrong.com/tag/goal-directedness?showPostCount=true&amp;useTagName=true\">Goal-Directedness<\/a><br><a href=\"https://www.lesswrong.com/tag/gradient-hacking?showPostCount=true&amp;useTagName=true\">Gradient Hacking<\/a><br><a href=\"http://www.lesswrong.com/tag/infra-bayesianism?showPostCount=true&amp;useTagName=true\">Infra-Bayesianism<\/a><br><a href=\"https://www.lesswrong.com/tag/inner-alignment?showPostCount=true&amp;useTagName=true\">Inner Alignment<\/a><br><a href=\"https://www.lesswrong.com/tag/instrumental-convergence?showPostCount=true&amp;useTagName=true\">Instrumental Convergence<\/a><br><a href=\"https://www.lesswrong.com/tag/intelligence-explosion?showPostCount=true&amp;useTagName=true\">Intelligence Explosion<\/a><br><a href=\"https://www.lesswrong.com/tag/logical-induction?showPostCount=true&amp;useTagName=true\">Logical Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/logical-uncertainty?showPostCount=true&amp;useTagName=true\">Logical Uncertainty<\/a><br><a href=\"https://www.lesswrong.com/tag/mesa-optimization?showPostCount=true&amp;useTagName=true\">Mesa-Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/multipolar-scenarios?showPostCount=true&amp;useTagName=true\">Multipolar Scenarios<\/a><br><a href=\"https://www.lesswrong.com/tag/myopia?showPostCount=true&amp;useTagName=true\">Myopia<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"https://www.lesswrong.com/tag/optimization?showPostCount=true&amp;useTagName=true\">Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/orthogonality-thesis?showPostCount=true&amp;useTagName=true\">Orthogonality Thesis<\/a><br><a href=\"https://www.lesswrong.com/tag/outer-alignment?showPostCount=true&amp;useTagName=true\">Outer Alignment<\/a><br><a href=\"http://www.lesswrong.com/tag/paperclip-maximizer?showPostCount=true&amp;useTagName=true\">Paperclip Maximizer<\/a><br><a href=\"https://www.lesswrong.com/tag/power-seeking-ai?showPostCount=true&amp;useTagName=true\">Power Seeking (AI)<\/a><br><a href=\"https://www.lesswrong.com/tag/recursive-self-improvement?showPostCount=true&amp;useTagName=true\">Recursive Self-Improvement<\/a><br><a href=\"https://www.lesswrong.com/tag/simulator-theory\">Simulator Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/sharp-left-turn?showPostCount=true&amp;useTagName=true\">Sharp Left Turn<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"https://www.lesswrong.com/tag/superintelligence?showPostCount=true&amp;useTagName=true\">Superintelligence<\/a><br><a href=\"https://www.lesswrong.com/tag/symbol-grounding\">Symbol Grounding<\/a><br><a href=\"https://www.lesswrong.com/tag/transformative-ai?showPostCount=true&amp;useTagName=true\">Transformative AI<\/a><br><a href=\"https://www.lesswrong.com/tag/treacherous-turn?showPostCount=true&amp;useTagName=true\">Treacherous Turn<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br><a href=\"https://www.lesswrong.com/tag/whole-brain-emulation?showPostCount=true&amp;useTagName=true\">Whole Brain Emulation<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Engineering Alignment<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/agent-foundations?showPostCount=true&amp;useTagName=true\">Agent Foundations<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-assisted-alignment?showPostCount=true&amp;useTagName=true\">AI-assisted Alignment&nbsp;<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-boxing-containment?showPostCount=true&amp;useTagName=true\">AI Boxing (Containment)<\/a><br><a href=\"https://www.lesswrong.com/tag/conservatism-ai?showPostCount=true&amp;useTagName=true\">Conservatism (AI)<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-safety-via-debate?showPostCount=true&amp;useTagName=true\">Debate (AI safety technique)<\/a><br><a href=\"https://www.lesswrong.com/tag/eliciting-latent-knowledge-elk\">Eliciting Latent Knowledge (ELK)<\/a><br><a href=\"https://www.lesswrong.com/tag/factored-cognition?showPostCount=true&amp;useTagName=true\">Factored Cognition<\/a><br><a href=\"https://www.lesswrong.com/tag/hch?showPostCount=true&amp;useTagName=true\">Humans Consulting HCH<\/a><br><a href=\"https://www.lesswrong.com/tag/impact-measures?showPostCount=true&amp;useTagName=true\">Impact Measures<\/a><br><a href=\"https://www.lesswrong.com/tag/inverse-reinforcement-learning?showPostCount=true&amp;useTagName=true\">Inverse Reinforcement Learning<\/a><br><a href=\"https://www.lesswrong.com/tag/iterated-amplification?showPostCount=true&amp;useTagName=true\">Iterated Amplification<\/a><br><a href=\"http://www.lesswrong.com/tag/mild-optimization?showPostCount=true&amp;useTagName=true\">Mild Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/oracle-ai?showPostCount=true&amp;useTagName=true\">Oracle AI<\/a><br><a href=\"https://www.lesswrong.com/tag/reward-functions?showPostCount=true&amp;useTagName=true\">Reward Functions<\/a><br><a href=\"https://www.lesswrong.com/tag/rlhf?showPostCount=true&amp;useTagName=true\">RLHF<\/a><br><a href=\"https://www.lesswrong.com/tag/shard-theory?showPostCount=true&amp;useTagName=true\">Shard Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/tool-ai?showPostCount=true&amp;useTagName=true\">Tool AI<\/a><br><a href=\"https://www.lesswrong.com/tag/transparency-interpretability-ml-and-ai?showPostCount=true\">Transparency / Interpretability<\/a><br><a href=\"https://www.lesswrong.com/tag/tripwire?showPostCount=true&amp;useTagName=true\">Tripwire<\/a><br><a href=\"https://www.lesswrong.com/tag/value-learning?showPostCount=true&amp;useTagName=true\">Value Learning<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Organizations<\/strong><\/p><p><a href=\"https://aisafety.world/map/\">Full map here<\/a><\/p><p><a href=\"https://www.lesswrong.com/tag/ai-safety-camp?showPostCount=true&amp;useTagName=true\">AI Safety Camp<\/a><br><a href=\"https://www.lesswrong.com/tag/alignment-research-center\">Alignment Resea<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>... "},"Tag:sYm3HiWcfZvrGu3ui":{"_id":"sYm3HiWcfZvrGu3ui","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:sYm3HiWcfZvrGu3ui_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"AI","shortName":null,"slug":"ai","core":true,"postCount":9865,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T22:24:22.097Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:NGkBfd8LTqcpbQn5Z":{"_id":"NGkBfd8LTqcpbQn5Z","__typename":"SocialPreviewType","imageUrl":"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F076623f5-43fb-4195-b55b-7db9d1583048_514x310.png"},"Post:NGkBfd8LTqcpbQn5Z":{"_id":"NGkBfd8LTqcpbQn5Z","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:n2ZpMJKzva2oW6gF4"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":39,"rejectedReason":null,"customHighlight":{"__ref":"Revision:NGkBfd8LTqcpbQn5Z_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:zHjC29kkPmsdo7WTr"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:NGkBfd8LTqcpbQn5Z"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":"https://astralcodexten.substack.com/p/biological-anchors-a-trick-that-might","postedAt":"2023-08-12T00:53:30.159Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-08-12T00:54:56.881Z","meta":false,"postCategory":"post","tagRelevance":{"sYm3HiWcfZvrGu3ui":2,"zHjC29kkPmsdo7WTr":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"n2ZpMJKzva2oW6gF4","commentCount":3,"voteCount":37,"baseScore":91,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":37,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.00248629879206419,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-08-13T00:25:56.106Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":33,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":22,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2023-08-12T00:52:01.274Z","afSticky":false,"hideAuthor":false,"moderationStyle":"norm-enforcing","ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"biological-anchors-the-trick-that-might-or-might-not-work","title":"Biological Anchors: The Trick that Might or Might Not Work","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:AQFyerkcqQd8Jexjx":{"_id":"AQFyerkcqQd8Jexjx","__typename":"Revision","htmlHighlight":"<p>Many cities have regular Astral Codex Ten meetup groups. Twice a year, I try to advertise their upcoming meetups and make a bigger deal of it than usual so that irregular attendees can attend. This is one of those times.<\/p><p>This year we have spring meetups planned in over eighty cities, from Tokyo to Punta Cana in the Dominican Republic. Thanks to all the organizers who responded to my request for details, and to Meetups Czar Skyler and the Less Wrong team for making this happen.<\/p><p>There's a map of these meetups on<a href=\"https://www.lesswrong.com/community\"> the LessWrong community page<\/a>.<\/p><p>Within each section, it’s alphabetized first by region, then by city - so the first entry in Europe is <strong>B<\/strong>asel, Switzerland. Sorry if this is confusing.<\/p><p>I’ll provisionally be attending the Berkeley meetup on May 6th. Skyler will provisionally be attending Manhattan, DC, Boston, Philadelphia, and Berkeley.<\/p><p><strong>Extra Info For Potential Attendees<\/strong><\/p><p><strong>1. <\/strong>If you’re reading this, you’re invited. Please don’t feel like you “won’t be welcome” just because you’re new to the blog, demographically different from the average reader, or hate ACX and everything it stands for. You’ll be fine!<br><strong>2<\/strong>. You don’t have to RSVP or contact the organizer to be able to attend (unless the event description says otherwise); RSVPs are mostly to give organizers a better sense of how many people might show up, and let them tell you if there are last-second changes. I’ve also given email addresses for all organizers in case you have a question.<\/p><p><strong>Extra Info For Meetup Organizers:<\/strong><br><br><strong>1.<\/strong> If you’re the host, bring a sign that says “ACX MEETUP” and prop it up somewhere (or otherwise be identifiable).<br><strong>2. <\/strong>Bring blank labels and pens for nametags.<br><strong>3. <\/strong>Have people type their name and email address in a spreadsheet or in a Google Form (accessed via a bit.ly link or QR code), so you can start a mailing list to make organizing future meetups easier.<br><strong>4.<\/strong> If it’s the first meetup, people are probably just going to want to talk, and if you try to organize some kind of “fun” “event” it’ll probably just be annoying.<br><strong>5.<\/strong> It’s easier to schedule a followup meetup while you’re having the first, compared to trying to do it later on by email.<br><strong>6.<\/strong> In case people want to get to know each other better outside the meetup, you might want to mention<a href=\"https://www.reciprocity.io/\"> reciprocity.io<\/a>, the rationalist friend-finder/dating site.<br><strong>7.<\/strong> If you didn’t make a LessWrong event for your meetup, the LessWrong team did it for you using the email add... <\/p>","plaintextDescription":"Many cities have regular Astral Codex Ten meetup groups. Twice a year, I try to advertise their upcoming meetups and make a bigger deal of it than usual so that irregular attendees can attend. This is one of those times.\n\nThis year we have spring meetups planned in over eighty cities, from Tokyo to Punta Cana in the Dominican Republic. Thanks to all the organizers who responded to my request for details, and to Meetups Czar Skyler and the Less Wrong team for making this happen.\n\nThere's a map of these meetups on the LessWrong community page.\n\nWithin each section, it’s alphabetized first by region, then by city - so the first entry in Europe is Basel, Switzerland. Sorry if this is confusing.\n\nI’ll provisionally be attending the Berkeley meetup on May 6th. Skyler will provisionally be attending Manhattan, DC, Boston, Philadelphia, and Berkeley.\n\nExtra Info For Potential Attendees\n\n1. If you’re reading this, you’re invited. Please don’t feel like you “won’t be welcome” just because you’re new to the blog, demographically different from the average reader, or hate ACX and everything it stands for. You’ll be fine!\n2. You don’t have to RSVP or contact the organizer to be able to attend (unless the event description says otherwise); RSVPs are mostly to give organizers a better sense of how many people might show up, and let them tell you if there are last-second changes. I’ve also given email addresses for all organizers in case you have a question.\n\nExtra Info For Meetup Organizers:\n\n1. If you’re the host, bring a sign that says “ACX MEETUP” and prop it up somewhere (or otherwise be identifiable).\n2. Bring blank labels and pens for nametags.\n3. Have people type their name and email address in a spreadsheet or in a Google Form (accessed via a bit.ly link or QR code), so you can start a mailing list to make organizing future meetups easier.\n4. If it’s the first meetup, people are probably just going to want to talk, and if you try to organize some kind of “fun” “event” it’l","wordCount":484,"version":"1.0.0"},"Revision:55aoSeDTDKbw9dgza_customHighlight":{"_id":"55aoSeDTDKbw9dgza_customHighlight","__typename":"Revision","html":"","plaintextDescription":""},"SocialPreviewType:55aoSeDTDKbw9dgza":{"_id":"55aoSeDTDKbw9dgza","__typename":"SocialPreviewType","imageUrl":""},"Post:55aoSeDTDKbw9dgza":{"_id":"55aoSeDTDKbw9dgza","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:AQFyerkcqQd8Jexjx"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":2,"rejectedReason":null,"customHighlight":{"__ref":"Revision:55aoSeDTDKbw9dgza_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"socialPreviewData":{"__ref":"SocialPreviewType:55aoSeDTDKbw9dgza"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":"https://astralcodexten.substack.com/p/spring-meetups-everywhere-2023","postedAt":"2023-04-11T00:59:20.265Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-04-11T01:17:31.492Z","meta":false,"postCategory":"linkpost","tagRelevance":{"izp6eeJJEg9v5zcur":1},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"AQFyerkcqQd8Jexjx","commentCount":0,"voteCount":16,"baseScore":35,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0008265054202638566,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-04-11T00:59:20.265Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":6,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2023-04-11T00:59:20.269Z","afSticky":false,"hideAuthor":false,"moderationStyle":"norm-enforcing","ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"spring-meetups-everywhere-2023","title":"Spring Meetups Everywhere 2023","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:fCbsyCLtdktHxFMLz":{"_id":"fCbsyCLtdktHxFMLz","__typename":"Revision","htmlHighlight":"<p>This is a lightly edited transcript of a chatroom conversation between Scott Alexander and Eliezer Yudkowsky last year, following up on the <a href=\"https://www.lesswrong.com/s/n945eovrA3oDueqtq\">Late 2021 MIRI Conversations<\/a>. Questions discussed include \"How hard is it to get the right goals into AGI systems?\" and \"In what contexts do AI systems exhibit 'consequentialism'?\".<\/p><p>&nbsp;<\/p><h2>1. Analogies to human moral development<\/h2><figure class=\"table\"><table><tbody><tr><td style=\"border:1pt solid #000000;vertical-align:top\"><p><strong>[Yudkowsky][13:29]<\/strong><i>&nbsp;<strong>&nbsp;<\/strong><\/i><\/p><p>@ScottAlexander ready when you are<\/p><\/td><\/tr><tr><td style=\"border:1pt solid #000000;vertical-align:top\"><p><strong>[Alexander][13:31]<\/strong><i> &nbsp;<\/i><\/p><p>Okay, how do you want to do this?<\/p><\/td><\/tr><tr><td style=\"border:1pt solid #000000;vertical-align:top\"><p><strong>[Yudkowsky][13:32]<\/strong><i> &nbsp;<\/i><\/p><p>If you have an agenda of Things To Ask, you can follow it; otherwise I can start by posing a probing question or you can?<\/p><p>We've been very much winging it on these and that has worked... as well as you have seen it working!<\/p><\/td><\/tr><tr><td style=\"border:1pt solid #000000;vertical-align:top\"><p><strong>[Alexander][13:34]<\/strong><i> &nbsp;<\/i><\/p><p>Okay. I'll post from my agenda. I'm assuming we both have the right to edit logs before releasing them? I have one question where I ask about a specific party where your real answer might offend some people it's bad to offend - if that happens, maybe we just have that discussion and then decide if we want to include it later?<\/p><\/td><\/tr><tr><td style=\"border:1pt solid #000000;vertical-align:top\"><p><strong>[Yudkowsky][13:34]<\/strong> &nbsp;<i> &nbsp;<\/i><\/p><p>Yup, both parties have rights to edit before releasing.<\/p><\/td><\/tr><tr><td style=\"border:1pt solid #000000;vertical-align:top\"><p><strong>[Alexander][13:34]<\/strong>&nbsp;<i>&nbsp;<\/i><\/p><p>Okay.<\/p><p>One story that psychologists tell goes something like this: a child does something socially proscribed (eg steal). Their parents punish them. They learn some combination of \"don't steal\" and \"don't get caught stealing\". A few people (eg sociopaths) learn only \"don't get caught stealing\", but most of the rest of us get at least some genuine aversion to stealing that eventually generalizes into a real sense of ethics. If a sociopath got absolute power, they would probably steal all the time. But there are at least a few people whose ethics would successfully restrain them.<\/p><p>I interpret a major strain in your thought as being that we're going to train fledgling AIs to do things like not steal, and they're going to learn not to get caught stealing by anyone who can punish them. Then, once they're superintelligent and have absolute power, they'll reveal that it was all a lie, and steal whenever they want. Is this worry at the level of \"we can't be sure they won't do this\"? Or do you think it's overwhelmingly likely? If the latter, what makes you think AIs won't internalize ethical prohibitions, even though most children do? Is it that evolution has given us priors to interpret rew<\/p><\/td><\/tr><\/tbody><\/table><\/figure>... ","plaintextDescription":"This is a lightly edited transcript of a chatroom conversation between Scott Alexander and Eliezer Yudkowsky last year, following up on the Late 2021 MIRI Conversations. Questions discussed include \"How hard is it to get the right goals into AGI systems?\" and \"In what contexts do AI systems exhibit 'consequentialism'?\".\n\n \n\n\n1. Analogies to human moral development\n[Yudkowsky][13:29]  \n\n@ScottAlexander ready when you are\n\n[Alexander][13:31]  \n\nOkay, how do you want to do this?\n\n[Yudkowsky][13:32]  \n\nIf you have an agenda of Things To Ask, you can follow it; otherwise I can start by posing a probing question or you can?\n\nWe've been very much winging it on these and that has worked... as well as you have seen it working!\n\n[Alexander][13:34]  \n\nOkay. I'll post from my agenda. I'm assuming we both have the right to edit logs before releasing them? I have one question where I ask about a specific party where your real answer might offend some people it's bad to offend - if that happens, maybe we just have that discussion and then decide if we want to include it later?\n\n[Yudkowsky][13:34]    \n\nYup, both parties have rights to edit before releasing.\n\n[Alexander][13:34]  \n\nOkay.\n\nOne story that psychologists tell goes something like this: a child does something socially proscribed (eg steal). Their parents punish them. They learn some combination of \"don't steal\" and \"don't get caught stealing\". A few people (eg sociopaths) learn only \"don't get caught stealing\", but most of the rest of us get at least some genuine aversion to stealing that eventually generalizes into a real sense of ethics. If a sociopath got absolute power, they would probably steal all the time. But there are at least a few people whose ethics would successfully restrain them.\n\nI interpret a major strain in your thought as being that we're going to train fledgling AIs to do things like not steal, and they're going to learn not to get caught stealing by anyone who can punish them. Then, once they're superi","wordCount":7740,"version":"1.0.0"},"Revision:rwkkcgSpnAyE8oNo3_customHighlight":{"_id":"rwkkcgSpnAyE8oNo3_customHighlight","__typename":"Revision","html":"","plaintextDescription":""},"Revision:ZFrgTgzwEfStg26JL_description":{"_id":"ZFrgTgzwEfStg26JL_description","__typename":"Revision","htmlHighlight":"<p><strong>AI Risk<\/strong> is analysis of the risks associated with building powerful AI systems.<\/p><p><i>Related: <\/i><a href=\"https://www.lesswrong.com/tag/ai\"><i>AI<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/orthogonality-thesis\"><i>Orthogonality thesis<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/complexity-of-value\"><i>Complexity of value<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/goodhart-s-law\"><i>Goodhart's law<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/paperclip-maximizer\"><i>Paperclip maximiser<\/i><\/a><\/p>"},"Tag:ZFrgTgzwEfStg26JL":{"_id":"ZFrgTgzwEfStg26JL","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZFrgTgzwEfStg26JL_description"},"canVoteOnRels":null,"userId":"EQNTWXLKMeWMp2FQS","name":"AI Risk","shortName":null,"slug":"ai-risk","core":false,"postCount":1358,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-16T10:29:25.410Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:rwkkcgSpnAyE8oNo3":{"_id":"rwkkcgSpnAyE8oNo3","__typename":"SocialPreviewType","imageUrl":""},"User:nmk3nLpQE89dMRzzN":{"_id":"nmk3nLpQE89dMRzzN","__typename":"User","slug":"eliezer_yudkowsky","createdAt":"2009-02-23T21:58:56.739Z","username":"Eliezer_Yudkowsky","displayName":"Eliezer Yudkowsky","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":144836,"afKarma":1831,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":951,"commentCount":7584,"sequenceCount":40,"afPostCount":18,"afCommentCount":116,"spamRiskScore":1,"tagRevisionCount":324,"reviewedByUserId":"r38pkCm7wF4M44MDQ"},"Post:rwkkcgSpnAyE8oNo3":{"_id":"rwkkcgSpnAyE8oNo3","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:fCbsyCLtdktHxFMLz"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":31,"rejectedReason":null,"customHighlight":{"__ref":"Revision:rwkkcgSpnAyE8oNo3_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ZFrgTgzwEfStg26JL"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"socialPreviewData":{"__ref":"SocialPreviewType:rwkkcgSpnAyE8oNo3"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2023-01-24T21:09:16.938Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-01-24T21:15:12.919Z","meta":false,"postCategory":"post","tagRelevance":{"ZFrgTgzwEfStg26JL":3,"sYm3HiWcfZvrGu3ui":4},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"fCbsyCLtdktHxFMLz","commentCount":52,"voteCount":82,"baseScore":174,"extendedScore":{"agreement":0,"approvalVoteCount":82,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0029144317377358675,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-05T13:24:58.836Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":58,"afExtendedScore":{"agreement":0,"approvalVoteCount":41,"agreementVoteCount":0},"afCommentCount":20,"afLastCommentedAt":"2023-02-05T13:24:58.621Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[{"__ref":"User:nmk3nLpQE89dMRzzN"}],"slug":"alexander-and-yudkowsky-on-agi-goals","title":"Alexander and Yudkowsky on AGI goals","draft":null,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null,"coauthorStatuses":[{"userId":"nmk3nLpQE89dMRzzN","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:gyehNHgFmcfdpe225":{"_id":"gyehNHgFmcfdpe225","__typename":"Revision","htmlHighlight":"<p>Original <a href=\"https://astralcodexten.substack.com/p/who-predicted-2022\">here<\/a>.<\/p><blockquote><p><i><strong>Submission statement/relevance to Less Wrong: <\/strong>This forecasting contest confirmed some things we already believed, like that superforecasters can consistently outperform others, or the \"wisdom of crowds\" effect. It also found a surprising benefit of prediction markets over other aggregation methods, which might or might not be spurious.<\/i><\/p><p><i>Several members of the EA and rationalist community scored highly, including one professional AI forecaster. But Less Wrongers didn't consistently outperform members of the general (ACX-reading, forecasting-competition-entering) population.<\/i><\/p><\/blockquote><p>Last year saw surging inflation, a Russian invasion of Ukraine, and a surprise victory for Democrats in the US Senate. Pundits, politicians, and economists were caught flat-footed by these developments. Did anyone get them right?<\/p><p>In a very technical sense, the single person who predicted 2022 most accurately was a 20-something data scientist at Amazon’s forecasting division.<\/p><p>I know this because last January, along with amateur statisticians Sam Marks and Eric Neyman, I solicited predictions from 508 people. This wasn’t a very creative or free-form exercise - contest participants assigned percentage chances to 71 yes-or-no questions, like “Will Russia invade Ukraine?” or “Will the Dow end the year above 35000?” The whole thing was a bit hokey and constrained - Nassim Taleb wouldn’t be amused - but it had the great advantage of allowing objective scoring.<\/p><figure class=\"image\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F953914da-0dda-4c0d-a555-67cadbaaf24a_659x521.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F953914da-0dda-4c0d-a555-67cadbaaf24a_659x521.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F953914da-0dda-4c0d-a555-67cadbaaf24a_659x521.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F953914da-0dda-4c0d-a555-67cadbaaf24a_659x521.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F953914da-0dda-4c0d-a555-67cadbaaf24a_659x521.png 1456w\"><figcaption>Sample questions.<\/figcaption><\/figure><p>Our goal wasn’t just to identify good predictors. It was to replicate previous findings about the nature of prediction. Are some people really “superforecasters” who do better than everyone else? Is there a “wisdom of crowds”? Does the Efficient Markets Hypothesis mean that prediction markets should beat individuals? Armed with 508 people’s predictions, can we do math to them until we know more about the future (probabilistically, of course) than any ordinary mortal?<\/p><p>After 2022 ended, Sam and Eric used a technique called log-loss scoring to grade everyone’s probability estimates. Lower scores are better. The details are hard to explain, but for our contest, guessing 50% for everything would give a score of 40.21<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefks2a8tu2zr9\"><sup><a href=\"#fnks2a8tu2zr9\">[1]<\/a><\/sup><\/span>, and complete omniscience would give a perfect score of 0.<\/p><p>Here’s how the contest went:<\/p><figure class=\"image\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3615430-5303-4370-8a32-045a16f57a3a_538x350.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3615430-5303-4370-8a32-045a16f57a3a_538x350.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3615430-5303-4370-8a32-045a16f57a3a_538x350.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3615430-5303-4370-8a32-045a16f57a3a_538x350.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3615430-5303-4370-8a32-045a16f57a3a_538x350.png 1456w\"><figcaption>Note truncated vertical axis<\/figcaption><\/figure><p>As mentioned above: guessing 50% corresponds to a score of 40.2. This would have put you in... <\/p>","plaintextDescription":"Original here.\n\n> Submission statement/relevance to Less Wrong: This forecasting contest confirmed some things we already believed, like that superforecasters can consistently outperform others, or the \"wisdom of crowds\" effect. It also found a surprising benefit of prediction markets over other aggregation methods, which might or might not be spurious.\n> \n> Several members of the EA and rationalist community scored highly, including one professional AI forecaster. But Less Wrongers didn't consistently outperform members of the general (ACX-reading, forecasting-competition-entering) population.\n\nLast year saw surging inflation, a Russian invasion of Ukraine, and a surprise victory for Democrats in the US Senate. Pundits, politicians, and economists were caught flat-footed by these developments. Did anyone get them right?\n\nIn a very technical sense, the single person who predicted 2022 most accurately was a 20-something data scientist at Amazon’s forecasting division.\n\nI know this because last January, along with amateur statisticians Sam Marks and Eric Neyman, I solicited predictions from 508 people. This wasn’t a very creative or free-form exercise - contest participants assigned percentage chances to 71 yes-or-no questions, like “Will Russia invade Ukraine?” or “Will the Dow end the year above 35000?” The whole thing was a bit hokey and constrained - Nassim Taleb wouldn’t be amused - but it had the great advantage of allowing objective scoring.\n\nSample questions.\nOur goal wasn’t just to identify good predictors. It was to replicate previous findings about the nature of prediction. Are some people really “superforecasters” who do better than everyone else? Is there a “wisdom of crowds”? Does the Efficient Markets Hypothesis mean that prediction markets should beat individuals? Armed with 508 people’s predictions, can we do math to them until we know more about the future (probabilistically, of course) than any ordinary mortal?\n\nAfter 2022 ended, Sam and Eric used a","wordCount":2293,"version":"1.1.0"},"Revision:R6dqPii4cyNpuecLt_description":{"_id":"R6dqPii4cyNpuecLt_description","__typename":"Revision","htmlHighlight":"<p><strong>Prediction markets<\/strong> are speculative markets created for the purpose of making predictions. Assets are created whose final cash value is tied to a particular event or parameter. The current market prices can then be interpreted as predictions of the probability of the event or the expected value of the parameter. Prediction markets are thus structured as betting exchanges, without any risk for the bookmaker. <a href=\"https://lessestwrong.com/tag/robin-hanson\">Robin Hanson<\/a> was the first to run a corporate prediction market - at Project Xanadu -, and has made several contributions to the field such as: conditional predictions, accuracy issues and market and media manipulation.<\/p><p>People who buy low and sell high are rewarded for improving the market prediction, while those who buy high and sell low are punished for degrading the market prediction. Evidence so far suggests that prediction markets are at least as accurate as other institutions predicting the same events with a similar pool of participants.<\/p><p>Predictions markets have been used by organizations such as Google, General Electric, and Microsoft; several online and commercial prediction markets are also in operation. Historically, prediction markets have often been used to predict election outcomes.<\/p><h2>See Also<\/h2><ul><li><a href=\"https://lessestwrong.com/tag/forecasting-and-prediction\">Prediction<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/economic-consequences-of-ai-and-whole-brain-emulation\">Economic consequences of AI and whole brain emulation<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/group-rationality\">Group rationality<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/making-beliefs-pay-rent\">Making beliefs pay rent<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/quri\">QURI<\/a><\/li><\/ul><h2>External Posts<\/h2><ul><li><a href=\"https://www.astralcodexten.com/p/prediction-market-faq\">Prediction Market FAQ<\/a> by <a href=\"https://www.lesswrong.com/users/scottalexander?mention=user\">@Scott Alexander<\/a>&nbsp;<\/li><li><a href=\"http://www.overcomingbias.com/2006/11/first_known_bus.html\">A 1990 Corporate Prediction Market<\/a> by <a href=\"https://lessestwrong.com/tag/robin-hanson\">Robin Hanson<\/a><\/li><li><a href=\"http://www.overcomingbias.com/2006/12/leamers_1986_id.html\">Leamer's 1986 Idea Futures Proposal<\/a> by Robin Hanson<\/li><li><a href=\"http://www.overcomingbias.com/2006/12/should_predicti.html\">Should Prediction Markets be Charities?<\/a> by Peter McCluskey<\/li><li><a href=\"http://www.overcomingbias.com/2006/12/the_future_of_o_1.html\">The Future of Oil Prices 2: Option Probabilities<\/a> by <a href=\"https://en.wikipedia.org/wiki/Hal_Finney_(cipherpunk)\">Hal Finney<\/a><\/li><li><a href=\"http://www.overcomingbias.com/2009/09/prediction-markets-as-collective-inteligence.html\">Prediction Markets As Collective Intelligence<\/a> by Robin Hanson<\/li><li><a href=\"http://www.overcomingbias.com/2011/11/conditional-close-election-markets.html\">Fixing Election Markets<\/a> by Robin Hanson<\/li><li><a href=\"http://www.gwern.net/Prediction%20markets\">Prediction Markets<\/a> at gwern.net<\/li><li><a href=\"http://hanson.gmu.edu/ideafutures.html\">Idea Futures (a.k.a. Prediction Markets)<\/a> by Robin Hanson<\/li><\/ul><h3>External Links<\/h3><ul><li><a href=\"http://dl.dropbox.com/u/5317066/2011-graefe.pdf\">Comparing face-to-face meetings, nominal groups, Delphi and prediction markets on an estimation task<\/a><\/li><li><a href=\"http://videolectures.net/uai08_hanson_cpm/\">Video of Robin Hanson's Combinatorial Prediction Markets lecture at the Uncertainty in Artificial Intelligence conference in Helsinki, 2008<\/a><\/li><\/ul>"},"Tag:R6dqPii4cyNpuecLt":{"_id":"R6dqPii4cyNpuecLt","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:R6dqPii4cyNpuecLt_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Prediction Markets","shortName":null,"slug":"prediction-markets","core":false,"postCount":146,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-01-14T03:06:53.703Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:3uE2pXvbcnS9nnZRE_description":{"_id":"3uE2pXvbcnS9nnZRE_description","__typename":"Revision","htmlHighlight":"<p><strong>World Modeling<\/strong> is getting curious about how the world works. It’s diving into wikipedia, it’s running a survey to get data from your friends, it’s dropping balls from different heights and measuring how long they take to fall. Empiricism, scholarship, googling, introspection, data-gathering, science. Applying your epistemology and curiosity, <i>finding out how the damn thing works,<\/i> and writing it down for the rest of us.<\/p><blockquote><p><i>The eleventh virtue is scholarship. Study many sciences and absorb their power as your own. Each field that you consume makes you larger. If you swallow enough sciences the gaps between them will diminish and your knowledge will become a unified whole. If you are gluttonous you will become vaster than mountains.<\/i><\/p><p>—<a href=\"https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/the-twelve-virtues-of-rationality\"><u>Twelve Virtues of Rationality<\/u><\/a><\/p><\/blockquote><hr><h1><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; World Modeling Sub-Topics<\/strong><\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Mathematical Sciences<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/abstraction?showPostCount=true&amp;useTagName=true\">Abstraction<\/a><br><a href=\"https://www.lesswrong.com/tag/anthropics?showPostCount=true&amp;useTagName=true\">Anthropics<\/a><br><a href=\"http://www.lesswrong.com/tag/category-theory?showPostCount=true&amp;useTagName=true\">Category Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/causality?showPostCount=true&amp;useTagName=true\">Causality<\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/information-theory?showPostCount=true&amp;useTagName=true\">Information Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/logic-and-mathematics?showPostCount=true&amp;useTagName=true\">Logic &amp; Mathematics<\/a><br><a href=\"https://www.lesswrong.com/tag/probability-and-statistics?showPostCount=true&amp;useTagName=false\">Probability &amp; Statistics<\/a><\/p><p><i>Specifics<\/i><br><a href=\"http://www.lesswrong.com/tag/prisoner-s-dilemma?showPostCount=true&amp;useTagName=true\">Prisoner's Dilemma<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33.33%\"><p><strong>General Science &amp; Eng<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/machine-learning?showPostCount=true&amp;useTagName=true\">Machine Learning<\/a><br><a href=\"https://www.lesswrong.com/tag/nanotechnology?showPostCount=true&amp;useTagName=true\">Nanotechnology<\/a><br><a href=\"https://www.lesswrong.com/tag/physics?showPostCount=true&amp;useTagName=true\">Physics<\/a><br><a href=\"https://www.lesswrong.com/tag/programming?showPostCount=true&amp;useTagName=true\">Programming<\/a><br><a href=\"http://www.lesswrong.com/tag/space-exploration-and-colonization?showPostCount=true&amp;useTagName=true\">Space Exploration &amp; Colonization<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/great-filter?showPostCount=true&amp;useTagName=true\">The Great Filter<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Meta / Misc<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/academic-papers?showPostCount=true&amp;useTagName=true\">Academic Papers<\/a><br><a href=\"https://www.lesswrong.com/tag/book-reviews?showPostCount=true&amp;useTagName=true\">Book Reviews<\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"https://www.lesswrong.com/tag/fact-posts?showPostCount=true&amp;useTagName=true\">Fact Posts<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><\/p><\/td><\/tr><tr><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><p><strong>Social &amp; Economic<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/economics?showPostCount=true&amp;useTagName=true\">Economics<\/a><br><a href=\"https://www.lesswrong.com/tag/financial-investing?showPostCount=true&amp;useTagName=true\">Financial Investing<\/a><br><a href=\"https://www.lesswrong.com/tag/history?showPostCount=true&amp;useTagName=true\">History<\/a><br><a href=\"https://www.lesswrong.com/tag/politics?showPostCount=true&amp;useTagName=true\">Politics<\/a><br><a href=\"https://www.lesswrong.com/tag/progress-studies?showPostCount=true&amp;useTagName=true\">Progress Studies<\/a><br><a href=\"https://www.lesswrong.com/tag/social-and-cultural-dynamics?showPostCount=true&amp;useTagName=true\">Social and Cultural Dynamics<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/conflict-vs-mistake?showPostCount=true&amp;useTagName=true\">Conflict vs Mistake Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/cost-disease?showPostCount=true&amp;useTagName=true\">Cost Disease<\/a><br><a href=\"https://www.lesswrong.com/tag/efficient-market-hypothesis?showPostCount=true&amp;useTagName=true\">Efficient Market Hypothesis<\/a><br><a href=\"https://www.lesswrong.com/tag/industrial-revolution?showPostCount=true&amp;useTagName=true\">Industrial Revolution<\/a><br><a href=\"https://www.lesswrong.com/tag/moral-mazes?showPostCount=true&amp;useTagName=true\">Moral Mazes<\/a><br><a href=\"https://www.lesswrong.com/tag/signaling?showPostCount=true&amp;useTagName=true\">Signaling<\/a><br><a href=\"https://www.lesswrong.com/tag/social-reality?showPostCount=true&amp;useTagName=true\">Social Reality<\/a><br><a href=\"https://www.lesswrong.com/tag/social-status?showPostCount=true&amp;useTagName=true\">Social Status<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:25px;padding:0px;vertical-align:top\"><p><strong>Biological &amp; Psychological<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aging?showPostCount=true&amp;useTagName=true\">Aging<\/a><br><a href=\"https://www.lesswrong.com/tag/biology?showPostCount=true&amp;useTagName=true\">Biology<\/a><br><a href=\"https://www.lesswrong.com/tag/consciousness?showPostCount=true&amp;useTagName=true\">Consciousness<\/a><br><a href=\"https://www.lesswrong.com/tag/evolution?showPostCount=true&amp;useTagName=true\">Evolution<\/a><br><a href=\"http://www.lesswrong.com/tag/evolutionary-psychology?showPostCount=true&amp;useTagName=true\">Evolutionary Psychology<\/a><br><a href=\"https://www.lesswrong.com/tag/medicine?showPostCount=true&amp;useTagName=true\">Medicine<\/a><br><a href=\"https://www.lesswrong.com/tag/neuroscience?showPostCount=true&amp;useTagName=true\">Neuroscience<\/a><br><a href=\"https://www.lesswrong.com/tag/qualia?showPostCount=true&amp;useTagName=true\">Qualia<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/coronavirus?showPostCount=true&amp;useTagName=true\">Coronavirus<\/a><br><a href=\"https://www.lesswrong.com/tag/general-intelligence?showPostCount=true&amp;useTagName=true\">General Intelligence<\/a><br><a href=\"http://www.lesswrong.com/tag/iq-g-factor?showPostCount=true&amp;useTagName=true\"><u>IQ / g-factor<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/neocortex?showPostCount=true&amp;useTagName=true\">Neocortex<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><p><strong>The Practice of Modeling<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/epistemic-review?showPostCount=true&amp;useTagName=true\">Epistemic Review<\/a><br><a href=\"https://www.lesswrong.com/tag/expertise?showPostCount=true&amp;useTagName=true\">Expertise<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\">Gears-Level Models<\/a><br><a href=\"http://www.lesswrong.com/tag/falsifiability?showPostCount=true&amp;useTagName=true\">Falsifiability<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasts-lists-of?showPostCount=true&amp;useTagName=true\">Forecasts (Lists of)<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/jargon-meta?showPostCount=true&amp;useTagName=true\">Jargon (meta)<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\">Practice and Philosophy of Science<\/a><br><a href=\"https://www.lesswrong.com/tag/prediction-markets?showPostCount=true&amp;useTagName=true\">Prediction Markets<\/a><br><a href=\"http://www.lesswrong.com/tag/reductionism?showPostCount=true&amp;useTagName=true\">Reductionism<\/a><br><a href=\"https://www.lesswrong.com/tag/replicability?showPostCount=true&amp;useTagName=true\">Replicability<\/a><br>&nbsp;<\/p><\/td><\/tr><\/tbody><\/table><\/figure><p>&nbsp;<\/p><h2>A definition by elimination<\/h2><p>Properly considered, the overwhelming majority of content LessWrong is about <i>modeling how the world is<\/i>, including almost all posts on Rationality and all practical advice. The intended usage of World Modeling is to capture all content describing how the world is that is not captured by the more specific major tags of <a href=\"https://www.lesswrong.com/tag/rationality\">Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a>, ... <\/p>"},"Tag:3uE2pXvbcnS9nnZRE":{"_id":"3uE2pXvbcnS9nnZRE","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3uE2pXvbcnS9nnZRE_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"World Modeling","shortName":null,"slug":"world-modeling","core":true,"postCount":5001,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":27,"createdAt":"2020-06-14T22:24:50.898Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:gS8Jmcfoa9FAh92YK":{"_id":"gS8Jmcfoa9FAh92YK","__typename":"SocialPreviewType","imageUrl":"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F953914da-0dda-4c0d-a555-67cadbaaf24a_659x521.png"},"User:rPtgB3HpLr4Y5vtuT":{"_id":"rPtgB3HpLr4Y5vtuT","__typename":"User","slug":"unexpectedvalues","createdAt":"2020-08-03T23:22:09.042Z","username":"UnexpectedValues","displayName":"Eric Neyman","profileImageId":null,"previousDisplayName":null,"fullName":null,"karma":2600,"afKarma":36,"deleted":false,"isAdmin":false,"htmlBio":"<p>I work at the Alignment Research Center (ARC). I write a blog on stuff I'm interested in (such as math, philosophy, puzzles, statistics, and elections): <a href=\"https://ericneyman.wordpress.com/\">https://ericneyman.wordpress.com/<\/a><\/p>","jobTitle":null,"organization":null,"postCount":20,"commentCount":72,"sequenceCount":1,"afPostCount":1,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"XtphY3uYHwruKqDyG"},"User:uHHMp4jDL4ySGyP7s":{"_id":"uHHMp4jDL4ySGyP7s","__typename":"User","slug":"sam-marks","createdAt":"2020-07-15T21:37:36.284Z","username":"samuel-marks","displayName":"Sam Marks","profileImageId":null,"previousDisplayName":null,"fullName":"Sam Marks","karma":1870,"afKarma":481,"deleted":false,"isAdmin":false,"htmlBio":"","jobTitle":null,"organization":null,"postCount":16,"commentCount":147,"sequenceCount":0,"afPostCount":8,"afCommentCount":57,"spamRiskScore":1,"tagRevisionCount":0,"reviewedByUserId":"XtphY3uYHwruKqDyG"},"Post:gS8Jmcfoa9FAh92YK":{"_id":"gS8Jmcfoa9FAh92YK","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:gyehNHgFmcfdpe225"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":9,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:R6dqPii4cyNpuecLt"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:gS8Jmcfoa9FAh92YK"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2023-01-24T06:56:33.101Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-01-24T18:12:20.704Z","meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":2,"R6dqPii4cyNpuecLt":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"gyehNHgFmcfdpe225","commentCount":6,"voteCount":14,"baseScore":46,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0008893145713955164,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-01-31T23:24:59.453Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":11,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2023-01-24T06:56:33.104Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[{"__ref":"User:rPtgB3HpLr4Y5vtuT"},{"__ref":"User:uHHMp4jDL4ySGyP7s"}],"slug":"crosspost-acx-2022-prediction-contest-results","title":"[Crosspost] ACX 2022 Prediction Contest Results","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":[{"userId":"rPtgB3HpLr4Y5vtuT","confirmed":true,"requested":true},{"userId":"uHHMp4jDL4ySGyP7s","confirmed":true,"requested":true}],"hasCoauthorPermission":false,"rejected":false,"collabEditorDialogue":false},"Revision:RhzMJeNrXDQ7Gphto":{"_id":"RhzMJeNrXDQ7Gphto","__typename":"Revision","htmlHighlight":"<p>It's September, which means going to beaches, holding barbecues, and . . . preparing for this year's Bay Area Winter Solstice. This year's team will include me, Shauna, Nova, and Mingyuan. In the meantime, we're looking for volunteers.<\/p><p>First, we have logistics volunteers. Some of these, especially AV and lighting, will require a commitment to be kind of agenty in figuring out what you need to do, attending dress rehearsals to help test things, etc. The simple tasks will just require you to show up day of. &nbsp;If you want to help with any of the following logistics tasks, please email <a href=\"mailto:smkravec@celest.ai\">smkravec@celest.ai<\/a>:<\/p><ol><li>Someone to monitor the Twitch stream/simulcast and give updates to AV on that.<\/li><li>Someone to work closely with Nova on the video side of AV; filming the event and running the live stream (possibly that's worth a separate role, they'd be responsible for the audio submix to the stream)<\/li><li>Someone to help setup and run lighting<\/li><li>5-10 people who can help with simple tasks on the day of, like ushering, taking tickets, and moving large objects<\/li><\/ol><p>Second, we have creative tasks. We seem pretty good for people willing to do creative tasks this year, so you don't need to volunteer unless you're really enthusiastic. If you do volunteer, expect to have to audition. If you're interested in any of the following creative tasks, please email <a href=\"mailto:scott@slatestarcodex.com\">scott@slatestarcodex.com<\/a>:<\/p><ol><li>Giving a speech (either writing your own, or giving a reading selected by the team)<\/li><li>Singing a song (either your own, or performing one selected by the team)<\/li><\/ol><p>We'll give volunteers more information by email, and we'll try to give everyone more information as we get closer to the event.<\/p><p>Thanks!<\/p>","plaintextDescription":"It's September, which means going to beaches, holding barbecues, and . . . preparing for this year's Bay Area Winter Solstice. This year's team will include me, Shauna, Nova, and Mingyuan. In the meantime, we're looking for volunteers.\n\nFirst, we have logistics volunteers. Some of these, especially AV and lighting, will require a commitment to be kind of agenty in figuring out what you need to do, attending dress rehearsals to help test things, etc. The simple tasks will just require you to show up day of.  If you want to help with any of the following logistics tasks, please email smkravec@celest.ai:\n\n 1. Someone to monitor the Twitch stream/simulcast and give updates to AV on that.\n 2. Someone to work closely with Nova on the video side of AV; filming the event and running the live stream (possibly that's worth a separate role, they'd be responsible for the audio submix to the stream)\n 3. Someone to help setup and run lighting\n 4. 5-10 people who can help with simple tasks on the day of, like ushering, taking tickets, and moving large objects\n\nSecond, we have creative tasks. We seem pretty good for people willing to do creative tasks this year, so you don't need to volunteer unless you're really enthusiastic. If you do volunteer, expect to have to audition. If you're interested in any of the following creative tasks, please email scott@slatestarcodex.com:\n\n 1. Giving a speech (either writing your own, or giving a reading selected by the team)\n 2. Singing a song (either your own, or performing one selected by the team)\n\nWe'll give volunteers more information by email, and we'll try to give everyone more information as we get closer to the event.\n\nThanks!","wordCount":281,"version":"1.0.0"},"Tag:vtozKm5BZ8gf6zd45":{"_id":"vtozKm5BZ8gf6zd45","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"canVoteOnRels":null,"userId":"kmiXJjx2GS4txx3yj","name":"Secular Solstice","shortName":null,"slug":"secular-solstice","core":false,"postCount":76,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-05T22:37:23.988Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:KCcdhZK7omEMwBdju":{"_id":"KCcdhZK7omEMwBdju","__typename":"SocialPreviewType","imageUrl":""},"Post:KCcdhZK7omEMwBdju":{"_id":"KCcdhZK7omEMwBdju","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:RhzMJeNrXDQ7Gphto"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:T57Qd9J3AfxmwhQtY"},{"__ref":"Tag:vtozKm5BZ8gf6zd45"},{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"socialPreviewData":{"__ref":"SocialPreviewType:KCcdhZK7omEMwBdju"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2022-09-04T06:44:19.043Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"postCategory":"post","tagRelevance":{"T57Qd9J3AfxmwhQtY":2,"izp6eeJJEg9v5zcur":2,"vtozKm5BZ8gf6zd45":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"RhzMJeNrXDQ7Gphto","commentCount":2,"voteCount":15,"baseScore":43,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0005454025231301785,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-10-19T06:50:59.793Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":9,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2022-09-04T06:44:19.048Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"bay-solstice-2022-call-for-volunteers","title":"Bay Solstice 2022 Call For Volunteers","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:LsS2qEz6E4qfNCj6y":{"_id":"LsS2qEz6E4qfNCj6y","__typename":"Revision","htmlHighlight":"<p>Here's the <a href=\"https://astralcodexten.substack.com/\">Astral Codex Ten<\/a> worldwide meetups list, crossposted at LW's request in case people here are interested in attending. Some cities have an ACX but not an LW meetup group, or vice versa; others combine their groups. You can find the list below, in the following order:<\/p><ol><li>Africa &amp; Middle East<\/li><li>Asia-Pacific (including Australia)<\/li><li>Canada<\/li><li>Europe (including UK)<\/li><li>Latin America<\/li><li>United States<\/li><\/ol><p>You can see a map of all the events on <a href=\"https://www.lesswrong.com/community\">the LessWrong community page<\/a>.<\/p><p>Within each section, it’s alphabetized first by country/state, then by city - so the first entry in Europe is Vienna, <strong>A<\/strong>ustria. Sorry if this is confusing.<\/p><p>I'll provisionally be attending the meetups in Berkeley, Los Angeles, and San Diego. ACX meetups coordinator Mingyuan will provisionally be attending Paris and London. I’ll be announcing some of the biggest ones on the blog, regardless of whether or not I attend.<\/p><p><strong>Extra Info For Potential Attendees<\/strong><\/p><p><strong>1. <\/strong>If you’re reading this, you’re invited. Please don’t feel like you “won’t be welcome” just because you’re new to the blog, demographically different from the average reader, or hate ACX and everything it stands for. You’ll be fine!&nbsp;<br><strong>2<\/strong>. You don’t have to RSVP or contact the organizer to be able to attend (unless the event description says otherwise); RSVPs are mostly to give organizers a better sense of how many people might show up, and let them tell you if there are last-second changes. I’ve also given email addresses for all organizers in case you have a question.<\/p><p><strong>Extra Info For Meetup Organizers:<\/strong><br><br><strong>1.<\/strong> If you’re the host, bring a sign that says “ACX MEETUP” and prop it up somewhere (or otherwise be identifiable).<br><strong>2. <\/strong>Bring blank labels and pens for nametags.<br><strong>3. <\/strong>Have people type their name and email address in a spreadsheet or in a Google Form (accessed via a bit.ly link or QR code), so you can start a mailing list to make organizing future meetups easier.<br><strong>4.<\/strong> If it’s the first meetup, people are probably just going to want to talk, and if you try to organize some kind of “fun” “event” it’ll probably just be annoying.<br><strong>5.<\/strong> It’s easier to schedule a followup meetup while you’re having the first, compared to trying to do it later on by email.<br><strong>6.<\/strong> In case people want to get to know each other better outside the meetup, you might want to mention <a href=\"https://www.reciprocity.io/\">reciprocity.io<\/a>, the rationalist friend-finder/dating site.<br><strong>7.<\/strong> If you didn’t make a LessWrong event for your meetup, the LessWrong team d... <\/p>","plaintextDescription":"Here's the Astral Codex Ten worldwide meetups list, crossposted at LW's request in case people here are interested in attending. Some cities have an ACX but not an LW meetup group, or vice versa; others combine their groups. You can find the list below, in the following order:\n\n 1. Africa & Middle East\n 2. Asia-Pacific (including Australia)\n 3. Canada\n 4. Europe (including UK)\n 5. Latin America\n 6. United States\n\nYou can see a map of all the events on the LessWrong community page.\n\nWithin each section, it’s alphabetized first by country/state, then by city - so the first entry in Europe is Vienna, Austria. Sorry if this is confusing.\n\nI'll provisionally be attending the meetups in Berkeley, Los Angeles, and San Diego. ACX meetups coordinator Mingyuan will provisionally be attending Paris and London. I’ll be announcing some of the biggest ones on the blog, regardless of whether or not I attend.\n\nExtra Info For Potential Attendees\n\n1. If you’re reading this, you’re invited. Please don’t feel like you “won’t be welcome” just because you’re new to the blog, demographically different from the average reader, or hate ACX and everything it stands for. You’ll be fine! \n2. You don’t have to RSVP or contact the organizer to be able to attend (unless the event description says otherwise); RSVPs are mostly to give organizers a better sense of how many people might show up, and let them tell you if there are last-second changes. I’ve also given email addresses for all organizers in case you have a question.\n\nExtra Info For Meetup Organizers:\n\n1. If you’re the host, bring a sign that says “ACX MEETUP” and prop it up somewhere (or otherwise be identifiable).\n2. Bring blank labels and pens for nametags.\n3. Have people type their name and email address in a spreadsheet or in a Google Form (accessed via a bit.ly link or QR code), so you can start a mailing list to make organizing future meetups easier.\n4. If it’s the first meetup, people are probably just going to want to talk, and i","wordCount":12304,"version":"1.3.0"},"Revision:fLdADsBLAMuGvky2M_customHighlight":{"_id":"fLdADsBLAMuGvky2M_customHighlight","__typename":"Revision","html":"","plaintextDescription":""},"SocialPreviewType:fLdADsBLAMuGvky2M":{"_id":"fLdADsBLAMuGvky2M","__typename":"SocialPreviewType","imageUrl":""},"Post:fLdADsBLAMuGvky2M":{"_id":"fLdADsBLAMuGvky2M","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:LsS2qEz6E4qfNCj6y"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":49,"rejectedReason":null,"customHighlight":{"__ref":"Revision:fLdADsBLAMuGvky2M_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"socialPreviewData":{"__ref":"SocialPreviewType:fLdADsBLAMuGvky2M"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2022-08-26T18:12:04.083Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2022-08-26T18:43:32.708Z","meta":false,"postCategory":"post","tagRelevance":{"izp6eeJJEg9v5zcur":2},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"LsS2qEz6E4qfNCj6y","commentCount":1,"voteCount":26,"baseScore":63,"extendedScore":null,"emojiReactors":{},"unlisted":false,"score":0.0009072004468180239,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-08-27T12:34:52.794Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":12,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2022-08-26T18:12:04.092Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"acx-meetups-everywhere-list","title":"ACX Meetups Everywhere List","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:N7qtGhwGHmZahkLDL":{"_id":"N7qtGhwGHmZahkLDL","__typename":"Revision","htmlHighlight":"<p>[crossposted from <a href=\"https://astralcodexten.substack.com/p/on-hreha-on-behavioral-economics\">Astral Codex Ten<\/a>]<\/p><p>Jason Hreha’s article on <a href=\"https://www.thebehavioralscientist.com/articles/the-death-of-behavioral-economics\">The Death Of Behavioral Economics<\/a> has been going around lately, after an experiment by behavioral econ guru Dan Ariely was discovered to be fraudulent. The article argues that this is the tip of the iceberg - looking back on the last few years of replication crisis, behavioral economics has been undermined almost to the point of irrelevance.<\/p><p>The article itself mostly just urges behavioral economists to do better, which is always good advice for everyone. But as usual, it’s the inflammatory title that’s gone viral. I think a strong interpretation of behavioral economics as dead or debunked is unjustified.<\/p><p><strong>I.<\/strong><\/p><p>My medical school had final exams made of true-false questions, with an option to answer “don’t know”. They were scored like so: if you got it right, +1 point; wrong, -0.5 points; don’t know, 0. You can easily confirm that it’s always worth guessing even if you genuinely don’t know the answer (+0.25 points on average instead of 0). On average people probably had to guess on ~30% of questions (don’t ask; it’s an Irish education system thing), so you could increase your test score 7.5% with the right strategy here.<\/p><p>I knew all this, but it was still really hard to guess. I did it, but I had to fight my natural inclinations. And when I talked about this with friends - smart people, the sort of people who got into medical school! - none of them guessed, and no matter how much I argued with them <a href=\"https://www.lesswrong.com/posts/znBJwbuT3f5eWgM4E/shut-up-and-guess\">they refused to start. <\/a>The average medical student would sell their soul for 7.5% higher grades on standardized tests - but <i>this <\/i>was a step too far.<\/p><p>This is Behavioral Econ 101 stuff - <a href=\"https://en.wikipedia.org/wiki/Risk_aversion\">risk aversion<\/a>, <a href=\"https://en.wikipedia.org/wiki/Loss_aversion\">loss aversion<\/a>, and <a href=\"https://en.wikipedia.org/wiki/Prospect_theory\">prospect theory<\/a>. If it’s true, the core of behavioral economics is salvageable. There might be some bad studies built on top of that core, but the basic insights are right.<\/p><p>One more example: every time I order food from GrubHub, I get a menu like this:<\/p><figure class=\"image\"><img src=\"https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffa9ca4-fe51-4da5-a049-2be13c2c3489_704x118.png\"><\/figure><p>And every time I order food from UberEats, I get a menu like this:<\/p><figure class=\"image\"><img src=\"https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F43182725-42d6-4943-b4df-559d1d337e75_457x315.png\"><\/figure><p>I find I usually click the third box on both. I want to tip generously, but giving the <i>maximum possible<\/i> tip seems profligate. Surely the third box is the right compromise.<\/p><p>I recently noticed that this is insane. For a $35 meal, I’m giving GrubHub drivers $3 and UberEats drivers $7 for the same service (or maybe there’s some difference between their services which makes UberEats suggest the h... <\/p>","plaintextDescription":"[crossposted from Astral Codex Ten]\n\nJason Hreha’s article on The Death Of Behavioral Economics has been going around lately, after an experiment by behavioral econ guru Dan Ariely was discovered to be fraudulent. The article argues that this is the tip of the iceberg - looking back on the last few years of replication crisis, behavioral economics has been undermined almost to the point of irrelevance.\n\nThe article itself mostly just urges behavioral economists to do better, which is always good advice for everyone. But as usual, it’s the inflammatory title that’s gone viral. I think a strong interpretation of behavioral economics as dead or debunked is unjustified.\n\nI.\n\nMy medical school had final exams made of true-false questions, with an option to answer “don’t know”. They were scored like so: if you got it right, +1 point; wrong, -0.5 points; don’t know, 0. You can easily confirm that it’s always worth guessing even if you genuinely don’t know the answer (+0.25 points on average instead of 0). On average people probably had to guess on ~30% of questions (don’t ask; it’s an Irish education system thing), so you could increase your test score 7.5% with the right strategy here.\n\nI knew all this, but it was still really hard to guess. I did it, but I had to fight my natural inclinations. And when I talked about this with friends - smart people, the sort of people who got into medical school! - none of them guessed, and no matter how much I argued with them they refused to start. The average medical student would sell their soul for 7.5% higher grades on standardized tests - but this was a step too far.\n\nThis is Behavioral Econ 101 stuff - risk aversion, loss aversion, and prospect theory. If it’s true, the core of behavioral economics is salvageable. There might be some bad studies built on top of that core, but the basic insights are right.\n\nOne more example: every time I order food from GrubHub, I get a menu like this:\n\nAnd every time I order food from UberEats, ","wordCount":6519,"version":"1.0.0"},"Revision:4R8JYu4QF2FqzJxE5_description":{"_id":"4R8JYu4QF2FqzJxE5_description","__typename":"Revision","htmlHighlight":"<p><strong>Heuristics<\/strong> and <strong>Biases<\/strong> are the ways human reasoning differs from a theoretical ideal agent, due to reasoning shortcuts that don't always work (heuristics) and systematic errors (biases).<\/p><p><em>See also<\/em>: <a href=\"https://www.lesswrong.com/tag/affect-heuristic?showPostCount=true&amp;useTagName=true\">Affect Heuristic<\/a>, <a href=\"https://www.lesswrong.com/tag/confirmation-bias\">Confirmation Bias<\/a>, <a href=\"https://www.lesswrong.com/tag/fallacies\">Fallacies<\/a>, <a href=\"https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM\">Predictably Wrong<\/a>, <a href=\"https://www.lesswrong.com/tag/rationality?showPostCount=true\">Rationality<\/a>, <a href=\"https://www.lesswrong.com/posts/Psp8ZpYLCDJjshpRb/your-intuitions-are-not-magic\">Your Intuitions Are Not Magic<\/a>, <a href=\"https://lesswrong.com/tag/bias\">Bias<\/a>, <a href=\"https://lesswrong.com/tag/heuristic\">Heuristic<\/a><\/p>\n<h1>Basics<\/h1>\n<p><a href=\"https://www.lesswrong.com/posts/jnZbHi873v9vcpGpZ/what-s-a-bias-again\">“Cognitive biases”<\/a> are those obstacles to truth which are produced, not by the cost of information, nor by limited computing power, but by <em>the shape of our own mental machinery<\/em>. For example, our mental processes might be evolutionarily adapted to specifically believe some things that arent true, so that we could win political arguments in a tribal context. Or the mental machinery might be adapted not to particularly care whether something is true, such as when we feel the urge to believe what others believe to get along socially. Or the bias may be a side-effect of a useful reasoning heuristic. The availability heuristic is not itself a bias, but it gives rise to them; the machinery uses an algorithm (give things more evidential weight if they come to mind more readily) that does some good cognitive work but also produces systematic errors.<\/p><p>Our brains are doing something wrong, and after a lot of experimentation and/or heavy thinking, someone identifies the problem verbally and concretely; then we call it a “(cognitive) bias.” Not to be confused with the colloquial “that person is biased,” which just means “that person has a skewed or prejudiced attitude toward something.”<\/p><p>A bias is an obstacle to our goal of obtaining truth, and thus <em>in our way<\/em>.<\/p><p>We are here to pursue the great human quest for truth: for we have desperate need of the knowledge, and besides, we're curious. To this end let us strive to overcome whatever obstacles lie in our way, whether we call them “biases” or not.<\/p><p><a href=\"https://www.lesswrong.com/posts/Psp8ZpYLCDJjshpRb/your-intuitions-are-not-magic\">It's also useful to know the kinds of faults human brains are prone to, in the same way it's useful to know that your car's brakes are a little gummy (so you don't sail through a red light and into an 18-wheeler).<\/a><\/p><p>The Sequence, <a href=\"https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM\">Predictably Wrong<\/a>, offers an excellent introduction to the topic for those who are not familiar.<\/p>\n<h1>Wait a minute... fallacies, biases, heuristics... what's the difference??<\/h1>\n<p>While a <strong>bias<\/strong> is always wrong, a <strong>heuristic<\/strong> is just a shortcut which may or may not give you an accurate answer. Just because you know complex mathematical methods for preci... <\/p>"},"Tag:4R8JYu4QF2FqzJxE5":{"_id":"4R8JYu4QF2FqzJxE5","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:4R8JYu4QF2FqzJxE5_description"},"canVoteOnRels":null,"userId":"BpBzKEueak7J8vHNi","name":"Heuristics & Biases","shortName":null,"slug":"heuristics-and-biases","core":false,"postCount":255,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-13T15:40:30.194Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:vg4LDxjdwHLotCm8w_description":{"_id":"vg4LDxjdwHLotCm8w_description","__typename":"Revision","htmlHighlight":"<p>The <strong>Replication Crisis<\/strong> was the discovery that many fields of so-called science were producing experimental results that could not be replicated, because they were illusions resulting from bad statistical and experimental practices.<\/p><p>The replication crisis began in the early 2010s when several high-profile irreproducible results inspired mass replication attempts, revealing that the majority of papers checked in psychology and a number of other fields were not replicable. Some of the irreproducible results, like <a href=\"https://www.lesswrong.com/tag/priming\">Priming<\/a>, appeared to bear on rationality and were referenced in early LessWrong posts.<\/p><ul><li><strong>External Links:<\/strong><br><a href=\"https://retractionwatch.com/\">Retraction Watch<\/a><\/li><li><a href=\"https://www.gwern.net/Replication\">Replication<\/a> on gwern.net<\/li><li><a href=\"https://arbital.com/p/likelihood_vs_pvalue/\">Likelihood functions, p-values, and the replication crisis<\/a> by Eliezer Yudkowsky<\/li><li><a href=\"https://en.wikipedia.org/wiki/Replication_crisis\">Wikipedia<\/a><\/li><\/ul><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science\">Practice &amp; Philosophy of Science<\/a>, <a href=\"https://www.lesswrong.com/tag/psychology\">Psychology<\/a>, <a href=\"https://www.lesswrong.com/tag/information-cascades\">Information Cascades<\/a>, <a href=\"https://www.lesswrong.com/tag/falsifiability\">Falsifiability<\/a><\/p>"},"Tag:vg4LDxjdwHLotCm8w":{"_id":"vg4LDxjdwHLotCm8w","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:vg4LDxjdwHLotCm8w_description"},"canVoteOnRels":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Replication Crisis","shortName":null,"slug":"replication-crisis","core":false,"postCount":62,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-02T20:55:24.286Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:PDJ6KqJBRzvKPfuS3_description":{"_id":"PDJ6KqJBRzvKPfuS3_description","__typename":"Revision","htmlHighlight":"<p><strong>Economics<\/strong> is the social science that studies how humans and other agents interact in a universe with scarce resources. It deals with topics such as trade, specialization of labor, accumulation of capital, technology, and resource consumption. Agents in economics are generally assumed to have utility functions, which they try to maximize under various constraints.<\/p><p>Economics is usually separated into microeconomics and macroeconomics. Microeconomics concerns the behavior of agents as they interact in a market. More narrowly, it studies the price mechanism, a decentralized system of allocating goods and services based on an evolving system of prices and trade, which all actors in a market economy contribute towards. The price mechanism is closely related to the concept of the <a href=\"https://en.wikipedia.org/wiki/Invisible_hand\">invisible hand<\/a>, first introduced by <a href=\"https://en.wikipedia.org/wiki/Adam_Smith\">Adam Smith<\/a>. <a href=\"https://www.lesswrong.com/tag/game-theory\">Game theory<\/a> is the mathematical study of rational agency, which formalizes many standard results in microeconomics.<\/p><p>Macroeconomics concerns the aggregate behavior of entire economies. For example, it studies economic growth, inflation, international trade and unemployment. An ongoing debate concerns to what extent the <a href=\"https://www.lesswrong.com/tag/economic-consequences-of-agi\">impacts of artificial intelligence<\/a> should be viewed through the lens of economics.<\/p>"},"Tag:PDJ6KqJBRzvKPfuS3":{"_id":"PDJ6KqJBRzvKPfuS3","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:PDJ6KqJBRzvKPfuS3_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Economics","shortName":null,"slug":"economics","core":false,"postCount":462,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T22:24:48.135Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:Ng8Gice9KNkncxqcj_description":{"_id":"Ng8Gice9KNkncxqcj_description","__typename":"Revision","htmlHighlight":"<p><strong>Rationality<\/strong> is the art of thinking in ways that result in <a href=\"https://www.lesswrong.com/tag/world-modeling\">accurate beliefs<\/a> and <a href=\"https://www.lesswrong.com/tag/decision-theory\">good decisions<\/a>. It is the primary topic of LessWrong.<br><br>Rationality is not only about avoiding the vices of <a href=\"https://www.lesswrong.com/tag/self-deception\">self-deception<\/a> and obfuscation (the failure to <a href=\"https://www.lesswrong.com/tag/conversation-topic\">communicate clearly<\/a>), but also about the virtue of <a href=\"https://www.lesswrong.com/tag/curiosity\">curiosity<\/a>, seeing the world more clearly than before, and <a href=\"https://www.lesswrong.com/tag/ambition\">achieving things<\/a> <a href=\"https://www.lesswrong.com/tag/skill-building\">previously unreachable<\/a> <a href=\"https://www.lesswrong.com/tag/coordination-cooperation\">to you<\/a>. The study of rationality on LessWrong includes a theoretical understanding of ideal cognitive algorithms, as well as building a practice that uses these idealized algorithms to inform <a href=\"https://www.lesswrong.com/tag/heuristics-and-biases\">heuristics<\/a>, <a href=\"https://www.lesswrong.com/tag/habits\">habits<\/a>, and <a href=\"https://www.lesswrong.com/tag/techniques\">techniques<\/a>, to successfully reason and make decisions in the real world.<\/p><p>Topics covered in rationality include (but are not limited to): normative and theoretical explorations of <a href=\"https://www.lesswrong.com/tag/solomonoff-induction\">ideal<\/a> <a href=\"https://www.lesswrong.com/tag/probability-and-statistics\">reasoning<\/a>; the <a href=\"https://www.lesswrong.com/tag/evolutionary-psychology\">capabilities and limitations<\/a> <a href=\"https://www.lesswrong.com/tag/neuroscience\">of our brain<\/a>, <a href=\"https://www.lesswrong.com/tag/dual-process-theory-system-1-and-system-2\">mind and psychology<\/a>; applied advice such as <a href=\"https://www.lesswrong.com/tag/introspection\">introspection<\/a> techniques and <a href=\"https://www.lesswrong.com/tag/group-rationality\">how to achieve truth collaboratively<\/a>; practical techniques and methodologies for figuring out what’s true ranging from rough quantitative modeling to full research guides.<\/p><p>Note that content about <i>how the world is <\/i>can be found under <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a>, and practical advice about <i>how to change the world<\/i> is categorized under <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a> or <a href=\"/tag/practical\">Practical<\/a>.<\/p><hr><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\"><p><strong>Theory / Concepts<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/anticipated-experiences?showPostCount=true&amp;useTagName=true\"><u>Anticipated Experiences<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/aumann-s-agreement-theorem?showPostCount=true&amp;useTagName=true\">Aumann's Agreement Theorem<\/a><br><a href=\"http://www.lesswrong.com/tag/bayes-theorem?showPostCount=true&amp;useTagName=true\"><u>Bayes Theorem<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/bounded-rationality?showPostCount=true&amp;useTagName=true\">Bounded Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/conservation-of-expected-evidence?showPostCount=true&amp;useTagName=true\">Conservation of Expected<\/a><br><a href=\"http://www.lesswrong.com/tag/contrarianism?showPostCount=true&amp;useTagName=true\">Contrarianism<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemology?showPostCount=true&amp;useTagName=true\"><u>Epistemology<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\"><u>Gears-Level<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/hansonian-pre-rationality?useTagName=true&amp;showPostCount=true\">Hansonian Pre-Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/law-thinking?showPostCount=true&amp;useTagName=true\">Law-Thinking<\/a><br><a href=\"http://www.lesswrong.com/tag/map-and-territory?showPostCount=true&amp;useTagName=true\">Map and Territory<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"http://www.lesswrong.com/tag/occam-s-razor?showPostCount=true&amp;useTagName=true\">Occam's razor<\/a><br><a href=\"https://www.lesswrong.com/tag/robust-agents?showPostCount=true&amp;useTagName=true\">Robust Agents<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/truth-semantics-and-meaning?showPostCount=true&amp;useTagName=true\">Truth, Semantics, &amp; Meaning<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/alief?showPostCount=true&amp;useTagName=true\"><u>Alief<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/betting?showPostCount=true&amp;useTagName=true\">Betting<\/a><br><a href=\"http://www.lesswrong.com/tag/cached-thoughts?showPostCount=true&amp;useTagName=true\">Cached Thoughts<\/a><br><a href=\"http://www.lesswrong.com/tag/calibration?showPostCount=true&amp;useTagName=true\">Calibration<\/a><br><a href=\"https://www.lesswrong.com/tag/dark-arts?showPostCount=true&amp;useTagName=true\">Dark Arts<\/a><br><a href=\"http://www.lesswrong.com/tag/empiricism?showPostCount=true&amp;useTagName=true\">Empiricism<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemic-modesty?showPostCount=true&amp;useTagName=true\">Epistemic Modesty<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/identity?showPostCount=true&amp;useTagName=true\">Identity<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/introspection?showPostCount=true&amp;useTagName=true\"><u>Introspection<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/intuition?showPostCount=true&amp;useTagName=true\">Intuition<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\"><u>Practice &amp; Philosophy of Science<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><br><a href=\"http://www.lesswrong.com/tag/taking-ideas-seriously?showPostCount=true&amp;useTagName=true\">Taking Ideas Seriously<\/a><br><a href=\"https://www.lesswrong.com/tag/value-of-information?showPostCount=true&amp;useTagName=true\">Value of Information<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Failure Modes<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/affect-heuristic?showPostCount=true&amp;useTagName=true\">Affect Heuristic<\/a><br><a href=\"https://www.lesswrong.com/tag/bucket-errors?showPostCount=true&amp;useTagName=true\">Bucket Errors<\/a><br><a href=\"https://www.lesswrong.com/tag/compartmentalization?showPostCount=true&amp;useTagName=true\">Compartmentalization<\/a><br><a href=\"https://www.lesswrong.com/tag/confirmation-bias?showPostCount=true&amp;useTagName=true\"><u>Confirmation Bias<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/logical-fallacies?showPostCount=true&amp;useTagName=true\">Fallacies<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodhart’s Law<\/a><br><a href=\"http://www.lesswrong.com/tag/groupthink?showPostCount=true&amp;useTagName=true\"><u>Groupthink<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/heuristics-and-biases?showPostCount=true&amp;useTagName=true\">Heuristics and Biases<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-projection-fallacy?showPostCount=true&amp;useTagName=true\">Mind Projection Fallacy<\/a><br><a href=\"https://www.lesswrong.com/tag/motivated-reasoning?showPostCount=true&amp;useTagName=true\"><u>Motivated Reasoning<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true&amp;useTagName=true\">Pica<\/a><br><a href=\"https://www.lesswrong.com/tag/pitfalls-of-rationality?showPostCount=true&amp;useTagName=true\">Pitfalls of Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/rationalization?showPostCount=true&amp;useTagName=true\">Rationalization<\/a>&nbsp;<br><a href=\"https://www.lesswrong.com/tag/self-deception?showPostCount=true&amp;useTagName=true\">Self-Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/sunk-cost-fallacy?showPostCount=true&amp;useTagName=true\">Sunk-Cost Fallacy<\/a><\/p><\/td><\/tr><tr><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top\" rowspan=\"2\"><p><strong>Communication<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true\"><u>Conversation<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/decoupling-vs-contextualizing?showPostCount=true&amp;useTagName=true\"><u>Decoupling vs Contextualizing<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/disagreement?showPostCount=true&amp;useTagName=true\"><u>Disagreement<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"http://www.lesswrong.com/tag/double-crux?showPostCount=true&amp;useTagName=true\"><u>Double-Crux<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/good-explanations-advice?showPostCount=true&amp;useTagName=true\">Good Explanations (Advice)<\/a><br><a href=\"http://www.lesswrong.com/tag/ideological-turing-tests?showPostCount=true&amp;useTagName=true\">Ideological Turing Tests<\/a><br><a href=\"https://www.lesswrong.com/tag/inferential-distance?showPostCount=true&amp;useTagName=true\">Inferential Distance<\/a><br><a href=\"https://www.lesswrong.com/tag/information-cascades?showPostCount=true&amp;useTagName=true\">Information Cascades<\/a><br><a href=\"https://www.lesswrong.com/tag/memetic-immune-system?showPostCount=true&amp;useTagName=true\">Memetic Immune System<\/a><br><a href=\"https://www.lesswrong.com/tag/philosophy-of-language?showPostCount=true&amp;useTagName=true\"><u>Philos<\/u><\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>... "},"Tag:Ng8Gice9KNkncxqcj":{"_id":"Ng8Gice9KNkncxqcj","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Ng8Gice9KNkncxqcj_description"},"canVoteOnRels":null,"userId":"r38pkCm7wF4M44MDQ","name":"Rationality","shortName":null,"slug":"rationality","core":true,"postCount":3828,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":100,"createdAt":"2020-06-14T22:24:17.072Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:gBpYo7mt2zNBmtBJd":{"_id":"gBpYo7mt2zNBmtBJd","__typename":"SocialPreviewType","imageUrl":"https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9ffa9ca4-fe51-4da5-a049-2be13c2c3489_704x118.png"},"Post:gBpYo7mt2zNBmtBJd":{"_id":"gBpYo7mt2zNBmtBJd","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:N7qtGhwGHmZahkLDL"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":26,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:4R8JYu4QF2FqzJxE5"},{"__ref":"Tag:vg4LDxjdwHLotCm8w"},{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"socialPreviewData":{"__ref":"SocialPreviewType:gBpYo7mt2zNBmtBJd"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2021-08-31T18:14:39.075Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2021-08-31T19:00:09.564Z","meta":false,"postCategory":"post","tagRelevance":{"3uE2pXvbcnS9nnZRE":4,"4R8JYu4QF2FqzJxE5":9,"Ng8Gice9KNkncxqcj":4,"PDJ6KqJBRzvKPfuS3":3,"vg4LDxjdwHLotCm8w":5},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"N7qtGhwGHmZahkLDL","commentCount":6,"voteCount":38,"baseScore":106,"extendedScore":{"reacts":{"laugh":[{"karma":82,"quotes":["one of the most important studies it discusses had n = 7"],"userId":"aAFFNKuipmCQPb9ob","reactType":"created","displayName":"ErioirE"}]},"agreement":0,"approvalVoteCount":37,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0009266517008654773,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-11-10T23:05:27.967Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"EQNTWXLKMeWMp2FQS","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":27,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":16,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2021-08-31T18:14:39.079Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"crosspost-on-hreha-on-behavioral-economics","title":"[Crosspost] On Hreha On Behavioral Economics","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:Rrkr9zk8SoGMq7SsC":{"_id":"Rrkr9zk8SoGMq7SsC","__typename":"Revision","htmlHighlight":"<p><i>[cross-posted from my blog <\/i><a href=\"https://astralcodexten.substack.com/p/eight-hundred-slightly-poisoned-word\"><i>Astral Codex Ten<\/i><\/a><i>]<\/i><\/p><p>In 2012, a Berkeley team found that indoor carbon dioxide had dramatic negative effects on cognition (<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3548274/\">paper<\/a>, <a href=\"https://alumni.berkeley.edu/california-magazine/summer-2016-welcome-there/your-brain-carbon-dioxide-research-finds-even-low\">popular article<\/a>). Subjects in poorly ventilated environments did up to 50% worse on a test of reasoning and decision-making. This is potentially pretty important, because lots of office buildings (and private houses) count as poorly-ventilated environments, so a lot of decision-making might be happening while severely impaired.<\/p><p>Since then people have debated this on and off, with <a href=\"https://dash.harvard.edu/bitstream/handle/1/27662232/4892924.pdf?sequence=1\">some studies<\/a> confirming the effect and <a href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/ina.12284\">others<\/a> failing to find it. I personally am skeptical, partly because the effect is so big I would expect someone to have noticed, but also because submarines, spaceships, etc have orders of magnitude more carbon dioxide than any civilian environment, but people still seem to do pretty hard work in them pretty effectively.<\/p><p>As part of my continuing effort to test this theory in my own life, I played a word game eight hundred times under varying ventilation conditions.<\/p><p>…okay, fine, no, I admit it, I played a word game eight hundred times because I’m addicted to it. But since I was playing the word game eight hundred times anyway, I varied the ventilation conditions to see what would happen.<\/p><p>The game was WordTwist, which you can find <a href=\"https://wordtwist.puzzlebaron.com/init5.php\">here<\/a> (warning: potentially addictive). You get a 5x5 square of letters and you have to find as many words as possible (of four letters or more) within three minutes. You can move up, down, right, left, or diagonal, and get more points for harder words. A typical board looks like this:<\/p><figure class=\"image\"><img src=\"https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1902078a-2b4f-4f8d-8b6c-7a8122700660_298x299.png\"><figcaption>Did you spot “lace”? What about “intrapsychically”?<\/figcaption><\/figure><p>I played this game about 5-10x/day over three months. During this time, the carbon dioxide monitor in my room recorded levels between 445 ppm (with all windows open and the fan on) and 3208 ppm (with all windows closed and several people crammed into the room for several hours). I discounted a stray reading of 285 as an outlier, since this is climatologically impossible (I’m not claiming my monitor is perfectly calibrated, just that it clearly shows higher levels when my room is less well ventilated). CO2 445 is basically the same as outdoors; 3208 is considered extremely poor air quality, likely to cause headaches, nausea, and other minor ailments. The Berkeley study looked at levels between 600 and 2500, so my range was comparable to theirs.... <\/p>","plaintextDescription":"[cross-posted from my blog Astral Codex Ten]\n\nIn 2012, a Berkeley team found that indoor carbon dioxide had dramatic negative effects on cognition (paper, popular article). Subjects in poorly ventilated environments did up to 50% worse on a test of reasoning and decision-making. This is potentially pretty important, because lots of office buildings (and private houses) count as poorly-ventilated environments, so a lot of decision-making might be happening while severely impaired.\n\nSince then people have debated this on and off, with some studies confirming the effect and others failing to find it. I personally am skeptical, partly because the effect is so big I would expect someone to have noticed, but also because submarines, spaceships, etc have orders of magnitude more carbon dioxide than any civilian environment, but people still seem to do pretty hard work in them pretty effectively.\n\nAs part of my continuing effort to test this theory in my own life, I played a word game eight hundred times under varying ventilation conditions.\n\n…okay, fine, no, I admit it, I played a word game eight hundred times because I’m addicted to it. But since I was playing the word game eight hundred times anyway, I varied the ventilation conditions to see what would happen.\n\nThe game was WordTwist, which you can find here (warning: potentially addictive). You get a 5x5 square of letters and you have to find as many words as possible (of four letters or more) within three minutes. You can move up, down, right, left, or diagonal, and get more points for harder words. A typical board looks like this:\n\nDid you spot “lace”? What about “intrapsychically”?\nI played this game about 5-10x/day over three months. During this time, the carbon dioxide monitor in my room recorded levels between 445 ppm (with all windows open and the fan on) and 3208 ppm (with all windows closed and several people crammed into the room for several hours). I discounted a stray reading of 285 as an outlier, since thi","wordCount":1042,"version":"1.1.0"},"Revision:dNNwmxdmvtxMGMFgX_description":{"_id":"dNNwmxdmvtxMGMFgX_description","__typename":"Revision","htmlHighlight":"<p>Poor <strong>Air Quality<\/strong> can reduce cognitive functioning<sup class=\"footnote-ref\"><a href=\"#fn-wdiYZ7FEBvFx2tzGn-1\" id=\"fnref-wdiYZ7FEBvFx2tzGn-1\">[1]<\/a><\/sup>, lifespans<sup class=\"footnote-ref\"><a href=\"#fn-wdiYZ7FEBvFx2tzGn-2\" id=\"fnref-wdiYZ7FEBvFx2tzGn-2\">[2]<\/a><\/sup> and the techniques to improve air quality are also useful for getting rid of aerosolized respiratory pathogens. Improving air quality can be an impactful global health intervention.<sup class=\"footnote-ref\"><a href=\"#fn-wdiYZ7FEBvFx2tzGn-3\" id=\"fnref-wdiYZ7FEBvFx2tzGn-3\">[3]<\/a><\/sup> Many members of the LessWrong community have also put effort into improving the air quality of their own homes or offices, as an implication of instrumental rationality.<\/p><p>Newer Green buildings are infamous among those who care about this topic for being excellently sealed, meaning that they have less interchange with outside air. This is good for energy efficiency, but bad for indoor air quality.<\/p>\n<h2>The Carbon Dioxide Debate<\/h2>\n<p>Mostly when people talk about air quality, they're talking about particulates and Volatile Organic Compounds (VOCs). However, some studies have tried to look at <a href=\"https://www.lesswrong.com/posts/pPZ27eZdBXtGuLqZC/what-is-up-with-carbon-dioxide-and-cognition-an-offer\">carbon dioxide alone<\/a>, and have found large effects on cognition. It is this wiki author's belief that better studies have failed to find anything close to the size of the original effect, if anything.<sup class=\"footnote-ref\"><a href=\"#fn-wdiYZ7FEBvFx2tzGn-2\" id=\"fnref-wdiYZ7FEBvFx2tzGn-2:1\">[2:1]<\/a><\/sup><sup class=\"footnote-ref\"><a href=\"#fn-wdiYZ7FEBvFx2tzGn-4\" id=\"fnref-wdiYZ7FEBvFx2tzGn-4\">[4]<\/a><\/sup><\/p>\n<h2>External Links<\/h2>\n<ul>\n<li><a href=\"https://forum.effectivealtruism.org/tag/air-pollution\">Air Pollution<\/a> on the Effective Altruism Forum<\/li>\n<li><a href=\"https://patrickcollison.com/pollution\">Collection of studies<\/a> by Patrick Collison on air pollution and cognition<\/li>\n<\/ul>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-wdiYZ7FEBvFx2tzGn-1\" class=\"footnote-item\"><p><a href=\"https://www.iza.org/publications/dp/12632/indoor-air-quality-and-cognitive-performance\">Künn et. al<\/a> <a href=\"#fnref-wdiYZ7FEBvFx2tzGn-1\" class=\"footnote-backref\">↩︎<\/a><\/p>\n<\/li>\n<li id=\"fn-wdiYZ7FEBvFx2tzGn-2\" class=\"footnote-item\"><p><a href=\"https://www.nature.com/articles/s41598-021-01802-5\">Juginovic et. al<\/a> <a href=\"#fnref-wdiYZ7FEBvFx2tzGn-2\" class=\"footnote-backref\">↩︎<\/a> <a href=\"#fnref-wdiYZ7FEBvFx2tzGn-2:1\" class=\"footnote-backref\">↩︎<\/a><\/p>\n<\/li>\n<li id=\"fn-wdiYZ7FEBvFx2tzGn-3\" class=\"footnote-item\"><p><a href=\"https://80000hours.org/podcast/episodes/alexander-berger-improving-global-health-wellbeing-clear-direct-ways/#south-asian-air-quality-021112\">Alexander Berger on the 80,000 Hours Podcast<\/a> (link goes to transcript or audio) <a href=\"#fnref-wdiYZ7FEBvFx2tzGn-3\" class=\"footnote-backref\">↩︎<\/a><\/p>\n<\/li>\n<li id=\"fn-wdiYZ7FEBvFx2tzGn-4\" class=\"footnote-item\"><p><a href=\"https://www.lesswrong.com/posts/kxW6q5YdTGWh5sWby/eight-hundred-slightly-poisoned-word-games\">Eight Hundred Slight Poisoned Word Games<\/a> by Scott Alexander <a href=\"#fnref-wdiYZ7FEBvFx2tzGn-4\" class=\"footnote-backref\">↩︎<\/a><\/p>\n<\/li>\n<\/ol>\n<\/section>"},"Tag:dNNwmxdmvtxMGMFgX":{"_id":"dNNwmxdmvtxMGMFgX","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:dNNwmxdmvtxMGMFgX_description"},"canVoteOnRels":null,"userId":"ezbRa3dntKWQ5995r","name":"Air Quality","shortName":null,"slug":"air-quality","core":false,"postCount":23,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-05-17T09:57:18.577Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:fkABsGCJZ6y9qConW_description":{"_id":"fkABsGCJZ6y9qConW_description","__typename":"Revision","htmlHighlight":"<p><strong>Practical<\/strong> posts give direct, actionable advice on how to achieve goals and generally succeed. The art of rationality would be useless if it did not connect to the real world; we must take our ideas and abstractions and collide them with reality. Many places on the internet will give you advice; here, we value survey data, literature reviews, self-blinded trials, quantitative estimates, and theoretical models that aim to explain the phenomena.<\/p><p>Material that is directly about <i>how to think better<\/i> can be found at <a href=\"https://www.lessestwrong.com/tag/rationality\">Rationality<\/a>.<\/p><p>&nbsp;<\/p><h1><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Practical Sub-Topics<\/strong><\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:2px solid hsl(0, 0%, 90%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33%\" rowspan=\"2\"><p><strong>Domains of Well-being<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/careers?showPostCount=true&amp;useTagName=true\">Careers<\/a><br><a href=\"https://www.lesswrong.com/tag/emotions?showPostCount=true&amp;useTagName=true\">Emotions<\/a><br><a href=\"http://www.lesswrong.com/tag/exercise-physical?showPostCount=true&amp;useTagName=true\">Exercise (Physical)<\/a><br><a href=\"https://www.lesswrong.com/tag/financial-investing?showPostCount=true&amp;useTagName=true\">Financial Investing<\/a><br><a href=\"http://www.lesswrong.com/tag/gratitude?showPostCount=true&amp;useTagName=true\">Gratitude<\/a><br><a href=\"http://www.lesswrong.com/tag/happiness-1?showPostCount=true&amp;useTagName=true\">Happiness<\/a><br><a href=\"http://www.lesswrong.com/tag/human-bodies?showPostCount=true&amp;useTagName=true\">Human Bodies<\/a><br><a href=\"http://www.lesswrong.com/tag/nutrition?showPostCount=true&amp;useTagName=true\">Nutrition<\/a><br><a href=\"https://www.lesswrong.com/tag/parenting?showPostCount=true&amp;useTagName=true\">Parenting<\/a><br><a href=\"https://www.lesswrong.com/tag/slack?showPostCount=true&amp;useTagName=true\">Slack<\/a><br><a href=\"https://www.lesswrong.com/tag/sleep?showPostCount=true&amp;useTagName=true\">Sleep<\/a><br><a href=\"https://www.lesswrong.com/tag/well-being?showPostCount=true&amp;useTagName=true\">Well-being<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\" rowspan=\"2\"><p><strong>Skills, Tools, Techniques<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/cryonics?showPostCount=true&amp;useTagName=true\">Cryonics<\/a><br><a href=\"https://www.lesswrong.com/tag/emotions?showPostCount=true&amp;useTagName=true\">Emotions<\/a><br><a href=\"https://www.lesswrong.com/tag/goal-factoring?showPostCount=true&amp;useTagName=true\">Goal Factoring<\/a><br><a href=\"http://www.lesswrong.com/tag/habits?showPostCount=true&amp;useTagName=true\">Habits<\/a><br><a href=\"https://www.lesswrong.com/tag/hamming-questions?showPostCount=true&amp;useTagName=true\">Hamming Questions<\/a><br><a href=\"http://www.lesswrong.com/tag/life-improvements?showPostCount=true&amp;useTagName=true\">Life Improvements<\/a><br><a href=\"https://www.lesswrong.com/tag/meditation?showPostCount=true&amp;useTagName=true\">Meditation<\/a><br><a href=\"http://www.lesswrong.com/tag/more-dakka?showPostCount=true&amp;useTagName=true\">More Dakka<\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true\"><u>Pica<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/planning-and-decision-making?showPostCount=true&amp;useTagName=true\">Planning &amp; Decision-Making<\/a><br><a href=\"https://www.lesswrong.com/tag/self-experimentation?showPostCount=true&amp;useTagName=true\">Self Experimentation<\/a><br><a href=\"http://www.lesswrong.com/tag/skill-building?showPostCount=true&amp;useTagName=true\">Skill Building<\/a><br><a href=\"https://www.lesswrong.com/tag/software-tools?showPostCount=true&amp;useTagName=true\">Software Tools<\/a><br><a href=\"https://www.lesswrong.com/tag/spaced-repetition?showPostCount=true&amp;useTagName=true\">Spaced Repetition<\/a><br><a href=\"https://www.lesswrong.com/tag/virtues-instrumental?showPostCount=true&amp;useTagName=false\">Virtues (Instrumental)<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33%\"><p><strong>Productivity<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/akrasia?showPostCount=true&amp;useTagName=true\">Akrasia<\/a><br><a href=\"https://www.lesswrong.com/tag/motivations?showPostCount=true&amp;useTagName=true\">Motivations<\/a><br><a href=\"https://www.lesswrong.com/tag/prioritization?showPostCount=true&amp;useTagName=true\">Prioritization<\/a><br><a href=\"https://www.lesswrong.com/tag/procrastination?showPostCount=true&amp;useTagName=true\">Procrastination<\/a><br><a href=\"https://www.lesswrong.com/tag/productivity?showPostCount=true&amp;useTagName=true\">Productivity<\/a><br><a href=\"https://www.lesswrong.com/tag/willpower?showPostCount=true&amp;useTagName=true\">Willpower<\/a><\/p><\/td><\/tr><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><strong>Interpersonal<\/strong><br><a href=\"http://www.lesswrong.com/tag/circling?showPostCount=true&amp;useTagName=true\"><u>Circling<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true&amp;useTagName=true\">Conversation (topic)<\/a><br><a href=\"https://www.lesswrong.com/tag/communication-cultures?showPostCount=true&amp;useTagName=true\">Communication Cultures<\/a><br><a href=\"http://www.lesswrong.com/tag/relationships-interpersonal?showPostCount=true&amp;useTagName=false\"><u>Relationship<\/u><\/a><\/td><\/tr><\/tbody><\/table><\/figure>"},"Tag:fkABsGCJZ6y9qConW":{"_id":"fkABsGCJZ6y9qConW","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:fkABsGCJZ6y9qConW_description"},"canVoteOnRels":null,"userId":"oBSWiHjgproTiThmY","name":"Practical","shortName":null,"slug":"practical","core":true,"postCount":2979,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T06:06:46.947Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:xexCWMyds6QLWognu_description":{"_id":"xexCWMyds6QLWognu_description","__typename":"Revision","htmlHighlight":"<p><strong>World Optimization<\/strong> is the full use of our agency. It is extending the reach of human civilization. It is building cities and democracies and economic systems and computers and flight and science and space rockets and the internet. World optimization is about adding to that list.&nbsp;<br><br>But it’s not just about growth, it’s also about preservation. We are still in the dawn of civilization, with most of civilization in the billions of years ahead. We mustn’t let this light go out.<\/p><hr><h1>World Optimization Sub-Topics<\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33%\"><p><strong>Moral Theory<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/altruism?showPostCount=true&amp;useTagName=true\">Altruism<\/a><br><a href=\"https://www.lesswrong.com/tag/consequentialism?showPostCount=true&amp;useTagName=true\">Consequentialism<\/a><br><a href=\"https://www.lesswrong.com/tag/deontology?showPostCount=true&amp;useTagName=true\">Deontology<\/a><br><a href=\"http://www.lesswrong.com/tag/ethics-and-morality?showPostCount=true&amp;useTagName=true\"><u>Ethics &amp; Morality<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/metaethics?showPostCount=true&amp;useTagName=true\">Metaethics<\/a><br><a href=\"http://www.lesswrong.com/tag/moral-uncertainty?showPostCount=true&amp;useTagName=true\"><u>Moral Uncertainty<\/u><\/a><\/p><p>&nbsp;<\/p><p>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\"><p><strong>Causes / Interventions<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aging?showPostCount=true&amp;useTagName=true\">Aging<\/a><br><a href=\"https://www.lesswrong.com/tag/animal-welfare?showPostCount=true&amp;useTagName=true\">Animal Welfare<\/a><br><a href=\"https://www.lesswrong.com/tag/existential-risk?showPostCount=true&amp;useTagName=true\">Existential Risk<\/a><br><a href=\"http://www.lesswrong.com/tag/futurism?showPostCount=true&amp;useTagName=true\">Futurism<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-uploading?showPostCount=true&amp;useTagName=true\">Mind Uploading<\/a><br><a href=\"https://www.lesswrong.com/tag/life-extension?showPostCount=true&amp;useTagName=true\">Life Extension<\/a><br><a href=\"http://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks?showPostCount=true&amp;useTagName=false\"><u>S-risks<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/transhumanism?showPostCount=true&amp;useTagName=true\"><u>Transhumanism<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/voting-theory?showPostCount=true&amp;useTagName=true\">Voting Theory<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\"><p><strong>Working with Humans<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/coalitional-instincts?showPostCount=true&amp;useTagName=true\"><u>Coalitional Instincts<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/coordination-cooperation?showPostCount=true&amp;useTagName=true\">Coordination / Cooperation<\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/institution-design?showPostCount=true&amp;useTagName=true\">Institution Design<\/a><br><a href=\"https://www.lesswrong.com/tag/moloch?showPostCount=true&amp;useTagName=true\">Moloch<\/a><br><a href=\"https://www.lesswrong.com/tag/signaling?showPostCount=true&amp;useTagName=true\">Signaling<\/a><br><a href=\"https://www.lesswrong.com/tag/simulacrum-levels?showPostCount=true&amp;useTagName=true\">Simulacrum Levels<\/a><br><a href=\"https://www.lesswrong.com/tag/social-status?showPostCount=true&amp;useTagName=true\">Social Status<\/a><\/p><\/td><\/tr><tr><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0em;vertical-align:top\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/blackmail?showPostCount=true&amp;useTagName=true\">Blackmail<\/a><br><a href=\"http://www.lesswrong.com/tag/censorship?showPostCount=true&amp;useTagName=true\">Censorship<\/a><br><a href=\"http://www.lesswrong.com/tag/chesterton-s-fence?showPostCount=true&amp;useTagName=true\">Chesterton's Fence<\/a><br><a href=\"http://www.lesswrong.com/tag/death?showPostCount=true&amp;useTagName=true\">Death<\/a><br><a href=\"https://www.lesswrong.com/tag/deception?showPostCount=true&amp;useTagName=true\">Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/honesty?showPostCount=true&amp;useTagName=true\">Honesty<\/a><br><a href=\"https://www.lesswrong.com/tag/hypocrisy?showPostCount=true&amp;useTagName=true\">Hypocrisy<\/a><br><a href=\"https://www.lesswrong.com/tag/information-hazards?showPostCount=true&amp;useTagName=true\">Information Hazards<\/a><br><a href=\"https://www.lesswrong.com/tag/meta-honesty?showPostCount=true&amp;useTagName=true\">Meta-Honesty<\/a><br><a href=\"http://www.lesswrong.com/tag/pascal-s-mugging?showPostCount=true&amp;useTagName=true\">Pascal's Mugging<\/a><br><a href=\"http://www.lesswrong.com/tag/war?showPostCount=true&amp;useTagName=true\">War<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:25px;padding:0px;vertical-align:top\"><p><strong>Value &amp; Virtue<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/ambition?showPostCount=true&amp;useTagName=true\">Ambition<\/a><br><a href=\"https://www.lesswrong.com/tag/art?showPostCount=true&amp;useTagName=true\">Art<\/a><br><a href=\"https://www.lesswrong.com/tag/aesthetics?showPostCount=true&amp;useTagName=true\">Aesthetics<\/a><br><a href=\"https://www.lesswrong.com/tag/complexity-of-value?showPostCount=true&amp;useTagName=true\">Complexity of Value<\/a><br><a href=\"http://www.lesswrong.com/tag/courage?showPostCount=true&amp;useTagName=true\">Courage<\/a><br><a href=\"http://www.lesswrong.com/tag/fun-theory?showPostCount=true&amp;useTagName=true\">Fun Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/principles?showPostCount=true&amp;useTagName=true\">Principles<\/a><br><a href=\"http://www.lesswrong.com/tag/suffering?showPostCount=true&amp;useTagName=true\"><u>Suffering<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/superstimuli?showPostCount=true&amp;useTagName=true\">Superstimuli<\/a><br><a href=\"https://www.lesswrong.com/tag/wireheading?showPostCount=true&amp;useTagName=true\">Wireheading<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0em;vertical-align:top\"><p><strong>Meta<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/cause-prioritization?showPostCount=true&amp;useTagName=true\">Cause Prioritization<\/a><br><a href=\"http://www.lesswrong.com/tag/center-on-long-term-risk-clr?useTagName=true&amp;showPostCount=true\">Center for Long-term Risk<\/a><br><a href=\"https://www.lesswrong.com/tag/effective-altruism?showPostCount=true&amp;useTagName=true\">Effective Altruism<\/a><br><a href=\"https://www.lesswrong.com/tag/heroic-responsibility?showPostCount=true&amp;useTagName=true\">Heroic Responsibility<\/a><br>&nbsp;<\/p><\/td><\/tr><\/tbody><\/table><\/figure><hr><p>Content which describes <i>how the world is <\/i>that directly bears upon choices one makes to optimize the world fall under this tag. Examples include discussion of the moral patienthood of different animals, the potential of human civilization, and the most effective interventions against a global health threat.<\/p><p>Some material has both immediate relevance to world optimization decisions but also can inform broader world models. This material might be included under both <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a> tag and this tag.<\/p>"},"Tag:xexCWMyds6QLWognu":{"_id":"xexCWMyds6QLWognu","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:xexCWMyds6QLWognu_description"},"canVoteOnRels":null,"userId":"XtphY3uYHwruKqDyG","name":"World Optimization","shortName":null,"slug":"world-optimization","core":true,"postCount":2711,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":20,"createdAt":"2020-06-14T03:38:23.532Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:kxW6q5YdTGWh5sWby":{"_id":"kxW6q5YdTGWh5sWby","__typename":"SocialPreviewType","imageUrl":"https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1902078a-2b4f-4f8d-8b6c-7a8122700660_298x299.png"},"Post:kxW6q5YdTGWh5sWby":{"_id":"kxW6q5YdTGWh5sWby","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:Rrkr9zk8SoGMq7SsC"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":4,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:dNNwmxdmvtxMGMFgX"},{"__ref":"Tag:fkABsGCJZ6y9qConW"},{"__ref":"Tag:xexCWMyds6QLWognu"}],"socialPreviewData":{"__ref":"SocialPreviewType:kxW6q5YdTGWh5sWby"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2021-08-09T20:17:17.814Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2021-08-09T20:37:39.890Z","meta":false,"postCategory":"post","tagRelevance":{"dNNwmxdmvtxMGMFgX":2,"fkABsGCJZ6y9qConW":3,"xexCWMyds6QLWognu":3},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"Rrkr9zk8SoGMq7SsC","commentCount":5,"voteCount":59,"baseScore":110,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":59,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0009311126777902246,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-08-21T13:17:00.467Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":21,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":24,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2021-08-09T20:17:17.817Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"eight-hundred-slightly-poisoned-word-games","title":"Eight Hundred Slightly Poisoned Word Games","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false},"Revision:Aaf86eL7B2qAos4FM":{"_id":"Aaf86eL7B2qAos4FM","__typename":"Revision","htmlHighlight":"<p>(crossposted from <a href=\"https://astralcodexten.substack.com/p/towards-a-bayesian-theory-of-willpower\">Astral Codex Ten<\/a>)<\/p><p><strong>I.<\/strong><\/p><p>What is willpower?<\/p><p>Five years ago, I reviewed <a href=\"https://slatestarcodex.com/2015/03/12/book-review-willpower/\">Baumeister and Tierney's book<\/a> on the subject. They tentatively concluded it's a way of rationing brain glucose. But their key results have <a href=\"https://www.discovermagazine.com/mind/the-end-of-ego-depletion-theory\">failed to replicate<\/a>, and people who know more about glucose physiology say it <a href=\"http://www.robkurzban.com/blog/2014/1/16/no-sugar-coating-problems-for-the-glucose-model\">makes no theoretical sense<\/a>.<\/p><p>Robert Kurzban, one of the most on-point critics of the glucose theory, gives his own model of willpower: it's a way of <a href=\"https://repository.upenn.edu/cgi/viewcontent.cgi?referer=https://duckduckgo.com/&amp;httpsredir=1&amp;article=1020&amp;context=psychology_papers\">minimizing opportunity costs<\/a>. But how come my brain is convinced that playing Civilization for ten hours has no opportunity cost, but spending five seconds putting away dishes has such immense opportunity costs that it will probably leave me permanently destitute? I can't find any correlation between the subjective phenomenon of willpower or effort-needingness and real opportunity costs at all.<\/p><p>A tradition originating in psychotherapy, and ably represented eg <a href=\"https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/M4w2rdYgCKctbADMn\">here by Kaj Sotala<\/a>, interprets willpower as conflict between mental agents. One \"subagent\" might want to sit down and study for a test. But maybe one subagent represents the pressure your parents are putting on you to do well in school so you can become a doctor and have a stable career, and another subagent represents your own desire to drop out and become a musician, and even though the \"do well in school\" subagent is on top now, the \"become a musician\" subagent is strong enough to sabotage you by making you feel mysteriously unable to study. This usually ends with something about how enough therapy can help you reconcile these subagents and have lots of willpower again. But this works a lot better in <a href=\"https://slatestarcodex.com/2019/11/20/book-review-all-therapy-books/\">therapy books<\/a> than it does in real life. Also, what childhood trauma made my subagents so averse to doing dishes?<\/p><p>I've come to disagree with all of these perspectives. I think willpower is best thought of as a Bayesian process, ie an attempt to add up different kinds of evidence.<\/p><p><strong>II.<\/strong><\/p><p>My model has several different competing mental processes trying to determine your actions. One is a prior on motionlessness; if you have no reason at all to do anything, stay where you are. A second is a pure reinforcement learner - \"do whatever has brought you the most reward in the past\". And the third is your high-level conscious calculations about what the right thing to do is.<\/p><p>These all submit \"evidence\" to your basal ganglia, the brain structure that chooses actions. Using the same evi... <\/p>","plaintextDescription":"(crossposted from Astral Codex Ten)\n\nI.\n\nWhat is willpower?\n\nFive years ago, I reviewed Baumeister and Tierney's book on the subject. They tentatively concluded it's a way of rationing brain glucose. But their key results have failed to replicate, and people who know more about glucose physiology say it makes no theoretical sense.\n\nRobert Kurzban, one of the most on-point critics of the glucose theory, gives his own model of willpower: it's a way of minimizing opportunity costs. But how come my brain is convinced that playing Civilization for ten hours has no opportunity cost, but spending five seconds putting away dishes has such immense opportunity costs that it will probably leave me permanently destitute? I can't find any correlation between the subjective phenomenon of willpower or effort-needingness and real opportunity costs at all.\n\nA tradition originating in psychotherapy, and ably represented eg here by Kaj Sotala, interprets willpower as conflict between mental agents. One \"subagent\" might want to sit down and study for a test. But maybe one subagent represents the pressure your parents are putting on you to do well in school so you can become a doctor and have a stable career, and another subagent represents your own desire to drop out and become a musician, and even though the \"do well in school\" subagent is on top now, the \"become a musician\" subagent is strong enough to sabotage you by making you feel mysteriously unable to study. This usually ends with something about how enough therapy can help you reconcile these subagents and have lots of willpower again. But this works a lot better in therapy books than it does in real life. Also, what childhood trauma made my subagents so averse to doing dishes?\n\nI've come to disagree with all of these perspectives. I think willpower is best thought of as a Bayesian process, ie an attempt to add up different kinds of evidence.\n\nII.\n\nMy model has several different competing mental processes trying to determine yo","wordCount":1798,"version":"1.0.0"},"Revision:YrLoz567b553YouZ2_description":{"_id":"YrLoz567b553YouZ2_description","__typename":"Revision","htmlHighlight":"<p><strong>Willpower<\/strong> is the ability to overcome urges to do or not some activity– to overcome temptation. Typically there is a sense of coercing oneself to do things despite inner resistance.<\/p>\n<p>Willpower is of interest those who wish to increase their productivity or otherwise do more thing that they wish to be done. The question then is \"how does one increase willpower?\"<\/p>\n<p>There is an argument that the use of willpower is undesirable. The use of willpower my constitute a form of <em>inner violence<\/em> which is in tension with <em>inner<\/em> <em>alignment<\/em> of <a href=\"https://www.lessestwrong.com/tag/subagents\">one's parts<\/a>– a better path to productivity and wellbeing.<\/p>\n<p><strong>Related:<\/strong> <a href=\"https://www.lessestwrong.com/tag/akrasia\">Akrasia<\/a><\/p>\n<h2>Resources<\/h2>\n<ul>\n<li>The writings on <a href=\"http://mindingourway.com/\">Minding Our Way<\/a> concerning productivity.<\/li>\n<\/ul>"},"Tag:YrLoz567b553YouZ2":{"_id":"YrLoz567b553YouZ2","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YrLoz567b553YouZ2_description"},"canVoteOnRels":null,"userId":"XchweonPm2TC7EJES","name":"Willpower","shortName":null,"slug":"willpower","core":false,"postCount":35,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-01T08:21:48.698Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"Revision:YAotJ9Le3S2rCJgf8_description":{"_id":"YAotJ9Le3S2rCJgf8_description","__typename":"Revision","htmlHighlight":"<p>(From <a href=\"https://en.wikipedia.org/wiki/Predictive_coding\">Wikipedia<\/a>) <strong>predictive processing<\/strong> (a.k.a. predictive coding, the Bayesian Brain hypothesis) is a theory of brain function in which the brain is constantly generating and updating a mental model of the environment. The model is used to generate predictions of sensory input that are compared to actual sensory input. This comparison results in prediction errors that are then used to update and revise the mental model.<\/p><p><a href=\"https://www.lesswrong.com/tag/free-energy-principle\">Active Inference<\/a> can be seen as a generalisation of predictive processing. While predictive processing only explains the agent's perception, Active Inference models both perception and action as inference under the same unifying objective: optimisation of the informational quantity called variational free energy.<\/p><p><strong>External Links:<\/strong><br><a href=\"https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/\">Book Review: Surfing Uncertainty<\/a> - Introduction to predictive processing by Scott Alexander<br><a href=\"https://slatestarcodex.com/2017/09/06/predictive-processing-and-perceptual-control/\">Predictive Processing And Perceptual Control<\/a> by Scott Alexander<\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/perceptual-control-theory\">Perceptual Control Theory<\/a>, <a href=\"https://www.lesswrong.com/tag/neuroscience\">Neuroscience<\/a><\/p>"},"Tag:YAotJ9Le3S2rCJgf8":{"_id":"YAotJ9Le3S2rCJgf8","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YAotJ9Le3S2rCJgf8_description"},"canVoteOnRels":null,"userId":"qxJ28GN72aiJu96iF","name":"Predictive Processing","shortName":null,"slug":"predictive-processing","core":false,"postCount":47,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-09T09:52:22.567Z","wikiOnly":false,"deleted":false,"isSubforum":false,"noindex":false},"SocialPreviewType:wZGpoZgDANdkwTrwt":{"_id":"wZGpoZgDANdkwTrwt","__typename":"SocialPreviewType","imageUrl":"https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6fd86d3-dddd-43d0-a840-eeb8f2fcf514_600x376.png"},"Post:wZGpoZgDANdkwTrwt":{"_id":"wZGpoZgDANdkwTrwt","__typename":"Post","currentUserVote":null,"currentUserExtendedVote":null,"podcastEpisode":null,"deletedDraft":false,"contents":{"__ref":"Revision:Aaf86eL7B2qAos4FM"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":7,"rejectedReason":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:YrLoz567b553YouZ2"},{"__ref":"Tag:YAotJ9Le3S2rCJgf8"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"socialPreviewData":{"__ref":"SocialPreviewType:wZGpoZgDANdkwTrwt"},"feedId":null,"totalDialogueResponseCount":0,"unreadDebateResponseCount":0,"dialogTooltipPreview":null,"disableSidenotes":false,"url":null,"postedAt":"2021-03-26T02:33:55.056Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2021-03-26T02:42:37.435Z","meta":false,"postCategory":"post","tagRelevance":{"Ng8Gice9KNkncxqcj":2,"YAotJ9Le3S2rCJgf8":2,"YrLoz567b553YouZ2":9},"shareWithUsers":[],"sharingSettings":null,"linkSharingKey":null,"contents_latest":"Aaf86eL7B2qAos4FM","commentCount":28,"voteCount":47,"baseScore":103,"extendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":46,"agreementVoteCount":0},"emojiReactors":{},"unlisted":false,"score":0.0007711168145760894,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2024-06-05T04:39:54.658Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"debate":false,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"EQNTWXLKMeWMp2FQS","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":21,"afExtendedScore":{"reacts":{},"agreement":0,"approvalVoteCount":19,"agreementVoteCount":0},"afCommentCount":0,"afLastCommentedAt":"2021-03-26T02:33:55.056Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"ignoreRateLimits":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"onlyVisibleToEstablishedAccounts":false,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"manifoldReviewMarketId":null,"annualReviewMarketProbability":null,"annualReviewMarketIsResolved":null,"annualReviewMarketYear":null,"annualReviewMarketUrl":null,"group":null,"podcastEpisodeId":null,"forceAllowType3Audio":false,"nominationCount2019":0,"reviewCount2019":0,"votingSystem":"namesAttachedReactions","disableRecommendation":false,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"toward-a-bayesian-theory-of-willpower","title":"Toward A Bayesian Theory Of Willpower","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"rejected":false,"collabEditorDialogue":false}}</script>
<script>window.__APOLLO_FOREIGN_STATE__ = {}</script>

<script src="scott_files/api.js"></script><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom"></iframe><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M18.601 8.39897C18.269 8.06702 17.7309 8.06702 17.3989 8.39897L12 13.7979L6.60099 8.39897C6.26904 8.06702 5.73086 8.06702 5.39891 8.39897C5.06696 8.73091 5.06696 9.2691 5.39891 9.60105L11.3989 15.601C11.7309 15.933 12.269 15.933 12.601 15.601L18.601 9.60105C18.9329 9.2691 18.9329 8.73091 18.601 8.39897Z" fill="white"></path>
</svg>
</div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    0% {
      opacity: 0;
      transform: scale(0);
    }
    40% {
      opacity: 1;
    }
    100% {
      transform: scale(1);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #f5f5f5;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }


  .intercom-lightweight-app-launcher:hover {
    transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    transform: scale(1.1)
  }

  .intercom-lightweight-app-launcher:active {
    transform: scale(0.85);
    transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
  }


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(0, 0, 0);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1, 1, 1);
    transform-origin: bottom right;

    
        width: 400px;
        height: calc(100% - 104px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 84px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 16px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    border-bottom: none;
    background: #f5f5f5

    
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    height: 80px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
    
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" width="256" height="60" role="presentation" name="a-r4x4oyc7i514" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox allow-storage-access-by-user-activation" src="scott_files/anchor.html"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;"></iframe></div></body></html>